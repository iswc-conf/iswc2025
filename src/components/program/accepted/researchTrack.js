const researchTrack = [
    {
        title: "Formalizing Repairs for Wikidata Constraint Violations: A Taxonomy and Empirical Analysis",
        authors: "Nicolas Ferranti, Axel Polleres, Dayane Guimaraes and Jairo Souza",
        abstract: "Collaboratively maintained knowledge graphs like Wikidata rely on property constraints to detect data inconsistencies. This paper systematically formalizes potential repairs for Wikidata constraint violations, presenting a comprehensive taxonomy of repair strategies encompassing both instance-level (A-box) and terminological-level (T-box) changes. T-box repairs, which alter constraint definitions or Wikidata's class hierarchy, can simultaneously address multiple violations and, to the best of our knowledge, have not been investigated in detail before. We observe repairs over time and evaluate how specific patterns within our taxonomy are applied in practice. Our analysis of historical data reveals insights into the prevalence of repair patterns in Wikidata's collaborative environment. The results indicate that T-box repairs are particularly relevant for certain constraint types and the overall consolidation of Wikidata, where modifying constraint definitions can reduce the number of recurring violations."
    },
    {
        title: "Beyond Manual Labels: Unsupervised Graph-Based Explanations for Error Analysis in Image Classifiers",
        authors: "Youmna Ismaeil, Jan Hendrik Metzen, Trung-Kien Tran, Hendrik Blockeel and Daria Stepanova",
        abstract: "Training datasets often contain subtle but irrelevant patterns that bias image classifiers and limit their generalization. Prior research has focused on detecting biases in misclassified data using manually defined dimensions, such as age or gender. However, these approaches often rely on manually predefined dimensions and overlook biases present in correctly classified data, making them labor-intensive and limiting their coverage. We propose an unsupervised framework that leverages commonsense knowledge and open-source foundation models to automatically derive semantic dimensions and their values, identifying biases that influence correct and incorrect classifications of data. Using these dimensions and values, we construct scene graphs and identify distinctive graph patterns for correctly and incorrectly classified data, uncovering how combinations of semantic dimensions impact classifier decisions. Evaluations confirm that our scene graphs are of high quality, as they include information from manual annotations while being denser and more informative than manually constructed graphs. Moreover, our framework demonstrates high predictive accuracy, effectively identifying patterns responsible for correct and incorrect classifications, with F1 scores ranging from 0.72 to 0.96. It also proves effective for error analysis and proactive bias detection in datasets."
    },
    {
        title: "GLIDE: Knowledge Graph Linking using Distance-Aware Embeddings",
        authors: "Alexander Becker, Axel-Cyrille Ngonga Ngomo and Mohamed Ahmed Sherif",
        abstract: "The number of datasets on the web of data increases continuously. However, the knowledge contained therein cannot be fully utilized without finding links between the entities contained in these datasets. Equivalent entities cannot be identified solely by checking the equivalence of IRIs because of the different origins and naming schemes of different data providers. Yet, such equivalences can be discovered by computing the similarity of their attributes. In this paper we propose GLIDE, an approach that links entities from two different datasets by embedding a joint model of these datasets enriched by additional relations describing the similarity of literals. The joint model is embedded into a latent vector space while paying attention to juxtaposing similar literals. We evaluate our approach against state-of-the-art algorithms using real-world datasets commonly used in link discovery literature. The results show that GLIDE outperforms all baselines on 5 of 7 datasets with perfect or near-perfect accuracy. Our approach achieves its best performance on datasets that feature several literals with similarities. Our experiments indicate that researchers should not only pay attention to equal literals in knowledge graph embedding but should also be aware of the distance between similar literals."
    },
    {
        title: "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting",
        authors: "David Maria Schmidt, Raoul Schubert and Philipp Cimiano",
        abstract: "Language interpretation is a compositional process, in which the meaning of more complex linguistic structures is inferred from the meaning of their parts. Large language models possess remarkable language interpretation capabilities and have been successfully applied to interpret questions by mapping them to SPARQL queries. An open question is how systematic this interpretation process is. Toward this question, in this paper, we propose a benchmark for investigating to what extent the abilities of LLMs to interpret questions are actually compositional. For this, we generate three datasets of varying difficulty based on graph patterns in DBpedia, relying on Lemon lexica for verbalization. Our datasets are created in a very controlled fashion in order to test the ability of LLMs to interpret structurally complex questions, given that they have seen the atomic building blocks. This allows us to evaluate to what degree LLMs are able to interpret complex questions for which they \"understand\" the atomic parts. We conduct experiments with models of different sizes using both various prompt and few-shot optimization techniques as well as fine-tuning. Our results show that performance in terms of macro F1 degrades from 0.45 over 0.26 down to 0.09 with increasing deviation from the samples optimized on. Even when all necessary information was provided to the model in the input, the F1 scores do not exceed 0.57 for the dataset of lowest complexity. We thus conclude that LLMs struggle to systematically and compositionally interpret questions and map them into SPARQL queries."
    },
    {
        title: "Language Models as Ontology Encoders",
        authors: "Hui Yang, Jiaoyan Chen, Yuan He, Yongsheng Gao and Ian Horrocks",
        abstract: "OWL (Web Ontology Language) ontologies which are able to formally represent complex knowledge and support semantic reasoning have been widely adopted across various domains such as healthcare and bioinformatics. Recently, ontology embeddings have gained wide attention due to its potential to infer plausible new knowledge and approximate complex reasoning. However, existing methods face notable limitations: geometric model-based embeddings typically overlook valuable textual information, resulting in suboptimal performance, while the approaches that incorporate text, which are often based on language models, fail to preserve the logical structure. In this work, we propose a new ontology embedding method OnT, which tunes a Pretrained Language Model (PLM) via geometric modeling in a hyperbolic space for effectively incorporating textual labels and simultaneously preserving class hierarchies and other logical relationships of Description Logic EL. Extensive experiments on four real-world ontologies show that OnT consistently outperforms the baselines including the state-of-the-art across both tasks of prediction and inference of axioms. OnT also demonstrates strong potential in real-world applications, indicated by its robust transfer learning abilities and effectiveness in real cases of constructing a new ontology from SNOMED CT."
    },
    {
        title: "Ontology-enhanced Knowledge Graph Completion using Large Language Models",
        authors: "Wenbin Guo, Xin Wang, Jiaoyan Chen, Zhao Li and Zirui Chen",
        abstract: "Large Language Models (LLMs) have been extensively adopted in Knowledge Graph Completion (KGC), showcasing significant research advancements. However, as black-box models driven by deep neural architectures, current LLM-based KGC methods rely on implicit knowledge representation with parallel propagation of erroneous knowledge, thereby hindering their ability to produce conclusive and decisive reasoning outcomes. We aim to integrate neural-perceptual structural information with ontological knowledge, leveraging the powerful capabilities of LLMs to achieve a deeper understanding of the intrinsic logic of the knowledge. We propose an ontology enhanced KGC method using LLMs --- OL-KGC. It first leverages neural perceptual mechanisms to effectively embed structural information into the textual space, and then uses an automated extraction algorithm to retrieve ontological knowledge from the knowledge graphs (KGs) that needs to be completed, which is further transformed into a textual format comprehensible to LLMs for providing logic guidance. Finally, KnoenKGC integrates the structural information of the KG with ontological knowledge using LLMs for triple classification. We conducted extensive experiments on three widely-used benchmarks --- FB15K-237, UMLS and WN18RR. The experimental results demonstrate that KnoenKGC significantly outperforms existing mainstream KGC methods across multiple evaluation metrics, achieving state-of-the-art performance. The implementation of the algorithm and related data have been open-sourced."
    },
    {
        title: "HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare",
        authors: "Yuzhang Xie, Xu Han, Ran Xu, Xiao Hu, Jiaying Lu and Carl Yang",
        abstract: "Knowledge graphs (KGs) are important products of the semantic web, which are widely used in various application domains. Healthcare is one of such domains where KGs are intensively used, due to the high requirement for knowledge accuracy and interconnected nature of healthcare data. However, KGs storing general factual information often lack the ability to account for important contexts of the knowledge such as the status of specific patients, which are crucial in precision healthcare. Meanwhile, electronic health records (EHRs) provide rich personal data, including various diagnoses and medications, which provide natural contexts for general KGs. In this paper, we propose HypKG, a framework that integrates patient information from EHRs into KGs to generate contextualized knowledge representations for accurate healthcare predictions. Using advanced entity-linking techniques, we connect relevant knowledge from general KGs with patient information from EHRs, and then utilize a hypergraph model to “contextualize” the knowledge with the patient information. Finally, we employ hypergraph transformers guided by downstream prediction tasks to jointly learn proper contextualized representations for both KGs and patients, fully leveraging existing knowledge in KGs and patient contexts in EHRs. In experiments using a large biomedical KG and two real-world EHR datasets, HypKG demonstrates significant improvements in healthcare prediction tasks across multiple evaluation metrics. Additionally, by integrating external contexts, HypKG can learn to adjust the representations of entities and relations in KG, potentially improving the quality and real-world utility of knowledge."
    },
    {
        title: "AdaGCRAG: Adaptive Graph-Chunk Retrieval for Lightweight RAG",
        authors: "Yanqiu Zhang, Zhen Xu and Dongdong Huo",
        abstract: "Retrieval-Augmented Generation (RAG) mitigates hallucinations of large language models (LLMs) and improves factual accuracy by incorporating external knowledge during inference. However, existing RAG approaches face critical limitations in resource-constrained environments: (1) dense retrieval often introduces irrelevant or redundant content due to semantic overlap in vector space, (2) graph-based methods still depend on sophisticated reasoning capabilities that exceed the capacity of Small Language Models (SLMs). To address these challenges, we propose Adaptive Graph-Chunk RAG (AdaGCRAG), a lightweight, local, and query-adaptive RAG framework that integrates chunk-level retrieval with graph-structured reasoning. AdaGCRAG categorizes each input into Simple Specific Question (Simple SQ), Complex Specific Question (Complex SQ), or Abstract Question (Abstract Q) and adaptively controls the retrieval granularity and reasoning depth. It leverages Qwen3’s dual-mode reasoning to minimize computation for simple tasks while enabling graph-based multi-hop inference for complex ones. A triple-level reranking module filters noisy subgraphs before fusion with dense retrieval results. AdaGCRAG runs efficiently on a single RTX 3070 GPU, making it suitable for personal agents and offline assistants. Experiments across five Question Answering (QA) benchmarks show consistent improvements over state-of-the-art lightweight RAG systems, achieving improvements of 9.5%, 6.9%, and 6.8% on HotpotQA, MultihopRAG, and MuSiQue, respectively, demonstrating its effectiveness under limited-resource settings. Our implementation is available at: https://anonymous.4open.science/r/AdaGCRAG."
    },
    {
        title: "FastER: On-Demand Entity Resolution in Property Graphs",
        authors: "Shujing Wang, Sibo Zhao, Shiqi Miao, Selasi Kwashie, Michael Bewong, Junwei Hu, Vincent M. Nofong and Zaiwen Feng",
        abstract: "Entity resolution (ER) is the problem of identifying and linking database records that refer to the same real-world entity. Traditional ER methods use batch processing, which becomes impractical with growing data volumes due to high computational costs and a lack of real-time capabilities. In many applications, users need to resolve entities for only a small portion of their data, making full data processing unnecessary—a scenario known as \"ER-on-demand\". This paper proposes FastER, an efficient ER-on-demand framework for property graphs. Our approach uses graph differential dependencies (GDD) as a knowledge-encoding language to design effective filtering mechanisms that leverage both the structural and attribute semantics of graphs. We construct a blocking graph from the filtered subgraphs to reduce the number of candidate entity pairs that require comparison. Additionally, FastER incorporates Progressive Profile Scheduling (PPS), allowing the system to incrementally produce results throughout the resolution process. Extensive evaluations on multiple benchmark datasets demonstrate that FastER significantly outperforms state-of-the-art ER methods in computational efficiency and real-time processing for on-demand tasks, without compromising quality or reliability. We make FastER publicly available at the Github link: https://anonymous.4open.science/r/On_Demand_Entity_Resolution-9DFB"
    },
    {
        title: "Efficient Updates for Worst-Case Optimal Join Triple Stores",
        authors: "Alexander Bigerl, Liss Heidrich, Nikolaos Karalis and Axel-Cyrille Ngonga Ngomo",
        abstract: "It has been recently shown that worst-case optimal joins can significantly speed up query processing in RDF triple stores, especially in analytical workloads. However, this increase in query speed comes at the expense of updates being slow or not supported at all. We see this limited compatibility with updates as a key reason for the slow adoption of worst-case optimal joins in triple stores. In this paper, we address this challenge by presenting a fast, incremental insertion and deletion algorithm for the hypertrie, a worst-case optimal join data structure. This update algorithm can be used for offline bulk updates as well as online updates. Our evaluation on realistic update loads from DBpedia and scaling update sizes on Wikidata shows that the online performance of our algorithm is comparable to or better than that of traditional triple stores."
    },
    {
        title: "Parameter-efficient Federated Knowledge Graph Embedding Learning and Unlearning",
        authors: "Xiangrong Zhu, Yuexiang Xie, Yang Liu, Yaliang Li and Wei Hu",
        abstract: "Knowledge graph (KG) embedding aims to learn vector representations for entities and relations. To support distributed training and privacy protection, federated KG embedding collaboratively learns an embedding model among multiple organizations without directly sharing raw data. A federated KG embedding framework should be capable of incorporating both learning and unlearning paradigms, due to the dynamic nature of KGs and the potential need for visibility adjustment by KG owners. However, there are still several challenges in developing a federated KG embedding framework, including overcoming the communication and computation overhead caused by the huge number of entities and controlling the scope of influence when unlearning. In this paper, we propose a novel parameter-efficient federated KG embedding learning and unlearning framework, named PFLU. Specifically, we incorporate an anchor-based federated KG embedding technique to reduce computation and communication overhead when transferring knowledge. We address the anchor selection problem by formulating it as a maximum coverage problem and designing a greedy strategy for its resolution. Besides, to achieve a desirable balance between propagation and retention of unlearning effects, we adopt a two-stage mechanism consisting of structural and semantic unlearning. Extensive experiments on widely-used datasets show the superior parameter efficiency of PFLU over several baselines in both federated KG embedding learning and unlearning. Furthermore, we provide empirical evidence and discussions to show the effectiveness of the proposed anchor selection strategy."
    },
    {
        title: "The Graph Language: How Knowledge Graphs Speak to Large Language Models",
        authors: "Giuseppe Pirrò",
        abstract: "Large Language Models (LLMs) excel at reasoning but benefit from grounding provided by Knowledge Graphs (KGs), although integrating these two knowledge representation paradigms is challenging. We introduce GRALAN (The Graph Language), a novel framework that enables KGs to \"speak\" directly in the LLM’s semantic space through relational tokens—learned representations that preserve KG structure and semantics. GRALAN’s trainable graph language mediator generates structured relational tokens that can be fed into any frozen LLM, creating a versatile foundation for diverse knowledge-intensive applications, including reasoning, recommendation, and knowledge discovery. While this approach has broad implications across multiple domains, we demonstrate its effectiveness in question-answering as a concrete use case, where we re-frame the task as entity classification over nodes of a question-focused subgraph. Experiments across multiple benchmarks show that GRALAN significantly outperforms existing methods, particularly on complex multi-hop reasoning tasks, establishing a new paradigm for KG-LLM integration that maintains structural fidelity while leveraging LLMs’ reasoning capabilities"
    },
    {
        title: "Are quality dimensions correlated? An empirical investigation",
        authors: "Maria Angela Pellegrino, Anisa Rula and Gabriele Tuozzo",
        abstract: "Data quality is a complex and multidimensional concept, hierarchically organized into categories, dimensions, and metrics. Although theoretical correlations among quality dimensions have been proposed, they have not yet been empirically validated. This study addresses this gap by systematically investigating whether such correlations hold in practice, comparing theoretical assumptions with empirical, data-driven insights over a five-quarter longitudinal analysis. Leveraging outputs from a freely available quality assessment tool, the findings challenge some prior assumptions, e.g., the relationship between timeliness and accuracy, while uncovering new correlations, including a positive association between interpretability and intrinsic-related dimensions. Through this empirical evidence, this work refines existing data quality models, enhances best practices for dataset management, and informs future efforts to optimize quality assessment frameworks in the Semantic Web."
    },
    {
        title: "SAT-Based Bounded Fitting for the Description Logic ALC",
        authors: "Maurice Funk, Jean Christoph Jung and Tom Voellmer",
        abstract: "Bounded fitting is a general paradigm for learning logical formulas from positive and negative data examples, that has received considerable interest recently. We investigate bounded fitting for the description logic ALC and all its syntactic fragments. We show that the related size-restricted fitting problem is NP-complete for any such fragment as well as for ALC, even in the special case of a single positive and a single negative example. By design, bounded fitting comes with probabilistic guarantees in Valiant's PAC learning framework. In contrast, we show that other classes of algorithms for learning ALC concepts do not provide such guarantees. In addition, we show how size-restricted fitting for ALC can be reduced to propositional satisfiability and present an implementation of bounded fitting using this reduction and a SAT solver. We discuss optimizations of our SAT-encoding and compare our implementation to other concept learning tools."
    },
    {
        title: "ProgKGC: Progressive Structure-Enhanced Semantic Framework for Knowledge Graph Completion",
        authors: "Zhuang Li, Yingwen Wu, Yachao Yuan and Jin Wang",
        abstract: "Knowledge graph completion (KGC) aims to predict missing links between entities based on known relational facts. Text-based methods typically leverage pretrained language models to extract semantic representations of entities, and some of these methods further incorporate graph structure information to enhance the representations. Despite these advances, current approaches face two significant limitations: insufficient integration of semantic and structural information, and incomplete neighborhood context representation that neglects tail-entity perspectives. In this work, we introduce a progressive semantic framework enhanced by structural signals, which is trained in stages by first establishing robust semantic representations and then gradually integrating graph attention to incorporate structural context. It also includes a bidirectional neighborhood aggregation mechanism that captures both head- and tail-entity contexts to enrich relational understanding. Experiments on two public datasets demonstrate the effectiveness of our method in improving KGC performance while keeping the architecture simple and lightweight."
    },
    {
        title: "Proxy-Enriched Imputation on Contextually Incomplete Web Tables",
        authors: "Denis Nagel, Jonas Meißner, Niklas Kiehne and Wolf-Tilo Balke",
        abstract: "Structured data in the form of Web tables and open data repositories lays the foundation for the Semantic Web. However, quality concerns are often raised, mostly with respect to accuracy and completeness. While missing value imputation is the go-to solution to fill in blanks, (1) it can only approximate known unknowns and (2) struggles if values are missing not at random. As a remedy, this paper combines semantically rich narratives with proven-quality knowledge graphs to dynamically assess the completeness of individual data sets while accounting for the user's intent, too. Having determined which values are actually missing, we leverage state-of-the-art NLP techniques to identify functionally dependent attributes as proxies for later value imputation. Being functionally dependent (at least to some degree), these attributes provide the necessary context in the sense of relatedness allowing for more sophisticated imputation techniques. As a proof of concept we demonstrate our approach's benefits in a real world setting using real-life narratives on the open data repository of the World Health Organization."
    },
    {
        title: "Query-aware Dynamic Representation Learning for Temporal Knowledge Graph Reasoning",
        authors: "Juan Chen, Zixuan Li, Wei Zhang and Yuanzhuo Wang",
        abstract: "Temporal Knowledge Graph (TKG) reasoning, which predicts future queries based on historical facts, has garnered significant attention. Existing methods learn dynamic representations of entities and then predict queries based on these representations. However, they primarily learns these representations from historical facts without considering the information in the queries. Actually, queries can highlight relevant historical facts, thereby enabling the model to learn more task-specific and accurate dynamic representations. Moreover, concurrent queries often exhibit structural dependencies and can facilitate more precise and coherent predictions. Motivated by these, we propose a Query-aware Dynamic Representation Learning (QDRL), a method that adaptively incorporates query information into the dynamic representation learning process. Specifically, to capture the structural dependencies among concurrent queries, QDRL employs a CNN-based query encoder to generate query representations, which are subsequently integrated into the dynamic entity representations via a Transformer-based temporal encoder. In addition, acknowledging that some static background knowledge of entities is not explicitly represented in TKG, we leverage Large Language Models (LLMs) to construct a comprehensive background knowledge graph. By modeling this graph, QDRL generates more informative initial representations of entities, leading to improved dynamic representations. TKG reasoning experiments on five benchmark datasets demonstrate the significant improvement of the proposed QDRL method, with up to 5.41\\% and 16.96\\% performance improvement in MRR on entity and relation prediction tasks, respectively, compared to the state-of-the-art baselines."
    },
    {
        title: "Leveraging Open Path from Pruned Graph for Link Prediction on Knowledge Graphs",
        authors: "Xingyu Liu, Yuyin Lu and Yanghui Rao",
        abstract: "Real-world Knowledge Graphs (KGs) are inherently incomplete, necessitating effective link prediction to infer missing facts and enhance their utility in knowledge-driven applications. While embedding-based methods falter in inductive scenarios with unseen entities, GNN-based link predictors sacrifice interpretability despite their expressive power. Path-based alternatives address these limitations through transparent reasoning patterns, yet conventional implementations relying on Closed Paths (CPs) between entity pairs face severe path scarcity in sparse KGs. To overcome this bottleneck, we propose Open Path from Pruned Graph enhanced Link Predictor (OPPGLP), a novel framework that integrates GNN-derived relational patterns with path-based reasoning. Specifically, OPPGLP consists of an OPPG module followed by an encoder. The OPPG module decodes implicit relational patterns discovered by GNNs into explicit high-quality Open Paths (OPs) through interpretable representation analysis, while the transformer-based encoder processes these OPs along with CPs to perform link prediction. Comprehensive evaluations across three public datasets demonstrate state-of-the-art performance of our OPPGLP in 5 out of 6 transductive and inductive settings. Ablation analysis confirms the performance gains from OPs, while case study  provides interpretable reasoning traces, establishing our method's dual advantage in accuracy and explainability."
    },
    {
        title: "Neuro-Symbolic Adaptive Query Processing over Knowledge Graphs",
        authors: "Chang Qin and Maribel Acosta",
        abstract: "In adaptive query processing (AQP), the query plan is ad- justed based on actual execution conditions. AQP has proven effective in dynamic querying environments, such as knowledge graphs (KGs) on the web. The technique known as eddies enables tuple-wise adaptivity by dynamically reordering query operators at runtime. Eddies operate under a predefined symbolic routing policy, which determines the next operator to process each tuple. Although various routing policies have been proposed, their effectiveness varies across queries, and choosing a suboptimal policy can significantly degrade performance. To address this challenge, we propose a neuro-symbolic AQP approach that combines representation learning and supervised learning to predict the optimal routing policy for a given query. Experimental results on synthetic and real-world KGs demonstrate that our method achieves high precision in predicting optimal policies, is efficient to train and use at inference time, and generalizes well to queries with constants not seen during training."
    },
    {
        title: "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic",
        authors: "Yiwen Peng, Thomas Bonald and Fabian Suchanek",
        abstract: "Knowledge graph alignment is the task of matching equivalent entities (that is, instances and classes) and relations across two knowledge graphs. Most existing methods focus on pure entity-level alignment, computing the similarity of entities in some embedding space. They lack interpretable reasoning and need training data to work. In this paper, we propose FLORA, a simple yet effective method that (1) is unsupervised, i.e., does not require training data, (2) provides a holistic alignment for entities and relations iteratively, (3) is based on fuzzy logic and thus delivers interpretable results, (4) provably converges, (5) allows dangling entities, i.e., entities without a counterpart in the other KG, and (6) achieves state-of-the-art results on major benchmarks."
    },
    {
        title: "Measuring the Impact of Narrative Complexity on Knowledge Graph Embeddings",
        authors: "Inès Blin, Ilaria Tiddi and Annette Ten Teije",
        abstract: "In this work, we study how semantic narrative enrichment and syntactic encoding affect the performance of knowledge graph embedding models. Narratives are central to human understanding, yet their structured representation in knowledge graphs remains challenging due to their semantic and structural complexity. Although traditional knowledge graphs use binary relations, they struggle to capture richer narrative elements, such as roles and causality. More complex knowledge graph syntaxes such as RDF-star, reification, singleton or n-ary properties offer greater modeling flexibility, but their impact on downstream tasks such as link prediction remains unclear. We define a six-level categorization of narrative semantics and use it to construct a suite of structured knowledge graphs using four syntactic representations. Using different embedding models, we evaluate how semantic and syntactic factors influence the embedding quality. We find that semantic features such as properties and subevents generally enhance performance, while roles tend to have a detrimental effect. On the syntactic side, although differences were not statistically significant across all metrics, reification and RDF-star achieved the strongest results on average."
    },
    {
        title: "Revisiting Link Prioritization for Efficient Traversal in Structured Decentralized Environments",
        authors: "Ruben Eschauzier, Ruben Taelman and Ruben Verborgh",
        abstract: "Decentralized environments distribute personal data across numerous small, independent data sources; a necessity driven by legal and socio-economic constraints that prevent the technologically more convenient central aggregation. Link Traversal-based Query Processing (LTQP) is a query technique that respects these constraints by iteratively discovering and accessing data sources while enabling fine-grained access control.  Unfortunately, current LTQP implementations are slow due to limited prior knowledge of queried data and the high volume of HTTP requests required. While link prioritization algorithms have been studied for Linked Open Data (LOD), their performance in structured decentralized environments remains untested. Evaluating this performance is essential to establish a baseline as a reference point for improving future implementations.  To measure prioritization performance, we formally define the R³ metric, extend it to continuous efficiency, and account for real-world scenarios. Furthermore, we provide modular and open-source implementations of the prioritization algorithms from the literature. Finally, using the R³ metric with existing metrics from the literature, we benchmark these link prioritization algorithms in a simulated Solid environment.  In this paper, we report the benchmark results, provide a thorough analysis, and lessons learned for future work.  We find that existing prioritization algorithms fail to leverage the structure in structured decentralized environments to improve performance, with no method outperforming the look-up order produced by a FIFO queue.  We conclude that general-purpose prioritization algorithms do not work in structured decentralized environments without explicitly incorporating the structural information."
    },
    {
        title: "Compact Answers to Temporal Path Queries",
        authors: "Muhammad Adnan, Diego Calvanese, Julien Corman, Anton Dignös, Werner Nutt and Ognjen Savković",
        abstract: "We study path-based graph queries that in addition to navigation over edges also perform navigation over time. This allows one to ask questions about the dynamics of networks, like traffic movement, cause effect relationships, or spread of diseases. In this setting, graphs consist of triples annotated with validity intervals while a query produces pairs of nodes where each pair is associated with a binary relation over time. For instance, such a pair could be two airports and the relation could map potential departure times to possible arrival times. An open question is how to represent such a relation in a compact form and how to maintain such properties during query evaluation. We investigate four compact representations of answers to a such a query that rely on alternative ways of encoding sets of intervals over both discrete and dense time. We discuss their respective advantages and drawbacks, in terms of conciseness, uniqueness, and computational cost. Notably, the most refined encoding guarantees that query answers over dense time can be finitely represented."
    },
    {
        title: "Graph Querying or Similarity Search? Both!",
        authors: "Vicente Calisto, Sebastián Ferrada, Gonzalo Navarro, Juan L. Reutter, Juan Pablo Sánchez and Domagoj Vrgoc",
        abstract: "Extracting information from knowledge graphs is a significant algorithmic challenge, especially when dealing with multimodal knowledge graphs that integrate images, text, and/or videos. While current graph management systems can efficiently evaluate graph queries, they struggle with multimedia data. To address this, systems rely on metadata, such as vector embeddings, for similarity search. While both graph pattern evaluation and similarity search work well independently, real-world applications often require their combination to retrieve media based on both the graph structure and specific similarity criteria.  This paper studies the problem of querying multimodal knowledge graphs by combining graph patterns with similarity constraints. We formalize this as an extraction task where some nodes in the graph pattern are filtered by similarity, and then the results must be ordered by a similarity score. While a straightforward approach is to evaluate the graph pattern first and then sort by similarity, we introduce alternative algorithms that evaluate both tasks jointly, leveraging indexes for efficient similarity computation. Our implementation employs an approximate version of these indexes, and our experiments show that graph database systems can efficiently integrate semantic similarity constraints into their queries."
    },
    {
        title: "GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs",
        authors: "Sebastian Walter and Hannah Bast",
        abstract: "We propose a new approach for generating SPARQL queries on RDF knowledge graphs from natural language questions or keyword queries, using a large language model. Our approach does not require fine-tuning. Instead, it uses the language model to explore the knowledge graph by strategically executing SPARQL queries and searching for relevant IRIs and literals. We evaluate our approach on a variety of benchmarks (for knowledge graphs of different kinds and sizes) and language models (of different scales and types, commercial as well as open-source) and compare it with existing approaches. On Wikidata we reach state-of-the-art results on multiple benchmarks, despite the zero-shot setting. On Freebase we come close to the best few-shot methods. On other, less commonly evaluated knowledge graphs and benchmarks our approach also performs well overall. We conduct several additional studies, like comparing different ways of searching the graphs, incorporating a feedback mechanism, or making use of few-shot examples."
    },
    {
        title: "Large Language Models Assisting Ontology Evaluation",
        authors: "Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskisärkkä, Eva Blomqvist, Andrea Giovanni Nuzzolese and Aldo Gangemi",
        abstract: "Ontology evaluation through functional requirements—such as testing via competency question (CQ) verification—is a well-established yet costly, labour-intensive, and error-prone endeavour, even for ontology engineering experts. In this work, we introduce OE-Assist, a novel framework designed to assist ontology evaluation through automated and semi-automated CQ verification. By presenting and leveraging a dataset of 1,393 CQs paired with corresponding ontologies and ontology stories, our contributions present, to our knowledge, the first systematic investigation into large language model (LLM)-assisted ontology evaluation, and include: (i) evaluating the effectiveness of a LLM-based approach for automatically performing CQ verification against a manually created gold standard, and (ii) developing and assessing an LLM-powered framework to assist CQ verification with Protégé, by providing suggestions. We found that automated LLM-based evaluation with o1-preview and o3-mini perform at a similar level to the average user’s performance. Through a user study on the framework with 19 knowledge engineers from eight international institutions, we also show that LLMs can assist manual CQ verification and improve user accuracy, especially when suggestions are correct. Additionally, participants reported a marked decrease in perceived task difficulty. However, we also observed a reduction in human performance when the LLM provided incorrect guidance, showing a critical trade-off between efficiency and accuracy in assisted ontology evaluation."
    },
    {
        title: "UpSHACL: Targeted Constraint Validation for Updates over Knowledge Graphs",
        authors: "Zenon Zacouris, Jin Ke and Maribel Acosta",
        abstract: "Knowledge Graphs (KGs) evolve frequently through updates that reflect new information or corrections, but such changes can compromise data quality constraints. For KGs modelled in RDF, such constraints can be expressed with the Shapes Constraint Language (SHACL). Current SHACL engines are tailored to validating static graphs but are inefficient for KGs under updates, as they require re-validating the entire graph after each update. In this paper, we present UpSHACL, an approach for efficient SHACL validation after updates. UpSHACL introduces a formal model to identify the subgraph affected by an update and constructs a reduced subgraph that can be validated using existing SHACL engines. Our algorithm, implemented with SPARQL over RDF triple stores, integrates seamlessly with Semantic Web technologies. Experimental results show that UpSHACL achieves up to 10× speedup over static validation, with performance gains increasing on larger KGs."
    },
    {
        title: "Link Prediction Under Non-targeted Attacks: Do Soft Labels Always Help?",
        authors: "Adel Memariani, Michael Röder, Arnab Sharma, Caglar Demir and Axel-Cyrille Ngonga Ngomo",
        abstract: "Knowledge Graph Embedding (KGE) models rely on precise factual information to learn effective representations. These learned representations support many downstream tasks, with link prediction being a primary application. However, recent studies have shown that noise in training data can compromise the effectiveness of knowledge graph embeddings. Therefore, KGEs are highly vulnerable to data poisoning attacks. Typically current attacks on KGEs are studied under targeted scenarios, where target facts and the model are assumed to be known beforehand. Yet, this information is not often available in real-world scenarios. Thus, more realistic scenarios involve non-targeted but malicious perturbations aimed at reducing the overall model performance. In this paper, we focus on enhancing the robustness of link prediction approaches in non-targeted settings. To mitigate the harmful impact of the noisy data, we explore soft-label loss functions as a strategy for reducing overconfidence in model predictions. We performed a thorough evaluation on six state-of-the-art models and five benchmark datasets, with different noise ratios introduced into each dataset. Our results show that soft labels commonly improve the robustness of KGE models across various noise ratios."
    },
    {
        title: "Scalable Reasoning with Real Facts via Constrained Generation",
        authors: "Riccardo Pozzi, Matteo Palmonari, Andrea Coletta, Luigi Bellomarini, Jens Lehmann and Sahar Vahdati",
        abstract: "Knowledge gaps and hallucinations are important problems for Large Language Models (LLMs) that may lack sufficient information to fulfill user instructions, resulting in unreliable responses. Existing approaches, such as Retrieval-Augmented Generation (RAG) and tool use, aim to address these issues by incorporating external knowledge. Yet, they depend on additional models or services, resulting in complex pipelines, potential error propagation, and often requiring the model to process a large number of tokens. In this paper we present a scalable method that enables LLMs to access external knowledge without relying on retrievers or auxiliary models. Our approach uses constrained generation with a prebuilt prefix-tree index. Triples from a Knowledge Graph are verbalized in textual facts, tokenized, and indexed in a prefix-tree structure for efficient access. During inference, to acquire external knowledge, the LLM generates facts with constrained generation which allows only sequences of tokens that form a real fact. We evaluate our proposal on Question Answering and show that it scales to large knowledge bases (800 million facts), adapts to domain-specific data, and improves performance on questions where internal model knowledge is lacking. These gains come with minimal generation-time overhead."
    },
    {
        title: "Controlled Query Evaluation under Epistemic Dependencies: Algorithms and Experiments",
        authors: "Lorenzo Marconi, Flavia Ricci and Riccardo Rosati",
        abstract: "We investigate Controlled Query Evaluation (CQE) over ontologies, where information disclosure is regulated by epistemic dependencies (EDs), a family of logical rules recently proposed for the CQE framework. In particular, we combine EDs with the notion of optimal GA censors, i.e. maximal sets of ground atoms that are entailed by the ontology and can be safely revealed. We focus on answering Boolean unions of conjunctive queries (BUCQs) with respect to the intersection of all optimal GA censors—an approach that has been shown in other contexts to ensure strong security guarantees with favorable computational behavior. First, we characterize the security of this intersection-based approach and identify a class of EDs (namely, full EDs) for which it remains safe. Then, for a subclass of EDs and for DL-Lite_R ontologies, we show that answering BUCQs in the above CQE semantics is in AC^0 in data complexity by presenting a suitable, detailed first-order rewriting algorithm. Finally, we report on experiments conducted in two different evaluation scenarios, showing the practical feasibility of our rewriting function."
    },
    {
        title: "KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models",
        authors: "Lam Nguyen, Erika Barcelos, Roger French and Yinghui Wu",
        abstract: "Ontology Matching (OM) is a cornerstone task of semantic interoperability, yet existing systems often rely on handcrafted rules or specialized models with limited adaptability. We present KROMA, a novel OM framework that harnesses Large Language Models (LLMs) within a Retrieval‑Augmented Generation (RAG) pipeline, to dynamically enrich the semantic prompt context of OM tasks with structural, lexical, and definitional knowledge. To optimize both accuracy and efficiency, KROMA integrates a bisimilarity‑based concept matching and a lightweight ontology refinement step, which prune candidate concepts and substantially reduce the communication overhead from invoking LLMs. Using a variety of benchmark datasets, we experimentally verify that knowledge retrieval and context‑augmented LLMs effectively improve ontology matching outperforms both traditional OM systems and state-of-the-art LLM‑based OM methods, with comparable communication overhead. Our study highlights the feasibility and benefit of the proposed optimization techniques (targeted knowledge retrieval, prompt enrichment, and ontology refinement) for ontology matching at scale."
    },
    {
        title: "A Domain-Independent Approach for Semantic Table Interpretation",
        authors: "Binh Vu, Craig Knoblock and Fandel Lin",
        abstract: "Understanding the semantic structure of tabular data is essential for data integration and discovery. Specifically, the goal is to annotate columns in a tabular source with types and relationships between them using classes and predicates of a target ontology. Previous work either requires trained labeled data or exploits the overlapping data between the table data and a knowledge graph to predict types and relationships. However, they cannot be used in a new domain with limited labeled data. To address this issue, we propose a novel distant supervision approach to estimate a score reflecting the semantic relatedness between a table column and an ontology class or property using the table metadata and data. Our empirical evaluation demonstrates that our approach significantly outperforms strong baselines."
    },
    {
        title: "SHACL Validation under Graph Updates",
        authors: "Shqiponja Ahmetaj, George Konstantinidis, Magdalena Ortiz, Paolo Pareti and Mantas Šimkus",
        abstract: "SHACL (SHApe Constraint Language) is a W3C standardized constraint language for RDF graphs. In this paper, we study SHACL validation in RDF graphs under updates. We present a SHACL-based update language that can capture intuitive and realistic modifications on RDF graphs and study the problem of static validation under such updates. This problem asks to verify whether every graph that validates a SHACL specification will still do so after applying a given update sequence. More importantly, it provides a basis for further services for reasoning about evolving RDF graphs.  Using a regression technique, that embeds the update actions into SHACL constraints, we show that static validation under updates can be reduced to (un)satisfiability of a shapes graph in (a minor extension of) SHACL. We analyze the computational complexity of the static validation problem for SHACL and some key fragments. Finally, we present a prototype implementation that performs static validation under updates and other static analysis tasks on SHACL shapes graphs and demonstrate its behavior through preliminary experiments."
    },
    {
        title: "Parallel Reasoning in Sequoia",
        authors: "Alexander Furmston, David Tena Cucala, Jieying Chen and Bernardo Cuenca Grau",
        abstract: "Description Logic (DL) ontologies underpin many Semantic Web applications. Consequence-based reasoning, which integrates techniques from hypertableau and resolution, has proved effective for tasks such as consistency checking and classification in both lightweight and expressive DLs. However, existing reasoners often fall short when applied to large, complex ontologies commonly found in domains such as healthcare and industry. In this paper, we extend the state-of-the-art consequence-based reasoner Sequoia to support parallel reasoning, improving its scalability by leveraging system architectures with multiple cores. We explore and evaluate two parallelisation strategies for consequence-based reasoners: message passing and thread pools, and demonstrate their application within the Sequoia reasoner. Our extensive empirical evaluation shows that thread pool-based implementations achieve superior performance and resource efficiency, offering up to 2.46x speedup over the baseline on hard ontologies. We also explore the effect of increasing the number of available cores or restricting the expressivity of the ontology on the performance of our implementations."
    }
];

export { researchTrack };