/*! For license information please see main.7ecf5649.js.LICENSE.txt */
(()=>{"use strict";var e={2730:(e,t,a)=>{var n=a(5043),i=a(8853);function s(e){for(var t="https://reactjs.org/docs/error-decoder.html?invariant="+e,a=1;a<arguments.length;a++)t+="&args[]="+encodeURIComponent(arguments[a]);return"Minified React error #"+e+"; visit "+t+" for the full message or use the non-minified dev environment for full errors and additional helpful warnings."}var r=new Set,o={};function l(e,t){c(e,t),c(e+"Capture",t)}function c(e,t){for(o[e]=t,e=0;e<t.length;e++)r.add(t[e])}var d=!("undefined"===typeof window||"undefined"===typeof window.document||"undefined"===typeof window.document.createElement),h=Object.prototype.hasOwnProperty,u=/^[:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD][:A-Z_a-z\u00C0-\u00D6\u00D8-\u00F6\u00F8-\u02FF\u0370-\u037D\u037F-\u1FFF\u200C-\u200D\u2070-\u218F\u2C00-\u2FEF\u3001-\uD7FF\uF900-\uFDCF\uFDF0-\uFFFD\-.0-9\u00B7\u0300-\u036F\u203F-\u2040]*$/,p={},m={};function g(e,t,a,n,i,s,r){this.acceptsBooleans=2===t||3===t||4===t,this.attributeName=n,this.attributeNamespace=i,this.mustUseProperty=a,this.propertyName=e,this.type=t,this.sanitizeURL=s,this.removeEmptyString=r}var f={};"children dangerouslySetInnerHTML defaultValue defaultChecked innerHTML suppressContentEditableWarning suppressHydrationWarning style".split(" ").forEach((function(e){f[e]=new g(e,0,!1,e,null,!1,!1)})),[["acceptCharset","accept-charset"],["className","class"],["htmlFor","for"],["httpEquiv","http-equiv"]].forEach((function(e){var t=e[0];f[t]=new g(t,1,!1,e[1],null,!1,!1)})),["contentEditable","draggable","spellCheck","value"].forEach((function(e){f[e]=new g(e,2,!1,e.toLowerCase(),null,!1,!1)})),["autoReverse","externalResourcesRequired","focusable","preserveAlpha"].forEach((function(e){f[e]=new g(e,2,!1,e,null,!1,!1)})),"allowFullScreen async autoFocus autoPlay controls default defer disabled disablePictureInPicture disableRemotePlayback formNoValidate hidden loop noModule noValidate open playsInline readOnly required reversed scoped seamless itemScope".split(" ").forEach((function(e){f[e]=new g(e,3,!1,e.toLowerCase(),null,!1,!1)})),["checked","multiple","muted","selected"].forEach((function(e){f[e]=new g(e,3,!0,e,null,!1,!1)})),["capture","download"].forEach((function(e){f[e]=new g(e,4,!1,e,null,!1,!1)})),["cols","rows","size","span"].forEach((function(e){f[e]=new g(e,6,!1,e,null,!1,!1)})),["rowSpan","start"].forEach((function(e){f[e]=new g(e,5,!1,e.toLowerCase(),null,!1,!1)}));var b=/[\-:]([a-z])/g;function y(e){return e[1].toUpperCase()}function x(e,t,a,n){var i=f.hasOwnProperty(t)?f[t]:null;(null!==i?0!==i.type:n||!(2<t.length)||"o"!==t[0]&&"O"!==t[0]||"n"!==t[1]&&"N"!==t[1])&&(function(e,t,a,n){if(null===t||"undefined"===typeof t||function(e,t,a,n){if(null!==a&&0===a.type)return!1;switch(typeof t){case"function":case"symbol":return!0;case"boolean":return!n&&(null!==a?!a.acceptsBooleans:"data-"!==(e=e.toLowerCase().slice(0,5))&&"aria-"!==e);default:return!1}}(e,t,a,n))return!0;if(n)return!1;if(null!==a)switch(a.type){case 3:return!t;case 4:return!1===t;case 5:return isNaN(t);case 6:return isNaN(t)||1>t}return!1}(t,a,i,n)&&(a=null),n||null===i?function(e){return!!h.call(m,e)||!h.call(p,e)&&(u.test(e)?m[e]=!0:(p[e]=!0,!1))}(t)&&(null===a?e.removeAttribute(t):e.setAttribute(t,""+a)):i.mustUseProperty?e[i.propertyName]=null===a?3!==i.type&&"":a:(t=i.attributeName,n=i.attributeNamespace,null===a?e.removeAttribute(t):(a=3===(i=i.type)||4===i&&!0===a?"":""+a,n?e.setAttributeNS(n,t,a):e.setAttribute(t,a))))}"accent-height alignment-baseline arabic-form baseline-shift cap-height clip-path clip-rule color-interpolation color-interpolation-filters color-profile color-rendering dominant-baseline enable-background fill-opacity fill-rule flood-color flood-opacity font-family font-size font-size-adjust font-stretch font-style font-variant font-weight glyph-name glyph-orientation-horizontal glyph-orientation-vertical horiz-adv-x horiz-origin-x image-rendering letter-spacing lighting-color marker-end marker-mid marker-start overline-position overline-thickness paint-order panose-1 pointer-events rendering-intent shape-rendering stop-color stop-opacity strikethrough-position strikethrough-thickness stroke-dasharray stroke-dashoffset stroke-linecap stroke-linejoin stroke-miterlimit stroke-opacity stroke-width text-anchor text-decoration text-rendering underline-position underline-thickness unicode-bidi unicode-range units-per-em v-alphabetic v-hanging v-ideographic v-mathematical vector-effect vert-adv-y vert-origin-x vert-origin-y word-spacing writing-mode xmlns:xlink x-height".split(" ").forEach((function(e){var t=e.replace(b,y);f[t]=new g(t,1,!1,e,null,!1,!1)})),"xlink:actuate xlink:arcrole xlink:role xlink:show xlink:title xlink:type".split(" ").forEach((function(e){var t=e.replace(b,y);f[t]=new g(t,1,!1,e,"http://www.w3.org/1999/xlink",!1,!1)})),["xml:base","xml:lang","xml:space"].forEach((function(e){var t=e.replace(b,y);f[t]=new g(t,1,!1,e,"http://www.w3.org/XML/1998/namespace",!1,!1)})),["tabIndex","crossOrigin"].forEach((function(e){f[e]=new g(e,1,!1,e.toLowerCase(),null,!1,!1)})),f.xlinkHref=new g("xlinkHref",1,!1,"xlink:href","http://www.w3.org/1999/xlink",!0,!1),["src","href","action","formAction"].forEach((function(e){f[e]=new g(e,1,!1,e.toLowerCase(),null,!0,!0)}));var v=n.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED,w=Symbol.for("react.element"),j=Symbol.for("react.portal"),k=Symbol.for("react.fragment"),S=Symbol.for("react.strict_mode"),N=Symbol.for("react.profiler"),C=Symbol.for("react.provider"),T=Symbol.for("react.context"),A=Symbol.for("react.forward_ref"),L=Symbol.for("react.suspense"),I=Symbol.for("react.suspense_list"),P=Symbol.for("react.memo"),R=Symbol.for("react.lazy");Symbol.for("react.scope"),Symbol.for("react.debug_trace_mode");var E=Symbol.for("react.offscreen");Symbol.for("react.legacy_hidden"),Symbol.for("react.cache"),Symbol.for("react.tracing_marker");var D=Symbol.iterator;function W(e){return null===e||"object"!==typeof e?null:"function"===typeof(e=D&&e[D]||e["@@iterator"])?e:null}var M,G=Object.assign;function O(e){if(void 0===M)try{throw Error()}catch(a){var t=a.stack.trim().match(/\n( *(at )?)/);M=t&&t[1]||""}return"\n"+M+e}var F=!1;function z(e,t){if(!e||F)return"";F=!0;var a=Error.prepareStackTrace;Error.prepareStackTrace=void 0;try{if(t)if(t=function(){throw Error()},Object.defineProperty(t.prototype,"props",{set:function(){throw Error()}}),"object"===typeof Reflect&&Reflect.construct){try{Reflect.construct(t,[])}catch(c){var n=c}Reflect.construct(e,[],t)}else{try{t.call()}catch(c){n=c}e.call(t.prototype)}else{try{throw Error()}catch(c){n=c}e()}}catch(c){if(c&&n&&"string"===typeof c.stack){for(var i=c.stack.split("\n"),s=n.stack.split("\n"),r=i.length-1,o=s.length-1;1<=r&&0<=o&&i[r]!==s[o];)o--;for(;1<=r&&0<=o;r--,o--)if(i[r]!==s[o]){if(1!==r||1!==o)do{if(r--,0>--o||i[r]!==s[o]){var l="\n"+i[r].replace(" at new "," at ");return e.displayName&&l.includes("<anonymous>")&&(l=l.replace("<anonymous>",e.displayName)),l}}while(1<=r&&0<=o);break}}}finally{F=!1,Error.prepareStackTrace=a}return(e=e?e.displayName||e.name:"")?O(e):""}function K(e){switch(e.tag){case 5:return O(e.type);case 16:return O("Lazy");case 13:return O("Suspense");case 19:return O("SuspenseList");case 0:case 2:case 15:return e=z(e.type,!1);case 11:return e=z(e.type.render,!1);case 1:return e=z(e.type,!0);default:return""}}function q(e){if(null==e)return null;if("function"===typeof e)return e.displayName||e.name||null;if("string"===typeof e)return e;switch(e){case k:return"Fragment";case j:return"Portal";case N:return"Profiler";case S:return"StrictMode";case L:return"Suspense";case I:return"SuspenseList"}if("object"===typeof e)switch(e.$$typeof){case T:return(e.displayName||"Context")+".Consumer";case C:return(e._context.displayName||"Context")+".Provider";case A:var t=e.render;return(e=e.displayName)||(e=""!==(e=t.displayName||t.name||"")?"ForwardRef("+e+")":"ForwardRef"),e;case P:return null!==(t=e.displayName||null)?t:q(e.type)||"Memo";case R:t=e._payload,e=e._init;try{return q(e(t))}catch(a){}}return null}function _(e){var t=e.type;switch(e.tag){case 24:return"Cache";case 9:return(t.displayName||"Context")+".Consumer";case 10:return(t._context.displayName||"Context")+".Provider";case 18:return"DehydratedFragment";case 11:return e=(e=t.render).displayName||e.name||"",t.displayName||(""!==e?"ForwardRef("+e+")":"ForwardRef");case 7:return"Fragment";case 5:return t;case 4:return"Portal";case 3:return"Root";case 6:return"Text";case 16:return q(t);case 8:return t===S?"StrictMode":"Mode";case 22:return"Offscreen";case 12:return"Profiler";case 21:return"Scope";case 13:return"Suspense";case 19:return"SuspenseList";case 25:return"TracingMarker";case 1:case 0:case 17:case 2:case 14:case 15:if("function"===typeof t)return t.displayName||t.name||null;if("string"===typeof t)return t}return null}function H(e){switch(typeof e){case"boolean":case"number":case"string":case"undefined":case"object":return e;default:return""}}function B(e){var t=e.type;return(e=e.nodeName)&&"input"===e.toLowerCase()&&("checkbox"===t||"radio"===t)}function U(e){e._valueTracker||(e._valueTracker=function(e){var t=B(e)?"checked":"value",a=Object.getOwnPropertyDescriptor(e.constructor.prototype,t),n=""+e[t];if(!e.hasOwnProperty(t)&&"undefined"!==typeof a&&"function"===typeof a.get&&"function"===typeof a.set){var i=a.get,s=a.set;return Object.defineProperty(e,t,{configurable:!0,get:function(){return i.call(this)},set:function(e){n=""+e,s.call(this,e)}}),Object.defineProperty(e,t,{enumerable:a.enumerable}),{getValue:function(){return n},setValue:function(e){n=""+e},stopTracking:function(){e._valueTracker=null,delete e[t]}}}}(e))}function J(e){if(!e)return!1;var t=e._valueTracker;if(!t)return!0;var a=t.getValue(),n="";return e&&(n=B(e)?e.checked?"true":"false":e.value),(e=n)!==a&&(t.setValue(e),!0)}function Q(e){if("undefined"===typeof(e=e||("undefined"!==typeof document?document:void 0)))return null;try{return e.activeElement||e.body}catch(t){return e.body}}function V(e,t){var a=t.checked;return G({},t,{defaultChecked:void 0,defaultValue:void 0,value:void 0,checked:null!=a?a:e._wrapperState.initialChecked})}function Y(e,t){var a=null==t.defaultValue?"":t.defaultValue,n=null!=t.checked?t.checked:t.defaultChecked;a=H(null!=t.value?t.value:a),e._wrapperState={initialChecked:n,initialValue:a,controlled:"checkbox"===t.type||"radio"===t.type?null!=t.checked:null!=t.value}}function X(e,t){null!=(t=t.checked)&&x(e,"checked",t,!1)}function Z(e,t){X(e,t);var a=H(t.value),n=t.type;if(null!=a)"number"===n?(0===a&&""===e.value||e.value!=a)&&(e.value=""+a):e.value!==""+a&&(e.value=""+a);else if("submit"===n||"reset"===n)return void e.removeAttribute("value");t.hasOwnProperty("value")?ee(e,t.type,a):t.hasOwnProperty("defaultValue")&&ee(e,t.type,H(t.defaultValue)),null==t.checked&&null!=t.defaultChecked&&(e.defaultChecked=!!t.defaultChecked)}function $(e,t,a){if(t.hasOwnProperty("value")||t.hasOwnProperty("defaultValue")){var n=t.type;if(!("submit"!==n&&"reset"!==n||void 0!==t.value&&null!==t.value))return;t=""+e._wrapperState.initialValue,a||t===e.value||(e.value=t),e.defaultValue=t}""!==(a=e.name)&&(e.name=""),e.defaultChecked=!!e._wrapperState.initialChecked,""!==a&&(e.name=a)}function ee(e,t,a){"number"===t&&Q(e.ownerDocument)===e||(null==a?e.defaultValue=""+e._wrapperState.initialValue:e.defaultValue!==""+a&&(e.defaultValue=""+a))}var te=Array.isArray;function ae(e,t,a,n){if(e=e.options,t){t={};for(var i=0;i<a.length;i++)t["$"+a[i]]=!0;for(a=0;a<e.length;a++)i=t.hasOwnProperty("$"+e[a].value),e[a].selected!==i&&(e[a].selected=i),i&&n&&(e[a].defaultSelected=!0)}else{for(a=""+H(a),t=null,i=0;i<e.length;i++){if(e[i].value===a)return e[i].selected=!0,void(n&&(e[i].defaultSelected=!0));null!==t||e[i].disabled||(t=e[i])}null!==t&&(t.selected=!0)}}function ne(e,t){if(null!=t.dangerouslySetInnerHTML)throw Error(s(91));return G({},t,{value:void 0,defaultValue:void 0,children:""+e._wrapperState.initialValue})}function ie(e,t){var a=t.value;if(null==a){if(a=t.children,t=t.defaultValue,null!=a){if(null!=t)throw Error(s(92));if(te(a)){if(1<a.length)throw Error(s(93));a=a[0]}t=a}null==t&&(t=""),a=t}e._wrapperState={initialValue:H(a)}}function se(e,t){var a=H(t.value),n=H(t.defaultValue);null!=a&&((a=""+a)!==e.value&&(e.value=a),null==t.defaultValue&&e.defaultValue!==a&&(e.defaultValue=a)),null!=n&&(e.defaultValue=""+n)}function re(e){var t=e.textContent;t===e._wrapperState.initialValue&&""!==t&&null!==t&&(e.value=t)}function oe(e){switch(e){case"svg":return"http://www.w3.org/2000/svg";case"math":return"http://www.w3.org/1998/Math/MathML";default:return"http://www.w3.org/1999/xhtml"}}function le(e,t){return null==e||"http://www.w3.org/1999/xhtml"===e?oe(t):"http://www.w3.org/2000/svg"===e&&"foreignObject"===t?"http://www.w3.org/1999/xhtml":e}var ce,de,he=(de=function(e,t){if("http://www.w3.org/2000/svg"!==e.namespaceURI||"innerHTML"in e)e.innerHTML=t;else{for((ce=ce||document.createElement("div")).innerHTML="<svg>"+t.valueOf().toString()+"</svg>",t=ce.firstChild;e.firstChild;)e.removeChild(e.firstChild);for(;t.firstChild;)e.appendChild(t.firstChild)}},"undefined"!==typeof MSApp&&MSApp.execUnsafeLocalFunction?function(e,t,a,n){MSApp.execUnsafeLocalFunction((function(){return de(e,t)}))}:de);function ue(e,t){if(t){var a=e.firstChild;if(a&&a===e.lastChild&&3===a.nodeType)return void(a.nodeValue=t)}e.textContent=t}var pe={animationIterationCount:!0,aspectRatio:!0,borderImageOutset:!0,borderImageSlice:!0,borderImageWidth:!0,boxFlex:!0,boxFlexGroup:!0,boxOrdinalGroup:!0,columnCount:!0,columns:!0,flex:!0,flexGrow:!0,flexPositive:!0,flexShrink:!0,flexNegative:!0,flexOrder:!0,gridArea:!0,gridRow:!0,gridRowEnd:!0,gridRowSpan:!0,gridRowStart:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnSpan:!0,gridColumnStart:!0,fontWeight:!0,lineClamp:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,tabSize:!0,widows:!0,zIndex:!0,zoom:!0,fillOpacity:!0,floodOpacity:!0,stopOpacity:!0,strokeDasharray:!0,strokeDashoffset:!0,strokeMiterlimit:!0,strokeOpacity:!0,strokeWidth:!0},me=["Webkit","ms","Moz","O"];function ge(e,t,a){return null==t||"boolean"===typeof t||""===t?"":a||"number"!==typeof t||0===t||pe.hasOwnProperty(e)&&pe[e]?(""+t).trim():t+"px"}function fe(e,t){for(var a in e=e.style,t)if(t.hasOwnProperty(a)){var n=0===a.indexOf("--"),i=ge(a,t[a],n);"float"===a&&(a="cssFloat"),n?e.setProperty(a,i):e[a]=i}}Object.keys(pe).forEach((function(e){me.forEach((function(t){t=t+e.charAt(0).toUpperCase()+e.substring(1),pe[t]=pe[e]}))}));var be=G({menuitem:!0},{area:!0,base:!0,br:!0,col:!0,embed:!0,hr:!0,img:!0,input:!0,keygen:!0,link:!0,meta:!0,param:!0,source:!0,track:!0,wbr:!0});function ye(e,t){if(t){if(be[e]&&(null!=t.children||null!=t.dangerouslySetInnerHTML))throw Error(s(137,e));if(null!=t.dangerouslySetInnerHTML){if(null!=t.children)throw Error(s(60));if("object"!==typeof t.dangerouslySetInnerHTML||!("__html"in t.dangerouslySetInnerHTML))throw Error(s(61))}if(null!=t.style&&"object"!==typeof t.style)throw Error(s(62))}}function xe(e,t){if(-1===e.indexOf("-"))return"string"===typeof t.is;switch(e){case"annotation-xml":case"color-profile":case"font-face":case"font-face-src":case"font-face-uri":case"font-face-format":case"font-face-name":case"missing-glyph":return!1;default:return!0}}var ve=null;function we(e){return(e=e.target||e.srcElement||window).correspondingUseElement&&(e=e.correspondingUseElement),3===e.nodeType?e.parentNode:e}var je=null,ke=null,Se=null;function Ne(e){if(e=xi(e)){if("function"!==typeof je)throw Error(s(280));var t=e.stateNode;t&&(t=wi(t),je(e.stateNode,e.type,t))}}function Ce(e){ke?Se?Se.push(e):Se=[e]:ke=e}function Te(){if(ke){var e=ke,t=Se;if(Se=ke=null,Ne(e),t)for(e=0;e<t.length;e++)Ne(t[e])}}function Ae(e,t){return e(t)}function Le(){}var Ie=!1;function Pe(e,t,a){if(Ie)return e(t,a);Ie=!0;try{return Ae(e,t,a)}finally{Ie=!1,(null!==ke||null!==Se)&&(Le(),Te())}}function Re(e,t){var a=e.stateNode;if(null===a)return null;var n=wi(a);if(null===n)return null;a=n[t];e:switch(t){case"onClick":case"onClickCapture":case"onDoubleClick":case"onDoubleClickCapture":case"onMouseDown":case"onMouseDownCapture":case"onMouseMove":case"onMouseMoveCapture":case"onMouseUp":case"onMouseUpCapture":case"onMouseEnter":(n=!n.disabled)||(n=!("button"===(e=e.type)||"input"===e||"select"===e||"textarea"===e)),e=!n;break e;default:e=!1}if(e)return null;if(a&&"function"!==typeof a)throw Error(s(231,t,typeof a));return a}var Ee=!1;if(d)try{var De={};Object.defineProperty(De,"passive",{get:function(){Ee=!0}}),window.addEventListener("test",De,De),window.removeEventListener("test",De,De)}catch(de){Ee=!1}function We(e,t,a,n,i,s,r,o,l){var c=Array.prototype.slice.call(arguments,3);try{t.apply(a,c)}catch(d){this.onError(d)}}var Me=!1,Ge=null,Oe=!1,Fe=null,ze={onError:function(e){Me=!0,Ge=e}};function Ke(e,t,a,n,i,s,r,o,l){Me=!1,Ge=null,We.apply(ze,arguments)}function qe(e){var t=e,a=e;if(e.alternate)for(;t.return;)t=t.return;else{e=t;do{0!==(4098&(t=e).flags)&&(a=t.return),e=t.return}while(e)}return 3===t.tag?a:null}function _e(e){if(13===e.tag){var t=e.memoizedState;if(null===t&&(null!==(e=e.alternate)&&(t=e.memoizedState)),null!==t)return t.dehydrated}return null}function He(e){if(qe(e)!==e)throw Error(s(188))}function Be(e){return null!==(e=function(e){var t=e.alternate;if(!t){if(null===(t=qe(e)))throw Error(s(188));return t!==e?null:e}for(var a=e,n=t;;){var i=a.return;if(null===i)break;var r=i.alternate;if(null===r){if(null!==(n=i.return)){a=n;continue}break}if(i.child===r.child){for(r=i.child;r;){if(r===a)return He(i),e;if(r===n)return He(i),t;r=r.sibling}throw Error(s(188))}if(a.return!==n.return)a=i,n=r;else{for(var o=!1,l=i.child;l;){if(l===a){o=!0,a=i,n=r;break}if(l===n){o=!0,n=i,a=r;break}l=l.sibling}if(!o){for(l=r.child;l;){if(l===a){o=!0,a=r,n=i;break}if(l===n){o=!0,n=r,a=i;break}l=l.sibling}if(!o)throw Error(s(189))}}if(a.alternate!==n)throw Error(s(190))}if(3!==a.tag)throw Error(s(188));return a.stateNode.current===a?e:t}(e))?Ue(e):null}function Ue(e){if(5===e.tag||6===e.tag)return e;for(e=e.child;null!==e;){var t=Ue(e);if(null!==t)return t;e=e.sibling}return null}var Je=i.unstable_scheduleCallback,Qe=i.unstable_cancelCallback,Ve=i.unstable_shouldYield,Ye=i.unstable_requestPaint,Xe=i.unstable_now,Ze=i.unstable_getCurrentPriorityLevel,$e=i.unstable_ImmediatePriority,et=i.unstable_UserBlockingPriority,tt=i.unstable_NormalPriority,at=i.unstable_LowPriority,nt=i.unstable_IdlePriority,it=null,st=null;var rt=Math.clz32?Math.clz32:function(e){return e>>>=0,0===e?32:31-(ot(e)/lt|0)|0},ot=Math.log,lt=Math.LN2;var ct=64,dt=4194304;function ht(e){switch(e&-e){case 1:return 1;case 2:return 2;case 4:return 4;case 8:return 8;case 16:return 16;case 32:return 32;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return 4194240&e;case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:return 130023424&e;case 134217728:return 134217728;case 268435456:return 268435456;case 536870912:return 536870912;case 1073741824:return 1073741824;default:return e}}function ut(e,t){var a=e.pendingLanes;if(0===a)return 0;var n=0,i=e.suspendedLanes,s=e.pingedLanes,r=268435455&a;if(0!==r){var o=r&~i;0!==o?n=ht(o):0!==(s&=r)&&(n=ht(s))}else 0!==(r=a&~i)?n=ht(r):0!==s&&(n=ht(s));if(0===n)return 0;if(0!==t&&t!==n&&0===(t&i)&&((i=n&-n)>=(s=t&-t)||16===i&&0!==(4194240&s)))return t;if(0!==(4&n)&&(n|=16&a),0!==(t=e.entangledLanes))for(e=e.entanglements,t&=n;0<t;)i=1<<(a=31-rt(t)),n|=e[a],t&=~i;return n}function pt(e,t){switch(e){case 1:case 2:case 4:return t+250;case 8:case 16:case 32:case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:return t+5e3;default:return-1}}function mt(e){return 0!==(e=-1073741825&e.pendingLanes)?e:1073741824&e?1073741824:0}function gt(){var e=ct;return 0===(4194240&(ct<<=1))&&(ct=64),e}function ft(e){for(var t=[],a=0;31>a;a++)t.push(e);return t}function bt(e,t,a){e.pendingLanes|=t,536870912!==t&&(e.suspendedLanes=0,e.pingedLanes=0),(e=e.eventTimes)[t=31-rt(t)]=a}function yt(e,t){var a=e.entangledLanes|=t;for(e=e.entanglements;a;){var n=31-rt(a),i=1<<n;i&t|e[n]&t&&(e[n]|=t),a&=~i}}var xt=0;function vt(e){return 1<(e&=-e)?4<e?0!==(268435455&e)?16:536870912:4:1}var wt,jt,kt,St,Nt,Ct=!1,Tt=[],At=null,Lt=null,It=null,Pt=new Map,Rt=new Map,Et=[],Dt="mousedown mouseup touchcancel touchend touchstart auxclick dblclick pointercancel pointerdown pointerup dragend dragstart drop compositionend compositionstart keydown keypress keyup input textInput copy cut paste click change contextmenu reset submit".split(" ");function Wt(e,t){switch(e){case"focusin":case"focusout":At=null;break;case"dragenter":case"dragleave":Lt=null;break;case"mouseover":case"mouseout":It=null;break;case"pointerover":case"pointerout":Pt.delete(t.pointerId);break;case"gotpointercapture":case"lostpointercapture":Rt.delete(t.pointerId)}}function Mt(e,t,a,n,i,s){return null===e||e.nativeEvent!==s?(e={blockedOn:t,domEventName:a,eventSystemFlags:n,nativeEvent:s,targetContainers:[i]},null!==t&&(null!==(t=xi(t))&&jt(t)),e):(e.eventSystemFlags|=n,t=e.targetContainers,null!==i&&-1===t.indexOf(i)&&t.push(i),e)}function Gt(e){var t=yi(e.target);if(null!==t){var a=qe(t);if(null!==a)if(13===(t=a.tag)){if(null!==(t=_e(a)))return e.blockedOn=t,void Nt(e.priority,(function(){kt(a)}))}else if(3===t&&a.stateNode.current.memoizedState.isDehydrated)return void(e.blockedOn=3===a.tag?a.stateNode.containerInfo:null)}e.blockedOn=null}function Ot(e){if(null!==e.blockedOn)return!1;for(var t=e.targetContainers;0<t.length;){var a=Vt(e.domEventName,e.eventSystemFlags,t[0],e.nativeEvent);if(null!==a)return null!==(t=xi(a))&&jt(t),e.blockedOn=a,!1;var n=new(a=e.nativeEvent).constructor(a.type,a);ve=n,a.target.dispatchEvent(n),ve=null,t.shift()}return!0}function Ft(e,t,a){Ot(e)&&a.delete(t)}function zt(){Ct=!1,null!==At&&Ot(At)&&(At=null),null!==Lt&&Ot(Lt)&&(Lt=null),null!==It&&Ot(It)&&(It=null),Pt.forEach(Ft),Rt.forEach(Ft)}function Kt(e,t){e.blockedOn===t&&(e.blockedOn=null,Ct||(Ct=!0,i.unstable_scheduleCallback(i.unstable_NormalPriority,zt)))}function qt(e){function t(t){return Kt(t,e)}if(0<Tt.length){Kt(Tt[0],e);for(var a=1;a<Tt.length;a++){var n=Tt[a];n.blockedOn===e&&(n.blockedOn=null)}}for(null!==At&&Kt(At,e),null!==Lt&&Kt(Lt,e),null!==It&&Kt(It,e),Pt.forEach(t),Rt.forEach(t),a=0;a<Et.length;a++)(n=Et[a]).blockedOn===e&&(n.blockedOn=null);for(;0<Et.length&&null===(a=Et[0]).blockedOn;)Gt(a),null===a.blockedOn&&Et.shift()}var _t=v.ReactCurrentBatchConfig,Ht=!0;function Bt(e,t,a,n){var i=xt,s=_t.transition;_t.transition=null;try{xt=1,Jt(e,t,a,n)}finally{xt=i,_t.transition=s}}function Ut(e,t,a,n){var i=xt,s=_t.transition;_t.transition=null;try{xt=4,Jt(e,t,a,n)}finally{xt=i,_t.transition=s}}function Jt(e,t,a,n){if(Ht){var i=Vt(e,t,a,n);if(null===i)Hn(e,t,n,Qt,a),Wt(e,n);else if(function(e,t,a,n,i){switch(t){case"focusin":return At=Mt(At,e,t,a,n,i),!0;case"dragenter":return Lt=Mt(Lt,e,t,a,n,i),!0;case"mouseover":return It=Mt(It,e,t,a,n,i),!0;case"pointerover":var s=i.pointerId;return Pt.set(s,Mt(Pt.get(s)||null,e,t,a,n,i)),!0;case"gotpointercapture":return s=i.pointerId,Rt.set(s,Mt(Rt.get(s)||null,e,t,a,n,i)),!0}return!1}(i,e,t,a,n))n.stopPropagation();else if(Wt(e,n),4&t&&-1<Dt.indexOf(e)){for(;null!==i;){var s=xi(i);if(null!==s&&wt(s),null===(s=Vt(e,t,a,n))&&Hn(e,t,n,Qt,a),s===i)break;i=s}null!==i&&n.stopPropagation()}else Hn(e,t,n,null,a)}}var Qt=null;function Vt(e,t,a,n){if(Qt=null,null!==(e=yi(e=we(n))))if(null===(t=qe(e)))e=null;else if(13===(a=t.tag)){if(null!==(e=_e(t)))return e;e=null}else if(3===a){if(t.stateNode.current.memoizedState.isDehydrated)return 3===t.tag?t.stateNode.containerInfo:null;e=null}else t!==e&&(e=null);return Qt=e,null}function Yt(e){switch(e){case"cancel":case"click":case"close":case"contextmenu":case"copy":case"cut":case"auxclick":case"dblclick":case"dragend":case"dragstart":case"drop":case"focusin":case"focusout":case"input":case"invalid":case"keydown":case"keypress":case"keyup":case"mousedown":case"mouseup":case"paste":case"pause":case"play":case"pointercancel":case"pointerdown":case"pointerup":case"ratechange":case"reset":case"resize":case"seeked":case"submit":case"touchcancel":case"touchend":case"touchstart":case"volumechange":case"change":case"selectionchange":case"textInput":case"compositionstart":case"compositionend":case"compositionupdate":case"beforeblur":case"afterblur":case"beforeinput":case"blur":case"fullscreenchange":case"focus":case"hashchange":case"popstate":case"select":case"selectstart":return 1;case"drag":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"mousemove":case"mouseout":case"mouseover":case"pointermove":case"pointerout":case"pointerover":case"scroll":case"toggle":case"touchmove":case"wheel":case"mouseenter":case"mouseleave":case"pointerenter":case"pointerleave":return 4;case"message":switch(Ze()){case $e:return 1;case et:return 4;case tt:case at:return 16;case nt:return 536870912;default:return 16}default:return 16}}var Xt=null,Zt=null,$t=null;function ea(){if($t)return $t;var e,t,a=Zt,n=a.length,i="value"in Xt?Xt.value:Xt.textContent,s=i.length;for(e=0;e<n&&a[e]===i[e];e++);var r=n-e;for(t=1;t<=r&&a[n-t]===i[s-t];t++);return $t=i.slice(e,1<t?1-t:void 0)}function ta(e){var t=e.keyCode;return"charCode"in e?0===(e=e.charCode)&&13===t&&(e=13):e=t,10===e&&(e=13),32<=e||13===e?e:0}function aa(){return!0}function na(){return!1}function ia(e){function t(t,a,n,i,s){for(var r in this._reactName=t,this._targetInst=n,this.type=a,this.nativeEvent=i,this.target=s,this.currentTarget=null,e)e.hasOwnProperty(r)&&(t=e[r],this[r]=t?t(i):i[r]);return this.isDefaultPrevented=(null!=i.defaultPrevented?i.defaultPrevented:!1===i.returnValue)?aa:na,this.isPropagationStopped=na,this}return G(t.prototype,{preventDefault:function(){this.defaultPrevented=!0;var e=this.nativeEvent;e&&(e.preventDefault?e.preventDefault():"unknown"!==typeof e.returnValue&&(e.returnValue=!1),this.isDefaultPrevented=aa)},stopPropagation:function(){var e=this.nativeEvent;e&&(e.stopPropagation?e.stopPropagation():"unknown"!==typeof e.cancelBubble&&(e.cancelBubble=!0),this.isPropagationStopped=aa)},persist:function(){},isPersistent:aa}),t}var sa,ra,oa,la={eventPhase:0,bubbles:0,cancelable:0,timeStamp:function(e){return e.timeStamp||Date.now()},defaultPrevented:0,isTrusted:0},ca=ia(la),da=G({},la,{view:0,detail:0}),ha=ia(da),ua=G({},da,{screenX:0,screenY:0,clientX:0,clientY:0,pageX:0,pageY:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,getModifierState:Sa,button:0,buttons:0,relatedTarget:function(e){return void 0===e.relatedTarget?e.fromElement===e.srcElement?e.toElement:e.fromElement:e.relatedTarget},movementX:function(e){return"movementX"in e?e.movementX:(e!==oa&&(oa&&"mousemove"===e.type?(sa=e.screenX-oa.screenX,ra=e.screenY-oa.screenY):ra=sa=0,oa=e),sa)},movementY:function(e){return"movementY"in e?e.movementY:ra}}),pa=ia(ua),ma=ia(G({},ua,{dataTransfer:0})),ga=ia(G({},da,{relatedTarget:0})),fa=ia(G({},la,{animationName:0,elapsedTime:0,pseudoElement:0})),ba=G({},la,{clipboardData:function(e){return"clipboardData"in e?e.clipboardData:window.clipboardData}}),ya=ia(ba),xa=ia(G({},la,{data:0})),va={Esc:"Escape",Spacebar:" ",Left:"ArrowLeft",Up:"ArrowUp",Right:"ArrowRight",Down:"ArrowDown",Del:"Delete",Win:"OS",Menu:"ContextMenu",Apps:"ContextMenu",Scroll:"ScrollLock",MozPrintableKey:"Unidentified"},wa={8:"Backspace",9:"Tab",12:"Clear",13:"Enter",16:"Shift",17:"Control",18:"Alt",19:"Pause",20:"CapsLock",27:"Escape",32:" ",33:"PageUp",34:"PageDown",35:"End",36:"Home",37:"ArrowLeft",38:"ArrowUp",39:"ArrowRight",40:"ArrowDown",45:"Insert",46:"Delete",112:"F1",113:"F2",114:"F3",115:"F4",116:"F5",117:"F6",118:"F7",119:"F8",120:"F9",121:"F10",122:"F11",123:"F12",144:"NumLock",145:"ScrollLock",224:"Meta"},ja={Alt:"altKey",Control:"ctrlKey",Meta:"metaKey",Shift:"shiftKey"};function ka(e){var t=this.nativeEvent;return t.getModifierState?t.getModifierState(e):!!(e=ja[e])&&!!t[e]}function Sa(){return ka}var Na=G({},da,{key:function(e){if(e.key){var t=va[e.key]||e.key;if("Unidentified"!==t)return t}return"keypress"===e.type?13===(e=ta(e))?"Enter":String.fromCharCode(e):"keydown"===e.type||"keyup"===e.type?wa[e.keyCode]||"Unidentified":""},code:0,location:0,ctrlKey:0,shiftKey:0,altKey:0,metaKey:0,repeat:0,locale:0,getModifierState:Sa,charCode:function(e){return"keypress"===e.type?ta(e):0},keyCode:function(e){return"keydown"===e.type||"keyup"===e.type?e.keyCode:0},which:function(e){return"keypress"===e.type?ta(e):"keydown"===e.type||"keyup"===e.type?e.keyCode:0}}),Ca=ia(Na),Ta=ia(G({},ua,{pointerId:0,width:0,height:0,pressure:0,tangentialPressure:0,tiltX:0,tiltY:0,twist:0,pointerType:0,isPrimary:0})),Aa=ia(G({},da,{touches:0,targetTouches:0,changedTouches:0,altKey:0,metaKey:0,ctrlKey:0,shiftKey:0,getModifierState:Sa})),La=ia(G({},la,{propertyName:0,elapsedTime:0,pseudoElement:0})),Ia=G({},ua,{deltaX:function(e){return"deltaX"in e?e.deltaX:"wheelDeltaX"in e?-e.wheelDeltaX:0},deltaY:function(e){return"deltaY"in e?e.deltaY:"wheelDeltaY"in e?-e.wheelDeltaY:"wheelDelta"in e?-e.wheelDelta:0},deltaZ:0,deltaMode:0}),Pa=ia(Ia),Ra=[9,13,27,32],Ea=d&&"CompositionEvent"in window,Da=null;d&&"documentMode"in document&&(Da=document.documentMode);var Wa=d&&"TextEvent"in window&&!Da,Ma=d&&(!Ea||Da&&8<Da&&11>=Da),Ga=String.fromCharCode(32),Oa=!1;function Fa(e,t){switch(e){case"keyup":return-1!==Ra.indexOf(t.keyCode);case"keydown":return 229!==t.keyCode;case"keypress":case"mousedown":case"focusout":return!0;default:return!1}}function za(e){return"object"===typeof(e=e.detail)&&"data"in e?e.data:null}var Ka=!1;var qa={color:!0,date:!0,datetime:!0,"datetime-local":!0,email:!0,month:!0,number:!0,password:!0,range:!0,search:!0,tel:!0,text:!0,time:!0,url:!0,week:!0};function _a(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return"input"===t?!!qa[e.type]:"textarea"===t}function Ha(e,t,a,n){Ce(n),0<(t=Un(t,"onChange")).length&&(a=new ca("onChange","change",null,a,n),e.push({event:a,listeners:t}))}var Ba=null,Ua=null;function Ja(e){On(e,0)}function Qa(e){if(J(vi(e)))return e}function Va(e,t){if("change"===e)return t}var Ya=!1;if(d){var Xa;if(d){var Za="oninput"in document;if(!Za){var $a=document.createElement("div");$a.setAttribute("oninput","return;"),Za="function"===typeof $a.oninput}Xa=Za}else Xa=!1;Ya=Xa&&(!document.documentMode||9<document.documentMode)}function en(){Ba&&(Ba.detachEvent("onpropertychange",tn),Ua=Ba=null)}function tn(e){if("value"===e.propertyName&&Qa(Ua)){var t=[];Ha(t,Ua,e,we(e)),Pe(Ja,t)}}function an(e,t,a){"focusin"===e?(en(),Ua=a,(Ba=t).attachEvent("onpropertychange",tn)):"focusout"===e&&en()}function nn(e){if("selectionchange"===e||"keyup"===e||"keydown"===e)return Qa(Ua)}function sn(e,t){if("click"===e)return Qa(t)}function rn(e,t){if("input"===e||"change"===e)return Qa(t)}var on="function"===typeof Object.is?Object.is:function(e,t){return e===t&&(0!==e||1/e===1/t)||e!==e&&t!==t};function ln(e,t){if(on(e,t))return!0;if("object"!==typeof e||null===e||"object"!==typeof t||null===t)return!1;var a=Object.keys(e),n=Object.keys(t);if(a.length!==n.length)return!1;for(n=0;n<a.length;n++){var i=a[n];if(!h.call(t,i)||!on(e[i],t[i]))return!1}return!0}function cn(e){for(;e&&e.firstChild;)e=e.firstChild;return e}function dn(e,t){var a,n=cn(e);for(e=0;n;){if(3===n.nodeType){if(a=e+n.textContent.length,e<=t&&a>=t)return{node:n,offset:t-e};e=a}e:{for(;n;){if(n.nextSibling){n=n.nextSibling;break e}n=n.parentNode}n=void 0}n=cn(n)}}function hn(e,t){return!(!e||!t)&&(e===t||(!e||3!==e.nodeType)&&(t&&3===t.nodeType?hn(e,t.parentNode):"contains"in e?e.contains(t):!!e.compareDocumentPosition&&!!(16&e.compareDocumentPosition(t))))}function un(){for(var e=window,t=Q();t instanceof e.HTMLIFrameElement;){try{var a="string"===typeof t.contentWindow.location.href}catch(n){a=!1}if(!a)break;t=Q((e=t.contentWindow).document)}return t}function pn(e){var t=e&&e.nodeName&&e.nodeName.toLowerCase();return t&&("input"===t&&("text"===e.type||"search"===e.type||"tel"===e.type||"url"===e.type||"password"===e.type)||"textarea"===t||"true"===e.contentEditable)}function mn(e){var t=un(),a=e.focusedElem,n=e.selectionRange;if(t!==a&&a&&a.ownerDocument&&hn(a.ownerDocument.documentElement,a)){if(null!==n&&pn(a))if(t=n.start,void 0===(e=n.end)&&(e=t),"selectionStart"in a)a.selectionStart=t,a.selectionEnd=Math.min(e,a.value.length);else if((e=(t=a.ownerDocument||document)&&t.defaultView||window).getSelection){e=e.getSelection();var i=a.textContent.length,s=Math.min(n.start,i);n=void 0===n.end?s:Math.min(n.end,i),!e.extend&&s>n&&(i=n,n=s,s=i),i=dn(a,s);var r=dn(a,n);i&&r&&(1!==e.rangeCount||e.anchorNode!==i.node||e.anchorOffset!==i.offset||e.focusNode!==r.node||e.focusOffset!==r.offset)&&((t=t.createRange()).setStart(i.node,i.offset),e.removeAllRanges(),s>n?(e.addRange(t),e.extend(r.node,r.offset)):(t.setEnd(r.node,r.offset),e.addRange(t)))}for(t=[],e=a;e=e.parentNode;)1===e.nodeType&&t.push({element:e,left:e.scrollLeft,top:e.scrollTop});for("function"===typeof a.focus&&a.focus(),a=0;a<t.length;a++)(e=t[a]).element.scrollLeft=e.left,e.element.scrollTop=e.top}}var gn=d&&"documentMode"in document&&11>=document.documentMode,fn=null,bn=null,yn=null,xn=!1;function vn(e,t,a){var n=a.window===a?a.document:9===a.nodeType?a:a.ownerDocument;xn||null==fn||fn!==Q(n)||("selectionStart"in(n=fn)&&pn(n)?n={start:n.selectionStart,end:n.selectionEnd}:n={anchorNode:(n=(n.ownerDocument&&n.ownerDocument.defaultView||window).getSelection()).anchorNode,anchorOffset:n.anchorOffset,focusNode:n.focusNode,focusOffset:n.focusOffset},yn&&ln(yn,n)||(yn=n,0<(n=Un(bn,"onSelect")).length&&(t=new ca("onSelect","select",null,t,a),e.push({event:t,listeners:n}),t.target=fn)))}function wn(e,t){var a={};return a[e.toLowerCase()]=t.toLowerCase(),a["Webkit"+e]="webkit"+t,a["Moz"+e]="moz"+t,a}var jn={animationend:wn("Animation","AnimationEnd"),animationiteration:wn("Animation","AnimationIteration"),animationstart:wn("Animation","AnimationStart"),transitionend:wn("Transition","TransitionEnd")},kn={},Sn={};function Nn(e){if(kn[e])return kn[e];if(!jn[e])return e;var t,a=jn[e];for(t in a)if(a.hasOwnProperty(t)&&t in Sn)return kn[e]=a[t];return e}d&&(Sn=document.createElement("div").style,"AnimationEvent"in window||(delete jn.animationend.animation,delete jn.animationiteration.animation,delete jn.animationstart.animation),"TransitionEvent"in window||delete jn.transitionend.transition);var Cn=Nn("animationend"),Tn=Nn("animationiteration"),An=Nn("animationstart"),Ln=Nn("transitionend"),In=new Map,Pn="abort auxClick cancel canPlay canPlayThrough click close contextMenu copy cut drag dragEnd dragEnter dragExit dragLeave dragOver dragStart drop durationChange emptied encrypted ended error gotPointerCapture input invalid keyDown keyPress keyUp load loadedData loadedMetadata loadStart lostPointerCapture mouseDown mouseMove mouseOut mouseOver mouseUp paste pause play playing pointerCancel pointerDown pointerMove pointerOut pointerOver pointerUp progress rateChange reset resize seeked seeking stalled submit suspend timeUpdate touchCancel touchEnd touchStart volumeChange scroll toggle touchMove waiting wheel".split(" ");function Rn(e,t){In.set(e,t),l(t,[e])}for(var En=0;En<Pn.length;En++){var Dn=Pn[En];Rn(Dn.toLowerCase(),"on"+(Dn[0].toUpperCase()+Dn.slice(1)))}Rn(Cn,"onAnimationEnd"),Rn(Tn,"onAnimationIteration"),Rn(An,"onAnimationStart"),Rn("dblclick","onDoubleClick"),Rn("focusin","onFocus"),Rn("focusout","onBlur"),Rn(Ln,"onTransitionEnd"),c("onMouseEnter",["mouseout","mouseover"]),c("onMouseLeave",["mouseout","mouseover"]),c("onPointerEnter",["pointerout","pointerover"]),c("onPointerLeave",["pointerout","pointerover"]),l("onChange","change click focusin focusout input keydown keyup selectionchange".split(" ")),l("onSelect","focusout contextmenu dragend focusin keydown keyup mousedown mouseup selectionchange".split(" ")),l("onBeforeInput",["compositionend","keypress","textInput","paste"]),l("onCompositionEnd","compositionend focusout keydown keypress keyup mousedown".split(" ")),l("onCompositionStart","compositionstart focusout keydown keypress keyup mousedown".split(" ")),l("onCompositionUpdate","compositionupdate focusout keydown keypress keyup mousedown".split(" "));var Wn="abort canplay canplaythrough durationchange emptied encrypted ended error loadeddata loadedmetadata loadstart pause play playing progress ratechange resize seeked seeking stalled suspend timeupdate volumechange waiting".split(" "),Mn=new Set("cancel close invalid load scroll toggle".split(" ").concat(Wn));function Gn(e,t,a){var n=e.type||"unknown-event";e.currentTarget=a,function(e,t,a,n,i,r,o,l,c){if(Ke.apply(this,arguments),Me){if(!Me)throw Error(s(198));var d=Ge;Me=!1,Ge=null,Oe||(Oe=!0,Fe=d)}}(n,t,void 0,e),e.currentTarget=null}function On(e,t){t=0!==(4&t);for(var a=0;a<e.length;a++){var n=e[a],i=n.event;n=n.listeners;e:{var s=void 0;if(t)for(var r=n.length-1;0<=r;r--){var o=n[r],l=o.instance,c=o.currentTarget;if(o=o.listener,l!==s&&i.isPropagationStopped())break e;Gn(i,o,c),s=l}else for(r=0;r<n.length;r++){if(l=(o=n[r]).instance,c=o.currentTarget,o=o.listener,l!==s&&i.isPropagationStopped())break e;Gn(i,o,c),s=l}}}if(Oe)throw e=Fe,Oe=!1,Fe=null,e}function Fn(e,t){var a=t[gi];void 0===a&&(a=t[gi]=new Set);var n=e+"__bubble";a.has(n)||(_n(t,e,2,!1),a.add(n))}function zn(e,t,a){var n=0;t&&(n|=4),_n(a,e,n,t)}var Kn="_reactListening"+Math.random().toString(36).slice(2);function qn(e){if(!e[Kn]){e[Kn]=!0,r.forEach((function(t){"selectionchange"!==t&&(Mn.has(t)||zn(t,!1,e),zn(t,!0,e))}));var t=9===e.nodeType?e:e.ownerDocument;null===t||t[Kn]||(t[Kn]=!0,zn("selectionchange",!1,t))}}function _n(e,t,a,n){switch(Yt(t)){case 1:var i=Bt;break;case 4:i=Ut;break;default:i=Jt}a=i.bind(null,t,a,e),i=void 0,!Ee||"touchstart"!==t&&"touchmove"!==t&&"wheel"!==t||(i=!0),n?void 0!==i?e.addEventListener(t,a,{capture:!0,passive:i}):e.addEventListener(t,a,!0):void 0!==i?e.addEventListener(t,a,{passive:i}):e.addEventListener(t,a,!1)}function Hn(e,t,a,n,i){var s=n;if(0===(1&t)&&0===(2&t)&&null!==n)e:for(;;){if(null===n)return;var r=n.tag;if(3===r||4===r){var o=n.stateNode.containerInfo;if(o===i||8===o.nodeType&&o.parentNode===i)break;if(4===r)for(r=n.return;null!==r;){var l=r.tag;if((3===l||4===l)&&((l=r.stateNode.containerInfo)===i||8===l.nodeType&&l.parentNode===i))return;r=r.return}for(;null!==o;){if(null===(r=yi(o)))return;if(5===(l=r.tag)||6===l){n=s=r;continue e}o=o.parentNode}}n=n.return}Pe((function(){var n=s,i=we(a),r=[];e:{var o=In.get(e);if(void 0!==o){var l=ca,c=e;switch(e){case"keypress":if(0===ta(a))break e;case"keydown":case"keyup":l=Ca;break;case"focusin":c="focus",l=ga;break;case"focusout":c="blur",l=ga;break;case"beforeblur":case"afterblur":l=ga;break;case"click":if(2===a.button)break e;case"auxclick":case"dblclick":case"mousedown":case"mousemove":case"mouseup":case"mouseout":case"mouseover":case"contextmenu":l=pa;break;case"drag":case"dragend":case"dragenter":case"dragexit":case"dragleave":case"dragover":case"dragstart":case"drop":l=ma;break;case"touchcancel":case"touchend":case"touchmove":case"touchstart":l=Aa;break;case Cn:case Tn:case An:l=fa;break;case Ln:l=La;break;case"scroll":l=ha;break;case"wheel":l=Pa;break;case"copy":case"cut":case"paste":l=ya;break;case"gotpointercapture":case"lostpointercapture":case"pointercancel":case"pointerdown":case"pointermove":case"pointerout":case"pointerover":case"pointerup":l=Ta}var d=0!==(4&t),h=!d&&"scroll"===e,u=d?null!==o?o+"Capture":null:o;d=[];for(var p,m=n;null!==m;){var g=(p=m).stateNode;if(5===p.tag&&null!==g&&(p=g,null!==u&&(null!=(g=Re(m,u))&&d.push(Bn(m,g,p)))),h)break;m=m.return}0<d.length&&(o=new l(o,c,null,a,i),r.push({event:o,listeners:d}))}}if(0===(7&t)){if(l="mouseout"===e||"pointerout"===e,(!(o="mouseover"===e||"pointerover"===e)||a===ve||!(c=a.relatedTarget||a.fromElement)||!yi(c)&&!c[mi])&&(l||o)&&(o=i.window===i?i:(o=i.ownerDocument)?o.defaultView||o.parentWindow:window,l?(l=n,null!==(c=(c=a.relatedTarget||a.toElement)?yi(c):null)&&(c!==(h=qe(c))||5!==c.tag&&6!==c.tag)&&(c=null)):(l=null,c=n),l!==c)){if(d=pa,g="onMouseLeave",u="onMouseEnter",m="mouse","pointerout"!==e&&"pointerover"!==e||(d=Ta,g="onPointerLeave",u="onPointerEnter",m="pointer"),h=null==l?o:vi(l),p=null==c?o:vi(c),(o=new d(g,m+"leave",l,a,i)).target=h,o.relatedTarget=p,g=null,yi(i)===n&&((d=new d(u,m+"enter",c,a,i)).target=p,d.relatedTarget=h,g=d),h=g,l&&c)e:{for(u=c,m=0,p=d=l;p;p=Jn(p))m++;for(p=0,g=u;g;g=Jn(g))p++;for(;0<m-p;)d=Jn(d),m--;for(;0<p-m;)u=Jn(u),p--;for(;m--;){if(d===u||null!==u&&d===u.alternate)break e;d=Jn(d),u=Jn(u)}d=null}else d=null;null!==l&&Qn(r,o,l,d,!1),null!==c&&null!==h&&Qn(r,h,c,d,!0)}if("select"===(l=(o=n?vi(n):window).nodeName&&o.nodeName.toLowerCase())||"input"===l&&"file"===o.type)var f=Va;else if(_a(o))if(Ya)f=rn;else{f=nn;var b=an}else(l=o.nodeName)&&"input"===l.toLowerCase()&&("checkbox"===o.type||"radio"===o.type)&&(f=sn);switch(f&&(f=f(e,n))?Ha(r,f,a,i):(b&&b(e,o,n),"focusout"===e&&(b=o._wrapperState)&&b.controlled&&"number"===o.type&&ee(o,"number",o.value)),b=n?vi(n):window,e){case"focusin":(_a(b)||"true"===b.contentEditable)&&(fn=b,bn=n,yn=null);break;case"focusout":yn=bn=fn=null;break;case"mousedown":xn=!0;break;case"contextmenu":case"mouseup":case"dragend":xn=!1,vn(r,a,i);break;case"selectionchange":if(gn)break;case"keydown":case"keyup":vn(r,a,i)}var y;if(Ea)e:{switch(e){case"compositionstart":var x="onCompositionStart";break e;case"compositionend":x="onCompositionEnd";break e;case"compositionupdate":x="onCompositionUpdate";break e}x=void 0}else Ka?Fa(e,a)&&(x="onCompositionEnd"):"keydown"===e&&229===a.keyCode&&(x="onCompositionStart");x&&(Ma&&"ko"!==a.locale&&(Ka||"onCompositionStart"!==x?"onCompositionEnd"===x&&Ka&&(y=ea()):(Zt="value"in(Xt=i)?Xt.value:Xt.textContent,Ka=!0)),0<(b=Un(n,x)).length&&(x=new xa(x,e,null,a,i),r.push({event:x,listeners:b}),y?x.data=y:null!==(y=za(a))&&(x.data=y))),(y=Wa?function(e,t){switch(e){case"compositionend":return za(t);case"keypress":return 32!==t.which?null:(Oa=!0,Ga);case"textInput":return(e=t.data)===Ga&&Oa?null:e;default:return null}}(e,a):function(e,t){if(Ka)return"compositionend"===e||!Ea&&Fa(e,t)?(e=ea(),$t=Zt=Xt=null,Ka=!1,e):null;switch(e){case"paste":default:return null;case"keypress":if(!(t.ctrlKey||t.altKey||t.metaKey)||t.ctrlKey&&t.altKey){if(t.char&&1<t.char.length)return t.char;if(t.which)return String.fromCharCode(t.which)}return null;case"compositionend":return Ma&&"ko"!==t.locale?null:t.data}}(e,a))&&(0<(n=Un(n,"onBeforeInput")).length&&(i=new xa("onBeforeInput","beforeinput",null,a,i),r.push({event:i,listeners:n}),i.data=y))}On(r,t)}))}function Bn(e,t,a){return{instance:e,listener:t,currentTarget:a}}function Un(e,t){for(var a=t+"Capture",n=[];null!==e;){var i=e,s=i.stateNode;5===i.tag&&null!==s&&(i=s,null!=(s=Re(e,a))&&n.unshift(Bn(e,s,i)),null!=(s=Re(e,t))&&n.push(Bn(e,s,i))),e=e.return}return n}function Jn(e){if(null===e)return null;do{e=e.return}while(e&&5!==e.tag);return e||null}function Qn(e,t,a,n,i){for(var s=t._reactName,r=[];null!==a&&a!==n;){var o=a,l=o.alternate,c=o.stateNode;if(null!==l&&l===n)break;5===o.tag&&null!==c&&(o=c,i?null!=(l=Re(a,s))&&r.unshift(Bn(a,l,o)):i||null!=(l=Re(a,s))&&r.push(Bn(a,l,o))),a=a.return}0!==r.length&&e.push({event:t,listeners:r})}var Vn=/\r\n?/g,Yn=/\u0000|\uFFFD/g;function Xn(e){return("string"===typeof e?e:""+e).replace(Vn,"\n").replace(Yn,"")}function Zn(e,t,a){if(t=Xn(t),Xn(e)!==t&&a)throw Error(s(425))}function $n(){}var ei=null,ti=null;function ai(e,t){return"textarea"===e||"noscript"===e||"string"===typeof t.children||"number"===typeof t.children||"object"===typeof t.dangerouslySetInnerHTML&&null!==t.dangerouslySetInnerHTML&&null!=t.dangerouslySetInnerHTML.__html}var ni="function"===typeof setTimeout?setTimeout:void 0,ii="function"===typeof clearTimeout?clearTimeout:void 0,si="function"===typeof Promise?Promise:void 0,ri="function"===typeof queueMicrotask?queueMicrotask:"undefined"!==typeof si?function(e){return si.resolve(null).then(e).catch(oi)}:ni;function oi(e){setTimeout((function(){throw e}))}function li(e,t){var a=t,n=0;do{var i=a.nextSibling;if(e.removeChild(a),i&&8===i.nodeType)if("/$"===(a=i.data)){if(0===n)return e.removeChild(i),void qt(t);n--}else"$"!==a&&"$?"!==a&&"$!"!==a||n++;a=i}while(a);qt(t)}function ci(e){for(;null!=e;e=e.nextSibling){var t=e.nodeType;if(1===t||3===t)break;if(8===t){if("$"===(t=e.data)||"$!"===t||"$?"===t)break;if("/$"===t)return null}}return e}function di(e){e=e.previousSibling;for(var t=0;e;){if(8===e.nodeType){var a=e.data;if("$"===a||"$!"===a||"$?"===a){if(0===t)return e;t--}else"/$"===a&&t++}e=e.previousSibling}return null}var hi=Math.random().toString(36).slice(2),ui="__reactFiber$"+hi,pi="__reactProps$"+hi,mi="__reactContainer$"+hi,gi="__reactEvents$"+hi,fi="__reactListeners$"+hi,bi="__reactHandles$"+hi;function yi(e){var t=e[ui];if(t)return t;for(var a=e.parentNode;a;){if(t=a[mi]||a[ui]){if(a=t.alternate,null!==t.child||null!==a&&null!==a.child)for(e=di(e);null!==e;){if(a=e[ui])return a;e=di(e)}return t}a=(e=a).parentNode}return null}function xi(e){return!(e=e[ui]||e[mi])||5!==e.tag&&6!==e.tag&&13!==e.tag&&3!==e.tag?null:e}function vi(e){if(5===e.tag||6===e.tag)return e.stateNode;throw Error(s(33))}function wi(e){return e[pi]||null}var ji=[],ki=-1;function Si(e){return{current:e}}function Ni(e){0>ki||(e.current=ji[ki],ji[ki]=null,ki--)}function Ci(e,t){ki++,ji[ki]=e.current,e.current=t}var Ti={},Ai=Si(Ti),Li=Si(!1),Ii=Ti;function Pi(e,t){var a=e.type.contextTypes;if(!a)return Ti;var n=e.stateNode;if(n&&n.__reactInternalMemoizedUnmaskedChildContext===t)return n.__reactInternalMemoizedMaskedChildContext;var i,s={};for(i in a)s[i]=t[i];return n&&((e=e.stateNode).__reactInternalMemoizedUnmaskedChildContext=t,e.__reactInternalMemoizedMaskedChildContext=s),s}function Ri(e){return null!==(e=e.childContextTypes)&&void 0!==e}function Ei(){Ni(Li),Ni(Ai)}function Di(e,t,a){if(Ai.current!==Ti)throw Error(s(168));Ci(Ai,t),Ci(Li,a)}function Wi(e,t,a){var n=e.stateNode;if(t=t.childContextTypes,"function"!==typeof n.getChildContext)return a;for(var i in n=n.getChildContext())if(!(i in t))throw Error(s(108,_(e)||"Unknown",i));return G({},a,n)}function Mi(e){return e=(e=e.stateNode)&&e.__reactInternalMemoizedMergedChildContext||Ti,Ii=Ai.current,Ci(Ai,e),Ci(Li,Li.current),!0}function Gi(e,t,a){var n=e.stateNode;if(!n)throw Error(s(169));a?(e=Wi(e,t,Ii),n.__reactInternalMemoizedMergedChildContext=e,Ni(Li),Ni(Ai),Ci(Ai,e)):Ni(Li),Ci(Li,a)}var Oi=null,Fi=!1,zi=!1;function Ki(e){null===Oi?Oi=[e]:Oi.push(e)}function qi(){if(!zi&&null!==Oi){zi=!0;var e=0,t=xt;try{var a=Oi;for(xt=1;e<a.length;e++){var n=a[e];do{n=n(!0)}while(null!==n)}Oi=null,Fi=!1}catch(i){throw null!==Oi&&(Oi=Oi.slice(e+1)),Je($e,qi),i}finally{xt=t,zi=!1}}return null}var _i=[],Hi=0,Bi=null,Ui=0,Ji=[],Qi=0,Vi=null,Yi=1,Xi="";function Zi(e,t){_i[Hi++]=Ui,_i[Hi++]=Bi,Bi=e,Ui=t}function $i(e,t,a){Ji[Qi++]=Yi,Ji[Qi++]=Xi,Ji[Qi++]=Vi,Vi=e;var n=Yi;e=Xi;var i=32-rt(n)-1;n&=~(1<<i),a+=1;var s=32-rt(t)+i;if(30<s){var r=i-i%5;s=(n&(1<<r)-1).toString(32),n>>=r,i-=r,Yi=1<<32-rt(t)+i|a<<i|n,Xi=s+e}else Yi=1<<s|a<<i|n,Xi=e}function es(e){null!==e.return&&(Zi(e,1),$i(e,1,0))}function ts(e){for(;e===Bi;)Bi=_i[--Hi],_i[Hi]=null,Ui=_i[--Hi],_i[Hi]=null;for(;e===Vi;)Vi=Ji[--Qi],Ji[Qi]=null,Xi=Ji[--Qi],Ji[Qi]=null,Yi=Ji[--Qi],Ji[Qi]=null}var as=null,ns=null,is=!1,ss=null;function rs(e,t){var a=Pc(5,null,null,0);a.elementType="DELETED",a.stateNode=t,a.return=e,null===(t=e.deletions)?(e.deletions=[a],e.flags|=16):t.push(a)}function os(e,t){switch(e.tag){case 5:var a=e.type;return null!==(t=1!==t.nodeType||a.toLowerCase()!==t.nodeName.toLowerCase()?null:t)&&(e.stateNode=t,as=e,ns=ci(t.firstChild),!0);case 6:return null!==(t=""===e.pendingProps||3!==t.nodeType?null:t)&&(e.stateNode=t,as=e,ns=null,!0);case 13:return null!==(t=8!==t.nodeType?null:t)&&(a=null!==Vi?{id:Yi,overflow:Xi}:null,e.memoizedState={dehydrated:t,treeContext:a,retryLane:1073741824},(a=Pc(18,null,null,0)).stateNode=t,a.return=e,e.child=a,as=e,ns=null,!0);default:return!1}}function ls(e){return 0!==(1&e.mode)&&0===(128&e.flags)}function cs(e){if(is){var t=ns;if(t){var a=t;if(!os(e,t)){if(ls(e))throw Error(s(418));t=ci(a.nextSibling);var n=as;t&&os(e,t)?rs(n,a):(e.flags=-4097&e.flags|2,is=!1,as=e)}}else{if(ls(e))throw Error(s(418));e.flags=-4097&e.flags|2,is=!1,as=e}}}function ds(e){for(e=e.return;null!==e&&5!==e.tag&&3!==e.tag&&13!==e.tag;)e=e.return;as=e}function hs(e){if(e!==as)return!1;if(!is)return ds(e),is=!0,!1;var t;if((t=3!==e.tag)&&!(t=5!==e.tag)&&(t="head"!==(t=e.type)&&"body"!==t&&!ai(e.type,e.memoizedProps)),t&&(t=ns)){if(ls(e))throw us(),Error(s(418));for(;t;)rs(e,t),t=ci(t.nextSibling)}if(ds(e),13===e.tag){if(!(e=null!==(e=e.memoizedState)?e.dehydrated:null))throw Error(s(317));e:{for(e=e.nextSibling,t=0;e;){if(8===e.nodeType){var a=e.data;if("/$"===a){if(0===t){ns=ci(e.nextSibling);break e}t--}else"$"!==a&&"$!"!==a&&"$?"!==a||t++}e=e.nextSibling}ns=null}}else ns=as?ci(e.stateNode.nextSibling):null;return!0}function us(){for(var e=ns;e;)e=ci(e.nextSibling)}function ps(){ns=as=null,is=!1}function ms(e){null===ss?ss=[e]:ss.push(e)}var gs=v.ReactCurrentBatchConfig;function fs(e,t,a){if(null!==(e=a.ref)&&"function"!==typeof e&&"object"!==typeof e){if(a._owner){if(a=a._owner){if(1!==a.tag)throw Error(s(309));var n=a.stateNode}if(!n)throw Error(s(147,e));var i=n,r=""+e;return null!==t&&null!==t.ref&&"function"===typeof t.ref&&t.ref._stringRef===r?t.ref:(t=function(e){var t=i.refs;null===e?delete t[r]:t[r]=e},t._stringRef=r,t)}if("string"!==typeof e)throw Error(s(284));if(!a._owner)throw Error(s(290,e))}return e}function bs(e,t){throw e=Object.prototype.toString.call(t),Error(s(31,"[object Object]"===e?"object with keys {"+Object.keys(t).join(", ")+"}":e))}function ys(e){return(0,e._init)(e._payload)}function xs(e){function t(t,a){if(e){var n=t.deletions;null===n?(t.deletions=[a],t.flags|=16):n.push(a)}}function a(a,n){if(!e)return null;for(;null!==n;)t(a,n),n=n.sibling;return null}function n(e,t){for(e=new Map;null!==t;)null!==t.key?e.set(t.key,t):e.set(t.index,t),t=t.sibling;return e}function i(e,t){return(e=Ec(e,t)).index=0,e.sibling=null,e}function r(t,a,n){return t.index=n,e?null!==(n=t.alternate)?(n=n.index)<a?(t.flags|=2,a):n:(t.flags|=2,a):(t.flags|=1048576,a)}function o(t){return e&&null===t.alternate&&(t.flags|=2),t}function l(e,t,a,n){return null===t||6!==t.tag?((t=Gc(a,e.mode,n)).return=e,t):((t=i(t,a)).return=e,t)}function c(e,t,a,n){var s=a.type;return s===k?h(e,t,a.props.children,n,a.key):null!==t&&(t.elementType===s||"object"===typeof s&&null!==s&&s.$$typeof===R&&ys(s)===t.type)?((n=i(t,a.props)).ref=fs(e,t,a),n.return=e,n):((n=Dc(a.type,a.key,a.props,null,e.mode,n)).ref=fs(e,t,a),n.return=e,n)}function d(e,t,a,n){return null===t||4!==t.tag||t.stateNode.containerInfo!==a.containerInfo||t.stateNode.implementation!==a.implementation?((t=Oc(a,e.mode,n)).return=e,t):((t=i(t,a.children||[])).return=e,t)}function h(e,t,a,n,s){return null===t||7!==t.tag?((t=Wc(a,e.mode,n,s)).return=e,t):((t=i(t,a)).return=e,t)}function u(e,t,a){if("string"===typeof t&&""!==t||"number"===typeof t)return(t=Gc(""+t,e.mode,a)).return=e,t;if("object"===typeof t&&null!==t){switch(t.$$typeof){case w:return(a=Dc(t.type,t.key,t.props,null,e.mode,a)).ref=fs(e,null,t),a.return=e,a;case j:return(t=Oc(t,e.mode,a)).return=e,t;case R:return u(e,(0,t._init)(t._payload),a)}if(te(t)||W(t))return(t=Wc(t,e.mode,a,null)).return=e,t;bs(e,t)}return null}function p(e,t,a,n){var i=null!==t?t.key:null;if("string"===typeof a&&""!==a||"number"===typeof a)return null!==i?null:l(e,t,""+a,n);if("object"===typeof a&&null!==a){switch(a.$$typeof){case w:return a.key===i?c(e,t,a,n):null;case j:return a.key===i?d(e,t,a,n):null;case R:return p(e,t,(i=a._init)(a._payload),n)}if(te(a)||W(a))return null!==i?null:h(e,t,a,n,null);bs(e,a)}return null}function m(e,t,a,n,i){if("string"===typeof n&&""!==n||"number"===typeof n)return l(t,e=e.get(a)||null,""+n,i);if("object"===typeof n&&null!==n){switch(n.$$typeof){case w:return c(t,e=e.get(null===n.key?a:n.key)||null,n,i);case j:return d(t,e=e.get(null===n.key?a:n.key)||null,n,i);case R:return m(e,t,a,(0,n._init)(n._payload),i)}if(te(n)||W(n))return h(t,e=e.get(a)||null,n,i,null);bs(t,n)}return null}function g(i,s,o,l){for(var c=null,d=null,h=s,g=s=0,f=null;null!==h&&g<o.length;g++){h.index>g?(f=h,h=null):f=h.sibling;var b=p(i,h,o[g],l);if(null===b){null===h&&(h=f);break}e&&h&&null===b.alternate&&t(i,h),s=r(b,s,g),null===d?c=b:d.sibling=b,d=b,h=f}if(g===o.length)return a(i,h),is&&Zi(i,g),c;if(null===h){for(;g<o.length;g++)null!==(h=u(i,o[g],l))&&(s=r(h,s,g),null===d?c=h:d.sibling=h,d=h);return is&&Zi(i,g),c}for(h=n(i,h);g<o.length;g++)null!==(f=m(h,i,g,o[g],l))&&(e&&null!==f.alternate&&h.delete(null===f.key?g:f.key),s=r(f,s,g),null===d?c=f:d.sibling=f,d=f);return e&&h.forEach((function(e){return t(i,e)})),is&&Zi(i,g),c}function f(i,o,l,c){var d=W(l);if("function"!==typeof d)throw Error(s(150));if(null==(l=d.call(l)))throw Error(s(151));for(var h=d=null,g=o,f=o=0,b=null,y=l.next();null!==g&&!y.done;f++,y=l.next()){g.index>f?(b=g,g=null):b=g.sibling;var x=p(i,g,y.value,c);if(null===x){null===g&&(g=b);break}e&&g&&null===x.alternate&&t(i,g),o=r(x,o,f),null===h?d=x:h.sibling=x,h=x,g=b}if(y.done)return a(i,g),is&&Zi(i,f),d;if(null===g){for(;!y.done;f++,y=l.next())null!==(y=u(i,y.value,c))&&(o=r(y,o,f),null===h?d=y:h.sibling=y,h=y);return is&&Zi(i,f),d}for(g=n(i,g);!y.done;f++,y=l.next())null!==(y=m(g,i,f,y.value,c))&&(e&&null!==y.alternate&&g.delete(null===y.key?f:y.key),o=r(y,o,f),null===h?d=y:h.sibling=y,h=y);return e&&g.forEach((function(e){return t(i,e)})),is&&Zi(i,f),d}return function e(n,s,r,l){if("object"===typeof r&&null!==r&&r.type===k&&null===r.key&&(r=r.props.children),"object"===typeof r&&null!==r){switch(r.$$typeof){case w:e:{for(var c=r.key,d=s;null!==d;){if(d.key===c){if((c=r.type)===k){if(7===d.tag){a(n,d.sibling),(s=i(d,r.props.children)).return=n,n=s;break e}}else if(d.elementType===c||"object"===typeof c&&null!==c&&c.$$typeof===R&&ys(c)===d.type){a(n,d.sibling),(s=i(d,r.props)).ref=fs(n,d,r),s.return=n,n=s;break e}a(n,d);break}t(n,d),d=d.sibling}r.type===k?((s=Wc(r.props.children,n.mode,l,r.key)).return=n,n=s):((l=Dc(r.type,r.key,r.props,null,n.mode,l)).ref=fs(n,s,r),l.return=n,n=l)}return o(n);case j:e:{for(d=r.key;null!==s;){if(s.key===d){if(4===s.tag&&s.stateNode.containerInfo===r.containerInfo&&s.stateNode.implementation===r.implementation){a(n,s.sibling),(s=i(s,r.children||[])).return=n,n=s;break e}a(n,s);break}t(n,s),s=s.sibling}(s=Oc(r,n.mode,l)).return=n,n=s}return o(n);case R:return e(n,s,(d=r._init)(r._payload),l)}if(te(r))return g(n,s,r,l);if(W(r))return f(n,s,r,l);bs(n,r)}return"string"===typeof r&&""!==r||"number"===typeof r?(r=""+r,null!==s&&6===s.tag?(a(n,s.sibling),(s=i(s,r)).return=n,n=s):(a(n,s),(s=Gc(r,n.mode,l)).return=n,n=s),o(n)):a(n,s)}}var vs=xs(!0),ws=xs(!1),js=Si(null),ks=null,Ss=null,Ns=null;function Cs(){Ns=Ss=ks=null}function Ts(e){var t=js.current;Ni(js),e._currentValue=t}function As(e,t,a){for(;null!==e;){var n=e.alternate;if((e.childLanes&t)!==t?(e.childLanes|=t,null!==n&&(n.childLanes|=t)):null!==n&&(n.childLanes&t)!==t&&(n.childLanes|=t),e===a)break;e=e.return}}function Ls(e,t){ks=e,Ns=Ss=null,null!==(e=e.dependencies)&&null!==e.firstContext&&(0!==(e.lanes&t)&&(xo=!0),e.firstContext=null)}function Is(e){var t=e._currentValue;if(Ns!==e)if(e={context:e,memoizedValue:t,next:null},null===Ss){if(null===ks)throw Error(s(308));Ss=e,ks.dependencies={lanes:0,firstContext:e}}else Ss=Ss.next=e;return t}var Ps=null;function Rs(e){null===Ps?Ps=[e]:Ps.push(e)}function Es(e,t,a,n){var i=t.interleaved;return null===i?(a.next=a,Rs(t)):(a.next=i.next,i.next=a),t.interleaved=a,Ds(e,n)}function Ds(e,t){e.lanes|=t;var a=e.alternate;for(null!==a&&(a.lanes|=t),a=e,e=e.return;null!==e;)e.childLanes|=t,null!==(a=e.alternate)&&(a.childLanes|=t),a=e,e=e.return;return 3===a.tag?a.stateNode:null}var Ws=!1;function Ms(e){e.updateQueue={baseState:e.memoizedState,firstBaseUpdate:null,lastBaseUpdate:null,shared:{pending:null,interleaved:null,lanes:0},effects:null}}function Gs(e,t){e=e.updateQueue,t.updateQueue===e&&(t.updateQueue={baseState:e.baseState,firstBaseUpdate:e.firstBaseUpdate,lastBaseUpdate:e.lastBaseUpdate,shared:e.shared,effects:e.effects})}function Os(e,t){return{eventTime:e,lane:t,tag:0,payload:null,callback:null,next:null}}function Fs(e,t,a){var n=e.updateQueue;if(null===n)return null;if(n=n.shared,0!==(2&Al)){var i=n.pending;return null===i?t.next=t:(t.next=i.next,i.next=t),n.pending=t,Ds(e,a)}return null===(i=n.interleaved)?(t.next=t,Rs(n)):(t.next=i.next,i.next=t),n.interleaved=t,Ds(e,a)}function zs(e,t,a){if(null!==(t=t.updateQueue)&&(t=t.shared,0!==(4194240&a))){var n=t.lanes;a|=n&=e.pendingLanes,t.lanes=a,yt(e,a)}}function Ks(e,t){var a=e.updateQueue,n=e.alternate;if(null!==n&&a===(n=n.updateQueue)){var i=null,s=null;if(null!==(a=a.firstBaseUpdate)){do{var r={eventTime:a.eventTime,lane:a.lane,tag:a.tag,payload:a.payload,callback:a.callback,next:null};null===s?i=s=r:s=s.next=r,a=a.next}while(null!==a);null===s?i=s=t:s=s.next=t}else i=s=t;return a={baseState:n.baseState,firstBaseUpdate:i,lastBaseUpdate:s,shared:n.shared,effects:n.effects},void(e.updateQueue=a)}null===(e=a.lastBaseUpdate)?a.firstBaseUpdate=t:e.next=t,a.lastBaseUpdate=t}function qs(e,t,a,n){var i=e.updateQueue;Ws=!1;var s=i.firstBaseUpdate,r=i.lastBaseUpdate,o=i.shared.pending;if(null!==o){i.shared.pending=null;var l=o,c=l.next;l.next=null,null===r?s=c:r.next=c,r=l;var d=e.alternate;null!==d&&((o=(d=d.updateQueue).lastBaseUpdate)!==r&&(null===o?d.firstBaseUpdate=c:o.next=c,d.lastBaseUpdate=l))}if(null!==s){var h=i.baseState;for(r=0,d=c=l=null,o=s;;){var u=o.lane,p=o.eventTime;if((n&u)===u){null!==d&&(d=d.next={eventTime:p,lane:0,tag:o.tag,payload:o.payload,callback:o.callback,next:null});e:{var m=e,g=o;switch(u=t,p=a,g.tag){case 1:if("function"===typeof(m=g.payload)){h=m.call(p,h,u);break e}h=m;break e;case 3:m.flags=-65537&m.flags|128;case 0:if(null===(u="function"===typeof(m=g.payload)?m.call(p,h,u):m)||void 0===u)break e;h=G({},h,u);break e;case 2:Ws=!0}}null!==o.callback&&0!==o.lane&&(e.flags|=64,null===(u=i.effects)?i.effects=[o]:u.push(o))}else p={eventTime:p,lane:u,tag:o.tag,payload:o.payload,callback:o.callback,next:null},null===d?(c=d=p,l=h):d=d.next=p,r|=u;if(null===(o=o.next)){if(null===(o=i.shared.pending))break;o=(u=o).next,u.next=null,i.lastBaseUpdate=u,i.shared.pending=null}}if(null===d&&(l=h),i.baseState=l,i.firstBaseUpdate=c,i.lastBaseUpdate=d,null!==(t=i.shared.interleaved)){i=t;do{r|=i.lane,i=i.next}while(i!==t)}else null===s&&(i.shared.lanes=0);Ml|=r,e.lanes=r,e.memoizedState=h}}function _s(e,t,a){if(e=t.effects,t.effects=null,null!==e)for(t=0;t<e.length;t++){var n=e[t],i=n.callback;if(null!==i){if(n.callback=null,n=a,"function"!==typeof i)throw Error(s(191,i));i.call(n)}}}var Hs={},Bs=Si(Hs),Us=Si(Hs),Js=Si(Hs);function Qs(e){if(e===Hs)throw Error(s(174));return e}function Vs(e,t){switch(Ci(Js,t),Ci(Us,e),Ci(Bs,Hs),e=t.nodeType){case 9:case 11:t=(t=t.documentElement)?t.namespaceURI:le(null,"");break;default:t=le(t=(e=8===e?t.parentNode:t).namespaceURI||null,e=e.tagName)}Ni(Bs),Ci(Bs,t)}function Ys(){Ni(Bs),Ni(Us),Ni(Js)}function Xs(e){Qs(Js.current);var t=Qs(Bs.current),a=le(t,e.type);t!==a&&(Ci(Us,e),Ci(Bs,a))}function Zs(e){Us.current===e&&(Ni(Bs),Ni(Us))}var $s=Si(0);function er(e){for(var t=e;null!==t;){if(13===t.tag){var a=t.memoizedState;if(null!==a&&(null===(a=a.dehydrated)||"$?"===a.data||"$!"===a.data))return t}else if(19===t.tag&&void 0!==t.memoizedProps.revealOrder){if(0!==(128&t.flags))return t}else if(null!==t.child){t.child.return=t,t=t.child;continue}if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return null;t=t.return}t.sibling.return=t.return,t=t.sibling}return null}var tr=[];function ar(){for(var e=0;e<tr.length;e++)tr[e]._workInProgressVersionPrimary=null;tr.length=0}var nr=v.ReactCurrentDispatcher,ir=v.ReactCurrentBatchConfig,sr=0,rr=null,or=null,lr=null,cr=!1,dr=!1,hr=0,ur=0;function pr(){throw Error(s(321))}function mr(e,t){if(null===t)return!1;for(var a=0;a<t.length&&a<e.length;a++)if(!on(e[a],t[a]))return!1;return!0}function gr(e,t,a,n,i,r){if(sr=r,rr=t,t.memoizedState=null,t.updateQueue=null,t.lanes=0,nr.current=null===e||null===e.memoizedState?Zr:$r,e=a(n,i),dr){r=0;do{if(dr=!1,hr=0,25<=r)throw Error(s(301));r+=1,lr=or=null,t.updateQueue=null,nr.current=eo,e=a(n,i)}while(dr)}if(nr.current=Xr,t=null!==or&&null!==or.next,sr=0,lr=or=rr=null,cr=!1,t)throw Error(s(300));return e}function fr(){var e=0!==hr;return hr=0,e}function br(){var e={memoizedState:null,baseState:null,baseQueue:null,queue:null,next:null};return null===lr?rr.memoizedState=lr=e:lr=lr.next=e,lr}function yr(){if(null===or){var e=rr.alternate;e=null!==e?e.memoizedState:null}else e=or.next;var t=null===lr?rr.memoizedState:lr.next;if(null!==t)lr=t,or=e;else{if(null===e)throw Error(s(310));e={memoizedState:(or=e).memoizedState,baseState:or.baseState,baseQueue:or.baseQueue,queue:or.queue,next:null},null===lr?rr.memoizedState=lr=e:lr=lr.next=e}return lr}function xr(e,t){return"function"===typeof t?t(e):t}function vr(e){var t=yr(),a=t.queue;if(null===a)throw Error(s(311));a.lastRenderedReducer=e;var n=or,i=n.baseQueue,r=a.pending;if(null!==r){if(null!==i){var o=i.next;i.next=r.next,r.next=o}n.baseQueue=i=r,a.pending=null}if(null!==i){r=i.next,n=n.baseState;var l=o=null,c=null,d=r;do{var h=d.lane;if((sr&h)===h)null!==c&&(c=c.next={lane:0,action:d.action,hasEagerState:d.hasEagerState,eagerState:d.eagerState,next:null}),n=d.hasEagerState?d.eagerState:e(n,d.action);else{var u={lane:h,action:d.action,hasEagerState:d.hasEagerState,eagerState:d.eagerState,next:null};null===c?(l=c=u,o=n):c=c.next=u,rr.lanes|=h,Ml|=h}d=d.next}while(null!==d&&d!==r);null===c?o=n:c.next=l,on(n,t.memoizedState)||(xo=!0),t.memoizedState=n,t.baseState=o,t.baseQueue=c,a.lastRenderedState=n}if(null!==(e=a.interleaved)){i=e;do{r=i.lane,rr.lanes|=r,Ml|=r,i=i.next}while(i!==e)}else null===i&&(a.lanes=0);return[t.memoizedState,a.dispatch]}function wr(e){var t=yr(),a=t.queue;if(null===a)throw Error(s(311));a.lastRenderedReducer=e;var n=a.dispatch,i=a.pending,r=t.memoizedState;if(null!==i){a.pending=null;var o=i=i.next;do{r=e(r,o.action),o=o.next}while(o!==i);on(r,t.memoizedState)||(xo=!0),t.memoizedState=r,null===t.baseQueue&&(t.baseState=r),a.lastRenderedState=r}return[r,n]}function jr(){}function kr(e,t){var a=rr,n=yr(),i=t(),r=!on(n.memoizedState,i);if(r&&(n.memoizedState=i,xo=!0),n=n.queue,Wr(Cr.bind(null,a,n,e),[e]),n.getSnapshot!==t||r||null!==lr&&1&lr.memoizedState.tag){if(a.flags|=2048,Ir(9,Nr.bind(null,a,n,i,t),void 0,null),null===Ll)throw Error(s(349));0!==(30&sr)||Sr(a,t,i)}return i}function Sr(e,t,a){e.flags|=16384,e={getSnapshot:t,value:a},null===(t=rr.updateQueue)?(t={lastEffect:null,stores:null},rr.updateQueue=t,t.stores=[e]):null===(a=t.stores)?t.stores=[e]:a.push(e)}function Nr(e,t,a,n){t.value=a,t.getSnapshot=n,Tr(t)&&Ar(e)}function Cr(e,t,a){return a((function(){Tr(t)&&Ar(e)}))}function Tr(e){var t=e.getSnapshot;e=e.value;try{var a=t();return!on(e,a)}catch(n){return!0}}function Ar(e){var t=Ds(e,1);null!==t&&ac(t,e,1,-1)}function Lr(e){var t=br();return"function"===typeof e&&(e=e()),t.memoizedState=t.baseState=e,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:xr,lastRenderedState:e},t.queue=e,e=e.dispatch=Jr.bind(null,rr,e),[t.memoizedState,e]}function Ir(e,t,a,n){return e={tag:e,create:t,destroy:a,deps:n,next:null},null===(t=rr.updateQueue)?(t={lastEffect:null,stores:null},rr.updateQueue=t,t.lastEffect=e.next=e):null===(a=t.lastEffect)?t.lastEffect=e.next=e:(n=a.next,a.next=e,e.next=n,t.lastEffect=e),e}function Pr(){return yr().memoizedState}function Rr(e,t,a,n){var i=br();rr.flags|=e,i.memoizedState=Ir(1|t,a,void 0,void 0===n?null:n)}function Er(e,t,a,n){var i=yr();n=void 0===n?null:n;var s=void 0;if(null!==or){var r=or.memoizedState;if(s=r.destroy,null!==n&&mr(n,r.deps))return void(i.memoizedState=Ir(t,a,s,n))}rr.flags|=e,i.memoizedState=Ir(1|t,a,s,n)}function Dr(e,t){return Rr(8390656,8,e,t)}function Wr(e,t){return Er(2048,8,e,t)}function Mr(e,t){return Er(4,2,e,t)}function Gr(e,t){return Er(4,4,e,t)}function Or(e,t){return"function"===typeof t?(e=e(),t(e),function(){t(null)}):null!==t&&void 0!==t?(e=e(),t.current=e,function(){t.current=null}):void 0}function Fr(e,t,a){return a=null!==a&&void 0!==a?a.concat([e]):null,Er(4,4,Or.bind(null,t,e),a)}function zr(){}function Kr(e,t){var a=yr();t=void 0===t?null:t;var n=a.memoizedState;return null!==n&&null!==t&&mr(t,n[1])?n[0]:(a.memoizedState=[e,t],e)}function qr(e,t){var a=yr();t=void 0===t?null:t;var n=a.memoizedState;return null!==n&&null!==t&&mr(t,n[1])?n[0]:(e=e(),a.memoizedState=[e,t],e)}function _r(e,t,a){return 0===(21&sr)?(e.baseState&&(e.baseState=!1,xo=!0),e.memoizedState=a):(on(a,t)||(a=gt(),rr.lanes|=a,Ml|=a,e.baseState=!0),t)}function Hr(e,t){var a=xt;xt=0!==a&&4>a?a:4,e(!0);var n=ir.transition;ir.transition={};try{e(!1),t()}finally{xt=a,ir.transition=n}}function Br(){return yr().memoizedState}function Ur(e,t,a){var n=tc(e);if(a={lane:n,action:a,hasEagerState:!1,eagerState:null,next:null},Qr(e))Vr(t,a);else if(null!==(a=Es(e,t,a,n))){ac(a,e,n,ec()),Yr(a,t,n)}}function Jr(e,t,a){var n=tc(e),i={lane:n,action:a,hasEagerState:!1,eagerState:null,next:null};if(Qr(e))Vr(t,i);else{var s=e.alternate;if(0===e.lanes&&(null===s||0===s.lanes)&&null!==(s=t.lastRenderedReducer))try{var r=t.lastRenderedState,o=s(r,a);if(i.hasEagerState=!0,i.eagerState=o,on(o,r)){var l=t.interleaved;return null===l?(i.next=i,Rs(t)):(i.next=l.next,l.next=i),void(t.interleaved=i)}}catch(c){}null!==(a=Es(e,t,i,n))&&(ac(a,e,n,i=ec()),Yr(a,t,n))}}function Qr(e){var t=e.alternate;return e===rr||null!==t&&t===rr}function Vr(e,t){dr=cr=!0;var a=e.pending;null===a?t.next=t:(t.next=a.next,a.next=t),e.pending=t}function Yr(e,t,a){if(0!==(4194240&a)){var n=t.lanes;a|=n&=e.pendingLanes,t.lanes=a,yt(e,a)}}var Xr={readContext:Is,useCallback:pr,useContext:pr,useEffect:pr,useImperativeHandle:pr,useInsertionEffect:pr,useLayoutEffect:pr,useMemo:pr,useReducer:pr,useRef:pr,useState:pr,useDebugValue:pr,useDeferredValue:pr,useTransition:pr,useMutableSource:pr,useSyncExternalStore:pr,useId:pr,unstable_isNewReconciler:!1},Zr={readContext:Is,useCallback:function(e,t){return br().memoizedState=[e,void 0===t?null:t],e},useContext:Is,useEffect:Dr,useImperativeHandle:function(e,t,a){return a=null!==a&&void 0!==a?a.concat([e]):null,Rr(4194308,4,Or.bind(null,t,e),a)},useLayoutEffect:function(e,t){return Rr(4194308,4,e,t)},useInsertionEffect:function(e,t){return Rr(4,2,e,t)},useMemo:function(e,t){var a=br();return t=void 0===t?null:t,e=e(),a.memoizedState=[e,t],e},useReducer:function(e,t,a){var n=br();return t=void 0!==a?a(t):t,n.memoizedState=n.baseState=t,e={pending:null,interleaved:null,lanes:0,dispatch:null,lastRenderedReducer:e,lastRenderedState:t},n.queue=e,e=e.dispatch=Ur.bind(null,rr,e),[n.memoizedState,e]},useRef:function(e){return e={current:e},br().memoizedState=e},useState:Lr,useDebugValue:zr,useDeferredValue:function(e){return br().memoizedState=e},useTransition:function(){var e=Lr(!1),t=e[0];return e=Hr.bind(null,e[1]),br().memoizedState=e,[t,e]},useMutableSource:function(){},useSyncExternalStore:function(e,t,a){var n=rr,i=br();if(is){if(void 0===a)throw Error(s(407));a=a()}else{if(a=t(),null===Ll)throw Error(s(349));0!==(30&sr)||Sr(n,t,a)}i.memoizedState=a;var r={value:a,getSnapshot:t};return i.queue=r,Dr(Cr.bind(null,n,r,e),[e]),n.flags|=2048,Ir(9,Nr.bind(null,n,r,a,t),void 0,null),a},useId:function(){var e=br(),t=Ll.identifierPrefix;if(is){var a=Xi;t=":"+t+"R"+(a=(Yi&~(1<<32-rt(Yi)-1)).toString(32)+a),0<(a=hr++)&&(t+="H"+a.toString(32)),t+=":"}else t=":"+t+"r"+(a=ur++).toString(32)+":";return e.memoizedState=t},unstable_isNewReconciler:!1},$r={readContext:Is,useCallback:Kr,useContext:Is,useEffect:Wr,useImperativeHandle:Fr,useInsertionEffect:Mr,useLayoutEffect:Gr,useMemo:qr,useReducer:vr,useRef:Pr,useState:function(){return vr(xr)},useDebugValue:zr,useDeferredValue:function(e){return _r(yr(),or.memoizedState,e)},useTransition:function(){return[vr(xr)[0],yr().memoizedState]},useMutableSource:jr,useSyncExternalStore:kr,useId:Br,unstable_isNewReconciler:!1},eo={readContext:Is,useCallback:Kr,useContext:Is,useEffect:Wr,useImperativeHandle:Fr,useInsertionEffect:Mr,useLayoutEffect:Gr,useMemo:qr,useReducer:wr,useRef:Pr,useState:function(){return wr(xr)},useDebugValue:zr,useDeferredValue:function(e){var t=yr();return null===or?t.memoizedState=e:_r(t,or.memoizedState,e)},useTransition:function(){return[wr(xr)[0],yr().memoizedState]},useMutableSource:jr,useSyncExternalStore:kr,useId:Br,unstable_isNewReconciler:!1};function to(e,t){if(e&&e.defaultProps){for(var a in t=G({},t),e=e.defaultProps)void 0===t[a]&&(t[a]=e[a]);return t}return t}function ao(e,t,a,n){a=null===(a=a(n,t=e.memoizedState))||void 0===a?t:G({},t,a),e.memoizedState=a,0===e.lanes&&(e.updateQueue.baseState=a)}var no={isMounted:function(e){return!!(e=e._reactInternals)&&qe(e)===e},enqueueSetState:function(e,t,a){e=e._reactInternals;var n=ec(),i=tc(e),s=Os(n,i);s.payload=t,void 0!==a&&null!==a&&(s.callback=a),null!==(t=Fs(e,s,i))&&(ac(t,e,i,n),zs(t,e,i))},enqueueReplaceState:function(e,t,a){e=e._reactInternals;var n=ec(),i=tc(e),s=Os(n,i);s.tag=1,s.payload=t,void 0!==a&&null!==a&&(s.callback=a),null!==(t=Fs(e,s,i))&&(ac(t,e,i,n),zs(t,e,i))},enqueueForceUpdate:function(e,t){e=e._reactInternals;var a=ec(),n=tc(e),i=Os(a,n);i.tag=2,void 0!==t&&null!==t&&(i.callback=t),null!==(t=Fs(e,i,n))&&(ac(t,e,n,a),zs(t,e,n))}};function io(e,t,a,n,i,s,r){return"function"===typeof(e=e.stateNode).shouldComponentUpdate?e.shouldComponentUpdate(n,s,r):!t.prototype||!t.prototype.isPureReactComponent||(!ln(a,n)||!ln(i,s))}function so(e,t,a){var n=!1,i=Ti,s=t.contextType;return"object"===typeof s&&null!==s?s=Is(s):(i=Ri(t)?Ii:Ai.current,s=(n=null!==(n=t.contextTypes)&&void 0!==n)?Pi(e,i):Ti),t=new t(a,s),e.memoizedState=null!==t.state&&void 0!==t.state?t.state:null,t.updater=no,e.stateNode=t,t._reactInternals=e,n&&((e=e.stateNode).__reactInternalMemoizedUnmaskedChildContext=i,e.__reactInternalMemoizedMaskedChildContext=s),t}function ro(e,t,a,n){e=t.state,"function"===typeof t.componentWillReceiveProps&&t.componentWillReceiveProps(a,n),"function"===typeof t.UNSAFE_componentWillReceiveProps&&t.UNSAFE_componentWillReceiveProps(a,n),t.state!==e&&no.enqueueReplaceState(t,t.state,null)}function oo(e,t,a,n){var i=e.stateNode;i.props=a,i.state=e.memoizedState,i.refs={},Ms(e);var s=t.contextType;"object"===typeof s&&null!==s?i.context=Is(s):(s=Ri(t)?Ii:Ai.current,i.context=Pi(e,s)),i.state=e.memoizedState,"function"===typeof(s=t.getDerivedStateFromProps)&&(ao(e,t,s,a),i.state=e.memoizedState),"function"===typeof t.getDerivedStateFromProps||"function"===typeof i.getSnapshotBeforeUpdate||"function"!==typeof i.UNSAFE_componentWillMount&&"function"!==typeof i.componentWillMount||(t=i.state,"function"===typeof i.componentWillMount&&i.componentWillMount(),"function"===typeof i.UNSAFE_componentWillMount&&i.UNSAFE_componentWillMount(),t!==i.state&&no.enqueueReplaceState(i,i.state,null),qs(e,a,i,n),i.state=e.memoizedState),"function"===typeof i.componentDidMount&&(e.flags|=4194308)}function lo(e,t){try{var a="",n=t;do{a+=K(n),n=n.return}while(n);var i=a}catch(s){i="\nError generating stack: "+s.message+"\n"+s.stack}return{value:e,source:t,stack:i,digest:null}}function co(e,t,a){return{value:e,source:null,stack:null!=a?a:null,digest:null!=t?t:null}}function ho(e,t){try{console.error(t.value)}catch(a){setTimeout((function(){throw a}))}}var uo="function"===typeof WeakMap?WeakMap:Map;function po(e,t,a){(a=Os(-1,a)).tag=3,a.payload={element:null};var n=t.value;return a.callback=function(){Hl||(Hl=!0,Bl=n),ho(0,t)},a}function mo(e,t,a){(a=Os(-1,a)).tag=3;var n=e.type.getDerivedStateFromError;if("function"===typeof n){var i=t.value;a.payload=function(){return n(i)},a.callback=function(){ho(0,t)}}var s=e.stateNode;return null!==s&&"function"===typeof s.componentDidCatch&&(a.callback=function(){ho(0,t),"function"!==typeof n&&(null===Ul?Ul=new Set([this]):Ul.add(this));var e=t.stack;this.componentDidCatch(t.value,{componentStack:null!==e?e:""})}),a}function go(e,t,a){var n=e.pingCache;if(null===n){n=e.pingCache=new uo;var i=new Set;n.set(t,i)}else void 0===(i=n.get(t))&&(i=new Set,n.set(t,i));i.has(a)||(i.add(a),e=Nc.bind(null,e,t,a),t.then(e,e))}function fo(e){do{var t;if((t=13===e.tag)&&(t=null===(t=e.memoizedState)||null!==t.dehydrated),t)return e;e=e.return}while(null!==e);return null}function bo(e,t,a,n,i){return 0===(1&e.mode)?(e===t?e.flags|=65536:(e.flags|=128,a.flags|=131072,a.flags&=-52805,1===a.tag&&(null===a.alternate?a.tag=17:((t=Os(-1,1)).tag=2,Fs(a,t,1))),a.lanes|=1),e):(e.flags|=65536,e.lanes=i,e)}var yo=v.ReactCurrentOwner,xo=!1;function vo(e,t,a,n){t.child=null===e?ws(t,null,a,n):vs(t,e.child,a,n)}function wo(e,t,a,n,i){a=a.render;var s=t.ref;return Ls(t,i),n=gr(e,t,a,n,s,i),a=fr(),null===e||xo?(is&&a&&es(t),t.flags|=1,vo(e,t,n,i),t.child):(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~i,Ho(e,t,i))}function jo(e,t,a,n,i){if(null===e){var s=a.type;return"function"!==typeof s||Rc(s)||void 0!==s.defaultProps||null!==a.compare||void 0!==a.defaultProps?((e=Dc(a.type,null,n,t,t.mode,i)).ref=t.ref,e.return=t,t.child=e):(t.tag=15,t.type=s,ko(e,t,s,n,i))}if(s=e.child,0===(e.lanes&i)){var r=s.memoizedProps;if((a=null!==(a=a.compare)?a:ln)(r,n)&&e.ref===t.ref)return Ho(e,t,i)}return t.flags|=1,(e=Ec(s,n)).ref=t.ref,e.return=t,t.child=e}function ko(e,t,a,n,i){if(null!==e){var s=e.memoizedProps;if(ln(s,n)&&e.ref===t.ref){if(xo=!1,t.pendingProps=n=s,0===(e.lanes&i))return t.lanes=e.lanes,Ho(e,t,i);0!==(131072&e.flags)&&(xo=!0)}}return Co(e,t,a,n,i)}function So(e,t,a){var n=t.pendingProps,i=n.children,s=null!==e?e.memoizedState:null;if("hidden"===n.mode)if(0===(1&t.mode))t.memoizedState={baseLanes:0,cachePool:null,transitions:null},Ci(El,Rl),Rl|=a;else{if(0===(1073741824&a))return e=null!==s?s.baseLanes|a:a,t.lanes=t.childLanes=1073741824,t.memoizedState={baseLanes:e,cachePool:null,transitions:null},t.updateQueue=null,Ci(El,Rl),Rl|=e,null;t.memoizedState={baseLanes:0,cachePool:null,transitions:null},n=null!==s?s.baseLanes:a,Ci(El,Rl),Rl|=n}else null!==s?(n=s.baseLanes|a,t.memoizedState=null):n=a,Ci(El,Rl),Rl|=n;return vo(e,t,i,a),t.child}function No(e,t){var a=t.ref;(null===e&&null!==a||null!==e&&e.ref!==a)&&(t.flags|=512,t.flags|=2097152)}function Co(e,t,a,n,i){var s=Ri(a)?Ii:Ai.current;return s=Pi(t,s),Ls(t,i),a=gr(e,t,a,n,s,i),n=fr(),null===e||xo?(is&&n&&es(t),t.flags|=1,vo(e,t,a,i),t.child):(t.updateQueue=e.updateQueue,t.flags&=-2053,e.lanes&=~i,Ho(e,t,i))}function To(e,t,a,n,i){if(Ri(a)){var s=!0;Mi(t)}else s=!1;if(Ls(t,i),null===t.stateNode)_o(e,t),so(t,a,n),oo(t,a,n,i),n=!0;else if(null===e){var r=t.stateNode,o=t.memoizedProps;r.props=o;var l=r.context,c=a.contextType;"object"===typeof c&&null!==c?c=Is(c):c=Pi(t,c=Ri(a)?Ii:Ai.current);var d=a.getDerivedStateFromProps,h="function"===typeof d||"function"===typeof r.getSnapshotBeforeUpdate;h||"function"!==typeof r.UNSAFE_componentWillReceiveProps&&"function"!==typeof r.componentWillReceiveProps||(o!==n||l!==c)&&ro(t,r,n,c),Ws=!1;var u=t.memoizedState;r.state=u,qs(t,n,r,i),l=t.memoizedState,o!==n||u!==l||Li.current||Ws?("function"===typeof d&&(ao(t,a,d,n),l=t.memoizedState),(o=Ws||io(t,a,o,n,u,l,c))?(h||"function"!==typeof r.UNSAFE_componentWillMount&&"function"!==typeof r.componentWillMount||("function"===typeof r.componentWillMount&&r.componentWillMount(),"function"===typeof r.UNSAFE_componentWillMount&&r.UNSAFE_componentWillMount()),"function"===typeof r.componentDidMount&&(t.flags|=4194308)):("function"===typeof r.componentDidMount&&(t.flags|=4194308),t.memoizedProps=n,t.memoizedState=l),r.props=n,r.state=l,r.context=c,n=o):("function"===typeof r.componentDidMount&&(t.flags|=4194308),n=!1)}else{r=t.stateNode,Gs(e,t),o=t.memoizedProps,c=t.type===t.elementType?o:to(t.type,o),r.props=c,h=t.pendingProps,u=r.context,"object"===typeof(l=a.contextType)&&null!==l?l=Is(l):l=Pi(t,l=Ri(a)?Ii:Ai.current);var p=a.getDerivedStateFromProps;(d="function"===typeof p||"function"===typeof r.getSnapshotBeforeUpdate)||"function"!==typeof r.UNSAFE_componentWillReceiveProps&&"function"!==typeof r.componentWillReceiveProps||(o!==h||u!==l)&&ro(t,r,n,l),Ws=!1,u=t.memoizedState,r.state=u,qs(t,n,r,i);var m=t.memoizedState;o!==h||u!==m||Li.current||Ws?("function"===typeof p&&(ao(t,a,p,n),m=t.memoizedState),(c=Ws||io(t,a,c,n,u,m,l)||!1)?(d||"function"!==typeof r.UNSAFE_componentWillUpdate&&"function"!==typeof r.componentWillUpdate||("function"===typeof r.componentWillUpdate&&r.componentWillUpdate(n,m,l),"function"===typeof r.UNSAFE_componentWillUpdate&&r.UNSAFE_componentWillUpdate(n,m,l)),"function"===typeof r.componentDidUpdate&&(t.flags|=4),"function"===typeof r.getSnapshotBeforeUpdate&&(t.flags|=1024)):("function"!==typeof r.componentDidUpdate||o===e.memoizedProps&&u===e.memoizedState||(t.flags|=4),"function"!==typeof r.getSnapshotBeforeUpdate||o===e.memoizedProps&&u===e.memoizedState||(t.flags|=1024),t.memoizedProps=n,t.memoizedState=m),r.props=n,r.state=m,r.context=l,n=c):("function"!==typeof r.componentDidUpdate||o===e.memoizedProps&&u===e.memoizedState||(t.flags|=4),"function"!==typeof r.getSnapshotBeforeUpdate||o===e.memoizedProps&&u===e.memoizedState||(t.flags|=1024),n=!1)}return Ao(e,t,a,n,s,i)}function Ao(e,t,a,n,i,s){No(e,t);var r=0!==(128&t.flags);if(!n&&!r)return i&&Gi(t,a,!1),Ho(e,t,s);n=t.stateNode,yo.current=t;var o=r&&"function"!==typeof a.getDerivedStateFromError?null:n.render();return t.flags|=1,null!==e&&r?(t.child=vs(t,e.child,null,s),t.child=vs(t,null,o,s)):vo(e,t,o,s),t.memoizedState=n.state,i&&Gi(t,a,!0),t.child}function Lo(e){var t=e.stateNode;t.pendingContext?Di(0,t.pendingContext,t.pendingContext!==t.context):t.context&&Di(0,t.context,!1),Vs(e,t.containerInfo)}function Io(e,t,a,n,i){return ps(),ms(i),t.flags|=256,vo(e,t,a,n),t.child}var Po,Ro,Eo,Do,Wo={dehydrated:null,treeContext:null,retryLane:0};function Mo(e){return{baseLanes:e,cachePool:null,transitions:null}}function Go(e,t,a){var n,i=t.pendingProps,r=$s.current,o=!1,l=0!==(128&t.flags);if((n=l)||(n=(null===e||null!==e.memoizedState)&&0!==(2&r)),n?(o=!0,t.flags&=-129):null!==e&&null===e.memoizedState||(r|=1),Ci($s,1&r),null===e)return cs(t),null!==(e=t.memoizedState)&&null!==(e=e.dehydrated)?(0===(1&t.mode)?t.lanes=1:"$!"===e.data?t.lanes=8:t.lanes=1073741824,null):(l=i.children,e=i.fallback,o?(i=t.mode,o=t.child,l={mode:"hidden",children:l},0===(1&i)&&null!==o?(o.childLanes=0,o.pendingProps=l):o=Mc(l,i,0,null),e=Wc(e,i,a,null),o.return=t,e.return=t,o.sibling=e,t.child=o,t.child.memoizedState=Mo(a),t.memoizedState=Wo,e):Oo(t,l));if(null!==(r=e.memoizedState)&&null!==(n=r.dehydrated))return function(e,t,a,n,i,r,o){if(a)return 256&t.flags?(t.flags&=-257,Fo(e,t,o,n=co(Error(s(422))))):null!==t.memoizedState?(t.child=e.child,t.flags|=128,null):(r=n.fallback,i=t.mode,n=Mc({mode:"visible",children:n.children},i,0,null),(r=Wc(r,i,o,null)).flags|=2,n.return=t,r.return=t,n.sibling=r,t.child=n,0!==(1&t.mode)&&vs(t,e.child,null,o),t.child.memoizedState=Mo(o),t.memoizedState=Wo,r);if(0===(1&t.mode))return Fo(e,t,o,null);if("$!"===i.data){if(n=i.nextSibling&&i.nextSibling.dataset)var l=n.dgst;return n=l,Fo(e,t,o,n=co(r=Error(s(419)),n,void 0))}if(l=0!==(o&e.childLanes),xo||l){if(null!==(n=Ll)){switch(o&-o){case 4:i=2;break;case 16:i=8;break;case 64:case 128:case 256:case 512:case 1024:case 2048:case 4096:case 8192:case 16384:case 32768:case 65536:case 131072:case 262144:case 524288:case 1048576:case 2097152:case 4194304:case 8388608:case 16777216:case 33554432:case 67108864:i=32;break;case 536870912:i=268435456;break;default:i=0}0!==(i=0!==(i&(n.suspendedLanes|o))?0:i)&&i!==r.retryLane&&(r.retryLane=i,Ds(e,i),ac(n,e,i,-1))}return gc(),Fo(e,t,o,n=co(Error(s(421))))}return"$?"===i.data?(t.flags|=128,t.child=e.child,t=Tc.bind(null,e),i._reactRetry=t,null):(e=r.treeContext,ns=ci(i.nextSibling),as=t,is=!0,ss=null,null!==e&&(Ji[Qi++]=Yi,Ji[Qi++]=Xi,Ji[Qi++]=Vi,Yi=e.id,Xi=e.overflow,Vi=t),t=Oo(t,n.children),t.flags|=4096,t)}(e,t,l,i,n,r,a);if(o){o=i.fallback,l=t.mode,n=(r=e.child).sibling;var c={mode:"hidden",children:i.children};return 0===(1&l)&&t.child!==r?((i=t.child).childLanes=0,i.pendingProps=c,t.deletions=null):(i=Ec(r,c)).subtreeFlags=14680064&r.subtreeFlags,null!==n?o=Ec(n,o):(o=Wc(o,l,a,null)).flags|=2,o.return=t,i.return=t,i.sibling=o,t.child=i,i=o,o=t.child,l=null===(l=e.child.memoizedState)?Mo(a):{baseLanes:l.baseLanes|a,cachePool:null,transitions:l.transitions},o.memoizedState=l,o.childLanes=e.childLanes&~a,t.memoizedState=Wo,i}return e=(o=e.child).sibling,i=Ec(o,{mode:"visible",children:i.children}),0===(1&t.mode)&&(i.lanes=a),i.return=t,i.sibling=null,null!==e&&(null===(a=t.deletions)?(t.deletions=[e],t.flags|=16):a.push(e)),t.child=i,t.memoizedState=null,i}function Oo(e,t){return(t=Mc({mode:"visible",children:t},e.mode,0,null)).return=e,e.child=t}function Fo(e,t,a,n){return null!==n&&ms(n),vs(t,e.child,null,a),(e=Oo(t,t.pendingProps.children)).flags|=2,t.memoizedState=null,e}function zo(e,t,a){e.lanes|=t;var n=e.alternate;null!==n&&(n.lanes|=t),As(e.return,t,a)}function Ko(e,t,a,n,i){var s=e.memoizedState;null===s?e.memoizedState={isBackwards:t,rendering:null,renderingStartTime:0,last:n,tail:a,tailMode:i}:(s.isBackwards=t,s.rendering=null,s.renderingStartTime=0,s.last=n,s.tail=a,s.tailMode=i)}function qo(e,t,a){var n=t.pendingProps,i=n.revealOrder,s=n.tail;if(vo(e,t,n.children,a),0!==(2&(n=$s.current)))n=1&n|2,t.flags|=128;else{if(null!==e&&0!==(128&e.flags))e:for(e=t.child;null!==e;){if(13===e.tag)null!==e.memoizedState&&zo(e,a,t);else if(19===e.tag)zo(e,a,t);else if(null!==e.child){e.child.return=e,e=e.child;continue}if(e===t)break e;for(;null===e.sibling;){if(null===e.return||e.return===t)break e;e=e.return}e.sibling.return=e.return,e=e.sibling}n&=1}if(Ci($s,n),0===(1&t.mode))t.memoizedState=null;else switch(i){case"forwards":for(a=t.child,i=null;null!==a;)null!==(e=a.alternate)&&null===er(e)&&(i=a),a=a.sibling;null===(a=i)?(i=t.child,t.child=null):(i=a.sibling,a.sibling=null),Ko(t,!1,i,a,s);break;case"backwards":for(a=null,i=t.child,t.child=null;null!==i;){if(null!==(e=i.alternate)&&null===er(e)){t.child=i;break}e=i.sibling,i.sibling=a,a=i,i=e}Ko(t,!0,a,null,s);break;case"together":Ko(t,!1,null,null,void 0);break;default:t.memoizedState=null}return t.child}function _o(e,t){0===(1&t.mode)&&null!==e&&(e.alternate=null,t.alternate=null,t.flags|=2)}function Ho(e,t,a){if(null!==e&&(t.dependencies=e.dependencies),Ml|=t.lanes,0===(a&t.childLanes))return null;if(null!==e&&t.child!==e.child)throw Error(s(153));if(null!==t.child){for(a=Ec(e=t.child,e.pendingProps),t.child=a,a.return=t;null!==e.sibling;)e=e.sibling,(a=a.sibling=Ec(e,e.pendingProps)).return=t;a.sibling=null}return t.child}function Bo(e,t){if(!is)switch(e.tailMode){case"hidden":t=e.tail;for(var a=null;null!==t;)null!==t.alternate&&(a=t),t=t.sibling;null===a?e.tail=null:a.sibling=null;break;case"collapsed":a=e.tail;for(var n=null;null!==a;)null!==a.alternate&&(n=a),a=a.sibling;null===n?t||null===e.tail?e.tail=null:e.tail.sibling=null:n.sibling=null}}function Uo(e){var t=null!==e.alternate&&e.alternate.child===e.child,a=0,n=0;if(t)for(var i=e.child;null!==i;)a|=i.lanes|i.childLanes,n|=14680064&i.subtreeFlags,n|=14680064&i.flags,i.return=e,i=i.sibling;else for(i=e.child;null!==i;)a|=i.lanes|i.childLanes,n|=i.subtreeFlags,n|=i.flags,i.return=e,i=i.sibling;return e.subtreeFlags|=n,e.childLanes=a,t}function Jo(e,t,a){var n=t.pendingProps;switch(ts(t),t.tag){case 2:case 16:case 15:case 0:case 11:case 7:case 8:case 12:case 9:case 14:return Uo(t),null;case 1:case 17:return Ri(t.type)&&Ei(),Uo(t),null;case 3:return n=t.stateNode,Ys(),Ni(Li),Ni(Ai),ar(),n.pendingContext&&(n.context=n.pendingContext,n.pendingContext=null),null!==e&&null!==e.child||(hs(t)?t.flags|=4:null===e||e.memoizedState.isDehydrated&&0===(256&t.flags)||(t.flags|=1024,null!==ss&&(rc(ss),ss=null))),Ro(e,t),Uo(t),null;case 5:Zs(t);var i=Qs(Js.current);if(a=t.type,null!==e&&null!=t.stateNode)Eo(e,t,a,n,i),e.ref!==t.ref&&(t.flags|=512,t.flags|=2097152);else{if(!n){if(null===t.stateNode)throw Error(s(166));return Uo(t),null}if(e=Qs(Bs.current),hs(t)){n=t.stateNode,a=t.type;var r=t.memoizedProps;switch(n[ui]=t,n[pi]=r,e=0!==(1&t.mode),a){case"dialog":Fn("cancel",n),Fn("close",n);break;case"iframe":case"object":case"embed":Fn("load",n);break;case"video":case"audio":for(i=0;i<Wn.length;i++)Fn(Wn[i],n);break;case"source":Fn("error",n);break;case"img":case"image":case"link":Fn("error",n),Fn("load",n);break;case"details":Fn("toggle",n);break;case"input":Y(n,r),Fn("invalid",n);break;case"select":n._wrapperState={wasMultiple:!!r.multiple},Fn("invalid",n);break;case"textarea":ie(n,r),Fn("invalid",n)}for(var l in ye(a,r),i=null,r)if(r.hasOwnProperty(l)){var c=r[l];"children"===l?"string"===typeof c?n.textContent!==c&&(!0!==r.suppressHydrationWarning&&Zn(n.textContent,c,e),i=["children",c]):"number"===typeof c&&n.textContent!==""+c&&(!0!==r.suppressHydrationWarning&&Zn(n.textContent,c,e),i=["children",""+c]):o.hasOwnProperty(l)&&null!=c&&"onScroll"===l&&Fn("scroll",n)}switch(a){case"input":U(n),$(n,r,!0);break;case"textarea":U(n),re(n);break;case"select":case"option":break;default:"function"===typeof r.onClick&&(n.onclick=$n)}n=i,t.updateQueue=n,null!==n&&(t.flags|=4)}else{l=9===i.nodeType?i:i.ownerDocument,"http://www.w3.org/1999/xhtml"===e&&(e=oe(a)),"http://www.w3.org/1999/xhtml"===e?"script"===a?((e=l.createElement("div")).innerHTML="<script><\/script>",e=e.removeChild(e.firstChild)):"string"===typeof n.is?e=l.createElement(a,{is:n.is}):(e=l.createElement(a),"select"===a&&(l=e,n.multiple?l.multiple=!0:n.size&&(l.size=n.size))):e=l.createElementNS(e,a),e[ui]=t,e[pi]=n,Po(e,t,!1,!1),t.stateNode=e;e:{switch(l=xe(a,n),a){case"dialog":Fn("cancel",e),Fn("close",e),i=n;break;case"iframe":case"object":case"embed":Fn("load",e),i=n;break;case"video":case"audio":for(i=0;i<Wn.length;i++)Fn(Wn[i],e);i=n;break;case"source":Fn("error",e),i=n;break;case"img":case"image":case"link":Fn("error",e),Fn("load",e),i=n;break;case"details":Fn("toggle",e),i=n;break;case"input":Y(e,n),i=V(e,n),Fn("invalid",e);break;case"option":default:i=n;break;case"select":e._wrapperState={wasMultiple:!!n.multiple},i=G({},n,{value:void 0}),Fn("invalid",e);break;case"textarea":ie(e,n),i=ne(e,n),Fn("invalid",e)}for(r in ye(a,i),c=i)if(c.hasOwnProperty(r)){var d=c[r];"style"===r?fe(e,d):"dangerouslySetInnerHTML"===r?null!=(d=d?d.__html:void 0)&&he(e,d):"children"===r?"string"===typeof d?("textarea"!==a||""!==d)&&ue(e,d):"number"===typeof d&&ue(e,""+d):"suppressContentEditableWarning"!==r&&"suppressHydrationWarning"!==r&&"autoFocus"!==r&&(o.hasOwnProperty(r)?null!=d&&"onScroll"===r&&Fn("scroll",e):null!=d&&x(e,r,d,l))}switch(a){case"input":U(e),$(e,n,!1);break;case"textarea":U(e),re(e);break;case"option":null!=n.value&&e.setAttribute("value",""+H(n.value));break;case"select":e.multiple=!!n.multiple,null!=(r=n.value)?ae(e,!!n.multiple,r,!1):null!=n.defaultValue&&ae(e,!!n.multiple,n.defaultValue,!0);break;default:"function"===typeof i.onClick&&(e.onclick=$n)}switch(a){case"button":case"input":case"select":case"textarea":n=!!n.autoFocus;break e;case"img":n=!0;break e;default:n=!1}}n&&(t.flags|=4)}null!==t.ref&&(t.flags|=512,t.flags|=2097152)}return Uo(t),null;case 6:if(e&&null!=t.stateNode)Do(e,t,e.memoizedProps,n);else{if("string"!==typeof n&&null===t.stateNode)throw Error(s(166));if(a=Qs(Js.current),Qs(Bs.current),hs(t)){if(n=t.stateNode,a=t.memoizedProps,n[ui]=t,(r=n.nodeValue!==a)&&null!==(e=as))switch(e.tag){case 3:Zn(n.nodeValue,a,0!==(1&e.mode));break;case 5:!0!==e.memoizedProps.suppressHydrationWarning&&Zn(n.nodeValue,a,0!==(1&e.mode))}r&&(t.flags|=4)}else(n=(9===a.nodeType?a:a.ownerDocument).createTextNode(n))[ui]=t,t.stateNode=n}return Uo(t),null;case 13:if(Ni($s),n=t.memoizedState,null===e||null!==e.memoizedState&&null!==e.memoizedState.dehydrated){if(is&&null!==ns&&0!==(1&t.mode)&&0===(128&t.flags))us(),ps(),t.flags|=98560,r=!1;else if(r=hs(t),null!==n&&null!==n.dehydrated){if(null===e){if(!r)throw Error(s(318));if(!(r=null!==(r=t.memoizedState)?r.dehydrated:null))throw Error(s(317));r[ui]=t}else ps(),0===(128&t.flags)&&(t.memoizedState=null),t.flags|=4;Uo(t),r=!1}else null!==ss&&(rc(ss),ss=null),r=!0;if(!r)return 65536&t.flags?t:null}return 0!==(128&t.flags)?(t.lanes=a,t):((n=null!==n)!==(null!==e&&null!==e.memoizedState)&&n&&(t.child.flags|=8192,0!==(1&t.mode)&&(null===e||0!==(1&$s.current)?0===Dl&&(Dl=3):gc())),null!==t.updateQueue&&(t.flags|=4),Uo(t),null);case 4:return Ys(),Ro(e,t),null===e&&qn(t.stateNode.containerInfo),Uo(t),null;case 10:return Ts(t.type._context),Uo(t),null;case 19:if(Ni($s),null===(r=t.memoizedState))return Uo(t),null;if(n=0!==(128&t.flags),null===(l=r.rendering))if(n)Bo(r,!1);else{if(0!==Dl||null!==e&&0!==(128&e.flags))for(e=t.child;null!==e;){if(null!==(l=er(e))){for(t.flags|=128,Bo(r,!1),null!==(n=l.updateQueue)&&(t.updateQueue=n,t.flags|=4),t.subtreeFlags=0,n=a,a=t.child;null!==a;)e=n,(r=a).flags&=14680066,null===(l=r.alternate)?(r.childLanes=0,r.lanes=e,r.child=null,r.subtreeFlags=0,r.memoizedProps=null,r.memoizedState=null,r.updateQueue=null,r.dependencies=null,r.stateNode=null):(r.childLanes=l.childLanes,r.lanes=l.lanes,r.child=l.child,r.subtreeFlags=0,r.deletions=null,r.memoizedProps=l.memoizedProps,r.memoizedState=l.memoizedState,r.updateQueue=l.updateQueue,r.type=l.type,e=l.dependencies,r.dependencies=null===e?null:{lanes:e.lanes,firstContext:e.firstContext}),a=a.sibling;return Ci($s,1&$s.current|2),t.child}e=e.sibling}null!==r.tail&&Xe()>ql&&(t.flags|=128,n=!0,Bo(r,!1),t.lanes=4194304)}else{if(!n)if(null!==(e=er(l))){if(t.flags|=128,n=!0,null!==(a=e.updateQueue)&&(t.updateQueue=a,t.flags|=4),Bo(r,!0),null===r.tail&&"hidden"===r.tailMode&&!l.alternate&&!is)return Uo(t),null}else 2*Xe()-r.renderingStartTime>ql&&1073741824!==a&&(t.flags|=128,n=!0,Bo(r,!1),t.lanes=4194304);r.isBackwards?(l.sibling=t.child,t.child=l):(null!==(a=r.last)?a.sibling=l:t.child=l,r.last=l)}return null!==r.tail?(t=r.tail,r.rendering=t,r.tail=t.sibling,r.renderingStartTime=Xe(),t.sibling=null,a=$s.current,Ci($s,n?1&a|2:1&a),t):(Uo(t),null);case 22:case 23:return hc(),n=null!==t.memoizedState,null!==e&&null!==e.memoizedState!==n&&(t.flags|=8192),n&&0!==(1&t.mode)?0!==(1073741824&Rl)&&(Uo(t),6&t.subtreeFlags&&(t.flags|=8192)):Uo(t),null;case 24:case 25:return null}throw Error(s(156,t.tag))}function Qo(e,t){switch(ts(t),t.tag){case 1:return Ri(t.type)&&Ei(),65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 3:return Ys(),Ni(Li),Ni(Ai),ar(),0!==(65536&(e=t.flags))&&0===(128&e)?(t.flags=-65537&e|128,t):null;case 5:return Zs(t),null;case 13:if(Ni($s),null!==(e=t.memoizedState)&&null!==e.dehydrated){if(null===t.alternate)throw Error(s(340));ps()}return 65536&(e=t.flags)?(t.flags=-65537&e|128,t):null;case 19:return Ni($s),null;case 4:return Ys(),null;case 10:return Ts(t.type._context),null;case 22:case 23:return hc(),null;default:return null}}Po=function(e,t){for(var a=t.child;null!==a;){if(5===a.tag||6===a.tag)e.appendChild(a.stateNode);else if(4!==a.tag&&null!==a.child){a.child.return=a,a=a.child;continue}if(a===t)break;for(;null===a.sibling;){if(null===a.return||a.return===t)return;a=a.return}a.sibling.return=a.return,a=a.sibling}},Ro=function(){},Eo=function(e,t,a,n){var i=e.memoizedProps;if(i!==n){e=t.stateNode,Qs(Bs.current);var s,r=null;switch(a){case"input":i=V(e,i),n=V(e,n),r=[];break;case"select":i=G({},i,{value:void 0}),n=G({},n,{value:void 0}),r=[];break;case"textarea":i=ne(e,i),n=ne(e,n),r=[];break;default:"function"!==typeof i.onClick&&"function"===typeof n.onClick&&(e.onclick=$n)}for(d in ye(a,n),a=null,i)if(!n.hasOwnProperty(d)&&i.hasOwnProperty(d)&&null!=i[d])if("style"===d){var l=i[d];for(s in l)l.hasOwnProperty(s)&&(a||(a={}),a[s]="")}else"dangerouslySetInnerHTML"!==d&&"children"!==d&&"suppressContentEditableWarning"!==d&&"suppressHydrationWarning"!==d&&"autoFocus"!==d&&(o.hasOwnProperty(d)?r||(r=[]):(r=r||[]).push(d,null));for(d in n){var c=n[d];if(l=null!=i?i[d]:void 0,n.hasOwnProperty(d)&&c!==l&&(null!=c||null!=l))if("style"===d)if(l){for(s in l)!l.hasOwnProperty(s)||c&&c.hasOwnProperty(s)||(a||(a={}),a[s]="");for(s in c)c.hasOwnProperty(s)&&l[s]!==c[s]&&(a||(a={}),a[s]=c[s])}else a||(r||(r=[]),r.push(d,a)),a=c;else"dangerouslySetInnerHTML"===d?(c=c?c.__html:void 0,l=l?l.__html:void 0,null!=c&&l!==c&&(r=r||[]).push(d,c)):"children"===d?"string"!==typeof c&&"number"!==typeof c||(r=r||[]).push(d,""+c):"suppressContentEditableWarning"!==d&&"suppressHydrationWarning"!==d&&(o.hasOwnProperty(d)?(null!=c&&"onScroll"===d&&Fn("scroll",e),r||l===c||(r=[])):(r=r||[]).push(d,c))}a&&(r=r||[]).push("style",a);var d=r;(t.updateQueue=d)&&(t.flags|=4)}},Do=function(e,t,a,n){a!==n&&(t.flags|=4)};var Vo=!1,Yo=!1,Xo="function"===typeof WeakSet?WeakSet:Set,Zo=null;function $o(e,t){var a=e.ref;if(null!==a)if("function"===typeof a)try{a(null)}catch(n){Sc(e,t,n)}else a.current=null}function el(e,t,a){try{a()}catch(n){Sc(e,t,n)}}var tl=!1;function al(e,t,a){var n=t.updateQueue;if(null!==(n=null!==n?n.lastEffect:null)){var i=n=n.next;do{if((i.tag&e)===e){var s=i.destroy;i.destroy=void 0,void 0!==s&&el(t,a,s)}i=i.next}while(i!==n)}}function nl(e,t){if(null!==(t=null!==(t=t.updateQueue)?t.lastEffect:null)){var a=t=t.next;do{if((a.tag&e)===e){var n=a.create;a.destroy=n()}a=a.next}while(a!==t)}}function il(e){var t=e.ref;if(null!==t){var a=e.stateNode;e.tag,e=a,"function"===typeof t?t(e):t.current=e}}function sl(e){var t=e.alternate;null!==t&&(e.alternate=null,sl(t)),e.child=null,e.deletions=null,e.sibling=null,5===e.tag&&(null!==(t=e.stateNode)&&(delete t[ui],delete t[pi],delete t[gi],delete t[fi],delete t[bi])),e.stateNode=null,e.return=null,e.dependencies=null,e.memoizedProps=null,e.memoizedState=null,e.pendingProps=null,e.stateNode=null,e.updateQueue=null}function rl(e){return 5===e.tag||3===e.tag||4===e.tag}function ol(e){e:for(;;){for(;null===e.sibling;){if(null===e.return||rl(e.return))return null;e=e.return}for(e.sibling.return=e.return,e=e.sibling;5!==e.tag&&6!==e.tag&&18!==e.tag;){if(2&e.flags)continue e;if(null===e.child||4===e.tag)continue e;e.child.return=e,e=e.child}if(!(2&e.flags))return e.stateNode}}function ll(e,t,a){var n=e.tag;if(5===n||6===n)e=e.stateNode,t?8===a.nodeType?a.parentNode.insertBefore(e,t):a.insertBefore(e,t):(8===a.nodeType?(t=a.parentNode).insertBefore(e,a):(t=a).appendChild(e),null!==(a=a._reactRootContainer)&&void 0!==a||null!==t.onclick||(t.onclick=$n));else if(4!==n&&null!==(e=e.child))for(ll(e,t,a),e=e.sibling;null!==e;)ll(e,t,a),e=e.sibling}function cl(e,t,a){var n=e.tag;if(5===n||6===n)e=e.stateNode,t?a.insertBefore(e,t):a.appendChild(e);else if(4!==n&&null!==(e=e.child))for(cl(e,t,a),e=e.sibling;null!==e;)cl(e,t,a),e=e.sibling}var dl=null,hl=!1;function ul(e,t,a){for(a=a.child;null!==a;)pl(e,t,a),a=a.sibling}function pl(e,t,a){if(st&&"function"===typeof st.onCommitFiberUnmount)try{st.onCommitFiberUnmount(it,a)}catch(o){}switch(a.tag){case 5:Yo||$o(a,t);case 6:var n=dl,i=hl;dl=null,ul(e,t,a),hl=i,null!==(dl=n)&&(hl?(e=dl,a=a.stateNode,8===e.nodeType?e.parentNode.removeChild(a):e.removeChild(a)):dl.removeChild(a.stateNode));break;case 18:null!==dl&&(hl?(e=dl,a=a.stateNode,8===e.nodeType?li(e.parentNode,a):1===e.nodeType&&li(e,a),qt(e)):li(dl,a.stateNode));break;case 4:n=dl,i=hl,dl=a.stateNode.containerInfo,hl=!0,ul(e,t,a),dl=n,hl=i;break;case 0:case 11:case 14:case 15:if(!Yo&&(null!==(n=a.updateQueue)&&null!==(n=n.lastEffect))){i=n=n.next;do{var s=i,r=s.destroy;s=s.tag,void 0!==r&&(0!==(2&s)||0!==(4&s))&&el(a,t,r),i=i.next}while(i!==n)}ul(e,t,a);break;case 1:if(!Yo&&($o(a,t),"function"===typeof(n=a.stateNode).componentWillUnmount))try{n.props=a.memoizedProps,n.state=a.memoizedState,n.componentWillUnmount()}catch(o){Sc(a,t,o)}ul(e,t,a);break;case 21:ul(e,t,a);break;case 22:1&a.mode?(Yo=(n=Yo)||null!==a.memoizedState,ul(e,t,a),Yo=n):ul(e,t,a);break;default:ul(e,t,a)}}function ml(e){var t=e.updateQueue;if(null!==t){e.updateQueue=null;var a=e.stateNode;null===a&&(a=e.stateNode=new Xo),t.forEach((function(t){var n=Ac.bind(null,e,t);a.has(t)||(a.add(t),t.then(n,n))}))}}function gl(e,t){var a=t.deletions;if(null!==a)for(var n=0;n<a.length;n++){var i=a[n];try{var r=e,o=t,l=o;e:for(;null!==l;){switch(l.tag){case 5:dl=l.stateNode,hl=!1;break e;case 3:case 4:dl=l.stateNode.containerInfo,hl=!0;break e}l=l.return}if(null===dl)throw Error(s(160));pl(r,o,i),dl=null,hl=!1;var c=i.alternate;null!==c&&(c.return=null),i.return=null}catch(d){Sc(i,t,d)}}if(12854&t.subtreeFlags)for(t=t.child;null!==t;)fl(t,e),t=t.sibling}function fl(e,t){var a=e.alternate,n=e.flags;switch(e.tag){case 0:case 11:case 14:case 15:if(gl(t,e),bl(e),4&n){try{al(3,e,e.return),nl(3,e)}catch(f){Sc(e,e.return,f)}try{al(5,e,e.return)}catch(f){Sc(e,e.return,f)}}break;case 1:gl(t,e),bl(e),512&n&&null!==a&&$o(a,a.return);break;case 5:if(gl(t,e),bl(e),512&n&&null!==a&&$o(a,a.return),32&e.flags){var i=e.stateNode;try{ue(i,"")}catch(f){Sc(e,e.return,f)}}if(4&n&&null!=(i=e.stateNode)){var r=e.memoizedProps,o=null!==a?a.memoizedProps:r,l=e.type,c=e.updateQueue;if(e.updateQueue=null,null!==c)try{"input"===l&&"radio"===r.type&&null!=r.name&&X(i,r),xe(l,o);var d=xe(l,r);for(o=0;o<c.length;o+=2){var h=c[o],u=c[o+1];"style"===h?fe(i,u):"dangerouslySetInnerHTML"===h?he(i,u):"children"===h?ue(i,u):x(i,h,u,d)}switch(l){case"input":Z(i,r);break;case"textarea":se(i,r);break;case"select":var p=i._wrapperState.wasMultiple;i._wrapperState.wasMultiple=!!r.multiple;var m=r.value;null!=m?ae(i,!!r.multiple,m,!1):p!==!!r.multiple&&(null!=r.defaultValue?ae(i,!!r.multiple,r.defaultValue,!0):ae(i,!!r.multiple,r.multiple?[]:"",!1))}i[pi]=r}catch(f){Sc(e,e.return,f)}}break;case 6:if(gl(t,e),bl(e),4&n){if(null===e.stateNode)throw Error(s(162));i=e.stateNode,r=e.memoizedProps;try{i.nodeValue=r}catch(f){Sc(e,e.return,f)}}break;case 3:if(gl(t,e),bl(e),4&n&&null!==a&&a.memoizedState.isDehydrated)try{qt(t.containerInfo)}catch(f){Sc(e,e.return,f)}break;case 4:default:gl(t,e),bl(e);break;case 13:gl(t,e),bl(e),8192&(i=e.child).flags&&(r=null!==i.memoizedState,i.stateNode.isHidden=r,!r||null!==i.alternate&&null!==i.alternate.memoizedState||(Kl=Xe())),4&n&&ml(e);break;case 22:if(h=null!==a&&null!==a.memoizedState,1&e.mode?(Yo=(d=Yo)||h,gl(t,e),Yo=d):gl(t,e),bl(e),8192&n){if(d=null!==e.memoizedState,(e.stateNode.isHidden=d)&&!h&&0!==(1&e.mode))for(Zo=e,h=e.child;null!==h;){for(u=Zo=h;null!==Zo;){switch(m=(p=Zo).child,p.tag){case 0:case 11:case 14:case 15:al(4,p,p.return);break;case 1:$o(p,p.return);var g=p.stateNode;if("function"===typeof g.componentWillUnmount){n=p,a=p.return;try{t=n,g.props=t.memoizedProps,g.state=t.memoizedState,g.componentWillUnmount()}catch(f){Sc(n,a,f)}}break;case 5:$o(p,p.return);break;case 22:if(null!==p.memoizedState){wl(u);continue}}null!==m?(m.return=p,Zo=m):wl(u)}h=h.sibling}e:for(h=null,u=e;;){if(5===u.tag){if(null===h){h=u;try{i=u.stateNode,d?"function"===typeof(r=i.style).setProperty?r.setProperty("display","none","important"):r.display="none":(l=u.stateNode,o=void 0!==(c=u.memoizedProps.style)&&null!==c&&c.hasOwnProperty("display")?c.display:null,l.style.display=ge("display",o))}catch(f){Sc(e,e.return,f)}}}else if(6===u.tag){if(null===h)try{u.stateNode.nodeValue=d?"":u.memoizedProps}catch(f){Sc(e,e.return,f)}}else if((22!==u.tag&&23!==u.tag||null===u.memoizedState||u===e)&&null!==u.child){u.child.return=u,u=u.child;continue}if(u===e)break e;for(;null===u.sibling;){if(null===u.return||u.return===e)break e;h===u&&(h=null),u=u.return}h===u&&(h=null),u.sibling.return=u.return,u=u.sibling}}break;case 19:gl(t,e),bl(e),4&n&&ml(e);case 21:}}function bl(e){var t=e.flags;if(2&t){try{e:{for(var a=e.return;null!==a;){if(rl(a)){var n=a;break e}a=a.return}throw Error(s(160))}switch(n.tag){case 5:var i=n.stateNode;32&n.flags&&(ue(i,""),n.flags&=-33),cl(e,ol(e),i);break;case 3:case 4:var r=n.stateNode.containerInfo;ll(e,ol(e),r);break;default:throw Error(s(161))}}catch(o){Sc(e,e.return,o)}e.flags&=-3}4096&t&&(e.flags&=-4097)}function yl(e,t,a){Zo=e,xl(e,t,a)}function xl(e,t,a){for(var n=0!==(1&e.mode);null!==Zo;){var i=Zo,s=i.child;if(22===i.tag&&n){var r=null!==i.memoizedState||Vo;if(!r){var o=i.alternate,l=null!==o&&null!==o.memoizedState||Yo;o=Vo;var c=Yo;if(Vo=r,(Yo=l)&&!c)for(Zo=i;null!==Zo;)l=(r=Zo).child,22===r.tag&&null!==r.memoizedState?jl(i):null!==l?(l.return=r,Zo=l):jl(i);for(;null!==s;)Zo=s,xl(s,t,a),s=s.sibling;Zo=i,Vo=o,Yo=c}vl(e)}else 0!==(8772&i.subtreeFlags)&&null!==s?(s.return=i,Zo=s):vl(e)}}function vl(e){for(;null!==Zo;){var t=Zo;if(0!==(8772&t.flags)){var a=t.alternate;try{if(0!==(8772&t.flags))switch(t.tag){case 0:case 11:case 15:Yo||nl(5,t);break;case 1:var n=t.stateNode;if(4&t.flags&&!Yo)if(null===a)n.componentDidMount();else{var i=t.elementType===t.type?a.memoizedProps:to(t.type,a.memoizedProps);n.componentDidUpdate(i,a.memoizedState,n.__reactInternalSnapshotBeforeUpdate)}var r=t.updateQueue;null!==r&&_s(t,r,n);break;case 3:var o=t.updateQueue;if(null!==o){if(a=null,null!==t.child)switch(t.child.tag){case 5:case 1:a=t.child.stateNode}_s(t,o,a)}break;case 5:var l=t.stateNode;if(null===a&&4&t.flags){a=l;var c=t.memoizedProps;switch(t.type){case"button":case"input":case"select":case"textarea":c.autoFocus&&a.focus();break;case"img":c.src&&(a.src=c.src)}}break;case 6:case 4:case 12:case 19:case 17:case 21:case 22:case 23:case 25:break;case 13:if(null===t.memoizedState){var d=t.alternate;if(null!==d){var h=d.memoizedState;if(null!==h){var u=h.dehydrated;null!==u&&qt(u)}}}break;default:throw Error(s(163))}Yo||512&t.flags&&il(t)}catch(p){Sc(t,t.return,p)}}if(t===e){Zo=null;break}if(null!==(a=t.sibling)){a.return=t.return,Zo=a;break}Zo=t.return}}function wl(e){for(;null!==Zo;){var t=Zo;if(t===e){Zo=null;break}var a=t.sibling;if(null!==a){a.return=t.return,Zo=a;break}Zo=t.return}}function jl(e){for(;null!==Zo;){var t=Zo;try{switch(t.tag){case 0:case 11:case 15:var a=t.return;try{nl(4,t)}catch(l){Sc(t,a,l)}break;case 1:var n=t.stateNode;if("function"===typeof n.componentDidMount){var i=t.return;try{n.componentDidMount()}catch(l){Sc(t,i,l)}}var s=t.return;try{il(t)}catch(l){Sc(t,s,l)}break;case 5:var r=t.return;try{il(t)}catch(l){Sc(t,r,l)}}}catch(l){Sc(t,t.return,l)}if(t===e){Zo=null;break}var o=t.sibling;if(null!==o){o.return=t.return,Zo=o;break}Zo=t.return}}var kl,Sl=Math.ceil,Nl=v.ReactCurrentDispatcher,Cl=v.ReactCurrentOwner,Tl=v.ReactCurrentBatchConfig,Al=0,Ll=null,Il=null,Pl=0,Rl=0,El=Si(0),Dl=0,Wl=null,Ml=0,Gl=0,Ol=0,Fl=null,zl=null,Kl=0,ql=1/0,_l=null,Hl=!1,Bl=null,Ul=null,Jl=!1,Ql=null,Vl=0,Yl=0,Xl=null,Zl=-1,$l=0;function ec(){return 0!==(6&Al)?Xe():-1!==Zl?Zl:Zl=Xe()}function tc(e){return 0===(1&e.mode)?1:0!==(2&Al)&&0!==Pl?Pl&-Pl:null!==gs.transition?(0===$l&&($l=gt()),$l):0!==(e=xt)?e:e=void 0===(e=window.event)?16:Yt(e.type)}function ac(e,t,a,n){if(50<Yl)throw Yl=0,Xl=null,Error(s(185));bt(e,a,n),0!==(2&Al)&&e===Ll||(e===Ll&&(0===(2&Al)&&(Gl|=a),4===Dl&&oc(e,Pl)),nc(e,n),1===a&&0===Al&&0===(1&t.mode)&&(ql=Xe()+500,Fi&&qi()))}function nc(e,t){var a=e.callbackNode;!function(e,t){for(var a=e.suspendedLanes,n=e.pingedLanes,i=e.expirationTimes,s=e.pendingLanes;0<s;){var r=31-rt(s),o=1<<r,l=i[r];-1===l?0!==(o&a)&&0===(o&n)||(i[r]=pt(o,t)):l<=t&&(e.expiredLanes|=o),s&=~o}}(e,t);var n=ut(e,e===Ll?Pl:0);if(0===n)null!==a&&Qe(a),e.callbackNode=null,e.callbackPriority=0;else if(t=n&-n,e.callbackPriority!==t){if(null!=a&&Qe(a),1===t)0===e.tag?function(e){Fi=!0,Ki(e)}(lc.bind(null,e)):Ki(lc.bind(null,e)),ri((function(){0===(6&Al)&&qi()})),a=null;else{switch(vt(n)){case 1:a=$e;break;case 4:a=et;break;case 16:default:a=tt;break;case 536870912:a=nt}a=Lc(a,ic.bind(null,e))}e.callbackPriority=t,e.callbackNode=a}}function ic(e,t){if(Zl=-1,$l=0,0!==(6&Al))throw Error(s(327));var a=e.callbackNode;if(jc()&&e.callbackNode!==a)return null;var n=ut(e,e===Ll?Pl:0);if(0===n)return null;if(0!==(30&n)||0!==(n&e.expiredLanes)||t)t=fc(e,n);else{t=n;var i=Al;Al|=2;var r=mc();for(Ll===e&&Pl===t||(_l=null,ql=Xe()+500,uc(e,t));;)try{yc();break}catch(l){pc(e,l)}Cs(),Nl.current=r,Al=i,null!==Il?t=0:(Ll=null,Pl=0,t=Dl)}if(0!==t){if(2===t&&(0!==(i=mt(e))&&(n=i,t=sc(e,i))),1===t)throw a=Wl,uc(e,0),oc(e,n),nc(e,Xe()),a;if(6===t)oc(e,n);else{if(i=e.current.alternate,0===(30&n)&&!function(e){for(var t=e;;){if(16384&t.flags){var a=t.updateQueue;if(null!==a&&null!==(a=a.stores))for(var n=0;n<a.length;n++){var i=a[n],s=i.getSnapshot;i=i.value;try{if(!on(s(),i))return!1}catch(o){return!1}}}if(a=t.child,16384&t.subtreeFlags&&null!==a)a.return=t,t=a;else{if(t===e)break;for(;null===t.sibling;){if(null===t.return||t.return===e)return!0;t=t.return}t.sibling.return=t.return,t=t.sibling}}return!0}(i)&&(2===(t=fc(e,n))&&(0!==(r=mt(e))&&(n=r,t=sc(e,r))),1===t))throw a=Wl,uc(e,0),oc(e,n),nc(e,Xe()),a;switch(e.finishedWork=i,e.finishedLanes=n,t){case 0:case 1:throw Error(s(345));case 2:case 5:wc(e,zl,_l);break;case 3:if(oc(e,n),(130023424&n)===n&&10<(t=Kl+500-Xe())){if(0!==ut(e,0))break;if(((i=e.suspendedLanes)&n)!==n){ec(),e.pingedLanes|=e.suspendedLanes&i;break}e.timeoutHandle=ni(wc.bind(null,e,zl,_l),t);break}wc(e,zl,_l);break;case 4:if(oc(e,n),(4194240&n)===n)break;for(t=e.eventTimes,i=-1;0<n;){var o=31-rt(n);r=1<<o,(o=t[o])>i&&(i=o),n&=~r}if(n=i,10<(n=(120>(n=Xe()-n)?120:480>n?480:1080>n?1080:1920>n?1920:3e3>n?3e3:4320>n?4320:1960*Sl(n/1960))-n)){e.timeoutHandle=ni(wc.bind(null,e,zl,_l),n);break}wc(e,zl,_l);break;default:throw Error(s(329))}}}return nc(e,Xe()),e.callbackNode===a?ic.bind(null,e):null}function sc(e,t){var a=Fl;return e.current.memoizedState.isDehydrated&&(uc(e,t).flags|=256),2!==(e=fc(e,t))&&(t=zl,zl=a,null!==t&&rc(t)),e}function rc(e){null===zl?zl=e:zl.push.apply(zl,e)}function oc(e,t){for(t&=~Ol,t&=~Gl,e.suspendedLanes|=t,e.pingedLanes&=~t,e=e.expirationTimes;0<t;){var a=31-rt(t),n=1<<a;e[a]=-1,t&=~n}}function lc(e){if(0!==(6&Al))throw Error(s(327));jc();var t=ut(e,0);if(0===(1&t))return nc(e,Xe()),null;var a=fc(e,t);if(0!==e.tag&&2===a){var n=mt(e);0!==n&&(t=n,a=sc(e,n))}if(1===a)throw a=Wl,uc(e,0),oc(e,t),nc(e,Xe()),a;if(6===a)throw Error(s(345));return e.finishedWork=e.current.alternate,e.finishedLanes=t,wc(e,zl,_l),nc(e,Xe()),null}function cc(e,t){var a=Al;Al|=1;try{return e(t)}finally{0===(Al=a)&&(ql=Xe()+500,Fi&&qi())}}function dc(e){null!==Ql&&0===Ql.tag&&0===(6&Al)&&jc();var t=Al;Al|=1;var a=Tl.transition,n=xt;try{if(Tl.transition=null,xt=1,e)return e()}finally{xt=n,Tl.transition=a,0===(6&(Al=t))&&qi()}}function hc(){Rl=El.current,Ni(El)}function uc(e,t){e.finishedWork=null,e.finishedLanes=0;var a=e.timeoutHandle;if(-1!==a&&(e.timeoutHandle=-1,ii(a)),null!==Il)for(a=Il.return;null!==a;){var n=a;switch(ts(n),n.tag){case 1:null!==(n=n.type.childContextTypes)&&void 0!==n&&Ei();break;case 3:Ys(),Ni(Li),Ni(Ai),ar();break;case 5:Zs(n);break;case 4:Ys();break;case 13:case 19:Ni($s);break;case 10:Ts(n.type._context);break;case 22:case 23:hc()}a=a.return}if(Ll=e,Il=e=Ec(e.current,null),Pl=Rl=t,Dl=0,Wl=null,Ol=Gl=Ml=0,zl=Fl=null,null!==Ps){for(t=0;t<Ps.length;t++)if(null!==(n=(a=Ps[t]).interleaved)){a.interleaved=null;var i=n.next,s=a.pending;if(null!==s){var r=s.next;s.next=i,n.next=r}a.pending=n}Ps=null}return e}function pc(e,t){for(;;){var a=Il;try{if(Cs(),nr.current=Xr,cr){for(var n=rr.memoizedState;null!==n;){var i=n.queue;null!==i&&(i.pending=null),n=n.next}cr=!1}if(sr=0,lr=or=rr=null,dr=!1,hr=0,Cl.current=null,null===a||null===a.return){Dl=1,Wl=t,Il=null;break}e:{var r=e,o=a.return,l=a,c=t;if(t=Pl,l.flags|=32768,null!==c&&"object"===typeof c&&"function"===typeof c.then){var d=c,h=l,u=h.tag;if(0===(1&h.mode)&&(0===u||11===u||15===u)){var p=h.alternate;p?(h.updateQueue=p.updateQueue,h.memoizedState=p.memoizedState,h.lanes=p.lanes):(h.updateQueue=null,h.memoizedState=null)}var m=fo(o);if(null!==m){m.flags&=-257,bo(m,o,l,0,t),1&m.mode&&go(r,d,t),c=d;var g=(t=m).updateQueue;if(null===g){var f=new Set;f.add(c),t.updateQueue=f}else g.add(c);break e}if(0===(1&t)){go(r,d,t),gc();break e}c=Error(s(426))}else if(is&&1&l.mode){var b=fo(o);if(null!==b){0===(65536&b.flags)&&(b.flags|=256),bo(b,o,l,0,t),ms(lo(c,l));break e}}r=c=lo(c,l),4!==Dl&&(Dl=2),null===Fl?Fl=[r]:Fl.push(r),r=o;do{switch(r.tag){case 3:r.flags|=65536,t&=-t,r.lanes|=t,Ks(r,po(0,c,t));break e;case 1:l=c;var y=r.type,x=r.stateNode;if(0===(128&r.flags)&&("function"===typeof y.getDerivedStateFromError||null!==x&&"function"===typeof x.componentDidCatch&&(null===Ul||!Ul.has(x)))){r.flags|=65536,t&=-t,r.lanes|=t,Ks(r,mo(r,l,t));break e}}r=r.return}while(null!==r)}vc(a)}catch(v){t=v,Il===a&&null!==a&&(Il=a=a.return);continue}break}}function mc(){var e=Nl.current;return Nl.current=Xr,null===e?Xr:e}function gc(){0!==Dl&&3!==Dl&&2!==Dl||(Dl=4),null===Ll||0===(268435455&Ml)&&0===(268435455&Gl)||oc(Ll,Pl)}function fc(e,t){var a=Al;Al|=2;var n=mc();for(Ll===e&&Pl===t||(_l=null,uc(e,t));;)try{bc();break}catch(i){pc(e,i)}if(Cs(),Al=a,Nl.current=n,null!==Il)throw Error(s(261));return Ll=null,Pl=0,Dl}function bc(){for(;null!==Il;)xc(Il)}function yc(){for(;null!==Il&&!Ve();)xc(Il)}function xc(e){var t=kl(e.alternate,e,Rl);e.memoizedProps=e.pendingProps,null===t?vc(e):Il=t,Cl.current=null}function vc(e){var t=e;do{var a=t.alternate;if(e=t.return,0===(32768&t.flags)){if(null!==(a=Jo(a,t,Rl)))return void(Il=a)}else{if(null!==(a=Qo(a,t)))return a.flags&=32767,void(Il=a);if(null===e)return Dl=6,void(Il=null);e.flags|=32768,e.subtreeFlags=0,e.deletions=null}if(null!==(t=t.sibling))return void(Il=t);Il=t=e}while(null!==t);0===Dl&&(Dl=5)}function wc(e,t,a){var n=xt,i=Tl.transition;try{Tl.transition=null,xt=1,function(e,t,a,n){do{jc()}while(null!==Ql);if(0!==(6&Al))throw Error(s(327));a=e.finishedWork;var i=e.finishedLanes;if(null===a)return null;if(e.finishedWork=null,e.finishedLanes=0,a===e.current)throw Error(s(177));e.callbackNode=null,e.callbackPriority=0;var r=a.lanes|a.childLanes;if(function(e,t){var a=e.pendingLanes&~t;e.pendingLanes=t,e.suspendedLanes=0,e.pingedLanes=0,e.expiredLanes&=t,e.mutableReadLanes&=t,e.entangledLanes&=t,t=e.entanglements;var n=e.eventTimes;for(e=e.expirationTimes;0<a;){var i=31-rt(a),s=1<<i;t[i]=0,n[i]=-1,e[i]=-1,a&=~s}}(e,r),e===Ll&&(Il=Ll=null,Pl=0),0===(2064&a.subtreeFlags)&&0===(2064&a.flags)||Jl||(Jl=!0,Lc(tt,(function(){return jc(),null}))),r=0!==(15990&a.flags),0!==(15990&a.subtreeFlags)||r){r=Tl.transition,Tl.transition=null;var o=xt;xt=1;var l=Al;Al|=4,Cl.current=null,function(e,t){if(ei=Ht,pn(e=un())){if("selectionStart"in e)var a={start:e.selectionStart,end:e.selectionEnd};else e:{var n=(a=(a=e.ownerDocument)&&a.defaultView||window).getSelection&&a.getSelection();if(n&&0!==n.rangeCount){a=n.anchorNode;var i=n.anchorOffset,r=n.focusNode;n=n.focusOffset;try{a.nodeType,r.nodeType}catch(w){a=null;break e}var o=0,l=-1,c=-1,d=0,h=0,u=e,p=null;t:for(;;){for(var m;u!==a||0!==i&&3!==u.nodeType||(l=o+i),u!==r||0!==n&&3!==u.nodeType||(c=o+n),3===u.nodeType&&(o+=u.nodeValue.length),null!==(m=u.firstChild);)p=u,u=m;for(;;){if(u===e)break t;if(p===a&&++d===i&&(l=o),p===r&&++h===n&&(c=o),null!==(m=u.nextSibling))break;p=(u=p).parentNode}u=m}a=-1===l||-1===c?null:{start:l,end:c}}else a=null}a=a||{start:0,end:0}}else a=null;for(ti={focusedElem:e,selectionRange:a},Ht=!1,Zo=t;null!==Zo;)if(e=(t=Zo).child,0!==(1028&t.subtreeFlags)&&null!==e)e.return=t,Zo=e;else for(;null!==Zo;){t=Zo;try{var g=t.alternate;if(0!==(1024&t.flags))switch(t.tag){case 0:case 11:case 15:case 5:case 6:case 4:case 17:break;case 1:if(null!==g){var f=g.memoizedProps,b=g.memoizedState,y=t.stateNode,x=y.getSnapshotBeforeUpdate(t.elementType===t.type?f:to(t.type,f),b);y.__reactInternalSnapshotBeforeUpdate=x}break;case 3:var v=t.stateNode.containerInfo;1===v.nodeType?v.textContent="":9===v.nodeType&&v.documentElement&&v.removeChild(v.documentElement);break;default:throw Error(s(163))}}catch(w){Sc(t,t.return,w)}if(null!==(e=t.sibling)){e.return=t.return,Zo=e;break}Zo=t.return}g=tl,tl=!1}(e,a),fl(a,e),mn(ti),Ht=!!ei,ti=ei=null,e.current=a,yl(a,e,i),Ye(),Al=l,xt=o,Tl.transition=r}else e.current=a;if(Jl&&(Jl=!1,Ql=e,Vl=i),r=e.pendingLanes,0===r&&(Ul=null),function(e){if(st&&"function"===typeof st.onCommitFiberRoot)try{st.onCommitFiberRoot(it,e,void 0,128===(128&e.current.flags))}catch(t){}}(a.stateNode),nc(e,Xe()),null!==t)for(n=e.onRecoverableError,a=0;a<t.length;a++)i=t[a],n(i.value,{componentStack:i.stack,digest:i.digest});if(Hl)throw Hl=!1,e=Bl,Bl=null,e;0!==(1&Vl)&&0!==e.tag&&jc(),r=e.pendingLanes,0!==(1&r)?e===Xl?Yl++:(Yl=0,Xl=e):Yl=0,qi()}(e,t,a,n)}finally{Tl.transition=i,xt=n}return null}function jc(){if(null!==Ql){var e=vt(Vl),t=Tl.transition,a=xt;try{if(Tl.transition=null,xt=16>e?16:e,null===Ql)var n=!1;else{if(e=Ql,Ql=null,Vl=0,0!==(6&Al))throw Error(s(331));var i=Al;for(Al|=4,Zo=e.current;null!==Zo;){var r=Zo,o=r.child;if(0!==(16&Zo.flags)){var l=r.deletions;if(null!==l){for(var c=0;c<l.length;c++){var d=l[c];for(Zo=d;null!==Zo;){var h=Zo;switch(h.tag){case 0:case 11:case 15:al(8,h,r)}var u=h.child;if(null!==u)u.return=h,Zo=u;else for(;null!==Zo;){var p=(h=Zo).sibling,m=h.return;if(sl(h),h===d){Zo=null;break}if(null!==p){p.return=m,Zo=p;break}Zo=m}}}var g=r.alternate;if(null!==g){var f=g.child;if(null!==f){g.child=null;do{var b=f.sibling;f.sibling=null,f=b}while(null!==f)}}Zo=r}}if(0!==(2064&r.subtreeFlags)&&null!==o)o.return=r,Zo=o;else e:for(;null!==Zo;){if(0!==(2048&(r=Zo).flags))switch(r.tag){case 0:case 11:case 15:al(9,r,r.return)}var y=r.sibling;if(null!==y){y.return=r.return,Zo=y;break e}Zo=r.return}}var x=e.current;for(Zo=x;null!==Zo;){var v=(o=Zo).child;if(0!==(2064&o.subtreeFlags)&&null!==v)v.return=o,Zo=v;else e:for(o=x;null!==Zo;){if(0!==(2048&(l=Zo).flags))try{switch(l.tag){case 0:case 11:case 15:nl(9,l)}}catch(j){Sc(l,l.return,j)}if(l===o){Zo=null;break e}var w=l.sibling;if(null!==w){w.return=l.return,Zo=w;break e}Zo=l.return}}if(Al=i,qi(),st&&"function"===typeof st.onPostCommitFiberRoot)try{st.onPostCommitFiberRoot(it,e)}catch(j){}n=!0}return n}finally{xt=a,Tl.transition=t}}return!1}function kc(e,t,a){e=Fs(e,t=po(0,t=lo(a,t),1),1),t=ec(),null!==e&&(bt(e,1,t),nc(e,t))}function Sc(e,t,a){if(3===e.tag)kc(e,e,a);else for(;null!==t;){if(3===t.tag){kc(t,e,a);break}if(1===t.tag){var n=t.stateNode;if("function"===typeof t.type.getDerivedStateFromError||"function"===typeof n.componentDidCatch&&(null===Ul||!Ul.has(n))){t=Fs(t,e=mo(t,e=lo(a,e),1),1),e=ec(),null!==t&&(bt(t,1,e),nc(t,e));break}}t=t.return}}function Nc(e,t,a){var n=e.pingCache;null!==n&&n.delete(t),t=ec(),e.pingedLanes|=e.suspendedLanes&a,Ll===e&&(Pl&a)===a&&(4===Dl||3===Dl&&(130023424&Pl)===Pl&&500>Xe()-Kl?uc(e,0):Ol|=a),nc(e,t)}function Cc(e,t){0===t&&(0===(1&e.mode)?t=1:(t=dt,0===(130023424&(dt<<=1))&&(dt=4194304)));var a=ec();null!==(e=Ds(e,t))&&(bt(e,t,a),nc(e,a))}function Tc(e){var t=e.memoizedState,a=0;null!==t&&(a=t.retryLane),Cc(e,a)}function Ac(e,t){var a=0;switch(e.tag){case 13:var n=e.stateNode,i=e.memoizedState;null!==i&&(a=i.retryLane);break;case 19:n=e.stateNode;break;default:throw Error(s(314))}null!==n&&n.delete(t),Cc(e,a)}function Lc(e,t){return Je(e,t)}function Ic(e,t,a,n){this.tag=e,this.key=a,this.sibling=this.child=this.return=this.stateNode=this.type=this.elementType=null,this.index=0,this.ref=null,this.pendingProps=t,this.dependencies=this.memoizedState=this.updateQueue=this.memoizedProps=null,this.mode=n,this.subtreeFlags=this.flags=0,this.deletions=null,this.childLanes=this.lanes=0,this.alternate=null}function Pc(e,t,a,n){return new Ic(e,t,a,n)}function Rc(e){return!(!(e=e.prototype)||!e.isReactComponent)}function Ec(e,t){var a=e.alternate;return null===a?((a=Pc(e.tag,t,e.key,e.mode)).elementType=e.elementType,a.type=e.type,a.stateNode=e.stateNode,a.alternate=e,e.alternate=a):(a.pendingProps=t,a.type=e.type,a.flags=0,a.subtreeFlags=0,a.deletions=null),a.flags=14680064&e.flags,a.childLanes=e.childLanes,a.lanes=e.lanes,a.child=e.child,a.memoizedProps=e.memoizedProps,a.memoizedState=e.memoizedState,a.updateQueue=e.updateQueue,t=e.dependencies,a.dependencies=null===t?null:{lanes:t.lanes,firstContext:t.firstContext},a.sibling=e.sibling,a.index=e.index,a.ref=e.ref,a}function Dc(e,t,a,n,i,r){var o=2;if(n=e,"function"===typeof e)Rc(e)&&(o=1);else if("string"===typeof e)o=5;else e:switch(e){case k:return Wc(a.children,i,r,t);case S:o=8,i|=8;break;case N:return(e=Pc(12,a,t,2|i)).elementType=N,e.lanes=r,e;case L:return(e=Pc(13,a,t,i)).elementType=L,e.lanes=r,e;case I:return(e=Pc(19,a,t,i)).elementType=I,e.lanes=r,e;case E:return Mc(a,i,r,t);default:if("object"===typeof e&&null!==e)switch(e.$$typeof){case C:o=10;break e;case T:o=9;break e;case A:o=11;break e;case P:o=14;break e;case R:o=16,n=null;break e}throw Error(s(130,null==e?e:typeof e,""))}return(t=Pc(o,a,t,i)).elementType=e,t.type=n,t.lanes=r,t}function Wc(e,t,a,n){return(e=Pc(7,e,n,t)).lanes=a,e}function Mc(e,t,a,n){return(e=Pc(22,e,n,t)).elementType=E,e.lanes=a,e.stateNode={isHidden:!1},e}function Gc(e,t,a){return(e=Pc(6,e,null,t)).lanes=a,e}function Oc(e,t,a){return(t=Pc(4,null!==e.children?e.children:[],e.key,t)).lanes=a,t.stateNode={containerInfo:e.containerInfo,pendingChildren:null,implementation:e.implementation},t}function Fc(e,t,a,n,i){this.tag=t,this.containerInfo=e,this.finishedWork=this.pingCache=this.current=this.pendingChildren=null,this.timeoutHandle=-1,this.callbackNode=this.pendingContext=this.context=null,this.callbackPriority=0,this.eventTimes=ft(0),this.expirationTimes=ft(-1),this.entangledLanes=this.finishedLanes=this.mutableReadLanes=this.expiredLanes=this.pingedLanes=this.suspendedLanes=this.pendingLanes=0,this.entanglements=ft(0),this.identifierPrefix=n,this.onRecoverableError=i,this.mutableSourceEagerHydrationData=null}function zc(e,t,a,n,i,s,r,o,l){return e=new Fc(e,t,a,o,l),1===t?(t=1,!0===s&&(t|=8)):t=0,s=Pc(3,null,null,t),e.current=s,s.stateNode=e,s.memoizedState={element:n,isDehydrated:a,cache:null,transitions:null,pendingSuspenseBoundaries:null},Ms(s),e}function Kc(e){if(!e)return Ti;e:{if(qe(e=e._reactInternals)!==e||1!==e.tag)throw Error(s(170));var t=e;do{switch(t.tag){case 3:t=t.stateNode.context;break e;case 1:if(Ri(t.type)){t=t.stateNode.__reactInternalMemoizedMergedChildContext;break e}}t=t.return}while(null!==t);throw Error(s(171))}if(1===e.tag){var a=e.type;if(Ri(a))return Wi(e,a,t)}return t}function qc(e,t,a,n,i,s,r,o,l){return(e=zc(a,n,!0,e,0,s,0,o,l)).context=Kc(null),a=e.current,(s=Os(n=ec(),i=tc(a))).callback=void 0!==t&&null!==t?t:null,Fs(a,s,i),e.current.lanes=i,bt(e,i,n),nc(e,n),e}function _c(e,t,a,n){var i=t.current,s=ec(),r=tc(i);return a=Kc(a),null===t.context?t.context=a:t.pendingContext=a,(t=Os(s,r)).payload={element:e},null!==(n=void 0===n?null:n)&&(t.callback=n),null!==(e=Fs(i,t,r))&&(ac(e,i,r,s),zs(e,i,r)),r}function Hc(e){return(e=e.current).child?(e.child.tag,e.child.stateNode):null}function Bc(e,t){if(null!==(e=e.memoizedState)&&null!==e.dehydrated){var a=e.retryLane;e.retryLane=0!==a&&a<t?a:t}}function Uc(e,t){Bc(e,t),(e=e.alternate)&&Bc(e,t)}kl=function(e,t,a){if(null!==e)if(e.memoizedProps!==t.pendingProps||Li.current)xo=!0;else{if(0===(e.lanes&a)&&0===(128&t.flags))return xo=!1,function(e,t,a){switch(t.tag){case 3:Lo(t),ps();break;case 5:Xs(t);break;case 1:Ri(t.type)&&Mi(t);break;case 4:Vs(t,t.stateNode.containerInfo);break;case 10:var n=t.type._context,i=t.memoizedProps.value;Ci(js,n._currentValue),n._currentValue=i;break;case 13:if(null!==(n=t.memoizedState))return null!==n.dehydrated?(Ci($s,1&$s.current),t.flags|=128,null):0!==(a&t.child.childLanes)?Go(e,t,a):(Ci($s,1&$s.current),null!==(e=Ho(e,t,a))?e.sibling:null);Ci($s,1&$s.current);break;case 19:if(n=0!==(a&t.childLanes),0!==(128&e.flags)){if(n)return qo(e,t,a);t.flags|=128}if(null!==(i=t.memoizedState)&&(i.rendering=null,i.tail=null,i.lastEffect=null),Ci($s,$s.current),n)break;return null;case 22:case 23:return t.lanes=0,So(e,t,a)}return Ho(e,t,a)}(e,t,a);xo=0!==(131072&e.flags)}else xo=!1,is&&0!==(1048576&t.flags)&&$i(t,Ui,t.index);switch(t.lanes=0,t.tag){case 2:var n=t.type;_o(e,t),e=t.pendingProps;var i=Pi(t,Ai.current);Ls(t,a),i=gr(null,t,n,e,i,a);var r=fr();return t.flags|=1,"object"===typeof i&&null!==i&&"function"===typeof i.render&&void 0===i.$$typeof?(t.tag=1,t.memoizedState=null,t.updateQueue=null,Ri(n)?(r=!0,Mi(t)):r=!1,t.memoizedState=null!==i.state&&void 0!==i.state?i.state:null,Ms(t),i.updater=no,t.stateNode=i,i._reactInternals=t,oo(t,n,e,a),t=Ao(null,t,n,!0,r,a)):(t.tag=0,is&&r&&es(t),vo(null,t,i,a),t=t.child),t;case 16:n=t.elementType;e:{switch(_o(e,t),e=t.pendingProps,n=(i=n._init)(n._payload),t.type=n,i=t.tag=function(e){if("function"===typeof e)return Rc(e)?1:0;if(void 0!==e&&null!==e){if((e=e.$$typeof)===A)return 11;if(e===P)return 14}return 2}(n),e=to(n,e),i){case 0:t=Co(null,t,n,e,a);break e;case 1:t=To(null,t,n,e,a);break e;case 11:t=wo(null,t,n,e,a);break e;case 14:t=jo(null,t,n,to(n.type,e),a);break e}throw Error(s(306,n,""))}return t;case 0:return n=t.type,i=t.pendingProps,Co(e,t,n,i=t.elementType===n?i:to(n,i),a);case 1:return n=t.type,i=t.pendingProps,To(e,t,n,i=t.elementType===n?i:to(n,i),a);case 3:e:{if(Lo(t),null===e)throw Error(s(387));n=t.pendingProps,i=(r=t.memoizedState).element,Gs(e,t),qs(t,n,null,a);var o=t.memoizedState;if(n=o.element,r.isDehydrated){if(r={element:n,isDehydrated:!1,cache:o.cache,pendingSuspenseBoundaries:o.pendingSuspenseBoundaries,transitions:o.transitions},t.updateQueue.baseState=r,t.memoizedState=r,256&t.flags){t=Io(e,t,n,a,i=lo(Error(s(423)),t));break e}if(n!==i){t=Io(e,t,n,a,i=lo(Error(s(424)),t));break e}for(ns=ci(t.stateNode.containerInfo.firstChild),as=t,is=!0,ss=null,a=ws(t,null,n,a),t.child=a;a;)a.flags=-3&a.flags|4096,a=a.sibling}else{if(ps(),n===i){t=Ho(e,t,a);break e}vo(e,t,n,a)}t=t.child}return t;case 5:return Xs(t),null===e&&cs(t),n=t.type,i=t.pendingProps,r=null!==e?e.memoizedProps:null,o=i.children,ai(n,i)?o=null:null!==r&&ai(n,r)&&(t.flags|=32),No(e,t),vo(e,t,o,a),t.child;case 6:return null===e&&cs(t),null;case 13:return Go(e,t,a);case 4:return Vs(t,t.stateNode.containerInfo),n=t.pendingProps,null===e?t.child=vs(t,null,n,a):vo(e,t,n,a),t.child;case 11:return n=t.type,i=t.pendingProps,wo(e,t,n,i=t.elementType===n?i:to(n,i),a);case 7:return vo(e,t,t.pendingProps,a),t.child;case 8:case 12:return vo(e,t,t.pendingProps.children,a),t.child;case 10:e:{if(n=t.type._context,i=t.pendingProps,r=t.memoizedProps,o=i.value,Ci(js,n._currentValue),n._currentValue=o,null!==r)if(on(r.value,o)){if(r.children===i.children&&!Li.current){t=Ho(e,t,a);break e}}else for(null!==(r=t.child)&&(r.return=t);null!==r;){var l=r.dependencies;if(null!==l){o=r.child;for(var c=l.firstContext;null!==c;){if(c.context===n){if(1===r.tag){(c=Os(-1,a&-a)).tag=2;var d=r.updateQueue;if(null!==d){var h=(d=d.shared).pending;null===h?c.next=c:(c.next=h.next,h.next=c),d.pending=c}}r.lanes|=a,null!==(c=r.alternate)&&(c.lanes|=a),As(r.return,a,t),l.lanes|=a;break}c=c.next}}else if(10===r.tag)o=r.type===t.type?null:r.child;else if(18===r.tag){if(null===(o=r.return))throw Error(s(341));o.lanes|=a,null!==(l=o.alternate)&&(l.lanes|=a),As(o,a,t),o=r.sibling}else o=r.child;if(null!==o)o.return=r;else for(o=r;null!==o;){if(o===t){o=null;break}if(null!==(r=o.sibling)){r.return=o.return,o=r;break}o=o.return}r=o}vo(e,t,i.children,a),t=t.child}return t;case 9:return i=t.type,n=t.pendingProps.children,Ls(t,a),n=n(i=Is(i)),t.flags|=1,vo(e,t,n,a),t.child;case 14:return i=to(n=t.type,t.pendingProps),jo(e,t,n,i=to(n.type,i),a);case 15:return ko(e,t,t.type,t.pendingProps,a);case 17:return n=t.type,i=t.pendingProps,i=t.elementType===n?i:to(n,i),_o(e,t),t.tag=1,Ri(n)?(e=!0,Mi(t)):e=!1,Ls(t,a),so(t,n,i),oo(t,n,i,a),Ao(null,t,n,!0,e,a);case 19:return qo(e,t,a);case 22:return So(e,t,a)}throw Error(s(156,t.tag))};var Jc="function"===typeof reportError?reportError:function(e){console.error(e)};function Qc(e){this._internalRoot=e}function Vc(e){this._internalRoot=e}function Yc(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType)}function Xc(e){return!(!e||1!==e.nodeType&&9!==e.nodeType&&11!==e.nodeType&&(8!==e.nodeType||" react-mount-point-unstable "!==e.nodeValue))}function Zc(){}function $c(e,t,a,n,i){var s=a._reactRootContainer;if(s){var r=s;if("function"===typeof i){var o=i;i=function(){var e=Hc(r);o.call(e)}}_c(t,r,e,i)}else r=function(e,t,a,n,i){if(i){if("function"===typeof n){var s=n;n=function(){var e=Hc(r);s.call(e)}}var r=qc(t,n,e,0,null,!1,0,"",Zc);return e._reactRootContainer=r,e[mi]=r.current,qn(8===e.nodeType?e.parentNode:e),dc(),r}for(;i=e.lastChild;)e.removeChild(i);if("function"===typeof n){var o=n;n=function(){var e=Hc(l);o.call(e)}}var l=zc(e,0,!1,null,0,!1,0,"",Zc);return e._reactRootContainer=l,e[mi]=l.current,qn(8===e.nodeType?e.parentNode:e),dc((function(){_c(t,l,a,n)})),l}(a,t,e,i,n);return Hc(r)}Vc.prototype.render=Qc.prototype.render=function(e){var t=this._internalRoot;if(null===t)throw Error(s(409));_c(e,t,null,null)},Vc.prototype.unmount=Qc.prototype.unmount=function(){var e=this._internalRoot;if(null!==e){this._internalRoot=null;var t=e.containerInfo;dc((function(){_c(null,e,null,null)})),t[mi]=null}},Vc.prototype.unstable_scheduleHydration=function(e){if(e){var t=St();e={blockedOn:null,target:e,priority:t};for(var a=0;a<Et.length&&0!==t&&t<Et[a].priority;a++);Et.splice(a,0,e),0===a&&Gt(e)}},wt=function(e){switch(e.tag){case 3:var t=e.stateNode;if(t.current.memoizedState.isDehydrated){var a=ht(t.pendingLanes);0!==a&&(yt(t,1|a),nc(t,Xe()),0===(6&Al)&&(ql=Xe()+500,qi()))}break;case 13:dc((function(){var t=Ds(e,1);if(null!==t){var a=ec();ac(t,e,1,a)}})),Uc(e,1)}},jt=function(e){if(13===e.tag){var t=Ds(e,134217728);if(null!==t)ac(t,e,134217728,ec());Uc(e,134217728)}},kt=function(e){if(13===e.tag){var t=tc(e),a=Ds(e,t);if(null!==a)ac(a,e,t,ec());Uc(e,t)}},St=function(){return xt},Nt=function(e,t){var a=xt;try{return xt=e,t()}finally{xt=a}},je=function(e,t,a){switch(t){case"input":if(Z(e,a),t=a.name,"radio"===a.type&&null!=t){for(a=e;a.parentNode;)a=a.parentNode;for(a=a.querySelectorAll("input[name="+JSON.stringify(""+t)+'][type="radio"]'),t=0;t<a.length;t++){var n=a[t];if(n!==e&&n.form===e.form){var i=wi(n);if(!i)throw Error(s(90));J(n),Z(n,i)}}}break;case"textarea":se(e,a);break;case"select":null!=(t=a.value)&&ae(e,!!a.multiple,t,!1)}},Ae=cc,Le=dc;var ed={usingClientEntryPoint:!1,Events:[xi,vi,wi,Ce,Te,cc]},td={findFiberByHostInstance:yi,bundleType:0,version:"18.3.1",rendererPackageName:"react-dom"},ad={bundleType:td.bundleType,version:td.version,rendererPackageName:td.rendererPackageName,rendererConfig:td.rendererConfig,overrideHookState:null,overrideHookStateDeletePath:null,overrideHookStateRenamePath:null,overrideProps:null,overridePropsDeletePath:null,overridePropsRenamePath:null,setErrorHandler:null,setSuspenseHandler:null,scheduleUpdate:null,currentDispatcherRef:v.ReactCurrentDispatcher,findHostInstanceByFiber:function(e){return null===(e=Be(e))?null:e.stateNode},findFiberByHostInstance:td.findFiberByHostInstance||function(){return null},findHostInstancesForRefresh:null,scheduleRefresh:null,scheduleRoot:null,setRefreshHandler:null,getCurrentFiber:null,reconcilerVersion:"18.3.1-next-f1338f8080-20240426"};if("undefined"!==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__){var nd=__REACT_DEVTOOLS_GLOBAL_HOOK__;if(!nd.isDisabled&&nd.supportsFiber)try{it=nd.inject(ad),st=nd}catch(de){}}t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=ed,t.createPortal=function(e,t){var a=2<arguments.length&&void 0!==arguments[2]?arguments[2]:null;if(!Yc(t))throw Error(s(200));return function(e,t,a){var n=3<arguments.length&&void 0!==arguments[3]?arguments[3]:null;return{$$typeof:j,key:null==n?null:""+n,children:e,containerInfo:t,implementation:a}}(e,t,null,a)},t.createRoot=function(e,t){if(!Yc(e))throw Error(s(299));var a=!1,n="",i=Jc;return null!==t&&void 0!==t&&(!0===t.unstable_strictMode&&(a=!0),void 0!==t.identifierPrefix&&(n=t.identifierPrefix),void 0!==t.onRecoverableError&&(i=t.onRecoverableError)),t=zc(e,1,!1,null,0,a,0,n,i),e[mi]=t.current,qn(8===e.nodeType?e.parentNode:e),new Qc(t)},t.findDOMNode=function(e){if(null==e)return null;if(1===e.nodeType)return e;var t=e._reactInternals;if(void 0===t){if("function"===typeof e.render)throw Error(s(188));throw e=Object.keys(e).join(","),Error(s(268,e))}return e=null===(e=Be(t))?null:e.stateNode},t.flushSync=function(e){return dc(e)},t.hydrate=function(e,t,a){if(!Xc(t))throw Error(s(200));return $c(null,e,t,!0,a)},t.hydrateRoot=function(e,t,a){if(!Yc(e))throw Error(s(405));var n=null!=a&&a.hydratedSources||null,i=!1,r="",o=Jc;if(null!==a&&void 0!==a&&(!0===a.unstable_strictMode&&(i=!0),void 0!==a.identifierPrefix&&(r=a.identifierPrefix),void 0!==a.onRecoverableError&&(o=a.onRecoverableError)),t=qc(t,null,e,1,null!=a?a:null,i,0,r,o),e[mi]=t.current,qn(e),n)for(e=0;e<n.length;e++)i=(i=(a=n[e])._getVersion)(a._source),null==t.mutableSourceEagerHydrationData?t.mutableSourceEagerHydrationData=[a,i]:t.mutableSourceEagerHydrationData.push(a,i);return new Vc(t)},t.render=function(e,t,a){if(!Xc(t))throw Error(s(200));return $c(null,e,t,!1,a)},t.unmountComponentAtNode=function(e){if(!Xc(e))throw Error(s(40));return!!e._reactRootContainer&&(dc((function(){$c(null,null,e,!1,(function(){e._reactRootContainer=null,e[mi]=null}))})),!0)},t.unstable_batchedUpdates=cc,t.unstable_renderSubtreeIntoContainer=function(e,t,a,n){if(!Xc(a))throw Error(s(200));if(null==e||void 0===e._reactInternals)throw Error(s(38));return $c(e,t,a,!1,n)},t.version="18.3.1-next-f1338f8080-20240426"},4391:(e,t,a)=>{var n=a(7950);t.createRoot=n.createRoot,t.hydrateRoot=n.hydrateRoot},7950:(e,t,a)=>{!function e(){if("undefined"!==typeof __REACT_DEVTOOLS_GLOBAL_HOOK__&&"function"===typeof __REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE)try{__REACT_DEVTOOLS_GLOBAL_HOOK__.checkDCE(e)}catch(t){console.error(t)}}(),e.exports=a(2730)},1153:(e,t,a)=>{var n=a(5043),i=Symbol.for("react.element"),s=Symbol.for("react.fragment"),r=Object.prototype.hasOwnProperty,o=n.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,l={key:!0,ref:!0,__self:!0,__source:!0};function c(e,t,a){var n,s={},c=null,d=null;for(n in void 0!==a&&(c=""+a),void 0!==t.key&&(c=""+t.key),void 0!==t.ref&&(d=t.ref),t)r.call(t,n)&&!l.hasOwnProperty(n)&&(s[n]=t[n]);if(e&&e.defaultProps)for(n in t=e.defaultProps)void 0===s[n]&&(s[n]=t[n]);return{$$typeof:i,type:e,key:c,ref:d,props:s,_owner:o.current}}t.Fragment=s,t.jsx=c,t.jsxs=c},4202:(e,t)=>{var a=Symbol.for("react.element"),n=Symbol.for("react.portal"),i=Symbol.for("react.fragment"),s=Symbol.for("react.strict_mode"),r=Symbol.for("react.profiler"),o=Symbol.for("react.provider"),l=Symbol.for("react.context"),c=Symbol.for("react.forward_ref"),d=Symbol.for("react.suspense"),h=Symbol.for("react.memo"),u=Symbol.for("react.lazy"),p=Symbol.iterator;var m={isMounted:function(){return!1},enqueueForceUpdate:function(){},enqueueReplaceState:function(){},enqueueSetState:function(){}},g=Object.assign,f={};function b(e,t,a){this.props=e,this.context=t,this.refs=f,this.updater=a||m}function y(){}function x(e,t,a){this.props=e,this.context=t,this.refs=f,this.updater=a||m}b.prototype.isReactComponent={},b.prototype.setState=function(e,t){if("object"!==typeof e&&"function"!==typeof e&&null!=e)throw Error("setState(...): takes an object of state variables to update or a function which returns an object of state variables.");this.updater.enqueueSetState(this,e,t,"setState")},b.prototype.forceUpdate=function(e){this.updater.enqueueForceUpdate(this,e,"forceUpdate")},y.prototype=b.prototype;var v=x.prototype=new y;v.constructor=x,g(v,b.prototype),v.isPureReactComponent=!0;var w=Array.isArray,j=Object.prototype.hasOwnProperty,k={current:null},S={key:!0,ref:!0,__self:!0,__source:!0};function N(e,t,n){var i,s={},r=null,o=null;if(null!=t)for(i in void 0!==t.ref&&(o=t.ref),void 0!==t.key&&(r=""+t.key),t)j.call(t,i)&&!S.hasOwnProperty(i)&&(s[i]=t[i]);var l=arguments.length-2;if(1===l)s.children=n;else if(1<l){for(var c=Array(l),d=0;d<l;d++)c[d]=arguments[d+2];s.children=c}if(e&&e.defaultProps)for(i in l=e.defaultProps)void 0===s[i]&&(s[i]=l[i]);return{$$typeof:a,type:e,key:r,ref:o,props:s,_owner:k.current}}function C(e){return"object"===typeof e&&null!==e&&e.$$typeof===a}var T=/\/+/g;function A(e,t){return"object"===typeof e&&null!==e&&null!=e.key?function(e){var t={"=":"=0",":":"=2"};return"$"+e.replace(/[=:]/g,(function(e){return t[e]}))}(""+e.key):t.toString(36)}function L(e,t,i,s,r){var o=typeof e;"undefined"!==o&&"boolean"!==o||(e=null);var l=!1;if(null===e)l=!0;else switch(o){case"string":case"number":l=!0;break;case"object":switch(e.$$typeof){case a:case n:l=!0}}if(l)return r=r(l=e),e=""===s?"."+A(l,0):s,w(r)?(i="",null!=e&&(i=e.replace(T,"$&/")+"/"),L(r,t,i,"",(function(e){return e}))):null!=r&&(C(r)&&(r=function(e,t){return{$$typeof:a,type:e.type,key:t,ref:e.ref,props:e.props,_owner:e._owner}}(r,i+(!r.key||l&&l.key===r.key?"":(""+r.key).replace(T,"$&/")+"/")+e)),t.push(r)),1;if(l=0,s=""===s?".":s+":",w(e))for(var c=0;c<e.length;c++){var d=s+A(o=e[c],c);l+=L(o,t,i,d,r)}else if(d=function(e){return null===e||"object"!==typeof e?null:"function"===typeof(e=p&&e[p]||e["@@iterator"])?e:null}(e),"function"===typeof d)for(e=d.call(e),c=0;!(o=e.next()).done;)l+=L(o=o.value,t,i,d=s+A(o,c++),r);else if("object"===o)throw t=String(e),Error("Objects are not valid as a React child (found: "+("[object Object]"===t?"object with keys {"+Object.keys(e).join(", ")+"}":t)+"). If you meant to render a collection of children, use an array instead.");return l}function I(e,t,a){if(null==e)return e;var n=[],i=0;return L(e,n,"","",(function(e){return t.call(a,e,i++)})),n}function P(e){if(-1===e._status){var t=e._result;(t=t()).then((function(t){0!==e._status&&-1!==e._status||(e._status=1,e._result=t)}),(function(t){0!==e._status&&-1!==e._status||(e._status=2,e._result=t)})),-1===e._status&&(e._status=0,e._result=t)}if(1===e._status)return e._result.default;throw e._result}var R={current:null},E={transition:null},D={ReactCurrentDispatcher:R,ReactCurrentBatchConfig:E,ReactCurrentOwner:k};function W(){throw Error("act(...) is not supported in production builds of React.")}t.Children={map:I,forEach:function(e,t,a){I(e,(function(){t.apply(this,arguments)}),a)},count:function(e){var t=0;return I(e,(function(){t++})),t},toArray:function(e){return I(e,(function(e){return e}))||[]},only:function(e){if(!C(e))throw Error("React.Children.only expected to receive a single React element child.");return e}},t.Component=b,t.Fragment=i,t.Profiler=r,t.PureComponent=x,t.StrictMode=s,t.Suspense=d,t.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED=D,t.act=W,t.cloneElement=function(e,t,n){if(null===e||void 0===e)throw Error("React.cloneElement(...): The argument must be a React element, but you passed "+e+".");var i=g({},e.props),s=e.key,r=e.ref,o=e._owner;if(null!=t){if(void 0!==t.ref&&(r=t.ref,o=k.current),void 0!==t.key&&(s=""+t.key),e.type&&e.type.defaultProps)var l=e.type.defaultProps;for(c in t)j.call(t,c)&&!S.hasOwnProperty(c)&&(i[c]=void 0===t[c]&&void 0!==l?l[c]:t[c])}var c=arguments.length-2;if(1===c)i.children=n;else if(1<c){l=Array(c);for(var d=0;d<c;d++)l[d]=arguments[d+2];i.children=l}return{$$typeof:a,type:e.type,key:s,ref:r,props:i,_owner:o}},t.createContext=function(e){return(e={$$typeof:l,_currentValue:e,_currentValue2:e,_threadCount:0,Provider:null,Consumer:null,_defaultValue:null,_globalName:null}).Provider={$$typeof:o,_context:e},e.Consumer=e},t.createElement=N,t.createFactory=function(e){var t=N.bind(null,e);return t.type=e,t},t.createRef=function(){return{current:null}},t.forwardRef=function(e){return{$$typeof:c,render:e}},t.isValidElement=C,t.lazy=function(e){return{$$typeof:u,_payload:{_status:-1,_result:e},_init:P}},t.memo=function(e,t){return{$$typeof:h,type:e,compare:void 0===t?null:t}},t.startTransition=function(e){var t=E.transition;E.transition={};try{e()}finally{E.transition=t}},t.unstable_act=W,t.useCallback=function(e,t){return R.current.useCallback(e,t)},t.useContext=function(e){return R.current.useContext(e)},t.useDebugValue=function(){},t.useDeferredValue=function(e){return R.current.useDeferredValue(e)},t.useEffect=function(e,t){return R.current.useEffect(e,t)},t.useId=function(){return R.current.useId()},t.useImperativeHandle=function(e,t,a){return R.current.useImperativeHandle(e,t,a)},t.useInsertionEffect=function(e,t){return R.current.useInsertionEffect(e,t)},t.useLayoutEffect=function(e,t){return R.current.useLayoutEffect(e,t)},t.useMemo=function(e,t){return R.current.useMemo(e,t)},t.useReducer=function(e,t,a){return R.current.useReducer(e,t,a)},t.useRef=function(e){return R.current.useRef(e)},t.useState=function(e){return R.current.useState(e)},t.useSyncExternalStore=function(e,t,a){return R.current.useSyncExternalStore(e,t,a)},t.useTransition=function(){return R.current.useTransition()},t.version="18.3.1"},5043:(e,t,a)=>{e.exports=a(4202)},579:(e,t,a)=>{e.exports=a(1153)},7234:(e,t)=>{function a(e,t){var a=e.length;e.push(t);e:for(;0<a;){var n=a-1>>>1,i=e[n];if(!(0<s(i,t)))break e;e[n]=t,e[a]=i,a=n}}function n(e){return 0===e.length?null:e[0]}function i(e){if(0===e.length)return null;var t=e[0],a=e.pop();if(a!==t){e[0]=a;e:for(var n=0,i=e.length,r=i>>>1;n<r;){var o=2*(n+1)-1,l=e[o],c=o+1,d=e[c];if(0>s(l,a))c<i&&0>s(d,l)?(e[n]=d,e[c]=a,n=c):(e[n]=l,e[o]=a,n=o);else{if(!(c<i&&0>s(d,a)))break e;e[n]=d,e[c]=a,n=c}}}return t}function s(e,t){var a=e.sortIndex-t.sortIndex;return 0!==a?a:e.id-t.id}if("object"===typeof performance&&"function"===typeof performance.now){var r=performance;t.unstable_now=function(){return r.now()}}else{var o=Date,l=o.now();t.unstable_now=function(){return o.now()-l}}var c=[],d=[],h=1,u=null,p=3,m=!1,g=!1,f=!1,b="function"===typeof setTimeout?setTimeout:null,y="function"===typeof clearTimeout?clearTimeout:null,x="undefined"!==typeof setImmediate?setImmediate:null;function v(e){for(var t=n(d);null!==t;){if(null===t.callback)i(d);else{if(!(t.startTime<=e))break;i(d),t.sortIndex=t.expirationTime,a(c,t)}t=n(d)}}function w(e){if(f=!1,v(e),!g)if(null!==n(c))g=!0,E(j);else{var t=n(d);null!==t&&D(w,t.startTime-e)}}function j(e,a){g=!1,f&&(f=!1,y(C),C=-1),m=!0;var s=p;try{for(v(a),u=n(c);null!==u&&(!(u.expirationTime>a)||e&&!L());){var r=u.callback;if("function"===typeof r){u.callback=null,p=u.priorityLevel;var o=r(u.expirationTime<=a);a=t.unstable_now(),"function"===typeof o?u.callback=o:u===n(c)&&i(c),v(a)}else i(c);u=n(c)}if(null!==u)var l=!0;else{var h=n(d);null!==h&&D(w,h.startTime-a),l=!1}return l}finally{u=null,p=s,m=!1}}"undefined"!==typeof navigator&&void 0!==navigator.scheduling&&void 0!==navigator.scheduling.isInputPending&&navigator.scheduling.isInputPending.bind(navigator.scheduling);var k,S=!1,N=null,C=-1,T=5,A=-1;function L(){return!(t.unstable_now()-A<T)}function I(){if(null!==N){var e=t.unstable_now();A=e;var a=!0;try{a=N(!0,e)}finally{a?k():(S=!1,N=null)}}else S=!1}if("function"===typeof x)k=function(){x(I)};else if("undefined"!==typeof MessageChannel){var P=new MessageChannel,R=P.port2;P.port1.onmessage=I,k=function(){R.postMessage(null)}}else k=function(){b(I,0)};function E(e){N=e,S||(S=!0,k())}function D(e,a){C=b((function(){e(t.unstable_now())}),a)}t.unstable_IdlePriority=5,t.unstable_ImmediatePriority=1,t.unstable_LowPriority=4,t.unstable_NormalPriority=3,t.unstable_Profiling=null,t.unstable_UserBlockingPriority=2,t.unstable_cancelCallback=function(e){e.callback=null},t.unstable_continueExecution=function(){g||m||(g=!0,E(j))},t.unstable_forceFrameRate=function(e){0>e||125<e?console.error("forceFrameRate takes a positive int between 0 and 125, forcing frame rates higher than 125 fps is not supported"):T=0<e?Math.floor(1e3/e):5},t.unstable_getCurrentPriorityLevel=function(){return p},t.unstable_getFirstCallbackNode=function(){return n(c)},t.unstable_next=function(e){switch(p){case 1:case 2:case 3:var t=3;break;default:t=p}var a=p;p=t;try{return e()}finally{p=a}},t.unstable_pauseExecution=function(){},t.unstable_requestPaint=function(){},t.unstable_runWithPriority=function(e,t){switch(e){case 1:case 2:case 3:case 4:case 5:break;default:e=3}var a=p;p=e;try{return t()}finally{p=a}},t.unstable_scheduleCallback=function(e,i,s){var r=t.unstable_now();switch("object"===typeof s&&null!==s?s="number"===typeof(s=s.delay)&&0<s?r+s:r:s=r,e){case 1:var o=-1;break;case 2:o=250;break;case 5:o=1073741823;break;case 4:o=1e4;break;default:o=5e3}return e={id:h++,callback:i,priorityLevel:e,startTime:s,expirationTime:o=s+o,sortIndex:-1},s>r?(e.sortIndex=s,a(d,e),null===n(c)&&e===n(d)&&(f?(y(C),C=-1):f=!0,D(w,s-r))):(e.sortIndex=o,a(c,e),g||m||(g=!0,E(j))),e},t.unstable_shouldYield=L,t.unstable_wrapCallback=function(e){var t=p;return function(){var a=p;p=t;try{return e.apply(this,arguments)}finally{p=a}}}},8853:(e,t,a)=>{e.exports=a(7234)}},t={};function a(n){var i=t[n];if(void 0!==i)return i.exports;var s=t[n]={exports:{}};return e[n](s,s.exports,a),s.exports}a.m=e,(()=>{var e,t=Object.getPrototypeOf?e=>Object.getPrototypeOf(e):e=>e.__proto__;a.t=function(n,i){if(1&i&&(n=this(n)),8&i)return n;if("object"===typeof n&&n){if(4&i&&n.__esModule)return n;if(16&i&&"function"===typeof n.then)return n}var s=Object.create(null);a.r(s);var r={};e=e||[null,t({}),t([]),t(t)];for(var o=2&i&&n;"object"==typeof o&&!~e.indexOf(o);o=t(o))Object.getOwnPropertyNames(o).forEach((e=>r[e]=()=>n[e]));return r.default=()=>n,a.d(s,r),s}})(),a.d=(e,t)=>{for(var n in t)a.o(t,n)&&!a.o(e,n)&&Object.defineProperty(e,n,{enumerable:!0,get:t[n]})},a.f={},a.e=e=>Promise.all(Object.keys(a.f).reduce(((t,n)=>(a.f[n](e,t),t)),[])),a.u=e=>"static/js/"+e+".7e499361.chunk.js",a.miniCssF=e=>{},a.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),(()=>{var e={},t="ieee:";a.l=(n,i,s,r)=>{if(e[n])e[n].push(i);else{var o,l;if(void 0!==s)for(var c=document.getElementsByTagName("script"),d=0;d<c.length;d++){var h=c[d];if(h.getAttribute("src")==n||h.getAttribute("data-webpack")==t+s){o=h;break}}o||(l=!0,(o=document.createElement("script")).charset="utf-8",o.timeout=120,a.nc&&o.setAttribute("nonce",a.nc),o.setAttribute("data-webpack",t+s),o.src=n),e[n]=[i];var u=(t,a)=>{o.onerror=o.onload=null,clearTimeout(p);var i=e[n];if(delete e[n],o.parentNode&&o.parentNode.removeChild(o),i&&i.forEach((e=>e(a))),t)return t(a)},p=setTimeout(u.bind(null,void 0,{type:"timeout",target:o}),12e4);o.onerror=u.bind(null,o.onerror),o.onload=u.bind(null,o.onload),l&&document.head.appendChild(o)}}})(),a.r=e=>{"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},a.p="./",(()=>{var e={792:0};a.f.j=(t,n)=>{var i=a.o(e,t)?e[t]:void 0;if(0!==i)if(i)n.push(i[2]);else{var s=new Promise(((a,n)=>i=e[t]=[a,n]));n.push(i[2]=s);var r=a.p+a.u(t),o=new Error;a.l(r,(n=>{if(a.o(e,t)&&(0!==(i=e[t])&&(e[t]=void 0),i)){var s=n&&("load"===n.type?"missing":n.type),r=n&&n.target&&n.target.src;o.message="Loading chunk "+t+" failed.\n("+s+": "+r+")",o.name="ChunkLoadError",o.type=s,o.request=r,i[1](o)}}),"chunk-"+t,t)}};var t=(t,n)=>{var i,s,r=n[0],o=n[1],l=n[2],c=0;if(r.some((t=>0!==e[t]))){for(i in o)a.o(o,i)&&(a.m[i]=o[i]);if(l)l(a)}for(t&&t(n);c<r.length;c++)s=r[c],a.o(e,s)&&e[s]&&e[s][0](),e[s]=0},n=self.webpackChunkieee=self.webpackChunkieee||[];n.forEach(t.bind(null,0)),n.push=t.bind(null,n.push.bind(n))})();var n=a(5043),i=a.t(n,2),s=a(4391),r=a(579);const o=()=>(0,r.jsx)(r.Fragment,{children:(0,r.jsxs)("div",{className:"flex justify-center item-center flex-col pb-0 lg:pb-4 mb-4 lg:my-6  lg:h-[14rem] lg:px-16 px-6",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"About ISWC 2025"}),(0,r.jsx)("p",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:"The International Semantic Web Conference (ISWC) is the premier international forum for the Semantic Web / Linked Data Community. ISWC2025 will bring together researchers, practitioners, and industry specialists to discuss, advance, and shape the future of semantic technologies. ISWC offers five exciting and fruitful days you don\u2019t want to miss every year!"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:"ISWC2025 will be an in-person conference. We look forward to meeting you in Nara, Japan, in November 2025."}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsxs)("p",{className:"text-md lg:text-md font-[300] lg:mx-10 sm:mx-2",children:["To make the conference more environmentally friendly the Semantic Web Association (SWSA) is offsetting the carbon footprint of ISWC 2025. Read more on the sustainability initiative\xa0",(0,r.jsx)("a",{href:"https://swsa.semanticweb.org/content/sustainability#:~:text=At%20ISWC2023%20SWSA%20announced%20the%20launch%20of,while%20recognising%20the%20significance%20of%20scientific%20networking",target:"_blank",style:{color:"#e94607","text-decoration":"underline"},children:"here"}),"."]})]})}),l=a.p+"static/media/nara.f23252a86df90f0e41a6.jpg",c=()=>(0,r.jsxs)("div",{class:"relative bg-gradient-to-r from-purple-600 to-blue-600 h-screen text-white overflow-hidden",children:[(0,r.jsxs)("div",{class:"absolute inset-0",children:[(0,r.jsx)("img",{src:l,alt:"Background",class:"object-cover object-center w-full h-full"}),(0,r.jsx)("div",{class:"absolute inset-0 bg-black opacity-[0.45]"})]}),(0,r.jsxs)("div",{class:"relative z-10 flex flex-col justify-center items-center h-full text-center m-2 lg:m-0",children:[(0,r.jsx)("h1",{class:"lg:text-5xl text-3xl font-semibold tracking-wide lg:font-[800] leading-tight mb-4",children:"ISWC 2025"}),(0,r.jsx)("h1",{class:"lg:text-5xl text-3xl font-semibold tracking-wide lg:font-[800] leading-tight mb-4",children:"THE 24th INTERNATIONAL SEMANTIC WEB CONFERENCE"}),(0,r.jsx)("p",{class:"text-2xl font-semibold mb-6",children:"Date:\xa0\xa0November 2-6,\xa0\xa02025"}),(0,r.jsx)("p",{class:"text-2xl font-semibold mb-6",children:"Nara,\xa0\xa0Japan"}),(0,r.jsx)("p",{class:"text-xl font-semibold  mb-6",children:"Venue:\xa0\xa0Nara Prefectural Convention Center"})]})]}),d=()=>(0,r.jsx)(r.Fragment,{children:(0,r.jsx)("div",{className:"flex justify-center items-center min-h-screen",children:(0,r.jsxs)("div",{className:"my-2 mx-4 mb-8",children:[(0,r.jsx)("div",{className:"container",children:(0,r.jsxs)("ul",{className:"list-unstyled",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("span",{className:"me-2",style:{color:"#57D131"},children:(0,r.jsx)("b",{children:"\u2022"})}),(0,r.jsx)("span",{style:{color:"#57D131"},children:(0,r.jsx)("b",{children:"Submissions"})})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("span",{className:"me-2",style:{color:"#4E84D8"},children:(0,r.jsx)("b",{children:"\u2022"})}),(0,r.jsx)("span",{style:{color:"#4E84D8"},children:(0,r.jsx)("b",{children:"Notifications"})})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("span",{className:"me-2",style:{color:"#E32D20"},children:(0,r.jsx)("b",{children:"\u2022"})}),(0,r.jsx)("span",{style:{color:"#E32D20"},children:(0,r.jsx)("b",{children:"Camera-Ready (impacting SPRINGER)"})})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("span",{className:"me-2",style:{color:"#912C8B"},children:(0,r.jsx)("b",{children:"\u2022"})}),(0,r.jsx)("span",{style:{color:"#912C8B"},children:(0,r.jsx)("b",{children:"Camera-Ready (CEUR companion volume)"})})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("span",{className:"me-2",style:{color:"#000000"},children:(0,r.jsx)("b",{children:"\u2022"})}),(0,r.jsx)("span",{style:{color:"#000000"},children:(0,r.jsx)("b",{children:"All other"})})]})]})}),(0,r.jsx)("br",{}),(0,r.jsx)("div",{className:"container my-2 mx-4 mb-8",children:[{date:"18-Feb-25",title:"Workshop proposals",color:"#57D131"},{date:"4-Mar-25",title:"Semantic Web Challenge proposals",color:"#57D131"},{date:"11-Mar-25",title:"Workshop notifications",color:"#4E84D8"},{date:"16-Mar-25",title:"Semantic Web Challenges notifications",color:"#4E84D8"},{date:"6-May-25",title:"Abstracts (Research, In-use, and Resource tracks)",color:"#57D131"},{date:"13-May-25 (extended 14-May-25)",title:"Papers (Research, In-use, and Resource tracks)",color:"#57D131"},{date:"3-Jun-25",title:"Tutorial proposals",color:"#57D131"},{date:"3-Jun-25",title:"Doctoral Consortium submissions",color:"#57D131"},{date:"10-Jun-25",title:"Tutorial notifications",color:"#4E84D8"},{date:"17-20 Jun-25",title:"Rebuttal (Research, In-use, and Resource tracks)",color:"#000000"},{date:"30-Jun-25",title:"Journal Sessions Proposals",color:"#57D131"},{date:"8-Jul-25",title:"Doctoral Consortium notifications",color:"#4E84D8"},{date:"17-Jul-25",title:"Paper notifications (Research, In-use, and Resource tracks)",color:"#4E84D8"},{date:"8-Jul-25",title:"Industry papers submissions",color:"#57D131"},{date:"8-Jul-25",title:"Dagstuhl-style workshop submission",color:"#57D131"},{date:"17-Jul-25",title:"Journal Sessions Notifications",color:"#4E84D8"},{date:"29-Jul-25",title:"Industry papers notifications",color:"#4E84D8"},{date:"31-Jul-25",title:"Camera-ready papers (Research, In-use, and Resource tracks)",color:"#E32D20"},{date:"31-Jul-25",title:"Poster & Demo submissions",color:"#57D131"},{date:"28-Aug-25",title:"Poster & Demo notifications",color:"#4E84D8"},{date:"28-Aug-25",title:"Workshop papers notifications",color:"#4E84D8"},{date:"11-Sep-25",title:"Camera-ready - Industry",color:"#912C8B"},{date:"11-Sep-25",title:"Camera-ready - Poster&Demo",color:"#912C8B"},{date:"11-Sep-25",title:"Camera-ready - Doctoral Consortium",color:"#912C8B"},{date:"2-3 Nov-25",title:"Workshops & Tutorials",color:"#000000"},{date:"4-6 Nov-25",title:"Main conference",color:"#000000"}].map(((e,t)=>(0,r.jsx)("div",{className:"relative pl-8 sm:pl-32 py-2 md:py-4 group",children:(0,r.jsxs)("div",{className:"flex flex-col sm:flex-row items-start group-last:before:hidden before:absolute before:left-7 sm:before:left-5 before:h-full before:px-px before:bg-slate-300 sm:before:ml-[6.5rem] before:self-start before:-translate-x-1/2 before:translate-y-3 after:absolute after:left-7 sm:after:left-5 after:w-2 after:h-2 after:bg-[#e94607] after:border-4 after:box-content after:border-slate-50 after:rounded-full sm:after:ml-[6.5rem] after:-translate-x-1/2 after:translate-y-1.5",children:[(0,r.jsx)("time",{className:"sm:absolute left-0 top-1/2 -translate-y-1/2 flex items-center justify-center text-sm font-bold uppercase mb-3 sm:mb-0 text-[#e94607] bg-emerald-100 rounded-full ml-4 lg:ml-0 px-2 py-1 text-center whitespace-normal break-words leading-tight w-[110px] h-auto min-h-[24px]",children:e.date}),(0,r.jsx)("div",{className:"text-xl font-[600] ml-4",style:{color:e.color},children:e.title})]})},t)))})]})})}),h=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)(c,{}),(0,r.jsx)("div",{className:"flex justify-center items-center lg:mx-24 mx-6 mt-2",children:(0,r.jsx)("div",{class:"relative flex overflow-x-hidden",children:(0,r.jsx)("div",{class:"flex py-4 animate-marquee whitespace-nowrap"})})}),(0,r.jsx)(o,{}),(0,r.jsx)("div",{className:"mx-auto flex flex-col justify-center items-center"})]}),u=a.p+"static/media/ISWC2025banner.07da39f4a9b0c9e3a353.webp",p=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 mt-12",children:[(0,r.jsx)("div",{className:"w-full mb-8 flex justify-center",children:(0,r.jsx)("img",{src:u,alt:"ISWC 2025 Banner",className:"w-full h-auto object-cover max-w-screen-lg min-h-[200px]"})}),(0,r.jsx)("div",{className:"bg-white p-6 lg:p-12 rounded-lg shadow-md",children:(0,r.jsx)(o,{})})]})]});function m(){return m=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var n in a)Object.prototype.hasOwnProperty.call(a,n)&&(e[n]=a[n])}return e},m.apply(this,arguments)}var g;!function(e){e.Pop="POP",e.Push="PUSH",e.Replace="REPLACE"}(g||(g={}));const f="popstate";function b(e,t){if(!1===e||null===e||"undefined"===typeof e)throw new Error(t)}function y(e,t){if(!e){"undefined"!==typeof console&&console.warn(t);try{throw new Error(t)}catch(a){}}}function x(e,t){return{usr:e.state,key:e.key,idx:t}}function v(e,t,a,n){return void 0===a&&(a=null),m({pathname:"string"===typeof e?e:e.pathname,search:"",hash:""},"string"===typeof t?j(t):t,{state:a,key:t&&t.key||n||Math.random().toString(36).substr(2,8)})}function w(e){let{pathname:t="/",search:a="",hash:n=""}=e;return a&&"?"!==a&&(t+="?"===a.charAt(0)?a:"?"+a),n&&"#"!==n&&(t+="#"===n.charAt(0)?n:"#"+n),t}function j(e){let t={};if(e){let a=e.indexOf("#");a>=0&&(t.hash=e.substr(a),e=e.substr(0,a));let n=e.indexOf("?");n>=0&&(t.search=e.substr(n),e=e.substr(0,n)),e&&(t.pathname=e)}return t}function k(e,t,a,n){void 0===n&&(n={});let{window:i=document.defaultView,v5Compat:s=!1}=n,r=i.history,o=g.Pop,l=null,c=d();function d(){return(r.state||{idx:null}).idx}function h(){o=g.Pop;let e=d(),t=null==e?null:e-c;c=e,l&&l({action:o,location:p.location,delta:t})}function u(e){let t="null"!==i.location.origin?i.location.origin:i.location.href,a="string"===typeof e?e:w(e);return a=a.replace(/ $/,"%20"),b(t,"No window.location.(origin|href) available to create URL for href: "+a),new URL(a,t)}null==c&&(c=0,r.replaceState(m({},r.state,{idx:c}),""));let p={get action(){return o},get location(){return e(i,r)},listen(e){if(l)throw new Error("A history only accepts one active listener");return i.addEventListener(f,h),l=e,()=>{i.removeEventListener(f,h),l=null}},createHref:e=>t(i,e),createURL:u,encodeLocation(e){let t=u(e);return{pathname:t.pathname,search:t.search,hash:t.hash}},push:function(e,t){o=g.Push;let n=v(p.location,e,t);a&&a(n,e),c=d()+1;let h=x(n,c),u=p.createHref(n);try{r.pushState(h,"",u)}catch(m){if(m instanceof DOMException&&"DataCloneError"===m.name)throw m;i.location.assign(u)}s&&l&&l({action:o,location:p.location,delta:1})},replace:function(e,t){o=g.Replace;let n=v(p.location,e,t);a&&a(n,e),c=d();let i=x(n,c),h=p.createHref(n);r.replaceState(i,"",h),s&&l&&l({action:o,location:p.location,delta:0})},go:e=>r.go(e)};return p}var S;!function(e){e.data="data",e.deferred="deferred",e.redirect="redirect",e.error="error"}(S||(S={}));new Set(["lazy","caseSensitive","path","id","index","children"]);function N(e,t,a){return void 0===a&&(a="/"),C(e,t,a,!1)}function C(e,t,a,n){let i=z(("string"===typeof t?j(t):t).pathname||"/",a);if(null==i)return null;let s=T(e);!function(e){e.sort(((e,t)=>e.score!==t.score?t.score-e.score:function(e,t){let a=e.length===t.length&&e.slice(0,-1).every(((e,a)=>e===t[a]));return a?e[e.length-1]-t[t.length-1]:0}(e.routesMeta.map((e=>e.childrenIndex)),t.routesMeta.map((e=>e.childrenIndex)))))}(s);let r=null;for(let o=0;null==r&&o<s.length;++o){let e=F(i);r=G(s[o],e,n)}return r}function T(e,t,a,n){void 0===t&&(t=[]),void 0===a&&(a=[]),void 0===n&&(n="");let i=(e,i,s)=>{let r={relativePath:void 0===s?e.path||"":s,caseSensitive:!0===e.caseSensitive,childrenIndex:i,route:e};r.relativePath.startsWith("/")&&(b(r.relativePath.startsWith(n),'Absolute route path "'+r.relativePath+'" nested under path "'+n+'" is not valid. An absolute child route path must start with the combined path of all its parent routes.'),r.relativePath=r.relativePath.slice(n.length));let o=B([n,r.relativePath]),l=a.concat(r);e.children&&e.children.length>0&&(b(!0!==e.index,'Index routes must not have child routes. Please remove all child routes from route path "'+o+'".'),T(e.children,t,l,o)),(null!=e.path||e.index)&&t.push({path:o,score:M(o,e.index),routesMeta:l})};return e.forEach(((e,t)=>{var a;if(""!==e.path&&null!=(a=e.path)&&a.includes("?"))for(let n of A(e.path))i(e,t,n);else i(e,t)})),t}function A(e){let t=e.split("/");if(0===t.length)return[];let[a,...n]=t,i=a.endsWith("?"),s=a.replace(/\?$/,"");if(0===n.length)return i?[s,""]:[s];let r=A(n.join("/")),o=[];return o.push(...r.map((e=>""===e?s:[s,e].join("/")))),i&&o.push(...r),o.map((t=>e.startsWith("/")&&""===t?"/":t))}const L=/^:[\w-]+$/,I=3,P=2,R=1,E=10,D=-2,W=e=>"*"===e;function M(e,t){let a=e.split("/"),n=a.length;return a.some(W)&&(n+=D),t&&(n+=P),a.filter((e=>!W(e))).reduce(((e,t)=>e+(L.test(t)?I:""===t?R:E)),n)}function G(e,t,a){void 0===a&&(a=!1);let{routesMeta:n}=e,i={},s="/",r=[];for(let o=0;o<n.length;++o){let e=n[o],l=o===n.length-1,c="/"===s?t:t.slice(s.length)||"/",d=O({path:e.relativePath,caseSensitive:e.caseSensitive,end:l},c),h=e.route;if(!d&&l&&a&&!n[n.length-1].route.index&&(d=O({path:e.relativePath,caseSensitive:e.caseSensitive,end:!1},c)),!d)return null;Object.assign(i,d.params),r.push({params:i,pathname:B([s,d.pathname]),pathnameBase:U(B([s,d.pathnameBase])),route:h}),"/"!==d.pathnameBase&&(s=B([s,d.pathnameBase]))}return r}function O(e,t){"string"===typeof e&&(e={path:e,caseSensitive:!1,end:!0});let[a,n]=function(e,t,a){void 0===t&&(t=!1);void 0===a&&(a=!0);y("*"===e||!e.endsWith("*")||e.endsWith("/*"),'Route path "'+e+'" will be treated as if it were "'+e.replace(/\*$/,"/*")+'" because the `*` character must always follow a `/` in the pattern. To get rid of this warning, please change the route path to "'+e.replace(/\*$/,"/*")+'".');let n=[],i="^"+e.replace(/\/*\*?$/,"").replace(/^\/*/,"/").replace(/[\\.*+^${}|()[\]]/g,"\\$&").replace(/\/:([\w-]+)(\?)?/g,((e,t,a)=>(n.push({paramName:t,isOptional:null!=a}),a?"/?([^\\/]+)?":"/([^\\/]+)")));e.endsWith("*")?(n.push({paramName:"*"}),i+="*"===e||"/*"===e?"(.*)$":"(?:\\/(.+)|\\/*)$"):a?i+="\\/*$":""!==e&&"/"!==e&&(i+="(?:(?=\\/|$))");let s=new RegExp(i,t?void 0:"i");return[s,n]}(e.path,e.caseSensitive,e.end),i=t.match(a);if(!i)return null;let s=i[0],r=s.replace(/(.)\/+$/,"$1"),o=i.slice(1);return{params:n.reduce(((e,t,a)=>{let{paramName:n,isOptional:i}=t;if("*"===n){let e=o[a]||"";r=s.slice(0,s.length-e.length).replace(/(.)\/+$/,"$1")}const l=o[a];return e[n]=i&&!l?void 0:(l||"").replace(/%2F/g,"/"),e}),{}),pathname:s,pathnameBase:r,pattern:e}}function F(e){try{return e.split("/").map((e=>decodeURIComponent(e).replace(/\//g,"%2F"))).join("/")}catch(t){return y(!1,'The URL path "'+e+'" could not be decoded because it is is a malformed URL segment. This is probably due to a bad percent encoding ('+t+")."),e}}function z(e,t){if("/"===t)return e;if(!e.toLowerCase().startsWith(t.toLowerCase()))return null;let a=t.endsWith("/")?t.length-1:t.length,n=e.charAt(a);return n&&"/"!==n?null:e.slice(a)||"/"}function K(e,t,a,n){return"Cannot include a '"+e+"' character in a manually specified `to."+t+"` field ["+JSON.stringify(n)+"].  Please separate it out to the `to."+a+'` field. Alternatively you may provide the full path as a string in <Link to="..."> and the router will parse it for you.'}function q(e){return e.filter(((e,t)=>0===t||e.route.path&&e.route.path.length>0))}function _(e,t){let a=q(e);return t?a.map(((e,t)=>t===a.length-1?e.pathname:e.pathnameBase)):a.map((e=>e.pathnameBase))}function H(e,t,a,n){let i;void 0===n&&(n=!1),"string"===typeof e?i=j(e):(i=m({},e),b(!i.pathname||!i.pathname.includes("?"),K("?","pathname","search",i)),b(!i.pathname||!i.pathname.includes("#"),K("#","pathname","hash",i)),b(!i.search||!i.search.includes("#"),K("#","search","hash",i)));let s,r=""===e||""===i.pathname,o=r?"/":i.pathname;if(null==o)s=a;else{let e=t.length-1;if(!n&&o.startsWith("..")){let t=o.split("/");for(;".."===t[0];)t.shift(),e-=1;i.pathname=t.join("/")}s=e>=0?t[e]:"/"}let l=function(e,t){void 0===t&&(t="/");let{pathname:a,search:n="",hash:i=""}="string"===typeof e?j(e):e,s=a?a.startsWith("/")?a:function(e,t){let a=t.replace(/\/+$/,"").split("/");return e.split("/").forEach((e=>{".."===e?a.length>1&&a.pop():"."!==e&&a.push(e)})),a.length>1?a.join("/"):"/"}(a,t):t;return{pathname:s,search:J(n),hash:Q(i)}}(i,s),c=o&&"/"!==o&&o.endsWith("/"),d=(r||"."===o)&&a.endsWith("/");return l.pathname.endsWith("/")||!c&&!d||(l.pathname+="/"),l}const B=e=>e.join("/").replace(/\/\/+/g,"/"),U=e=>e.replace(/\/+$/,"").replace(/^\/*/,"/"),J=e=>e&&"?"!==e?e.startsWith("?")?e:"?"+e:"",Q=e=>e&&"#"!==e?e.startsWith("#")?e:"#"+e:"";Error;function V(e){return null!=e&&"number"===typeof e.status&&"string"===typeof e.statusText&&"boolean"===typeof e.internal&&"data"in e}const Y=["post","put","patch","delete"],X=(new Set(Y),["get",...Y]);new Set(X),new Set([301,302,303,307,308]),new Set([307,308]);Symbol("deferred");function Z(){return Z=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var n in a)Object.prototype.hasOwnProperty.call(a,n)&&(e[n]=a[n])}return e},Z.apply(this,arguments)}const $=n.createContext(null);const ee=n.createContext(null);const te=n.createContext(null);const ae=n.createContext(null);const ne=n.createContext({outlet:null,matches:[],isDataRoute:!1});const ie=n.createContext(null);function se(){return null!=n.useContext(ae)}function re(){return se()||b(!1),n.useContext(ae).location}function oe(e){n.useContext(te).static||n.useLayoutEffect(e)}function le(){let{isDataRoute:e}=n.useContext(ne);return e?function(){let{router:e}=ye(fe.UseNavigateStable),t=ve(be.UseNavigateStable),a=n.useRef(!1);return oe((()=>{a.current=!0})),n.useCallback((function(n,i){void 0===i&&(i={}),a.current&&("number"===typeof n?e.navigate(n):e.navigate(n,Z({fromRouteId:t},i)))}),[e,t])}():function(){se()||b(!1);let e=n.useContext($),{basename:t,future:a,navigator:i}=n.useContext(te),{matches:s}=n.useContext(ne),{pathname:r}=re(),o=JSON.stringify(_(s,a.v7_relativeSplatPath)),l=n.useRef(!1);return oe((()=>{l.current=!0})),n.useCallback((function(a,n){if(void 0===n&&(n={}),!l.current)return;if("number"===typeof a)return void i.go(a);let s=H(a,JSON.parse(o),r,"path"===n.relative);null==e&&"/"!==t&&(s.pathname="/"===s.pathname?t:B([t,s.pathname])),(n.replace?i.replace:i.push)(s,n.state,n)}),[t,i,o,r,e])}()}function ce(e,t){let{relative:a}=void 0===t?{}:t,{future:i}=n.useContext(te),{matches:s}=n.useContext(ne),{pathname:r}=re(),o=JSON.stringify(_(s,i.v7_relativeSplatPath));return n.useMemo((()=>H(e,JSON.parse(o),r,"path"===a)),[e,o,r,a])}function de(e,t,a,i){se()||b(!1);let{navigator:s}=n.useContext(te),{matches:r}=n.useContext(ne),o=r[r.length-1],l=o?o.params:{},c=(o&&o.pathname,o?o.pathnameBase:"/");o&&o.route;let d,h=re();if(t){var u;let e="string"===typeof t?j(t):t;"/"===c||(null==(u=e.pathname)?void 0:u.startsWith(c))||b(!1),d=e}else d=h;let p=d.pathname||"/",m=p;if("/"!==c){let e=c.replace(/^\//,"").split("/");m="/"+p.replace(/^\//,"").split("/").slice(e.length).join("/")}let f=N(e,{pathname:m});let y=ge(f&&f.map((e=>Object.assign({},e,{params:Object.assign({},l,e.params),pathname:B([c,s.encodeLocation?s.encodeLocation(e.pathname).pathname:e.pathname]),pathnameBase:"/"===e.pathnameBase?c:B([c,s.encodeLocation?s.encodeLocation(e.pathnameBase).pathname:e.pathnameBase])}))),r,a,i);return t&&y?n.createElement(ae.Provider,{value:{location:Z({pathname:"/",search:"",hash:"",state:null,key:"default"},d),navigationType:g.Pop}},y):y}function he(){let e=function(){var e;let t=n.useContext(ie),a=xe(be.UseRouteError),i=ve(be.UseRouteError);if(void 0!==t)return t;return null==(e=a.errors)?void 0:e[i]}(),t=V(e)?e.status+" "+e.statusText:e instanceof Error?e.message:JSON.stringify(e),a=e instanceof Error?e.stack:null,i="rgba(200,200,200, 0.5)",s={padding:"0.5rem",backgroundColor:i};return n.createElement(n.Fragment,null,n.createElement("h2",null,"Unexpected Application Error!"),n.createElement("h3",{style:{fontStyle:"italic"}},t),a?n.createElement("pre",{style:s},a):null,null)}const ue=n.createElement(he,null);class pe extends n.Component{constructor(e){super(e),this.state={location:e.location,revalidation:e.revalidation,error:e.error}}static getDerivedStateFromError(e){return{error:e}}static getDerivedStateFromProps(e,t){return t.location!==e.location||"idle"!==t.revalidation&&"idle"===e.revalidation?{error:e.error,location:e.location,revalidation:e.revalidation}:{error:void 0!==e.error?e.error:t.error,location:t.location,revalidation:e.revalidation||t.revalidation}}componentDidCatch(e,t){console.error("React Router caught the following error during render",e,t)}render(){return void 0!==this.state.error?n.createElement(ne.Provider,{value:this.props.routeContext},n.createElement(ie.Provider,{value:this.state.error,children:this.props.component})):this.props.children}}function me(e){let{routeContext:t,match:a,children:i}=e,s=n.useContext($);return s&&s.static&&s.staticContext&&(a.route.errorElement||a.route.ErrorBoundary)&&(s.staticContext._deepestRenderedBoundaryId=a.route.id),n.createElement(ne.Provider,{value:t},i)}function ge(e,t,a,i){var s;if(void 0===t&&(t=[]),void 0===a&&(a=null),void 0===i&&(i=null),null==e){var r;if(!a)return null;if(a.errors)e=a.matches;else{if(!(null!=(r=i)&&r.v7_partialHydration&&0===t.length&&!a.initialized&&a.matches.length>0))return null;e=a.matches}}let o=e,l=null==(s=a)?void 0:s.errors;if(null!=l){let e=o.findIndex((e=>e.route.id&&void 0!==(null==l?void 0:l[e.route.id])));e>=0||b(!1),o=o.slice(0,Math.min(o.length,e+1))}let c=!1,d=-1;if(a&&i&&i.v7_partialHydration)for(let n=0;n<o.length;n++){let e=o[n];if((e.route.HydrateFallback||e.route.hydrateFallbackElement)&&(d=n),e.route.id){let{loaderData:t,errors:n}=a,i=e.route.loader&&void 0===t[e.route.id]&&(!n||void 0===n[e.route.id]);if(e.route.lazy||i){c=!0,o=d>=0?o.slice(0,d+1):[o[0]];break}}}return o.reduceRight(((e,i,s)=>{let r,h=!1,u=null,p=null;var m;a&&(r=l&&i.route.id?l[i.route.id]:void 0,u=i.route.errorElement||ue,c&&(d<0&&0===s?(m="route-fallback",!1||we[m]||(we[m]=!0),h=!0,p=null):d===s&&(h=!0,p=i.route.hydrateFallbackElement||null)));let g=t.concat(o.slice(0,s+1)),f=()=>{let t;return t=r?u:h?p:i.route.Component?n.createElement(i.route.Component,null):i.route.element?i.route.element:e,n.createElement(me,{match:i,routeContext:{outlet:e,matches:g,isDataRoute:null!=a},children:t})};return a&&(i.route.ErrorBoundary||i.route.errorElement||0===s)?n.createElement(pe,{location:a.location,revalidation:a.revalidation,component:u,error:r,children:f(),routeContext:{outlet:null,matches:g,isDataRoute:!0}}):f()}),null)}var fe=function(e){return e.UseBlocker="useBlocker",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e}(fe||{}),be=function(e){return e.UseBlocker="useBlocker",e.UseLoaderData="useLoaderData",e.UseActionData="useActionData",e.UseRouteError="useRouteError",e.UseNavigation="useNavigation",e.UseRouteLoaderData="useRouteLoaderData",e.UseMatches="useMatches",e.UseRevalidator="useRevalidator",e.UseNavigateStable="useNavigate",e.UseRouteId="useRouteId",e}(be||{});function ye(e){let t=n.useContext($);return t||b(!1),t}function xe(e){let t=n.useContext(ee);return t||b(!1),t}function ve(e){let t=function(){let e=n.useContext(ne);return e||b(!1),e}(),a=t.matches[t.matches.length-1];return a.route.id||b(!1),a.route.id}const we={};i.startTransition;function je(e){b(!1)}function ke(e){let{basename:t="/",children:a=null,location:i,navigationType:s=g.Pop,navigator:r,static:o=!1,future:l}=e;se()&&b(!1);let c=t.replace(/^\/*/,"/"),d=n.useMemo((()=>({basename:c,navigator:r,static:o,future:Z({v7_relativeSplatPath:!1},l)})),[c,l,r,o]);"string"===typeof i&&(i=j(i));let{pathname:h="/",search:u="",hash:p="",state:m=null,key:f="default"}=i,y=n.useMemo((()=>{let e=z(h,c);return null==e?null:{location:{pathname:e,search:u,hash:p,state:m,key:f},navigationType:s}}),[c,h,u,p,m,f,s]);return null==y?null:n.createElement(te.Provider,{value:d},n.createElement(ae.Provider,{children:a,value:y}))}function Se(e){let{children:t,location:a}=e;return de(Ne(t),a)}new Promise((()=>{}));n.Component;function Ne(e,t){void 0===t&&(t=[]);let a=[];return n.Children.forEach(e,((e,i)=>{if(!n.isValidElement(e))return;let s=[...t,i];if(e.type===n.Fragment)return void a.push.apply(a,Ne(e.props.children,s));e.type!==je&&b(!1),e.props.index&&e.props.children&&b(!1);let r={id:e.props.id||s.join("-"),caseSensitive:e.props.caseSensitive,element:e.props.element,Component:e.props.Component,index:e.props.index,path:e.props.path,loader:e.props.loader,action:e.props.action,errorElement:e.props.errorElement,ErrorBoundary:e.props.ErrorBoundary,hasErrorBoundary:null!=e.props.ErrorBoundary||null!=e.props.errorElement,shouldRevalidate:e.props.shouldRevalidate,handle:e.props.handle,lazy:e.props.lazy};e.props.children&&(r.children=Ne(e.props.children,s)),a.push(r)})),a}const Ce=a.p+"static/media/logo.6b455403899ff8e8b18d.webp";var Te=a(7950),Ae=a.t(Te,2);function Le(){return Le=Object.assign?Object.assign.bind():function(e){for(var t=1;t<arguments.length;t++){var a=arguments[t];for(var n in a)Object.prototype.hasOwnProperty.call(a,n)&&(e[n]=a[n])}return e},Le.apply(this,arguments)}function Ie(e,t){if(null==e)return{};var a,n,i={},s=Object.keys(e);for(n=0;n<s.length;n++)a=s[n],t.indexOf(a)>=0||(i[a]=e[a]);return i}new Set(["application/x-www-form-urlencoded","multipart/form-data","text/plain"]);const Pe=["onClick","relative","reloadDocument","replace","state","target","to","preventScrollReset","viewTransition"];try{window.__reactRouterVersion="6"}catch(hn){}new Map;const Re=i.startTransition;Ae.flushSync,i.useId;function Ee(e){let{basename:t,children:a,future:i,window:s}=e,r=n.useRef();var o;null==r.current&&(r.current=(void 0===(o={window:s,v5Compat:!0})&&(o={}),k((function(e,t){let{pathname:a="/",search:n="",hash:i=""}=j(e.location.hash.substr(1));return a.startsWith("/")||a.startsWith(".")||(a="/"+a),v("",{pathname:a,search:n,hash:i},t.state&&t.state.usr||null,t.state&&t.state.key||"default")}),(function(e,t){let a=e.document.querySelector("base"),n="";if(a&&a.getAttribute("href")){let t=e.location.href,a=t.indexOf("#");n=-1===a?t:t.slice(0,a)}return n+"#"+("string"===typeof t?t:w(t))}),(function(e,t){y("/"===e.pathname.charAt(0),"relative pathnames are not supported in hash history.push("+JSON.stringify(t)+")")}),o)));let l=r.current,[c,d]=n.useState({action:l.action,location:l.location}),{v7_startTransition:h}=i||{},u=n.useCallback((e=>{h&&Re?Re((()=>d(e))):d(e)}),[d,h]);return n.useLayoutEffect((()=>l.listen(u)),[l,u]),n.createElement(ke,{basename:t,children:a,location:c.location,navigationType:c.action,navigator:l,future:i})}const De="undefined"!==typeof window&&"undefined"!==typeof window.document&&"undefined"!==typeof window.document.createElement,We=/^(?:[a-z][a-z0-9+.-]*:|\/\/)/i,Me=n.forwardRef((function(e,t){let a,{onClick:i,relative:s,reloadDocument:r,replace:o,state:l,target:c,to:d,preventScrollReset:h,viewTransition:u}=e,p=Ie(e,Pe),{basename:m}=n.useContext(te),g=!1;if("string"===typeof d&&We.test(d)&&(a=d,De))try{let e=new URL(window.location.href),t=d.startsWith("//")?new URL(e.protocol+d):new URL(d),a=z(t.pathname,m);t.origin===e.origin&&null!=a?d=a+t.search+t.hash:g=!0}catch(hn){}let f=function(e,t){let{relative:a}=void 0===t?{}:t;se()||b(!1);let{basename:i,navigator:s}=n.useContext(te),{hash:r,pathname:o,search:l}=ce(e,{relative:a}),c=o;return"/"!==i&&(c="/"===o?i:B([i,o])),s.createHref({pathname:c,search:l,hash:r})}(d,{relative:s}),y=function(e,t){let{target:a,replace:i,state:s,preventScrollReset:r,relative:o,viewTransition:l}=void 0===t?{}:t,c=le(),d=re(),h=ce(e,{relative:o});return n.useCallback((t=>{if(function(e,t){return 0===e.button&&(!t||"_self"===t)&&!function(e){return!!(e.metaKey||e.altKey||e.ctrlKey||e.shiftKey)}(e)}(t,a)){t.preventDefault();let a=void 0!==i?i:w(d)===w(h);c(e,{replace:a,state:s,preventScrollReset:r,relative:o,viewTransition:l})}}),[d,c,h,i,s,a,e,r,o,l])}(d,{replace:o,state:l,target:c,preventScrollReset:h,relative:s,viewTransition:u});return n.createElement("a",Le({},p,{href:a||f,onClick:g||r?i:function(e){i&&i(e),e.defaultPrevented||y(e)},ref:t,target:c}))}));var Ge,Oe;(function(e){e.UseScrollRestoration="useScrollRestoration",e.UseSubmit="useSubmit",e.UseSubmitFetcher="useSubmitFetcher",e.UseFetcher="useFetcher",e.useViewTransitionState="useViewTransitionState"})(Ge||(Ge={})),function(e){e.UseFetcher="useFetcher",e.UseFetchers="useFetchers",e.UseScrollRestoration="useScrollRestoration"}(Oe||(Oe={}));const Fe=()=>{const[e,t]=(0,n.useState)(!1),[a,i]=(0,n.useState)(!1),[s,o]=(0,n.useState)({calls:!1,guidelines:!1}),l=re();let c;const d=e=>{o((n=>{if(a)return;const i={calls:!1,guidelines:!1,attendings:!1};return i[e]=!0,t(!0),i}))},h=()=>{o((()=>({calls:!1,guidelines:!1,attendings:!1})))};return(0,n.useEffect)((()=>{t(!1)}),[l]),(0,n.useEffect)((()=>{const e=()=>{var e=window.innerWidth<=768;i(e),e||t(!1)};return e(),window.addEventListener("resize",e),()=>{window.removeEventListener("resize",e)}}),[]),(0,r.jsx)("nav",{onMouseLeave:()=>{a||(c=setTimeout((()=>{o((()=>({calls:!1,guidelines:!1,attendings:!1})))}),2e3))},className:"absolute top-0 left-0 w-full z-[10000] bg-[#FEFFFE] text-[#000080]  shadow-md ",children:(0,r.jsxs)("div",{className:"flex items-center justify-between lg:justify-between   flex-wrap p-2 pb-0 mx-0 lg:mr-4",children:[(0,r.jsx)(Me,{to:"/",children:(0,r.jsx)("div",{className:"flex items-center justify-center flex-shrink-0 mr-2 md:mr-14 ",children:(0,r.jsx)("img",{src:Ce,className:"w-[74px] h-[74px]  mr-4",alt:"Logo"})})}),(0,r.jsx)("div",{className:"block lg:hidden",children:(0,r.jsxs)("button",{onClick:()=>t(!e),className:"flex items-center px-3 py-2 rounded text-black-500 hover:text-black-400",children:[(0,r.jsx)("svg",{className:"fill-current h-3 w-3 "+(e?"hidden":"block"),viewBox:"0 0 20 20",xmlns:"http://www.w3.org/2000/svg",children:(0,r.jsx)("path",{d:"M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"})}),(0,r.jsx)("svg",{className:"fill-current h-3 w-3 "+(e?"block":"hidden"),viewBox:"0 0 20 20",xmlns:"http://www.w3.org/2000/svg",children:(0,r.jsx)("path",{d:"M10 8.586L2.929 1.515 1.515 2.929 8.586 10l-7.071 7.071 1.414 1.414L10 11.414l7.071 7.071 1.414-1.414L11.414 10l7.071-7.071-1.414-1.414L10 8.586z"})})]})}),(0,r.jsx)("div",{className:"w-full lg:flex lg:items-center lg:w-auto "+(e?"block":"hidden"),children:(0,r.jsxs)("div",{className:"text-md font-medium lg:flex-wrap relative",children:[(0,r.jsxs)(Me,{to:"/",style:{color:"#e94607"},className:"block mt-4 lg:inline-block lg:mt-0 text-[#33358c]-200 mr-4 group",children:["About",(0,r.jsx)("div",{class:"bg-[#E30022] h-[px] w-0 group-hover:w-full transition-all duration-500"})]}),(0,r.jsxs)(Me,{to:"/importantdates",style:{color:"#e94607"},className:"block mt-4 lg:inline-block lg:mt-0 text-[#33358c]-200 mr-4 group",children:["Important Dates",(0,r.jsx)("div",{class:"bg-[#E30022] h-[px] w-0 group-hover:w-full transition-all duration-500"})]}),(0,r.jsxs)(Me,{to:"#",style:{color:"#e94607"},onMouseEnter:()=>d("calls"),className:"relative block mt-4 lg:inline-block items-center text-[#e94607] mr-4 group lg:mr-4 lg:inline-flex lg:mt-0 mt-4",children:["Calls",(0,r.jsx)("div",{className:"w-0 w-full",children:(a||s.calls)&&(0,r.jsxs)("div",{className:(a?"relative":"absolute")+" right-auto left-0 top-full mt-2 bg-white shadow-md rounded-md z-50",children:[(0,r.jsxs)(Me,{to:"/calls/research",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Research",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/resource",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Resource",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/in-use",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["In Use",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/posters",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Posters and Demos",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/challenges",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Challenges",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/industry",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Industry Track",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/doctoral",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Doctoral Consortium",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/workshops",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Workshops",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/dagstuhl",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Dagstuhl Workshops",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/tutorials",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Tutorials",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/swsa",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["SWSA Distinguished Dissertation Award",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/calls/journaltrack",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Journal track",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]})]})})]}),(0,r.jsxs)(Me,{to:"#",style:{color:"#e94607"},onMouseEnter:()=>d("program"),className:"relative block mt-4 lg:inline-block items-center text-[#e94607] mr-4 group lg:mr-4 lg:inline-flex lg:mt-0 mt-4",children:["Program",(0,r.jsx)("div",{className:"w-0 w-full",children:(a||s.program)&&(0,r.jsxs)("div",{className:(a?"relative":"absolute")+" right-auto left-0 top-full mt-2 bg-white shadow-md rounded-md z-50",children:[(0,r.jsxs)(Me,{to:"/program/schedule",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Schedule",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/program/acceptedpapers",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Accepted Papers",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/program/keynotespeakers",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Keynote Speakers",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/program/workshops",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Workshops",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/program/dagstuhl",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Dagstuhl Workshops",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/program/tutorials",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Tutorials",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/program/challenges",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Challenges",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/program/panel",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Panel",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/program/awards",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Awards",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]})]})})]}),(0,r.jsxs)(Me,{to:"#",style:{color:"#e94607"},onMouseEnter:()=>d("guidelines"),className:"relative block mt-4 lg:inline-block items-center text-[#e94607] mr-4 group lg:mr-4 lg:inline-flex lg:mt-0 mt-4",children:["Guidelines",(0,r.jsx)("div",{className:"w-0 w-full",children:(a||s.guidelines)&&(0,r.jsxs)("div",{className:(a?"relative":"absolute")+" right-auto left-0 top-full mt-2 bg-white shadow-md rounded-md z-50",children:[(0,r.jsxs)(Me,{to:"/guidelines/html-submission",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["HTML Submission Guide",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/guidelines/prior-publications",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Prior Publications and Simultaneous Submissions",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/guidelines/review",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Review Guidelines",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/guidelines/supplemental",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Supplemental Materials",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/guidelines/resources",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Resources Availability",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]})]})})]}),(0,r.jsxs)(Me,{to:"#",style:{color:"#e94607"},onMouseEnter:()=>d("sponsorship"),className:"relative block mt-4 lg:inline-block items-center text-[#e94607] mr-4 group lg:mr-4 lg:inline-flex lg:mt-0 mt-4",children:["Sponsorship",(0,r.jsx)("div",{className:"w-0 w-full",children:(a||s.sponsorship)&&(0,r.jsxs)("div",{className:(a?"relative":"absolute")+" right-auto left-0 top-full mt-2 bg-white shadow-md rounded-md z-50",children:[(0,r.jsxs)(Me,{to:"/sponsorship/sponsorshippackages",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Sponsorship Packages",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/sponsorship/sponsors",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Sponsors",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]})]})})]}),(0,r.jsxs)(Me,{to:"#",style:{color:"#e94607"},onMouseEnter:()=>d("attendings"),className:"relative block mt-4 lg:inline-block items-center text-[#e94607] mr-4 group lg:mr-4 lg:inline-flex lg:mt-0 mt-4",children:["Attending",(0,r.jsx)("div",{className:"w-0 w-full",children:(a||s.attendings)&&(0,r.jsxs)("div",{className:(a?"relative":"absolute")+" right-auto left-0 top-full mt-2 bg-white shadow-md rounded-md z-50",children:[(0,r.jsxs)(Me,{to:"/attending/visa",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["VISA Information",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/attending/studentgrants",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Student Grants",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/attending/codeofconduct",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Code of Conduct",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/atttending/venueandaccomodation",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Venue and Accomodation",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/atttending/registration",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Registration",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]})]})})]}),(0,r.jsxs)(Me,{to:"#",style:{color:"#e94607"},onMouseEnter:()=>d("blogs"),className:"relative block mt-4 lg:inline-block items-center text-[#e94607] mr-4 group lg:mr-4 lg:inline-flex lg:mt-0 mt-4",children:["Blogs",(0,r.jsx)("div",{className:"w-0 w-full",children:(a||s.blogs)&&(0,r.jsxs)("div",{className:(a?"relative":"absolute")+" right-auto left-0 top-full mt-2 bg-white shadow-md rounded-md z-50",children:[(0,r.jsxs)(Me,{to:"/blogs/host",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["ISWC 2025 Host",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/blogs/naturenavigator",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["ISWC 2025 Nature Navigator",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/blogs/community",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["ISWC Community",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]}),(0,r.jsxs)(Me,{to:"/blogs/presentingatiswc",className:"block px-4 py-2",style:{color:"#e94607"},onClick:()=>h(),children:["Presenting at ISWC",(0,r.jsx)("div",{className:"bg-[#E30022] w-0 group-hover:w-full"})]})]})})]}),(0,r.jsxs)(Me,{to:"/organizing_committee",style:{color:"#e94607"},className:"block mt-4 lg:inline-block lg:mt-0 text-[#33358c]-200 mr-4 group",children:["Organizing Committee",(0,r.jsx)("div",{class:"bg-[#E30022] h-[px] w-0 group-hover:w-full transition-all duration-500"})]})]})})]})})},ze=()=>(0,r.jsx)("footer",{className:"px-4 py-8 divide-y bg-white border-t-2 border-gray-100",children:(0,r.jsx)("div",{className:"py-4 text-sm text-center dark:text-gray-600",children:"\xa92025 ISWC."})});const Ke=function(e){let{img:t,name:a,role:n,detail:i}=e;return(0,r.jsxs)("div",{className:"max-w-xs w-72 h-64 shadow-md rounded-lg overflow-hidden flex flex-col items-center bg-white p-4",children:[t?(0,r.jsx)("img",{src:t,alt:a,className:"w-24 h-24 rounded-full object-cover mb-4"}):(0,r.jsx)("div",{className:"w-24 h-24 rounded-full bg-gray-200 mb-4 flex items-center justify-center text-gray-500",children:(0,r.jsx)("span",{className:"text-sm",children:"No Image"})}),(0,r.jsxs)("div",{className:"text-center",children:[(0,r.jsx)("h3",{className:"text-lg font-semibold truncate w-full",children:a}),(0,r.jsx)("p",{className:"text-sm font-medium text-gray-600",children:n}),(0,r.jsx)("p",{className:"text-sm text-gray-500 mt-2 break-words",children:i})]})]})};const qe=function(e){let{users:t}=e;return(0,r.jsx)("div",{className:"d-flex justify-content-center align-items-center",children:(0,r.jsx)("div",{className:"container text-center",children:Object.keys(t).map(((e,a)=>{const n=t[e],i=(1===n.length||n.length,"justify-center");return(0,r.jsxs)("div",{className:"mb-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-2xl font-bold mb-4 decoration-red-500",children:e}),(0,r.jsx)("div",{className:`flex ${i} gap-4 flex-wrap`,children:n.map((t=>(0,r.jsx)("div",{className:"max-w-xs",children:(0,r.jsx)(Ke,{img:t.img,name:t.name,role:e,detail:`${t.institution}, ${t.country}`,className:"p-3"})},t.name)))})]},e)}))})})};const _e=function(e){let{word:t,users:a}=e;return(0,r.jsx)(r.Fragment,{children:(0,r.jsxs)("section",{className:"lg:px-16 px-6 py-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 pb-6 lg:pb-4",children:t}),(0,r.jsx)("div",{className:"lg:mx-24 mx-6 mt-2",children:(0,r.jsx)(qe,{users:a})})]})})},He=a.p+"static/media/anna_lisa_gentile.cd65048aac4029634f75.png",Be=a.p+"static/media/kouji_kozaki.dd4b445a943886a1b2b8.png",Ue=a.p+"static/media/ken_fukuda.22c7d8382ad53a504a95.png",Je=a.p+"static/media/maribel_acosta.c0a65197da010100c85f.png",Qe=a.p+"static/media/sabrina_kirrane.740762fc0db9613575e2.jpg",Ve=a.p+"static/media/daniel_garijo.b36e4ff7c5732dfdb9c8.png",Ye=a.p+"static/media/angelo_salatino.b2e16917c75db6b5aef8.png",Xe=a.p+"static/media/blerina_sphaiu.1d2199a9c9ff151fe8ca.png",Ze=a.p+"static/media/juan_sequeda.b71003c3bde3dfb6e51f.png",$e=a.p+"static/media/natasha_noy.a45f10fe30e4af3fd37b.png",et=a.p+"static/media/abraham_bernstein.ee373ea16edb96da2d55.png",tt=a.p+"static/media/tetsuya_mihara.7e1bc80d0522cec2d3e1.jpg",at=a.p+"static/media/genet_asefa_gesese .1296d2c4fc6ac7a4a559.png",nt=a.p+"static/media/cogan_shimizu.e435636e93228e66ffa1.png",it=a.p+"static/media/jenifer_tabita_ciuciu_kiss.94fea9b446bfc31f86d4.png",st=a.p+"static/media/ohmukai_ikki.d413b99e039dff003a8d.jpg",rt=a.p+"static/media/hideaki_takeda.949906fb96c0d613441a.png",ot=a.p+"static/media/andrea_nuzzolese.ea6082e238bf95c7e8d8.png",lt=a.p+"static/media/sebastian_ferrada.d826184bacca845e5812.png",ct=a.p+"static/media/thibaut_soulard.60ae7a5bc358498892e8.png",dt=a.p+"static/media/oktie_hassanzadeh.db8a06cc165c73ce8d48.png",ht=a.p+"static/media/shenghui_wang.da5f84e19c2f2c87ebb2.png",ut=a.p+"static/media/irene_celino.bdb3285806e56a4d3334.png",pt=a.p+"static/media/mayank_kejriwal.d1ffd68992c662777dbe.png",mt=a.p+"static/media/neha_keshan.7c28c9cce493fb847f18.png",gt=a.p+"static/media/ray_atarashi.4f76c7bc9b628e63cd57.png",ft=a.p+"static/media/akaichi_ines.898232d136ad299c2f44.png",bt=a.p+"static/media/Cheng_Gong.2d1a83898e12a36312ab.jpg",yt=a.p+"static/media/stellato_armando.3bbf6bc248e9cc4595c7.jpg",xt=a.p+"static/media/Sun_Zequn.e4c9ac092fa505ef1f01.jpg",vt={"General Chair":[{name:"Anna Lisa Gentile",img:He,institution:"IBM Research",country:"US"}],"Local Chair":[{name:"Kouji Kozaki",img:Be,institution:"Osaka Electro-Communication University",country:"Japan"}],"Local Co-Chair":[{name:"Ken Fukuda",img:Ue,institution:"National Institute of Advanced Industrial Science and Technology (AIST)",country:"Japan"},{name:"Ikki Ohmukai",img:st,institution:"The University of Tokyo",country:"Japan"},{name:"Hideaki Takeda",img:rt,institution:"National Institute of Informatics",country:"Japan"}],"Research Track Chair":[{name:"Daniel Garijo",img:Ve,institution:"Universidad Polit\xe9cnica de Madrid",country:"Spain"},{name:"Sabrina Kirrane",img:Qe,institution:"Vienna University of Economics and Business",country:"Austria"}],"In-Use Application Track Chair":[{name:"Maribel Acosta",img:Je,institution:"Technical University of Munich",country:"Germany"},{name:"Andrea Giovanni Nuzzolese",img:ot,institution:"CNR - Institute of Cognitive Sciences and Technologies",country:"Italy"}],"Resource Track Chair":[{name:"Cogan Shimizu",img:nt,institution:"Wright State University",country:"US"},{name:"Angelo Salatino",img:Ye,institution:"KMi, The Open University",country:"United Kingdom"}],"Workshop and Tutorials Chair":[{name:"Blerina Spahiu",img:Xe,institution:"Universit\xe0 di Milano-Bicocca",country:"Italy"},{name:"Juan Sequeda",img:Ze,institution:"data.world",country:"US"}],"Industry Track Chair":[{name:"Oktie Hassanzadeh",img:dt,institution:"IBM Research",country:"US"},{name:"Irene Celino",img:ut,institution:"Cefriel",country:"Italy"}],"Doctoral Consortium Chair":[{name:"Natasha Noy",img:$e,institution:"Google",country:"US"},{name:"Abraham Bernstein",img:et,institution:"University of Zurich",country:"Switzerland"}],"Poster, Demo & Lightning Talk Chair":[{name:"Shenghui Wang",img:ht,institution:"Universiteit Twente",country:"Netherlands"},{name:"Gong Cheng",img:bt,institution:"Nanjing University",country:"China"}],"Semantic Web Challenge Chair":[{name:"Mayank Kejriwal",img:pt,institution:"University of Southern California",country:"US"}],"Job Fair Chair":[{name:"Nandana Mihindukulasooriya",img:a.p+"static/media/nandana.38440218645af3ddb2ed.jpeg",institution:"IBM Research",country:"US"}],"Sponsorship Chair":[{name:"Ray Atarashi",img:gt,institution:"Internet Initiative Japan",country:"Japan"},{name:"Neha Keshan",img:mt,institution:"Rensselaer Polytechnic Institute",country:"US"},{name:"Armando Stellato",img:yt,institution:"University of Rome Tor Vergata",country:"Italy"}],"Proceedings & Metadata Chair":[{name:"Sebasti\xe1n Ferrada",img:lt,institution:"University of Chile",country:"Chile"},{name:"Thibaut Soulard",img:ct,institution:"University Paris-Saclay",country:"France"}],"Students Grants and Activities Chair":[{name:"Atsuko Yamaguchi",img:"",institution:"Tokyo City University",country:"Japan"},{name:"Ines Akaichi",img:ft,institution:"Vienna University of Economics and Business",country:"Austria"}],"Web Presence & Publicity Chair":[{name:"Jenifer Tabita Ciuciu-Kiss",img:it,institution:"Universidad Polit\xe9cnica de Madrid",country:"Spain"},{name:"Tetsuya Mihara",img:tt,institution:"University of Tsukuba",country:"Japan"},{name:"Genet-Asefa Gesese",img:at,institution:"FIZ Karlsruhe, Karlsruhe Institute of Technology (KIT)",country:"Germany"},{name:"Zequn Sun",img:xt,institution:"Nanjing University",country:"China"}]},wt=()=>(0,r.jsx)(r.Fragment,{children:(0,r.jsxs)("div",{className:"flex justify-center items-center flex-col text-center",id:"img",children:[(0,r.jsx)("div",{className:"w-full mb-8 pt-16 relative",children:(0,r.jsx)("img",{src:u,alt:"Banner",className:"w-full h-auto object-cover"})}),(0,r.jsx)(_e,{users:vt,word:"Organizing Committee"})]})}),jt=()=>(0,r.jsx)("div",{className:"my-24  lg:px-36 flex justify-center",children:(0,r.jsx)("div",{class:"bg-white  w-full lg:max-w-[80%]"})}),kt=()=>{const e=(0,n.useRef)(null);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Research Track Papers"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2 overflow-auto",children:[(0,r.jsx)("p",{children:"The International Semantic Web Conference is the premier venue for presenting fundamental research, innovative technology, and applications concerning semantics, data, and the Web."}),(0,r.jsx)("p",{children:"The research track of ISWC 2025 solicits novel and significant research contributions addressing theoretical, analytical, and empirical aspects of the Semantic Web. We welcome work describing original and replicable research showing evidence of significant contribution to the Semantic Web."}),(0,r.jsxs)("p",{children:["All papers will be assessed by the track\u2019s program committee. Each paper will be reviewed by at least three committee members, with a meta-review provided by a senior member. The review criteria used are ",(0,r.jsx)("span",{onClick:()=>{e.current.scrollIntoView({behavior:"smooth"})},style:{color:"#e94607"},children:"outlined below"}),"."]}),(0,r.jsx)("p",{children:"As ISWC 2025 features multiple tracks, authors are asked to consult the calls of the other tracks to choose the track that best fits their contribution. The submission of the same work to multiple tracks (as well as other conferences) is not allowed and results in a rejection of the work without review."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important information for authors:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Submissions are dual anonymous. Under this system, not only are paper authors unaware of the identity of the reviewers, but the reviewers are not told the identities of the authors until after the evaluation and rating of all papers is over."}),(0,r.jsx)("li",{children:"Papers are limited to 15 pages excluding references. Supplemental material statements and annexes count toward the established page limit."}),(0,r.jsxs)("li",{children:["All submissions are expected to include a mandatory ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/supplemental",target:"_blank",style:{color:"#e94607"},children:"Supplemental Material Statement"})," - such material includes links to code and data repositories. In case this is not possible, the statement must provide a justification."]}),(0,r.jsx)("li",{children:"Unless otherwise justified in the Supplemental Material Statement, we expect supplemental material to be provided anonymously with the submitted paper."}),(0,r.jsx)("li",{children:"Pre-submission of abstracts is a strict requirement."})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important Dates"}),(0,r.jsxs)("p",{children:["Abstract submission due: ",(0,r.jsx)("b",{children:"May 6th, 2025"})]}),(0,r.jsxs)("p",{children:["Full paper submission due: ",(0,r.jsx)("b",{children:"May 13th, 2025"})]}),(0,r.jsxs)("p",{children:["Rebuttal: ",(0,r.jsx)("b",{children:"June 17th - 20th, 2025"})]}),(0,r.jsxs)("p",{children:["Notifications: ",(0,r.jsx)("b",{children:"July 17th, 2025"})]}),(0,r.jsxs)("p",{children:["Camera ready papers due: ",(0,r.jsx)("b",{children:"July 31st, 2025"})]}),(0,r.jsx)("p",{children:"All deadlines are 23:59 AoE (anywhere on Earth)"}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Topics of Interest"}),(0,r.jsx)("p",{children:"We encourage papers that directly contribute to the advancement of the Semantic Web area. The relationship to the core area of the conference needs to be clearly described in the submitted work. Submissions beyond the scope will be desk-rejected. Topics in the Semantic Web area include, but are not limited to:"}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("ul",{className:"space-y-4 list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{className:"list-none",children:["Ontologies and capturing knowledge including:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Ontology Engineering and ontology patterns"}),(0,r.jsx)("li",{children:"Ontology modularity, mapping, merging, and alignment"}),(0,r.jsx)("li",{children:"Information extraction, knowledge graph construction"})]})]}),(0,r.jsxs)("li",{className:"list-none",children:["Representation, management, and applications of Knowledge Graphs (including RDF and property graphs) including:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Knowledge Representation and Reasoning"}),(0,r.jsx)("li",{children:"Search, query, integration, and analysis"}),(0,r.jsx)("li",{children:"Robust and scalable management"}),(0,r.jsx)("li",{children:"Information visualization and exploratory analysis"}),(0,r.jsx)("li",{children:"Databases and ontology-based data access, integration and exchange on the Web"}),(0,r.jsx)("li",{children:"Knowledge graph centered Natural Language Processing, information retrieval, semantic analysis, and Large Language Models"})]})]}),(0,r.jsxs)("li",{className:"list-none",children:["Integration of the Semantic Web with:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Machine learning, data mining, and neural symbolic reasoning"}),(0,r.jsx)("li",{children:"Generative AI (Large Language Models)"}),(0,r.jsx)("li",{children:"User interfaces, usability, and accessibility"}),(0,r.jsx)("li",{children:"Data integration, quality assurance, and data provenance"}),(0,r.jsx)("li",{children:"Social issues including trust, bias, fairness, privacy, security, and policy"}),(0,r.jsx)("li",{children:"Web services, process management, social Web, and Internet of Things"}),(0,r.jsx)("li",{children:"Dynamic and streaming data, including complex event processing and stream reasoning"}),(0,r.jsx)("li",{children:"Software engineering, algorithms, and decentralized architectures"}),(0,r.jsx)("li",{children:"Specialized domains (geographical, biomedical, e-Science, multimedia, performing arts, public administration, cultural heritage, law, etc.)"}),(0,r.jsx)("li",{children:"Artificial Intelligence and hybrid approaches (including human-machine intelligence)"})]})]}),(0,r.jsxs)("li",{className:"list-none",children:["Semantic Web Agents including:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Autonomous systems, including multi-agent systems and robotics"}),(0,r.jsx)("li",{children:"Architecture characteristics for autonomy exploiting KGs"}),(0,r.jsx)("li",{children:"Incomplete or conflicting knowledge, beliefs, and assumptions and KGs"}),(0,r.jsx)("li",{children:"Human-machine social interactions and KGs"}),(0,r.jsx)("li",{children:"Architecture characteristics for exploiting KGs autonomously"}),(0,r.jsx)("li",{children:"Development platforms and frameworks for exploiting KGs in an autonomous manner"}),(0,r.jsx)("li",{children:"Governance of autonomous agents on the Web"})]})]})]}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"We welcome descriptions of contributions that leverage knowledge representation based on Semantic Web standards or other graph data models to improve the acquisition, processing, and sharing of data on the Web. We require authors to explicitly highlight how their work could be applied in a Semantic Web setting."}),(0,r.jsxs)("div",{ref:e,children:[(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Review Criteria"}),(0,r.jsx)("p",{children:"Papers in this track will be reviewed according to the following criteria:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Originality and novelty"}),(0,r.jsx)("li",{children:"Relevance of the topic to the conference"}),(0,r.jsx)("li",{children:"Impact of the research contributions"}),(0,r.jsx)("li",{children:"Technical soundness"}),(0,r.jsx)("li",{children:"Rigor and reproducibility of the work (including evaluation)"}),(0,r.jsx)("li",{children:"Clarity and quality of presentation"}),(0,r.jsx)("li",{children:"Grounding in the literature"})]}),(0,r.jsxs)("p",{children:["Any submissions that are clearly out of scope, or have significant omissions with respect to these criteria may be subject to desk-rejection prior to a full review. Guidelines for reviewers are available ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/review",target:"_blank",style:{color:"#e94607"},children:"here"}),"."]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Rebuttal"}),(0,r.jsx)("p",{children:"Authors will have the chance to provide a response to the reviews during a rebuttal period that precedes the reviewer discussion period. The SPCs and PC Chairs will consider the authors' responses to the points raised by the reviewers."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Supplemental Material Statement and Reproducibility"}),(0,r.jsxs)("p",{children:["Reproducibility is a key goal of scientific research. We require authors of all papers to include a statement at the end of their submission that facilitates the independent reproducibility or verification of the results presented (where relevant), pointing to where supplemental material can be found. These resources may include datasets, queries, code, proofs of results, configuration details, hyperparameters, etc., depending on the contributions of the paper. The statement should cover all of the resources necessary to reproduce or verify the results presented in the paper, indicating their persistent identifiers (e.g., DOI). In case certain resources cannot be made available (e.g., due to privacy, ethical, or financial concerns), the statement should include a justification of why this is the case. In case the paper is fully self-contained and does not have additional resources associated (e.g., a theoretical paper with full proofs contained in the body of the paper), a short statement can be provided arguing that the paper is self-contained. Please see the  ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/supplemental",target:"_blank",style:{color:"#e94607"},children:"Supplemental Material Statement Guide"})," for more details."]}),(0,r.jsx)("p",{children:"Reviewers will be asked to evaluate the statement. In particular, they will be asked to ensure that the statement convinces them that the results of the paper are reproducible, to ensure that the resources are indeed available and support reproducibility (both now and for the foreseeable future), and, in cases where resources are not provided, to verify that there is a reasonable justification. Unless otherwise justified, it is expected that access to resources is provided from the submitted paper since these resources may often play an important role in the review process. All resources must be provided anonymously; please see the \u201cSupplemental Material\u201d section for recommended options."})]}),(0,r.jsx)("h4",{style:{color:"#e94607"},className:"text-md font-medium mt-3",children:"Submission Details"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Pre-submission of abstracts is a strict requirement."}),(0,r.jsxs)("li",{children:["All papers and abstracts have to be submitted electronically via ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",target:"_blank",rel:"noopener noreferrer",style:{color:"#e94607"},children:"EasyChair"}),"."]}),(0,r.jsx)("li",{children:"Submitted papers will be checked to ensure that they satisfy the submission criteria and are in scope with the aims of the conference, and if such violations are identified, then the submission may be subject to desk rejection without review."}),(0,r.jsx)("li",{children:"Papers must provide a clear statement of their claims, argue how the results of the paper substantiate their claims, clarify any technical assumptions and/or known limitations, and provide a Supplemental Material Statement."}),(0,r.jsx)("li",{children:"All research submissions must be in English, and no longer than 15 pages (excluding references)."}),(0,r.jsxs)("li",{children:["Submissions must be either in PDF or HTML, formatted in the style of the Springer Publications format for Lecture Notes in Computer Science (LNCS). For details on the LNCS style, see ",(0,r.jsx)("a",{href:"https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines",target:"_blank",style:{color:"#e94607"},children:"Springer\u2019s Author Instructions"}),". For HTML submission guidance, please see the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/html-submission",target:"_blank",style:{color:"#e94607"},children:"HTML submission guide"}),"."]}),(0,r.jsx)("li",{children:"Each submission must be original. Authors need to authorize the organizer to perform a plagiarism check of the paper."}),(0,r.jsx)("li",{children:"Papers that exceed the page limit, violate the style or show any kind of plagiarism will be rejected without review."}),(0,r.jsx)("li",{children:"Papers submitted to the research track will be subject to dual anonymous peer review and must conform to the instructions (detailed below) for dual anonymous review."}),(0,r.jsx)("li",{children:"We encourage embedding metadata in the PDF/HTML to provide machine-readable links from the paper to resources."}),(0,r.jsx)("li",{children:"Authors of accepted papers will be required to provide semantic annotations for the submission, which will be made available online. Details will be provided at the time of acceptance."}),(0,r.jsx)("li",{children:"Accepted papers will be distributed to conference attendees and also published in the conference proceedings."}),(0,r.jsx)("li",{children:"At least one author of each accepted paper must register for the conference and present the paper."}),(0,r.jsx)("li",{children:"As in previous years, students will be able to apply for funding to support their travel to attend/register for the conference."})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Instructions for Dual Anonymous Reviewing"}),(0,r.jsx)("p",{children:"Reviewing for ISWC 2025 is dual-anonymous, i.e., the identities of the authors and reviewers are hidden. Both authors and reviewers are expected to make every effort to honor this process. Authors should do their best to ensure that the submission can be evaluated without it being obvious who wrote the paper, and reviewers should not undertake any investigation with the specific goal of revealing the authors\u2019 identity."}),(0,r.jsx)("p",{children:"To help with the dual anonymous reviewing process please ensure the following when submitting to ISWC 2025:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"The first page, on which the paper body begins, should include the title and abstract but not the names or affiliations of the authors."}),(0,r.jsx)("li",{children:"Remove any identifying information, including author names, from file names and ensure document properties are also anonymized."}),(0,r.jsx)("li",{children:"Remove any identifying information from your paper resources such as datasets, models, or code (e.g., README and package files in code repositories, Zenodo deposits, etc.)"}),(0,r.jsx)("li",{children:"The references should include all published literature relevant to the paper. When referring to one\u2019s own work, use the third person, rather than the first person. For example, say \u201cPreviously, Foo [4] showed that\u2026,\u201d rather than \u201cIn our previous work [4] we showed that\u2026\u201d"}),(0,r.jsx)("li",{children:"Try to avoid including any information that would identify the authors or their affiliations. Such information may be added to the final camera-ready version for publication."}),(0,r.jsx)("li",{children:"Remove references to funding sources and/or acknowledgments. Such information should be included in the final camera-ready version for publication."})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Supplemental Material"}),(0,r.jsx)("p",{children:"The length of the main submission is strictly limited as indicated in the call for papers. However, authors may choose to also submit supplemental material, which may include proofs of theorems that are stated in the main paper, video demonstrations, data concerning experimental evaluations, source code, and so on. Note that submissions may reference the supplemental material for further details, but should be self-contained. Reviewers are instructed to make their evaluations based on the main submission and are not obligated to consult the supplemental material. Therefore, make sure that your submission stands on its own without them."}),(0,r.jsx)("p",{children:"Please take care not to violate the dual anonymous review requirements in the supplemental material. You may make supplemental material available per one of the following options:"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"OPTION 1:"})," As an anonymized link to supplemental material included in the paper. This option may be used, in particular, in case the total size of the submission (paper+supplemental materials) exceeds 100MB. We recommend the use of Github, Zenodo, Figshare, or Dryad. Anonymous dataset submissions can be managed through Zenodo and Figshare without additional accounts; see, for example, ",(0,r.jsx)("a",{href:"https://github.com/dgraziotin/disclose-data-dbr-first-then-opendata",target:"_blank",style:{color:"#e94607"},children:"this guide"})," by Daniel Graziotin. Code repository submissions may be anonymized through platforms like ",(0,r.jsx)("a",{href:"https://anonymous.4open.science/",target:"_blank",style:{color:"#e94607"},children:"https://anonymous.4open.science/"}),"."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"OPTION 2:"})," As a second zipped folder uploaded via the ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",target:"_blank",rel:"noopener noreferrer",style:{color:"#e94607"},children:"EasyChair"})," system; note that the total size of the submission (paper+supplemental materials) must not exceed 100MB."]})]}),(0,r.jsx)("p",{children:"Supplemental material submitted at the time of submission for review will not be automatically published or posted if the paper is accepted for publication. Hence we expect authors of accepted papers choosing OPTION 2 to publish this material in one of the aforementioned repositories (or arXiv in the case of an extended version of the paper with proofs) and provide references to the supplemental material in the final camera-ready version of the paper."}),(0,r.jsx)("p",{children:"In the case of both options, we strongly encourage making supplemental material available under open licenses and providing sufficient documentation to enable reproducibility."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Prior Publication and Multiple Submissions"}),(0,r.jsxs)("p",{children:["ISWC 2025 will not accept research papers that, at the time of submission, are under review for or have already been published in, or accepted for publication, in a journal or another conference. Please refer to and adhere to the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/prior-publications",target:"_blank",style:{color:"#e94607"},children:"ISWC Prior Publication and Multiple Submission Policy."})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Research Track Chairs"}),(0,r.jsxs)("p",{children:["Contact: ",(0,r.jsx)("a",{href:"mailto:iswc2025-research@easychair.org",children:"iswc2025-research@easychair.org"})]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Daniel Garijo"}),", Universidad Polit\xe9cnica de Madrid, Spain"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Sabrina Kirrane"}),", Vienna University of Economics and Business, Austria"]})]})]})]})},St=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Resource Track Papers"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:"Resources are of paramount importance as they foster scientific advancement and the development of novel applications. Sharing resources is key to ensuring reproducibility, allowing other researchers to leverage FAIR principles for scientific data management to compare results and methods or to explore new lines of research, and supporting practitioners in reusing research outputs."}),(0,r.jsx)("p",{children:"The ISWC 2025 Resources Track aims to promote the sharing of resources that support, enable, or utilize semantic web research. We welcome descriptions of resources that leverage knowledge representation based on Semantic Web standards or other graph data models to improve the acquisition, processing, and sharing of data on the web."}),(0,r.jsx)("p",{children:"Resources include, but are not restricted to: datasets, knowledge graphs, ontologies/vocabularies, ontology design patterns, evaluation benchmarks or methods, software tools/services, APIs and software frameworks, workflows, crowdsourcing task designs, protocols, methodologies, and metrics, that have contributed or may contribute to the generation of novel scientific work and applications in the semantic web. In particular, we encourage the sharing of such resources following the best and well-established practices within the semantic web community. As such, this track calls for contributions that provide a concise and clear description of a resource and its usage."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important Dates"}),(0,r.jsxs)("p",{children:["Abstract submission due: ",(0,r.jsx)("b",{children:"May 6th, 2025"})]}),(0,r.jsxs)("p",{children:["Full paper submission due: ",(0,r.jsx)("b",{children:"May 13th, 2025"})]}),(0,r.jsxs)("p",{children:["Rebuttal: ",(0,r.jsx)("b",{children:"June 17th - 20th, 2025"})]}),(0,r.jsxs)("p",{children:["Notifications: ",(0,r.jsx)("b",{children:"July 17th, 2025"})]}),(0,r.jsxs)("p",{children:["Camera ready papers due: ",(0,r.jsx)("b",{children:"July 31st, 2025"})]}),(0,r.jsx)("p",{children:"All deadlines are 23:59 AoE (anywhere on Earth)"}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Resources of Interest"}),(0,r.jsx)("p",{children:"A typical Resource Track paper has its focus set on reporting on resources that fall into one of the following categories:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:["Datasets produced:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"to support specific evaluation tasks (for instance, labeled ground truth data);"}),(0,r.jsx)("li",{children:"to support novel research methods;"}),(0,r.jsx)("li",{children:"by novel algorithms."})]})]}),(0,r.jsx)("li",{children:"Knowledge graphs, represented using semantic web technologies or other graph models for web data, which can be reused in research or industry."}),(0,r.jsx)("li",{children:"Ontologies, vocabularies, and ontology design patterns, with a focus on describing the modelling process underlying their creation."}),(0,r.jsx)("li",{children:"Reusable software and services, e.g., prototypes/services supporting a given research hypothesis and enabling specific data processing and engineering tasks."}),(0,r.jsx)("li",{children:"Community-shared software frameworks that can be extended or adapted to support scientific study and experimentation."}),(0,r.jsx)("li",{children:"Crowdsourcing task designs that have been used and can be (re)used for building resources such as gold standards and the like."}),(0,r.jsx)("li",{children:"Benchmarking activities focusing on datasets and algorithms for comprehensible and systematic evaluation of existing and future systems."}),(0,r.jsx)("li",{children:"Novel evaluation methodologies and metrics, and their demonstration in an experimental study."}),(0,r.jsx)("li",{children:"Protocols for conducting experiments and studies."}),(0,r.jsx)("li",{children:"Educational Material for and about semantic technologies and techniques, including curriculum pertaining to education about knowledge graphs, ontologies, or other semantic technologies (e.g., well-described tutorials), and semantic artifacts (e.g., knowledge graphs or ontologies) that can be used to enhance education."})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Differentiation from the Other Tracks"}),(0,r.jsx)("p",{children:"We strongly recommend that prospective authors carefully check the calls of the other main tracks of the conference in order to identify the optimal track for their submission. Papers that propose new algorithms and architectures should be submitted to the regular Research track, whilst papers that describe the use of semantic web technologies in practical settings should be submitted to the In-Use track."}),(0,r.jsx)("p",{children:"When new reusable resources are produced during the process undertaken for achieving these results, such as datasets, ontologies, workflows, etc., and they can be reused on a wider range of use cases, they are suitable subjects for submission to the Resources Track. As examples of resources that fit the Resource Track, consider tools immediately available for reuse, or benchmarks where baseline algorithms are only used to prove their relevance."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Review Criteria"}),(0,r.jsxs)("p",{children:["The program committee will consider the quality of both the resource and the paper in its review process. Therefore, authors must ensure unfettered access to the resource both during the review process and after, by citing the resource at a permanent location. For example, data available in a repository such as ",(0,r.jsx)("a",{href:"https://figshare.com/",target:"_blank",style:{color:"#e94607"},children:"FigShare"}),", ",(0,r.jsx)("a",{href:"https://zenodo.org/",target:"_blank",style:{color:"#e94607"},children:"Zenodo"}),", or a domain-specific repository; or software code being available in a public code repository, such as ",(0,r.jsx)("a",{href:"https://github.com/",target:"_blank",style:{color:"#e94607"},children:"GitHub"})," or ",(0,r.jsx)("a",{href:"https://bitbucket.org/",target:"_blank",style:{color:"#e94607"},children:"BitBucket"})," or one\u2019s institutional open data repository. Code releases should be properly deposited according to community best practices. In exceptional cases, when it is not possible to make the resource public, authors must provide anonymous access to the resource for the reviewers and briefly explain why the resource cannot be made public. All resources should clearly disclose ",(0,r.jsx)("b",{children:"their license"}),"."]}),(0,r.jsx)("p",{children:"We welcome the submission of established resources, having a community using them (excluding the authors), and of new resources, which may not prove established reuse but have sufficient evidence and motivation for claiming potential adoption. Evidence of adoption of a resource is considered a positive factor in the evaluation."}),(0,r.jsx)("h4",{style:{color:"#e94607"},className:"text-md font-medium mt-3",children:"Impact:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Does the resource break new ground?"}),(0,r.jsx)("li",{children:"Does the resource fill an important gap?"}),(0,r.jsx)("li",{children:"How does the resource advance the state of the art?"}),(0,r.jsx)("li",{children:"Has the resource been compared to other existing resources (if any) of similar scope?"}),(0,r.jsx)("li",{children:"Is the resource of interest to the semantic web community?"}),(0,r.jsx)("li",{children:"Is the resource of interest to society in general?"}),(0,r.jsx)("li",{children:"How will this resource support the adoption of semantic web technologies?"}),(0,r.jsx)("li",{children:"What impact will this resource have (or currently has)?"})]}),(0,r.jsx)("h4",{style:{color:"#e94607"},className:"text-md font-medium mt-3",children:"Reusability:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Is there evidence of usage by a wider community beyond the resource creators or their project?"}),(0,r.jsx)("li",{children:"Is the resource easy to (re)use? For example, does it have high-quality documentation? Are there tutorials available?"}),(0,r.jsx)("li",{children:"Is the resource general enough to be applied in a wider set of scenarios, not just for the originally designed use?"}),(0,r.jsx)("li",{children:"Is there potential for extensibility to meet future requirements?"}),(0,r.jsx)("li",{children:"Does the resource include a clear explanation of how others use the data and software? Or (for new resources) how others are expected to use the data and software?"}),(0,r.jsx)("li",{children:"Does the resource description clearly state what the resource can and cannot do, and the rationale for the exclusion of some functionality?"})]}),(0,r.jsx)("h4",{style:{color:"#e94607"},className:"text-md font-medium mt-3",children:"Design & Technical Quality:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Does the design of the resource follow resource-specific best practices?"}),(0,r.jsx)("li",{children:"Did the authors perform an appropriate reuse or extension of suitable high-quality resources?"}),(0,r.jsx)("li",{children:"Is the resource suitable for solving the task at hand?"}),(0,r.jsx)("li",{children:"Does the resource provide an appropriate description (both human- and machine-readable), thus encouraging the adoption of FAIR principles?"})]}),(0,r.jsx)("h4",{style:{color:"#e94607"},className:"text-md font-medium mt-3",children:"Availability:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Is the resource publicly available? For example as API, Linked Open Data, Download, Open Code Repository."}),(0,r.jsx)("li",{children:"Is the resource publicly findable? Is it registered in (community) registries (e.g., Linked Open Vocabularies, BioPortal, or DataHub)?"}),(0,r.jsx)("li",{children:"Is there a sustainability plan specified for the resource?"}),(0,r.jsx)("li",{children:"Does the resource adopt open standards, when applicable? Alternatively, does it have a good reason not to adopt standards?"})]}),(0,r.jsxs)("p",{children:["In addition to the above criteria for evaluation, we stress that there are availability requirements to fulfill, as specified as follows:",(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Mandatory: Is the resource (and related results) published at a persistent URI (PURL, DOI, w3id)?"}),(0,r.jsx)("li",{children:"Mandatory: Is there a canonical citation associated with the resource?"}),(0,r.jsx)("li",{children:"Mandatory: Does the resource provide a license specification? (See creativecommons.org, opensource.org for more information)"})]})]}),(0,r.jsxs)("p",{children:["Guidelines for reviewers are available ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/review",target:"_blank",style:{color:"#e94607"},children:"here"}),"."]}),(0,r.jsxs)("p",{children:["To ensure that reviewers and readers of published papers will easily find the mandatory availability information, please use the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/resources",target:"_blank",style:{color:"#e94607"},children:"Resource Availability Statement Guide"})," and suggested wording."]}),(0,r.jsxs)("p",{children:["Regarding specific resource types, checklists of their quality attributes are available in a ",(0,r.jsx)("a",{href:"https://github.com/iswc-conf/iswc2025/blob/main/public/resource/calls/RESOURCES_TRACK_Instructions_for_Authors_and_Reviewer.pdf",target:"_blank",style:{color:"#e94607"},children:"presentation"}),". Both authors and reviewers may make use of them when assessing the quality of a particular resource."]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Submission Details"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:["Pre-submission of abstracts is a strict requirement. All papers and abstracts have to be submitted electronically via ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",target:"_blank",style:{color:"#e94607"},children:"EasyChair"}),"."]}),(0,r.jsx)("li",{children:"Papers describing a resource must be in the range of 8 and 15 pages (excluding references). Papers must describe the resource and focus on the sustainability and community surrounding the resource. Benchmark papers are expected to include evaluations and provide a detailed description of the experimental setting. Papers that exceed the page limit will be rejected without review."}),(0,r.jsxs)("li",{children:["All submissions must be in English. Submissions must be either in PDF or HTML, formatted in the style of the Springer Publications format for Lecture Notes in Computer Science (LNCS). For details on the LNCS style, see  ",(0,r.jsx)("a",{href:"http://www.springer.com/computer/lncs/lncs+authors?SGWID=0-40209-0-0-0",target:"_blank",style:{color:"#e94607"},children:"Springer\u2019s Author Instructions"}),". For ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/html-submission",target:"_blank",style:{color:"#e94607"},children:"HTML submission guidance, please see the HTML submission guide used for ISWC 2025"}),"."]}),(0,r.jsx)("li",{children:"ISWC 2025 submissions for the resources track are not anonymous. We encourage embedding metadata in the PDF or HTML to provide a machine-readable link from the paper to the resource."}),(0,r.jsx)("li",{children:"Authors of accepted papers will be required to provide semantic annotations for the abstract of their submission, which will be made available on the conference website. Details will be provided at the time of acceptance."}),(0,r.jsx)("li",{children:"Accepted papers will be distributed to conference attendees and also published by Springer in the printed conference proceedings, as part of the Lecture Notes in Computer Science series."}),(0,r.jsx)("li",{children:"At least one author of each accepted paper must register for the conference and present the paper. As in previous years, students will be able to apply for registration or travel support to attend the conference."})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Prior Publication and Multiple Submissions"}),(0,r.jsx)("p",{children:'ISWC 2025 will not accept resource papers that, at the time of submission, are under review for or have already been published or accepted for publication in a journal, another conference, or another ISWC track. Depositing articles to preprint servers is allowed. Please read our "prior publication and multiple submission policy" for further information.'}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Research Metadata and Comparisons"}),(0,r.jsxs)("p",{children:["To facilitate clearly stating novelty to readers and peer-reviewers alike, findability of the paper if accepted, and trying to use knowledge graphs ourselves, you may add to the paper a so-called \u201cORKG comparison\u201d with the ",(0,r.jsx)("a",{href:"https://orkg.org/",target:"_blank",style:{color:"#e94607"},children:"Open Research Knowledge Graph"})," (ORKG). Such an ORKG Comparison is a characterization of a submission by juxtaposing it with related resources, if there are any, and therewith highlighting the key difference(s) of your resource with related ones. More information on the background and how to create an ORKG comparison can be found  ",(0,r.jsx)("a",{href:"https://www.orkg.org/orkg/help-center/article/38/Accompany_your_paper_submission_with_an_ORKG_comparison",target:"_blank",style:{color:"#e94607"},children:"here"})," (including a how-to video). This can be done during the submission process \u2013 in which case a link to the comparison can be added to the submission for reviewers. ",(0,r.jsx)("a",{href:"https://iswc2023.semanticweb.org/wp-content/uploads/2023/01/ORKGWorkflow.pdf",target:"_blank",style:{color:"#e94607"},children:"This workflow"})," describes the steps involved in the creation of such a comparison. This addition to an ISWC paper submission is experimental and optional. It may not be relevant to your resource, and the absence of such a comparison will not negatively affect the review of the paper."]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Resource Track Chairs"}),(0,r.jsxs)("p",{children:["Contact: ",(0,r.jsx)("a",{href:"mailto:iswc2025-resource@easychair.org",children:"iswc2025-resource@easychair.org"})]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Cogan Shimizu"}),", Wright State University, US"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Angelo Salatino"}),", KMi, The Open University, UK"]})]})]})]}),Nt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for In-Use Track Papers"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:"The ISWC In-Use track provides a forum to explore the benefits and challenges of applying Semantic Web and Knowledge Graph technologies in concrete, practical use cases, in contexts ranging from industry to government and society."}),(0,r.jsx)("p",{children:"The track aims to give a stage to applied works addressing real-world problems in which Semantic Web and Knowledge Graph technologies have been employed, possibly in combination with machine learning, deep learning, and other AI techniques."}),(0,r.jsx)("p",{children:"The In-Use track thus seeks submissions describing applied research as well as software tools, systems, or architectures that benefit from the use of Semantic Web and Knowledge Graph technologies (including, but not limited to, technologies based on the Semantic Web standards). Importantly, submitted papers should provide convincing evidence of the use of the proposed application or tool by the target user group, preferably outside the group that conducted the development and, more broadly, outside the Semantic Web and Knowledge Graph research communities."}),(0,r.jsx)("p",{children:"A primary focus of the submissions should be on the benefits of Semantic Web and Knowledge Graph technologies for the intended use case and (if relevant) the added challenges they introduce. In addition, papers that advance the understanding of issues related to applying and deploying solutions involving Semantic Web and Knowledge Graph technologies in practice are strongly encouraged."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Important Dates"}),(0,r.jsx)("p",{children:"All deadlines are 23:59 AoE (anywhere on Earth)."}),(0,r.jsxs)("ul",{children:[(0,r.jsxs)("li",{children:["Abstract submission due: ",(0,r.jsx)("b",{children:"May 6th, 2025"})]}),(0,r.jsxs)("li",{children:["Full paper submission due: ",(0,r.jsx)("b",{children:"May 13th, 2025"})]}),(0,r.jsxs)("li",{children:["Rebuttal: ",(0,r.jsx)("b",{children:"June 17th - 20th, 2025"})]}),(0,r.jsxs)("li",{children:["Notifications: ",(0,r.jsx)("b",{children:"July 17th, 2025"})]}),(0,r.jsxs)("li",{children:["Camera ready papers due: ",(0,r.jsx)("b",{children:"July 31st, 2025"})]})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Topics of Interest"}),(0,r.jsx)("p",{children:"We welcome submissions that demonstrate the use of Semantic Web and Knowledge Graph technologies, encompassing all topics mentioned in the Research Track. Submissions may particularly emphasize one or more of the following types of contributions:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Applications in domain-specific areas such as libraries, cultural heritage, healthcare, life sciences, engineering, smart manufacturing, smart cities, open government, legal tech, finance."}),(0,r.jsx)("li",{children:"Descriptions of how Semantic Web resources (ontologies, datasets, software, standards, etc.) are being used in practice."}),(0,r.jsxs)("li",{children:["Assessment of the Semantic Web and Knowledge Graph technologies from diverse points of view, including:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Usability and acceptance by stakeholder groups"}),(0,r.jsx)("li",{children:"Uptake outside the proposing research communities"}),(0,r.jsx)("li",{children:"Scalability of solutions and their large-scale deployment"}),(0,r.jsx)("li",{children:"Costs and benefits of implementing, deploying, using, and managing Semantic Web and Knowledge Graph technologies"}),(0,r.jsx)("li",{children:"Risks and opportunities of using Semantic Web and Knowledge Graph technologies in organizations for their businesses and customers"})]})]}),(0,r.jsx)("li",{children:"Lessons learned and best practices from deploying and using an application or service based on Semantic Web and Knowledge Graph technologies."}),(0,r.jsx)("li",{children:"Comparison of Semantic Web and Knowledge Graph technologies with alternative approaches that use conventional or competing technologies (e.g., database management systems, model-driven engineering, other AI techniques)."}),(0,r.jsx)("li",{children:"Application-oriented work that does not qualify as a research paper, where the use of rather than the development of Semantic Web and Knowledge Graph technologies has a demonstrated impact on more flexible, more efficient, or otherwise improved solutions."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Differentiation From the Other Tracks"}),(0,r.jsx)("p",{children:"We strongly recommend that prospective authors carefully check the calls of the other tracks of the conference in order to identify the optimal track for their submission (submission of the same work to multiple tracks is prohibited). Papers that propose new algorithms and architectures should be submitted to the Research track as usual. Papers focusing on new reusable resources themselves, such as datasets, ontologies, workflows, etc., should be submitted to the Resources Track. Papers that describe and/or assess the use or application of Semantic Web and Knowledge Graph technologies in practical settings should be submitted to the In-Use track. See \u201cExemplary In-Use Papers From Previous Editions of ISWC\u201d (below) for additional details."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Review Criteria"}),(0,r.jsx)("p",{children:"Reviews for the In-Use track are not anonymous. Submissions will be assessed in terms of novelty and significance (of the proposed use case or solution), uptake by the target user group, demonstrated or potential impact, as well as overall soundness and quality. Therefore, authors should clearly address these aspects in their submission."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Soundness and Quality"}),(0,r.jsx)("p",{children:"Methodological correctness of the performed evaluation in terms of quantitative and/or qualitative metrics to assess the pros and cons of the proposed solution."}),(0,r.jsx)("p",{children:"Quality of the discussion of the benefits and challenges of adopting Semantic Web and Knowledge Graph technologies for solving the addressed problem and/or with respect to alternative approaches."}),(0,r.jsx)("p",{children:"Overall clarity and quality of the submission."}),(0,r.jsxs)("p",{children:["Guidelines for reviewers are available  ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/review",target:"_blank",style:{color:"#e94607"},children:"here"}),"."]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Novelty and Significance"}),(0,r.jsx)("p",{children:"Novelty and significance of the addressed problem or use case when applying Semantic Web and Knowledge Graph technologies. Novelty in the application or assessment of Semantic Web and Knowledge Graph technologies, which can be reflected in terms of, for example: (1) the role they play in the solution; (2) how they foster adoption; or (3) their combination/interplay with other technologies."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Uptake"}),(0,r.jsx)("p",{children:"Evidence of the adoption of the proposed solution by a relevant user base (domain practitioners, the general public, developers, etc.), preferably distinct from the proposer\u2019s institutions and the Semantic Web and Knowledge Graph research communities. This adoption can reflect either current uptake \u2013 demonstrating existing use \u2013 or expected uptake, supported by a well-founded plan for large-scale deployment or adoption in the specific domain."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Impact"}),(0,r.jsx)("p",{children:"Technological, business, and social impact of the proposed solution, especially in contrast to alternative approaches. Validity and applicability of the proposed approach in a different domain. Applicability of the lessons learned from the adoption of Semantic Web and Knowledge Graph technologies both from a technical and non-technical perspective."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Rebuttal"}),(0,r.jsx)("p",{children:"Authors will have the chance to respond to the reviews during a rebuttal period that precedes the reviewer discussion period. In order to reduce the workload on authors and reviewers, authors are encouraged to use their rebuttal in a focused way to:"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"highlight clear factual errors in reviews regarding the content of the submission, or"}),(0,r.jsx)("li",{children:"respond to explicit questions from reviewers."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Supplemental Material Statement"}),(0,r.jsx)("p",{children:"We recommend authors to add a statement at the end of their submission that clarifies the availability of supplemental material (see Supplemental Material Statement Guide for more details). Such material may include datasets, ontologies, queries, code, configuration details, etc., depending on the contributions of the paper. The statement should cover all of the material necessary to assess claims in the paper. Unless otherwise justified, it is expected that access to resources is provided from the submitted paper since these resources often play an important role in the review process and are relevant to the prospective readership. In case certain resources cannot be made available (e.g., due to privacy, ethical, or financial concerns), the statement should include a justification of why this is the case. In case the paper is fully self-contained and does not have supplemental material associated, a short statement can be provided arguing that the paper is self-contained. Please see the Supplemental Material Statement Guide for more details."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Submission Details"}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]"}),(0,r.jsxs)("li",{children:["Pre-submission of abstracts is a strict requirement. All papers and abstracts have to be submitted electronically via ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",target:"_blank",rel:"noopener noreferrer",style:{color:"#e94607"},children:"EasyChair"}),"."]}),(0,r.jsx)("li",{children:"All research submissions must be in English, and no longer than 15 pages (excluding references). Papers that exceed this limit will be rejected without review."}),(0,r.jsxs)("li",{children:["Submissions must be either in PDF or HTML, formatted in the style of the Springer Publications format for Lecture Notes in Computer Science (LNCS). For details on the LNCS style, see ",(0,r.jsx)("a",{href:"https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines",target:"_blank",style:{color:"#e94607"},children:"Springer\u2019s Author Instructions"}),". For HTML submission guidance, please see the HTML submission guide."]}),(0,r.jsx)("li",{children:"Submissions to the ISWC 2025 In-Use track are not anonymous. We encourage embedding metadata in the PDF or HTML to provide a machine-readable link from the paper to the resource."}),(0,r.jsx)("li",{children:"Authors of accepted papers will be required to provide semantic annotations for the abstract of their submission, which will be made available on the conference website. Details will be provided at the time of acceptance."}),(0,r.jsx)("li",{children:"Accepted papers will be distributed to conference attendees and also published by Springer in the conference proceedings, as part of the Lecture Notes in Computer Science series."}),(0,r.jsx)("li",{children:"At least one author of each accepted paper must register for the conference and present the paper."}),(0,r.jsx)("li",{children:"As in previous years, students will be able to apply for travel/registration support to attend the conference."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Prior Publication and Multiple Submissions"}),(0,r.jsx)("p",{children:"ISWC 2025 will not accept papers that, at the time of submission, are under review for or have already been published or accepted for publication in a journal, another conference, or another ISWC track. The conference organizers may share information on submissions with other venues to ensure that this rule is not violated."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Research Metadata and Comparisons"}),(0,r.jsx)("p",{children:"Authors are encouraged to consider whether their submission can profit from an explicit comparison with related approaches in the literature by means of an ORKG comparison in the Open Research Knowledge Graph (ORKG) (this is not mandatory). More information on the background and how to create an ORKG comparison can be found here (including a how-to video). This can be done during the submission process \u2013 in which case a link to the comparison can be added to the submission for reviewers. This workflow describes the steps involved in the creation of such a comparison."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Exemplary In-Use Papers from Previous Editions of ISWC"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://doi.org/10.1007/978-3-031-77847-6_12",children:"Scrocca, M. et al. (20245) Intelligent Urban Traffic Management via Semantic Interoperability Across Multiple Heterogeneous Mobility Data Sources. ISWC 2024. LNCS, vol. 15233. Springer, pp. 218\u2013235."})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://doi.org/10.1007/978-3-031-47243-5_19",children:"Cuddihy, P. et al. (2023) Aviation Certification Powered by the Semantic Web Stack. ISWC 2023. LNCS, vol. 14266. Springer, pp. 345\u2013361."})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://doi.org/10.1007/978-3-031-19433-7_42",children:" Angioni, S. et al. (2022) Leveraging Knowledge Graph Technologies to Assess Journals and Conferences at Springer Nature. ISWC 2022. LNCS, vol 13489. Springer, pp. 735-752."})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://doi.org/10.1007/978-3-030-88361-4_38",children:"Rojas J.A. et al. (2021) Leveraging Semantic Technologies for Digital Interoperability in the European Railway Domain. ISWC 2021. LNCS, vol 12922. Springer, pp. 648-664."})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://doi.org/10.1007/978-3-030-30796-7_27",children:"Ib\xe1\xf1ez LD., Millard I., Glaser H., Simperl E. (2019) An Assessment of Adoption and Quality of Linked Data in European Open Government Data. ISWC 2019. LNCS, vol 11779. Springer, pp. 436-453."})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://doi.org/10.1007/978-3-030-00668-6_21",children:"Thanapalasingam T., Osborne F., Birukou A., Motta E. (2018) Ontology-Based Recommendation of Editorial Products. ISWC 2018. LNCS, vol 11137. Springer, pp. 341-358."})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://doi.org/10.1007/978-3-319-68204-4_29",children:"Mehdi G. et al. (2017) Semantic Rule-Based Equipment Diagnostics. ISWC 2017. LNCS, vol 10588. Springer, pp. 314-333."})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://doi.org/10.1007/978-3-319-46547-0_34",children:"Piro R. et al. (2016) Semantic Technologies for Data Analysis in Health Care. ISWC 2016. LNCS, vol 9982. Springer, pp. 400-417."})})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"In-Use Track Chairs"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Maribel Acosta"}),", Technical University of Munich, Germany"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Andrea Giovanni Nuzzolese"}),", CNR - Institute of Cognitive Sciences and Technologies, Italy"]}),(0,r.jsxs)("p",{children:["Contact: ",(0,r.jsx)("a",{href:"mailto:iswc2025-inuse@easychair.org",children:"iswc2025-inuse@easychair.org"})]})]})]})]}),Ct=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Journal Track Sessions Proposals"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:"ISWC 2025 is iterating on the historical Journal Track. This year, we are soliciting a call for (journal track) sessions. These sessions will be held during the main track of the conference."}),(0,r.jsx)("p",{children:"We want to facilitate cross-pollination between sub-communities, as well as overall strengthen the ties and pipelines between ISWC and the journals that serve our community."}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"Eligibility"}),(0,r.jsx)("p",{children:"This track is open to any journal related to the Semantic Web or the principled use of related artifacts (e.g., ontologies, semantics, or semantic technologies). Proposal authors should be editors of the journal, and if they are not editors in chief, then should be submitted under their auspices."}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"Session Format Guidance"}),(0,r.jsx)("p",{children:"A session should be considered to be 90 minutes long. The session\u2019s internal organization is up to the proposer. However, we encourage that the session proposal has a coherent theme, or that the Editors have otherwise curated a selection of timely, impactful, or prescient papers from their journal\u2019s recent issues."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-md font-medium mt-3",children:"Proceedings"}),(0,r.jsx)("p",{children:"To encourage participation and otherwise facilitate attendance, there is capacity for inclusion in the ISWC proceedings and event \u2013 beyond the presentation during the proposed session."}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Journal Spotlight \u2013 Companion Proceedings"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"This is an optional venue, where the proposers may opt-in so that presenters may have some publication, which allows for attendance. Ideally, all presenters would provide a contextualization of their presented journal article. Ideally, the proposers (i.e., the editors) would provide an editorial-style introduction which discusses the entire session and its context."}),(0,r.jsx)("li",{children:"This is currently anticipated to be a CEUR volume."})]}),(0,r.jsx)("li",{children:"First-come, first-serve slots at the Poster & Demo session"}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"This must be communicated clearly, so that space can be reserved."})})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"Review Criteria"}),(0,r.jsxs)("p",{children:["The organizing committee will consider the organization of the session, as well as the selected papers for presentation and discussion. Therefore, proposers ",(0,r.jsx)("strong",{children:"must ensure unfettered access to the selected papers"})," both during the review process and to attendees of the conference (at least during the conference duration). All submissions will be evaluated along the following review criteria:"]}),(0,r.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"Scientific and Community Impact and Relevance"}),(0,r.jsxs)("ul",{className:"list-disc list-inside space-y-2 mb-6",children:[(0,r.jsx)("li",{children:"How did the collection break new ground?"}),(0,r.jsx)("li",{children:"How did the collection fill important gaps?"}),(0,r.jsx)("li",{children:"How did the collection otherwise advance the state of the art?"}),(0,r.jsx)("li",{children:"Is the collection of papers of interest to society in general?"}),(0,r.jsx)("li",{children:"What impact has this collection of papers had, scientifically and socially?"}),(0,r.jsx)("li",{children:"Is the collection relevant to the Semantic Web community, in particular along its emphasized themes for ISWC 2025?"})]}),(0,r.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"Availability"}),(0,r.jsx)("ul",{className:"list-disc list-inside space-y-2 mb-6",children:(0,r.jsx)("li",{children:"Are the selected papers available for attendees of the proposed session to read without a paywall?"})}),(0,r.jsx)("h3",{className:"text-xl font-semibold mb-2",children:"Attendance"}),(0,r.jsxs)("ul",{className:"list-disc list-inside space-y-2 mb-8",children:[(0,r.jsx)("li",{children:"Is at least one author of each of the selected papers confirmed to attend ISWC 2025?"}),(0,r.jsx)("li",{children:"Is at least one editor confirmed to attend ISWC 2025?"})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"Submission Details"}),(0,r.jsxs)("ul",{className:"list-disc list-inside space-y-2 mb-8",children:[(0,r.jsxs)("li",{children:["All papers and abstracts must be submitted electronically via ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",className:"text-blue-600 underline",target:"_blank",rel:"noopener noreferrer",children:"EasyChair"}),' (choose \\"Journal Session Proposals\\").']}),(0,r.jsxs)("li",{children:["Proposals must not exceed ",(0,r.jsx)("b",{children:"4 pages (excluding references). Proposals that exceed the page limit will be rejected without review"}),"."]}),(0,r.jsx)("li",{children:"All submissions must be in English."}),(0,r.jsx)("li",{children:"Submissions must be in PDF or HTML formatted in the CEURART 1-column style (LNCS is no longer valid)."}),(0,r.jsx)("li",{children:"The title should use emphasizing capitalized style, and submissions must not include page numbers."}),(0,r.jsxs)("li",{children:["For HTML submission guidance, see the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/html-submission",className:"text-blue-600 underline",target:"_blank",rel:"noopener noreferrer",children:"HTML Submission Guide"}),"."]}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"ISWC 2025 submissions for the journal track are necessarily not anonymous."})}),(0,r.jsx)("li",{children:"At least one proposer must register for the conference and chair the session."}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"At least one author of each selected paper must register for the conference and present the paper."})})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mb-4",children:"Important Dates"}),(0,r.jsxs)("ul",{className:"list-disc list-inside space-y-2",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Journal Track Session Proposals Due:"})," June 30, 2025"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Notifications to Proposers:"})," July 17, 2025"]}),(0,r.jsx)("li",{children:"All deadlines are 23:59 AoE (Anywhere on Earth)."})]})]})]})]}),Tt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Posters and Demos"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:"The ISWC 2025 Posters and Demos Track offers an opportunity to showcase late-breaking research results, ongoing research or resource projects, speculative or innovative ideas, and interactive demonstrations. This track is designed to encourage dynamic discussions between presenters and participants, fostering feedback that can shape future research directions. These discussions will offer participants an effective way to broaden their knowledge of emerging research trends and to network with other researchers."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important Dates"}),(0,r.jsxs)("p",{children:["Posters & demos submissions due: ",(0,r.jsx)("strong",{children:"July 31st, 2025"})]}),(0,r.jsxs)("p",{children:["Author notifications: ",(0,r.jsx)("strong",{children:"August 28th, 2025"})]}),(0,r.jsxs)("p",{children:["Camera-ready submissions due: ",(0,r.jsx)("strong",{children:"September 11th, 2025"})]}),(0,r.jsx)("p",{children:"All deadlines are 23:59 AoE (Anywhere on Earth)"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Topics of Interest"}),(0,r.jsx)("p",{children:"We invite submissions relevant to the areas of Semantic Web, Knowledge Graphs, and Linked Data, which address, but are not limited to, the topics of the Research Track, the Resources Track, the In-Use Track, and the Industry Track. Visionary ideas, position statements, negative results, and outrageous ideas are also welcome."}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[" ",(0,r.jsx)("strong",{children:"Posters"}),":",(0,r.jsx)("p",{children:" Submissions should describe research work (ongoing or completed), resource projects, or systems (both academic and commercial) relevant to the topics above."})]}),(0,r.jsxs)("li",{children:[" ",(0,r.jsx)("strong",{children:"Demos"}),":",(0,r.jsx)("p",{children:" Submissions should showcase innovative implementations, tools, or technologies from academia or industry. Demos must highlight a novel solution to a well-defined problem and avoid being purely promotional or commercial."})]})]}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"We welcome submissions from Industry, provided they focus on technical contributions rather than product advertisements. Authors of full papers accepted in the Research, Resources, and In-Use Tracks are encouraged to submit a poster or a demonstration. The submission should be formatted as other submissions to this track. Still, it must cite the accepted full paper and include a description of how it complements or adds value to the full paper. The added value could include:"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"extended results and experiments not presented in the full paper for reasons of space or"}),(0,r.jsx)("li",{children:"a demonstration of a supporting prototype implementation."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Review Criteria"}),(0,r.jsx)("p",{children:"Submissions must clearly demonstrate relevance to the aforementioned topics of interest of ISWC 2025. Decisions about acceptance will be based on the relevance to the topics of interest, originality, potential significance, topicality, and clarity. All submissions to the Posters & Demos Track will be reviewed by at least three program committee members, including those related to the already accepted full papers. The purpose of the track is to allow the presentation of preliminary results to the community, provided that originality and significance of the contribution are ensured."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Submission Details"}),(0,r.jsx)("p",{children:(0,r.jsx)("strong",{children:"All submissions should follow the single anonymous submission policy (i.e., authors are named, reviewers are anonymous)."})}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"All submissions must be in English and in PDF format."}),(0,r.jsxs)("li",{children:["Submissions must adhere to the ",(0,r.jsx)("a",{href:"https://ceurws.wordpress.com/2020/03/31/ceurws-publishes-ceurart-paper-style/",target:"_blank",style:{color:"#e94607"},children:"CEURART"})," 1-column style (LNCS is not valid anymore). The title should use the emphasizing capitalized style, and submissions should not include page numbers. "]}),(0,r.jsxs)("li",{children:["For HTML submission guidance, please see the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/html-submission",target:"_blank",style:{color:"#e94607"},children:"HTML submission guide"}),"."]}),(0,r.jsx)("li",{children:"Poster submissions are at most 4 pages long, excluding references. Demo submissions are at most 5 pages long, excluding references. Authors will be granted one extra page when preparing their camera-ready version in case of acceptance in order to address the reviewers\u2019 comments."}),(0,r.jsx)("li",{children:"Submissions that exceed the given page limits or do not follow the CEURART guidelines may be rejected without review. Posters and demos accompanying an accepted full paper must be marked as such in the submission form and explicitly explain the additional value provided by the poster or demo in the submission itself."}),(0,r.jsx)("li",{children:"Double submissions to any other conferences, workshops, or tracks of ISWC will be rejected."}),(0,r.jsx)("li",{children:"For demo submissions, authors are strongly encouraged to include a link to an online demo or a video of the application to be presented in the submission."}),(0,r.jsx)("li",{children:"We require the authors to specify the submission type (poster or demo) in the submission form at the time of submission."})]}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("p",{children:["All submissions must be made electronically via EasyChair at ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",target:"_blank",rel:"noopener noreferrer",style:{color:"#e94607"},children:"this link"}),"."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Conference Attendance and Presentation Format"}),(0,r.jsx)("p",{children:"At least one of the authors must register for the main conference and attend the Posters and Demos Session to present the work. The abstracts of accepted posters and demonstrations will be published on the conference website and compiled into a CEUR Proceedings for Web retrieval and archiving. The metadata for all accepted submissions will be included in the conference metadata corpus. Detailed information about metadata creation will be provided with the acceptance notification of the successful submissions."}),(0,r.jsx)("p",{children:"The presentation format for accepted posters will be a physical poster. For demos, authors are required to present both a physical poster and an on-site demo."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Posters and Demos Chairs"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Gong Cheng"}),", Nanjing University, China"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Shenghui Wang"}),", University of Twente, The Netherlands"]}),(0,r.jsxs)("p",{children:["Contact email: ",(0,r.jsx)("a",{style:{color:"#e94607"},href:"mailto:iswc2025-pd@easychair.org",children:"iswc2025-pd@easychair.org"})]})]})]})]}),At=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Challenges Proposals"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:"A great way to advance the state of the art in a given domain is to create competition. We invite you to propose an ISWC 2025 Challenge, in which you define an open competition on a problem of your choice within the Semantic Web domain."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Important Dates"}),(0,r.jsxs)("ul",{children:[(0,r.jsxs)("li",{children:["Challenge proposal submission due: ",(0,r.jsx)("strong",{children:"March 4th, 2025"})]}),(0,r.jsxs)("li",{children:["Notification of challenge acceptance: ",(0,r.jsx)("strong",{children:"March 16th, 2025"})]})]}),(0,r.jsx)("p",{children:"All deadlines are 23:59 AoE (Anywhere on Earth)."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Topics"}),(0,r.jsx)("p",{children:"For ISWC 2025, Challenge proposals are invited for any challenge involving Semantic Web tasks, including but not limited to:"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Ontology and knowledge graph alignment"}),(0,r.jsx)("li",{children:"Ontology and knowledge graph quality assurance (QA)"}),(0,r.jsx)("li",{children:"Knowledge graph construction and refinement"}),(0,r.jsx)("li",{children:"Graph embeddings and graph neural networks"}),(0,r.jsx)("li",{children:"Query and reasoning scalability"}),(0,r.jsx)("li",{children:"Open information extraction"}),(0,r.jsx)("li",{children:"Neurosymbolic reasoning"}),(0,r.jsx)("li",{children:"Semantic Web and data mining"}),(0,r.jsx)("li",{children:"Semantic Web, machine learning, and neuro-symbolic AI"}),(0,r.jsx)("li",{children:"Link prediction"}),(0,r.jsx)("li",{children:"Question answering"}),(0,r.jsx)("li",{children:"Stream processing and reasoning"}),(0,r.jsx)("li",{children:"Semantic table understanding"}),(0,r.jsx)("li",{children:"Agents (especially using neuro-symbolic methods) and agentic workflows"}),(0,r.jsx)("li",{children:"Retrieval Augmented Generation (RAG)"})]}),(0,r.jsx)("p",{children:"Recent Challenge examples can be found at:"}),(0,r.jsxs)("ul",{children:[(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://iswc2023.semanticweb.org/semantic-web-challenges/",target:"_blank",rel:"noopener noreferrer",children:"ISWC 2023 Semantic Web Challenges"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://iswc2022.semanticweb.org/index.php/challenges/",target:"_blank",rel:"noopener noreferrer",children:"ISWC 2022 Challenges"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://iswc2021.semanticweb.org/challenges",target:"_blank",rel:"noopener noreferrer",children:"ISWC 2021 Challenges"})})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Proposal Stage"}),(0,r.jsx)("p",{children:"ISWC 2025 will run multiple challenges with the aim of evaluating and comparing software solutions for the Semantic Web and Knowledge Graphs in a systematic way. To propose a challenge, you are required to:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Specify a task to be addressed."}),(0,r.jsx)("li",{children:"Provide an evaluation dataset."}),(0,r.jsx)("li",{children:"Define evaluation measures to compare the performance of participating systems."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Showcase Stage"}),(0,r.jsx)("p",{children:"At ISWC 2025, each challenge will receive one slot during the main conference, where organizers present the challenge, participating systems with accepted solutions, and announce the winner. At least one organizer must register and be present at the conference. Participants have the option to present their systems during the poster and demo session. Winners will receive a certificate."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Proposal Submission Guidelines"}),(0,r.jsx)("p",{children:"Proposals for challenges should be concise (2\u20134 pages) and include:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Names and affiliations of the organizers."}),(0,r.jsx)("li",{children:"Description of the challenge, including its relevance to the Semantic Web community."}),(0,r.jsx)("li",{children:"Process for selecting, acquiring, and preparing data for training and evaluation, with conditions of availability. Describing data in relation to the FAIR principles is recommended."}),(0,r.jsx)("li",{children:"Procedure for evaluating the performance of systems, including metrics and availability of evaluation software."}),(0,r.jsx)("li",{children:"A timeline based on the provided template for all challenges."}),(0,r.jsx)("li",{children:"Expected number of participants with supporting evidence (e.g., expression of interests, forum discussions, attendance in previous editions)."}),(0,r.jsx)("li",{children:"Plan for dissemination of the challenge (targeted mailing lists, social media, etc.)."}),(0,r.jsx)("li",{children:"Any other relevant information, including previous evaluations for the proposed challenge."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Selection Criteria"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Relevance to the Semantic Web community."}),(0,r.jsx)("li",{children:"Potential number of interested participants."}),(0,r.jsx)("li",{children:"Rigor and transparency of task description and evaluation procedure."})]}),(0,r.jsxs)("p",{children:["Please submit through EasyChair and select the track \u201cChallenge-Proposal\u201d.",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",style:{color:"#e94607"},target:"_blank",children:"Submit Proposal"})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Requirements upon Acceptance"}),(0,r.jsx)("p",{children:"Accepted challenges will need to adhere to the following requirements:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Challenge Web Page: Organizers must prepare a challenge web page with detailed participation instructions, format, and timelines."}),(0,r.jsx)("li",{children:"Timeline for Deadlines: Organizers are encouraged to adhere to the indicative timeline for challenges provided by ISWC."}),(0,r.jsx)("li",{children:"Participation Requirements: At least one challenge organizer must register for the conference by the early bird registration deadline and attend the challenge in person."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Timeline Template for Challenge Organizers"}),(0,r.jsx)("p",{children:"The tentative timeline template for organizing a Challenge is as follows (all deadlines are 23:59 AoE):"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Website & first call for participation - Mar 16th"}),(0,r.jsx)("li",{children:"Release datasets - Mar 30th"}),(0,r.jsx)("li",{children:"Release of Test Set (optional) - May 16th"}),(0,r.jsx)("li",{children:"Submission of Systems - June 28th"}),(0,r.jsx)("li",{children:"System Results - July 19th"}),(0,r.jsx)("li",{children:"Notification of Acceptance - July 19th"})]}),(0,r.jsx)("p",{children:"Note: The deadlines and mostly the dataset release deadline and system submission deadline can be flexibly adjusted according to the challenge, especially if the challenge includes several evaluation rounds (e.g., http://www.cs.ox.ac.uk/isg/challenges/sem-tab/2020/index.html)."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Semantic Web Challenge Chairs"}),(0,r.jsxs)("p",{children:["Contact: ",(0,r.jsx)("a",{href:"mailto:iswc2025-challenge@easychair.org",children:"iswc2025-challenge@easychair.org"})]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Mayank Kejriwal"})," - University of Southern California, United States"]})]})]})]}),Lt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call For Industry Papers"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:(0,r.jsx)("b",{children:"Have you employed knowledge graphs, semantic technologies, and Large Language Models (LLMs) to adopt semantics in innovative industrial applications?"})}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"The Industry Track at ISWC 2025 welcomes extended abstracts about the application of knowledge graphs and semantic technologies in various industrial sectors, aiming to showcase the state of their adoption and the latest trends. It provides an opportunity for industry adopters to highlight and share the key learnings and new research challenges posed by real-world implementations."}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"Knowledge Graphs and semantic technologies are increasingly being employed across multiple sectors, reshaping industries such as automotive, manufacturing, retail, e-commerce, media, finance, telecommunications, healthcare, life sciences, education, energy, government, intelligence, research, smart cities, and cultural heritage, among others. These technologies enhance applications by offering diverse capabilities, including business intelligence, analytics, search, content management, knowledge management, recommendation systems, information extraction, master data management, data integration, and more."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"New Focus on LLMs:"}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"In recent years, Large Language Models (LLMs) have emerged as powerful tools for language understanding and generation. We especially encourage submissions demonstrating how semantics, knowledge graphs, and LLMs can be combined to tackle real-world industrial challenges\u2014whether by improving data integration, automating knowledge extraction, providing semantically rich reasoning capabilities, or creating novel user experiences."}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"The Industry Track welcomes your case studies of success stories, as well as insightful discussions on challenges hindering the widespread adoption of knowledge graph, semantic technologies, and LLMs in industrial applications and settings. Reports detailing the application and deployment experiences of recent research advancements to industry-relevant problems are also encouraged."}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"Submissions should focus on demonstrating the business value and impact of employing knowledge graphs and semantic technologies\u2014potentially in conjunction with LLMs\u2014to solve real-world industry issues, serving as a competitive differentiator. Contributions from both small and large companies are welcomed. Each submission must feature at least one author affiliated with a non-academic organization."}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"Come and join us at the ISWC 2025 Industry Track to share your experiences with the largest community of researchers and practitioners in the Knowledge Graph and Semantic Web domain!"}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important Dates"}),(0,r.jsxs)("ul",{children:[(0,r.jsxs)("li",{children:["Submissions Due: ",(0,r.jsx)("b",{style:{fontWeight:500},children:"8th July 2025"})]}),(0,r.jsxs)("li",{children:["Notifications Due: ",(0,r.jsx)("b",{style:{fontWeight:500},children:"29th July 2025"})]}),(0,r.jsxs)("li",{children:["Camera-Ready Papers Due: ",(0,r.jsx)("b",{style:{fontWeight:500},children:"11th September 2025"})]})]}),(0,r.jsx)("p",{children:"All deadlines are 23:59 AoE (anywhere on Earth) "}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Topics of Interest"}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"Topics of interest include, but are not limited to, the following:"}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Case studies detailing the successful application of knowledge graphs and semantic technologies"})," to address relevant problems in specific industrial domains."]}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{style:{fontWeight:500},children:"Analysis of how semantic technologies can generate business value."})}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Assessments of the applicability of academic research outcomes to real-world industrial scenarios"}),", focusing on issues such as data relevance and scalability."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Integration of knowledge graphs and semantic technologies with other technologies"}),", including",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Large Language Models (LLMs)"}),": use cases and best practices for leveraging semantic structures and knowledge graphs to enhance LLM performance, as well as employing LLMs to enrich or refine semantic data."]}),(0,r.jsx)("li",{children:"Information retrieval, machine learning, natural language processing, human-AI interaction, distributed computing, and stream processing."})]})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Identification of new problems, use cases, and application areas "}),"that may catalyze further research in this field."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Discussion reports that identify barriers hindering the widespread adoption of knowledge graphs and semantic technologies"}),", along with proposed strategies to address these challenges."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"LLM-centric approaches that address challenges such as data integration, entity linking, disambiguation, or domain adaptation"}),", highlighting how semantic models help overcome these challenges at an industrial scale."]})]}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"Differently from the in-use track, successful submissions to this track will ideally emphasize the following:"}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("ul",{className:"list-disc list-inside pl-6 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Industry/Business problem:"})," A concise explanation of the specific issue."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Limitations of traditional solutions:"})," A discussion on why conventional methods failed to adequately address the problem."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Motivation for the semantic technologies:"})," A clear description of the reasons driving the need for these technologies, including their expected impact on the industry."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Application of the semantic technologies:"})," A detailed account of how knowledge graph technology (and, if relevant, LLMs) were implemented to tackle the issue."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Challenges:"})," A narrative on the strategies employed to navigate and resolve obstacles encountered during the implementation."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Business value:"})," An analysis of the return on investment (ROI) and other quantitative measures demonstrating the business value derived from the technology."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Scalability discussion:"})," An evaluation of the scalability of the technologies, considering their ability to expand and adapt to larger or more complex scenarios."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Best practices and lessons learned:"})," A summary of the key learnings and effective strategies identified through the process."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Description of real-world deployment:"})," A description of experiences and implementations in industrial settings (e.g., scale of deployment, dates launched and number of users, etc)."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Future research directions:"})," Insights into areas necessitating further investigation, including potential strategic applications and innovative use cases for knowledge graphs, semantic technologies, and LLMs."]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Review Criteria"}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"Submissions will be reviewed according to the following criteria:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside pl-6",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Value proposition in the specific industry/market "})," (quantitative and/or qualitative)."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Quality and depth of the discussion "})," regarding innovation, experiences, industry impact, lessons learned, and business value."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Relevance and necessity of knowledge graph and semantic technologies "})," (and, when applicable, LLMs) to the submission."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{style:{fontWeight:500},children:"Interestingness for the ISWC audience "})," and the potential discussions it could stimulate at the conference."]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Submission Details"}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("p",{children:["We invite submissions as an extended abstract of a maximum 3 pages (excluding references) formatted in the ",(0,r.jsx)("a",{href:"https://ceurws.wordpress.com/2020/03/31/ceurws-publishes-ceurart-paper-style/",target:"_blank",style:{color:"#e94607"},children:"CEURART single-column style."})]}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsx)("p",{children:"Each abstract should describe the content of the proposed talk, which should be of a technical or strategic nature. Pure marketing/promotional material will not be accepted."}),(0,r.jsxs)("p",{children:["Submissions should be made via ",(0,r.jsx)("a",{href:"https://easychair.org/my/conference?conf=iswc2025",target:"_blank",style:{color:"#e94607"},children:"EasyChair"})," and will be reviewed by a committee of practitioners from industry and academia. At least one author of each accepted paper must register for the conference and present the paper."]}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("p",{children:["Accepted extended abstracts will be published with ",(0,r.jsx)("a",{href:"https://ceur-ws.org/",target:"_blank",style:{color:"#e94607"},children:"CEUR-WS.org"})," and will have a presentation slot at the main conference."]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Format"}),(0,r.jsx)("p",{children:"Accepted extended abstracts will have a presentation slot at the main conference."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Industry Track Chairs"}),(0,r.jsxs)("p",{className:"text-md lg:text-lg font-[300]",children:["Contact email: ",(0,r.jsx)("a",{href:"mailto:iswc2025-industry@easychair.org",target:"_blank",style:{color:"#e94607"},children:"iswc2025-industry@easychair.org"})]}),(0,r.jsxs)("p",{className:"text-md lg:text-lg font-[300]",children:[(0,r.jsx)("b",{children:"Oktie Hassanzadeh"}),", IBM Research, US"]}),(0,r.jsxs)("p",{className:"text-md lg:text-lg font-[300]",children:[(0,r.jsx)("b",{children:"Irene Celino"}),", Cefriel, Italy"]})]})]})]}),It=()=>{const e=(0,n.useRef)(null);return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Doctoral Consortium Submissions"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsxs)("p",{children:["The ISWC 2025 Doctoral Consortium (DC) will take place as part of the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/",target:"_blank",style:{color:"#e94607"},children:"24th International Semantic Web Conference"}),". This forum provides PhD students an opportunity to:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"present and discuss their research ideas in a supportive, formative and yet critical environment;"}),(0,r.jsx)("li",{children:"receive feedback from mentors, typically senior members of the Semantic Web research community, and peers;"}),(0,r.jsx)("li",{children:"and network and build collaborations with other members of the community."})]})]}),(0,r.jsx)("p",{children:"The event is intended for students who have articulated a reasonably detailed research proposal, preferably supported by some preliminary results, but are not yet on the final stretch of their thesis, such that the feedback gathered at the DC will have a maximal impact. The aim is to support the students in refining their proposal and to suggest possible ways to improve their research plan and to achieve results with prospective greater impact."}),(0,r.jsxs)("p",{children:["The submissions to the Doctoral Consortium  should be structured like a research proposal (see \u201c",(0,r.jsx)("a",{onClick:()=>{var t;null===(t=e.current)||void 0===t||t.scrollIntoView({behavior:"smooth"})},style:{color:"#e94607"},children:"Submission Details"}),"\u201d below). Please note that anything  that looks like a research paper will be rejected without review."]}),(0,r.jsx)("p",{children:"All proposals submitted to the Doctoral Consortium will undergo a rigorous review process. The reviewers will provide detailed and constructive feedback and select which submissions will be presented at the Doctoral Consortium. If accepted, students will have to register and attend the full day event."}),(0,r.jsx)("p",{children:"We anticipate having student travel grants to cover some of the travel expenses to the conference."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important Dates:"}),(0,r.jsx)("p",{children:"All deadlines are 23:59 AoE (anywhere on Earth)"}),(0,r.jsxs)("ul",{children:[(0,r.jsxs)("li",{children:["Submissions Due: ",(0,r.jsx)("b",{children:"June 3, 2025"})]}),(0,r.jsxs)("li",{children:["Notifications: ",(0,r.jsx)("b",{children:"July 8, 2025"})]}),(0,r.jsxs)("li",{children:["Camera-ready Submissions Due: ",(0,r.jsx)("b",{children:"September 11, 2025"})]}),(0,r.jsxs)("li",{children:["Doctoral Consortium: ",(0,r.jsx)("b",{children:"November 3, 2025"})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Topics of Interest:"}),(0,r.jsx)("p",{children:"We are the doctoral consortium of the ISWC. As such, submissions should broadly fit the topics of interest of the ISWC research track."}),(0,r.jsxs)("div",{ref:e,id:"submission-details",children:[(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Submission Details:"}),(0,r.jsx)("p",{children:"Students should submit a 7-page description of their PhD research proposal. All proposals have to be submitted electronically via the EasyChair conference submission system."}),(0,r.jsx)("p",{children:"The submission should address the following questions:"}),(0,r.jsxs)("ol",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Problem statement:"})," what is the problem that you are trying to solve?"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Importance:"})," Why is this problem important and for whom? Who will benefit and who should care? What is the impact of solving this problem (for the research community, or society in general)?"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Related work:"})," Has a solution to this problem been attempted before and how?  If you are addressing an existing problem, what are the limitations of current solutions? What are you adding that is novel? Why? If not, have research efforts tried or solved similar, analogous problems? What can you learn from these efforts? "]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Research question(s) and hypotheses:"})," What research questions do you plan to explore? What hypotheses do you make in formulating your solution?"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Preliminary results:"})," Do you have any preliminary results that inform your research questions or hypotheses?"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Evaluation:"})," How will you know you\u2019ve answered your question(s)? What are the methods you apply to test your hypotheses? Have you identified criteria to measure the degree of success of your solution?"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Reflection and future work:"})," Are there any limitations in your approach? What are your planned next steps to complete your investigation?"]})]})]}),(0,r.jsx)("p",{children:"Please aim to answer the above questions with as much detail as possible, especially questions 2 and 4. You should provide as much detail as possible to allow a knowledgeable reviewer from the Semantic Web community, but possibly not an expert in your topic, to assess the validity of your research contribution. All submissions should include references. References will not count towards the page limit. All submissions exceeding 7 pages will be rejected without review."}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"The student should be the sole author of the submission."})," The supervisor(s) should be acknowledged at the end of the submission, together with a funding agency or any other party who supports or contributes to the research."]}),(0,r.jsxs)("p",{children:["Submissions must use the new CEUR-ART style. For details on the CEUR-ART style, see ",(0,r.jsx)("a",{href:"https://ceur-ws.org/HOWTOSUBMIT.html",target:"_blank",style:{color:"#e94607"},children:"Publishing at CEUR-WS.org"}),". For HTML submission guidance, please see the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/guidelines/html-submission",target:"_blank",style:{color:"#e94607"},children:"HTML submission guide"}),". They must be submitted online via ",(0,r.jsx)("a",{href:"https://easychair.org/my/conference?conf=iswc2025",target:"_blank",style:{color:"#e94607"},children:"EasyChair"})," (choosing the option: Doctoral Consortium), in PDF or HTML format."]}),(0,r.jsxs)("p",{children:["DC Proceeding will be published with ",(0,r.jsx)("a",{href:"http://ceur-ws.org/",target:"_blank",style:{color:"#e94607"},children:"CEUR-WS.org"}),"."]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Doctoral Consortium Track Chairs:"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Abraham Bernstein"})," - University of Zurich, Switzerland"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Natasha Noy"})," - Google Research, US"]}),(0,r.jsxs)("p",{children:["Contact: ",(0,r.jsx)("a",{href:"mailto:iswc2025-doctoral-consortium@easychair.org",children:"iswc2025-doctoral-consortium@easychair.org"})]})]})]})]})},Pt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 tracking-wide",children:"HTML Submission Guide"}),(0,r.jsx)("p",{children:"ISWC 2025 welcomes research articles employing the Open Web Platform. This document provides guidance to authors who wish to make their contributions available in HTML and related technology stack."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"General Guidance"}),(0,r.jsx)("p",{children:"Contributions in HTML should be shared in EasyChair as a ZIP archive that contains the complete and self-contained content of the article. It should include a main \u201cindex.html\u201d and all used resources (like media, scripts) to guarantee a correct visualization of the document on common desktop and mobile Web browsers. Please note the following key requirements"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"HTML template: any tooling or process can be used to produce the HTML."}),(0,r.jsx)("li",{children:"Content: the full content of the article must be human-readable with HTML alone. The use of CSS and JavaScript is encouraged, but should not interfere with the accessibility of the content."}),(0,r.jsx)("li",{children:"Offline-friendly: there must not be any external dependencies (e.g., a network connection) to retrieve, to render, or to manipulate the content of the article."}),(0,r.jsx)("li",{children:"Privacy: scripts must not be used to identify or track readers."}),(0,r.jsx)("li",{children:"View: the rendered article (HTML+CSS) should have the \u201clook and feel\u201d of the LNCS authoring guidelines. Pixel-perfection is not expected. This is to ensure visual consistency of the proceedings as well as to have comparative page limits with the print-based publication. The HTML article has to be compliant with the page limit constraint."})]}),(0,r.jsx)("p",{children:"It should be possible to read the HTML contributions on an average desktop computer or mobile computer that is equipped with a reasonably current, Javascript-enabled Web browser (e.g., Firefox, Chrome/Chromium, Internet Explorer, Brave, Safari). We encourage authors to make their articles as accessible as possible (for reading and interacting) because different consumers (in this case initially the reviewers and chairs) may have different environments and abilities."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Final (\u201ccamera-ready\u201d) Version"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"The publisher for the Research, In-Use, and Resources tracks will be confirmed soon. It is likely that the publisher will require submissions in LaTeX (or possibly Word) format. If an article submitted in HTML is accepted, the authors can choose to convert their paper manually or using tool support as outlined below."}),(0,r.jsx)("li",{children:"Articles accepted in the Posters & Demos track and in the Doctoral Consortium will be published as CEUR-WS.org proceedings volumes. CEUR-WS.org allows articles to be in HTML but, for guaranteed printability and archiving, requires an additional PDF, which should be a print-out of the HTML article in the LNCS layout."}),(0,r.jsx)("li",{children:"Articles accepted in the Industry track will be published on the conference website. The same \u201cHTML+PDF\u201d rule applies as explained above for posters, demos and doctoral papers."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Recommendations"}),(0,r.jsx)("p",{children:"We recommend that authors take the following steps independently of the general process:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Before sharing your article with ISWC, self-publish your HTML version, eg. at a repository, personal or institution website that\u2019s publicly accessible and archivable from a URL."}),(0,r.jsx)("li",{children:"Include the URL of your self-published article along the lines of: \u201cIdentifier: http://example.org/article \u201c after the list of authors and/or include the URL in the abstract of your article."}),(0,r.jsx)("li",{children:"Make sure to preserve this information in your camera-ready version."}),(0,r.jsxs)("li",{children:["Consider using a ",(0,r.jsx)("a",{href:"https://creativecommons.org/",target:"_blank",style:{color:"#e94607"},children:"Creative Commons"})," license like ",(0,r.jsx)("a",{href:"https://creativecommons.org/licenses/by/4.0/",target:"_blank",style:{color:"#e94607"},children:"CC BY 4.0"})," on the self-published version."]}),(0,r.jsxs)("li",{children:["Create multiple archived copies of the self-published version using on-demand free archive services like ",(0,r.jsx)("a",{href:"https://web.archive.org/",target:"_blank",style:{color:"#e94607"},children:"archive.org"}),", ",(0,r.jsx)("a",{href:"https://archive.is/",target:"_blank",style:{color:"#e94607"},children:"archive.is"}),"."]}),(0,r.jsxs)("li",{children:["If you intend to also publish the \u201cAuthor\u2019s Accepted Manuscript\u201d version following peer-review, note Springer\u2019s ",(0,r.jsx)("a",{href:"https://www.springernature.com/gp/open-research/policies/journal-policies",target:"_blank",style:{color:"#e94607"},children:"self-archiving policy"}),"."]}),(0,r.jsxs)("li",{children:["Send a notification about your original self-published article to the ",(0,r.jsx)("a",{href:"https://linkedresearch.org/",target:"_blank",style:{color:"#e94607"},children:"Linked Open Research Cloud"})," (LORC) to improve the discoverability of your article."]}),(0,r.jsxs)("li",{children:["For additional help, authors are welcome to ",(0,r.jsx)("a",{href:"https://gitter.im/linkedresearch/chat",target:"_blank",style:{color:"#e94607"},children:"join the public chat"})," on ",(0,r.jsx)("a",{href:"https://linkedresearch.org/",target:"_blank",style:{color:"#e94607"},children:"Linked Research"}),". Please note that this is not an official communication channel of the conference. It is an open community for scholarly communication and people passionate about the Web."]}),(0,r.jsx)("li",{children:"Authors are encouraged to use tooling and processes that work best for them."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"dokieli"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("a",{href:"https://dokie.li/",target:"_blank",style:{color:"#e94607"},children:"dokieli"})," is a client-side editor for decentralized article publishing in HTML+RDF annotations, notifications, and social interactions. It implements W3C Recommendations like ",(0,r.jsx)("a",{href:"https://www.w3.org/TR/annotation-model/",target:"_blank",style:{color:"#e94607"},children:"Web Annotation"}),", ",(0,r.jsx)("a",{href:"https://www.w3.org/TR/ldn/",target:"_blank",style:{color:"#e94607"},children:"Linked Data Notifications"}),", and ",(0,r.jsx)("a",{href:"https://www.w3.org/TR/activitypub/",target:"_blank",style:{color:"#e94607"},children:"ActivityPub"}),"."]}),(0,r.jsxs)("p",{children:["The LNCS author guidelines can be used as a template (ZIP package as expected for the submission). There is a list of ",(0,r.jsx)("a",{href:"https://github.com/linkeddata/dokieli/wiki#examples-in-the-wild",target:"_blank",style:{color:"#e94607"},children:"examples in the wild"}),"."]}),(0,r.jsxs)("p",{children:["Authors that would like to self-publish can use any HTTP server. Authors, reviewers, and readers can use their own WebID and Linked Data based personal storages, e.g., ",(0,r.jsx)("a",{href:"http://github.com/solid/node-solid-server/",target:"_blank",style:{color:"#e94607"},children:"Solid"}),", with dokieli. Join the ",(0,r.jsx)("a",{href:"https://gitter.im/linkeddata/dokieli",target:"_blank",style:{color:"#e94607"},children:"chat"})," if you need help."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"ScholarMarkdown"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("a",{href:"https://github.com/rubensworks/ScholarMarkdown",target:"_blank",style:{color:"#e94607"},children:"ScholarMarkdown"})," is a framework for writing articles in the lightweight Markdown syntax, with automatic translation into HTML+RDFa, and the option to output PDF. It provides syntactic sugar to easily perform common tasks such as citing articles, writing math equations, and more. Note: ScholarMarkdown requires ",(0,r.jsx)("a",{href:"https://www.ruby-lang.org/en/documentation/installation/",target:"_blank",style:{color:"#e94607"},children:"Ruby"})," to be installed."]}),(0,r.jsxs)("p",{children:["To get started, follow the ",(0,r.jsx)("a",{href:"https://github.com/rubensworks/ScholarMarkdown#quick-start",target:"_blank",style:{color:"#e94607"},children:"quick start guide"}),", which provides the required LNCS template in Markdown. After compiling your Markdown files to HTML, an output directory will be created. This folder contains a standalone version of your article in HTML, and this is the folder that must be submitted on EasyChair. Further details on ScholarMarkdown can be found on the ",(0,r.jsx)("a",{href:"https://github.com/rubensworks/ScholarMarkdown/wiki",target:"_blank",style:{color:"#e94607"},children:"wiki"}),"."]}),(0,r.jsxs)("p",{className:"text-md lg:text-lg font-[300]",children:["The Markdown-based source files enables straightforward versioning and collaborative editing with version-control systems such as git, and integrates nicely with automated ",(0,r.jsx)("a",{href:"https://github.com/rubensworks/ScholarMarkdown/wiki/Self-publishing",target:"_blank",style:{color:"#e94607"},children:"self-publishing via solutions such as GitHub pages"}),", as demonstrated by the ",(0,r.jsx)("a",{href:"https://github.com/rubensworks/ScholarMarkdown/wiki/Examples",target:"_blank",style:{color:"#e94607"},children:"examples in the wild"}),"."]}),(0,r.jsxs)("p",{children:["To get started, follow the ",(0,r.jsx)("a",{href:"https://github.com/rubensworks/ScholarMarkdown#quick-start",target:"_blank",style:{color:"#e94607"},children:"quick start guide"}),", which will provide you with the required LNCS template in Markdown (",(0,r.jsx)("a",{href:"https://iswc2019.semanticweb.org/files/2018/12/scholarmarkdown-template-initial-1ukmyy2.zip",target:"_blank",style:{color:"#e94607"},children:"Example of the initial template"}),"). After compiling your ",(0,r.jsx)("a",{href:"https://github.com/rubensworks/ScholarMarkdown#3-compile-your-article",target:"_blank",style:{color:"#e94607"},children:"Markdown files to HTML"}),", an output/ directory will be created (",(0,r.jsx)("a",{href:"https://iswc2019.semanticweb.org/files/2018/12/scholarmarkdown-template-compiled-10hkhxq.zip",target:"_blank",style:{color:"#e94607"},children:"Example of the compiled template"}),"). This output/folder contains a standalone version of your article in HTML, and this is the folder that must be submitted on EasyChair. Further details on ScholarMarkdown can be found on the ",(0,r.jsx)("a",{href:"https://github.com/rubensworks/ScholarMarkdown/wiki",target:"_blank",style:{color:"#e94607"},children:"wiki"}),"."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Acknowledgements"}),(0,r.jsxs)("p",{className:"text-md lg:text-lg font-[300]",children:["We would like to thank ",(0,r.jsx)("a",{href:"https://csarven.ca/#i",target:"_blank",style:{color:"#e94607"},children:"Sarven Capadisli"})," for his valuable contributions to these guidelines."]})]})]}),Rt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 tracking-wide",children:"Prior Publications and Simultaneous Submissions"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2 overflow-auto",children:[(0,r.jsx)("p",{children:"ISWC 2025 will not accept research/resource/in-use papers that, at the time of submission, are under review for or have already been published in, or accepted for publication, in a journal or another conference. Prior submissions to workshops are acceptable, provided that the authors avoid self-plagiarism, hold sufficient rights to publish overlapping content in the proceedings, and significantly extend it with 30% of novel work. The conference organizers may share information on submissions with other venues to ensure that this rule is not violated."}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("p",{children:["Depositing articles to preprint servers is allowed. However, Research Track submissions must adhere to the following policy (inspired by ",(0,r.jsx)("a",{href:"https://www.aclweb.org/adminwiki/index.php/ACL_Policies_for_Review_and_Citation",target:"_blank",style:{color:"#e94607"},children:"ACL\u2019s policy"}),"):"]}),(0,r.jsx)("div",{style:{marginBottom:"20px"}}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("em",{children:"Anonymized"})," preprints within the anonymity period are allowed. Please note that some preprint servers such as Arxiv do not support this option. "]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("em",{children:"Non-anonymized"})," preprints before the anonymity period are allowed. The anonymity period starts on April 30th, 2025 (one week before abstract submission) and ends on June 17th, 2025 (deadline review). We encourage authors to wait to post non-anonymized preprints until after the anonymity period has ended."]}),(0,r.jsxs)("li",{children:["If a ",(0,r.jsx)("em",{children:"non-anonymized"})," preprint version exists, authors should not cite it and are asked not to publicize it further during the anonymity period, as the submitted paper should be as anonymous as possible."]})]})]})]})]}),Et=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 tracking-wide",children:"Review Guidelines"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Review guidelines for ISWC 2025 Research/In-Use/Resource Tracks"}),(0,r.jsx)("p",{children:"Thank you for agreeing to review papers for ISWC 2025 and to help us form the programme!"}),(0,r.jsx)("p",{children:"Here we provide guidance on the review process. These guidelines are inspired by similar ones from SIGMOD to improve ISWC's review process for our community's benefit. The first section offers general review content guidance, and the second suggests a review structure."}),(0,r.jsxs)("p",{children:["Send feedback on this guide to ",(0,r.jsx)("a",{href:"mailto:iswc2025-research@easychair.org",style:{color:"#e94607"},children:"iswc2025-research@easychair.org"}),"."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Table of Contents"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Review Content"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Provide a detailed and constructive review"}),(0,r.jsx)("li",{children:"Be civil and polite"}),(0,r.jsx)("li",{children:"Adequately justify your recommendation"}),(0,r.jsx)("li",{children:"Do not try to de-anonymize authors"}),(0,r.jsx)("li",{children:"Be honest about your understanding of the paper"})]}),(0,r.jsx)("li",{children:"Suggested review structure"})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Review Content"}),(0,r.jsx)("p",{children:"We discuss five guidelines for reviews. We include examples of things to avoid in reviews, compared with examples of what would be better to include in a review."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-semibold mt-4",children:"Provide a detailed and constructive review"}),(0,r.jsx)("p",{children:"Please provide reviews that help the authors to improve their work, particularly in cases where your recommendation is to reject the paper. Please avoid vague, subjective, or overly-general feedback that could apply to any paper. Rather aim to provide detailed feedback that is specific to the paper under review, and indicates concrete ways in which the paper could be improved."}),(0,r.jsxs)("table",{className:"table-auto border-collapse border border-gray-400 mt-4",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{className:"border border-gray-400 px-4 py-2",children:"Examples to Avoid"}),(0,r.jsx)("th",{className:"border border-gray-400 px-4 py-2",children:"Better Examples"})]})}),(0,r.jsxs)("tbody",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe paper lacks novelty.\u201d(No justification or details provided.)"}),(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe key method described in Algorithm 1 appears to be very similar to that of Doe et al. [A], with only minor changes to the recursive aspect. The authors should clarify the novelty or relation of their method with respect to that proposed by Doe et al.\u201d"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe techniques seem trivial.\u201d(No justification or details provided.)"}),(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe proof of the key result, described in Theorem 1, involves a standard reduction from an existing result that is described, for example, in Section 4.2 of the textbook by Zoe [A].\u201d"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe paper is poorly written\u201d(No justification or details provided.)"}),(0,r.jsxs)("td",{className:"border border-gray-400 px-4 py-2",children:["\u201cI found the paper difficult to follow; for example:",(0,r.jsx)("br",{}),"\u2013 The novel concept of \u2018logical transmogrification\u2019 plays a central role in this paper, but only on page 8 is it actually discussed or defined. This left me lost for the first half of the paper. The concept should be clearly described in the introduction.",(0,r.jsx)("br",{}),"\u2013 Section 3 defines the proposed method, but provides no examples nor intuition to aid readability. Some examples would greatly improve this section\u2026.\u201d"]})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe paper is uninteresting\u201d(No justification or details provided.)"}),(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe paper proposes a method to generate pseudorandom numbers from RDF triples, but it is unclear to me what such a method is useful for. It would be helpful if the authors could highlight concrete use-cases for such a method in the introduction, along with a motivating example.\u201d"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe contributions are not clear\u201d(No justification or details provided.)"}),(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe title and introduction of the paper focus on data quality, but the techniques described and evaluated in the rest of the paper seem to apply standard OWL reasoners over the data for motivations that appear to be largely unrelated to data quality. The authors should clarify their contribution in the introduction and ensure that it reflects the content of the paper.\u201d"})]})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-semibold mt-4",children:"Be civil and polite"}),(0,r.jsx)("p",{children:"Please keep a civil tone. Though (almost) nobody sets out to be uncivil, it can be challenging to avoid indeliberately coming across as being \u201charsh\u201d in anonymous reviews. Keep in mind that you may be reviewing the papers of students who are new to research and the community, or more generally, the papers of authors who have invested a lot of time and effort into their work. Your review should be constructive. Your review should include discussions of both positive and negative aspects rather than focusing only on negatives. Your review should not be disparaging or dismissive, and should avoid unnecessarily negative language. Until proven otherwise, you should assume good faith on the part of the authors. Avoid calling into question the ethics or honesty of the authors, but rather keep your review factual. If you have an ethical concern regarding a paper, please discuss it with other PC/SPC/Chairs first to make sure there is consensus that the concern is indeed well-founded."}),(0,r.jsxs)("table",{className:"table-auto border-collapse border border-gray-400 mt-4",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{className:"border border-gray-400 px-4 py-2",children:"Examples to Avoid"}),(0,r.jsx)("th",{className:"border border-gray-400 px-4 py-2",children:"Better Examples"})]})}),(0,r.jsxs)("tbody",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe writing is terrible\u201d(Unnecessarily disparaging and dismissive. Not constructive.)"}),(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe writing contains frequent spelling mistakes and grammatical errors, making it hard to follow and review. Below I will provide some samples of these errors to illustrate the types of mistakes I hope the authors can fix for a future version.\u201d"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe authors clearly have little understanding of the area.\u201d(Unnecessarily disparaging and dismissive. Not constructive. Not justified. Speculative.)"}),(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe paper makes claims that contradict the literature, for example, that SPARQL 1.1 does not support path queries. The related works section misses some key references [A,B,C] for evaluating path queries. The authors could perhaps look into [C] as a survey of the relevant literature, if they have not seen it.\u201d"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe experiments were selected to make the authors\u2019 approach look good.\u201d(Assumes deliberate dishonesty when other possibilities have not been ruled out.)"}),(0,r.jsx)("td",{className:"border border-gray-400 px-4 py-2",children:"\u201cThe paper does not justify why the authors create a benchmark of their own queries (with few joins), nor why they did not use an existing benchmark such as proposed by Roe et al. [A]. The latter benchmark has been used in many works and includes queries with a high number of joins, for which I suspect the authors\u2019 approach will not work as well relative to the baselines. Including an external benchmark would help to examine these cases and solidify the papers\u2019 claims.\u201d"})]})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-semibold mt-4",children:"Adequately justify your recommendation"}),(0,r.jsx)("p",{children:"Please clearly relate your review comments to your recommendation. The authors do not necessarily need to agree with your recommendation, but they should at least be able to understand your rationale, and how you think they could improve their work."}),(0,r.jsx)("p",{children:"Each paper should satisfy the relevance criteria of the call, advance the area by providing significant novel insights/claims (which may include negative results), be technically correct in terms of its key contributions, be understandable and (when applicable) reproducible by someone knowledgeable and patient, and provide enough evidence to justify its key claims and conclusions. Failing (in part or whole) with respect to one of the criteria in the call for papers is potentially a valid reason to reject. Keep in mind that papers can achieve these goals without being highly technical and while leaving open questions or tasks for future work."}),(0,r.jsx)("p",{children:"In case you recommend a reject, ensure that you clearly justify the rejection \u2026"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Avoid rejecting a paper solely for infrequent minor issues that do not affect the key content of the paper, but can instead be addressed by the authors (in an obvious way) for a camera-ready version."}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"Rather make your recommendation assuming that infrequent minor issues are corrected. Make concrete suggestions on how to address these issues for a future (possibly camera-ready) version of the paper."})}),(0,r.jsx)("li",{}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"Rather base your recommendation on the proposed approach, and suggest exploring the idea for future work (if you are happy to share it)."})}),(0,r.jsx)("li",{children:"Avoid rejecting a paper solely because there is something it does not achieve."}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"Rather base your recommendation on what the paper does achieve, and whether or not that is correct, sufficient, etc. (Do, however, expect key limitations and scope to be adequately clarified.)"})}),(0,r.jsx)("li",{children:"Avoid rejecting a paper solely because there exists a benchmark or baseline not used in the experiments."}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"Rather base your recommendation on whether or not the experiments and/or proofs are sufficient to justify the key claims or conclusions of the paper, and whether or not those claims/conclusions are of importance."})}),(0,r.jsx)("li",{children:"Avoid rejecting a paper solely because the results are negative."}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"Rather base your recommendation on whether or not it advances the state-of-the-art, or offers negative results that provide novel insights on how the state-of-the-art can be advanced in future."})}),(0,r.jsx)("li",{children:"Avoid rejecting a paper solely because it is not clear how its results could be immediately put into practice."}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"Rather base your recommendation on what the community stands to learn from the paper."})}),(0,r.jsx)("li",{children:"Avoid rejecting a paper solely because it does not appear highly technical, or because the method (in hindsight) appears \u201cobvious\u201d or \u201ctrivial\u201d."}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"Rather base your recommendation on whether or not the paper provides novel ideas or insights that advance the field."})}),(0,r.jsx)("li",{children:"Avoid rejecting a paper for not meeting unrealistic, arbitrary or open-ended goals."}),(0,r.jsx)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:(0,r.jsx)("li",{children:"Rather base your recommendation on realistic and/or concrete criteria that are justified in the context of the goals of the work and the literature."})})]}),(0,r.jsx)("p",{children:"We also ask reviewers to refrain from later changing (only) their recommendation to \u201cfollow the crowd\u201d or to \u201cseek consensus\u201d, particularly when the new recommendation is no longer justified by the review text. However, if during the discussion phase with other reviewers and chairs you see something in a new light, or agree with another reviewer regarding a certain positive or negative aspect, you may of course change your recommendation, and modify your review text accordingly. We aim for real consensus on papers where the reviewers stand by their recommendations. Failing that, we prefer no consensus to an artificial consensus where recommendations are changed just for the sake of aligning them."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-semibold mt-4",children:"EXAMPLES TO FOLLOW"}),(0,r.jsx)("p",{children:"\u201cThis paper must be rejected due to having multiple typos, missing references to similar works in related areas, and bugs in Equation 1.\u201d"}),(0,r.jsx)("p",{children:"(All such issues have clear resolutions that could be easily addressed for the camera-ready version. Few specific details are provided to justify the recommendation or improve the work.)"}),(0,r.jsx)("p",{children:"\u201cFor a future version of this paper (potentially the camera-ready version, if accepted), the authors should be sure to address the following minor comments:"}),(0,r.jsx)("p",{children:"Please spell-check, e.g., \u2018qeury\u2019, \u2018frgment\u2019, etc.The authors should acknowledge similar works in relational databases, e.g., by pointing to the survey of Roe et al. [A]. In Equation 1, max should be replaced by arg max.\u201d"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"OR"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"\u201cThe paper has many grammatical errors and notational bugs that made it difficult for me to follow and review. I fear that other readers, even experts in the area, would likewise have difficulty understanding the work. For this reason I recommend a reject. Below I will provide some illustrative examples of these issues, which should be addressed for a future version\u201d"}),(0,r.jsx)("p",{children:"\u201cI am rejecting this paper because one could obviously achieve better performance in Algorithm 1 by parallelising the branches.\u201d"}),(0,r.jsx)("p",{children:"(This is speculative. It is best offered as a suggestion for future work, rather than a reason to reject. The suggestion might only be obvious after reading the paper.)"}),(0,r.jsx)("p",{children:"\u201cAs part of future work, I think it would be interesting to explore the idea of parallelising the branches in Algorithm 1, which may lead to further performance improvements.\u201d"}),(0,r.jsx)("p",{children:"\u201cOne argument for rejecting the paper is that the current approach does not support updates, which are crucial in practice.\u201d"}),(0,r.jsx)("p",{children:"(Even though updates are important and not considered, the approach could be extended in future. The justification for rejection should consider what is presented, not what is not presented.)"}),(0,r.jsx)("p",{children:"\u201cThe work achieves impressive results for the read-only case. Though a complete solution would require support for updates, the authors discuss how such features could be combined with the proposed approach in future.\u201d"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"OR"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"\u201cOne reason for rejecting the paper is that the current approach does not support updates, and there is no clear way in which the method could be extended to support updates due to the nature of the data structure proposed. The paper does not discuss this issue. While a highly-optimised read-only index might still be a useful contribution, the approach proves to be only marginally faster than baselines that do support updates.\u201d"}),(0,r.jsx)("p",{children:"\u201cThe paper does not deal with the case of cyclic graphs, and hence I recommend rejection.\u201d"}),(0,r.jsx)("p",{children:"(Even without considering the cyclic case, the results for acyclic cases might be an important contribution. The justification for rejection should consider what is presented, not what is not presented.)"}),(0,r.jsx)("p",{children:"\u201cThe paper proves a novel tractability result for the case of acyclic graphs using new techniques. This begs the question of what happens in the cyclic case, which seems an interesting direction for future research based on these results.\u201d"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"OR"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"\u201cWhile the paper proves a novel tractability result for the case of directed acyclic graphs, it is a minor extension of a similar result by Boe et al. [A] for trees, and uses the same techniques.\u201d"}),(0,r.jsx)("p",{children:"\u201cI recommend rejecting the paper as the benchmark from Doe et al. [A] is not used and the authors include only two baselines.\u201d"}),(0,r.jsx)("p",{children:"(It is not clear what the additional benchmark would add to the discussion. The baselines the reviewer wishes to see are not specified, nor why these particular baselines are specified. It is not made clear why extra baselines are needed or what they would add to the discussion. It is not clear that it would be feasible to run them. It is not clear what claims are not properly validated, but would be validated with these additional experiments.)"}),(0,r.jsx)("p",{children:"\u201cThe paper\u2019s selection of baselines and experiments, though incomplete, provides strong evidence for the claims of improved performance for path queries.\u201d"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"OR"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"\u201cI recommend a reject because the paper claims to provide superior performance versus the state of the art for SPARQL queries, with a main contribution being the optimisation of path queries. However, the benchmarks tested include very few path queries. To validate these claims, it would be necessary to include a benchmark with more (diverse) path queries, such as proposed by Poe et al. [A], in order to better understand the performance of such queries. Also, the baselines included run on disk while the proposed approach runs in memory. A fairer and stronger baseline would be to compare with the in-memory database proposed by Joe et al. [B], which is optimised for path queries, and has a code repository linked from the paper.\u201d"}),(0,r.jsx)("p",{children:"\u201cThe paper reports a precision measure of 46%, which is far too low for the approach to be applicable in practice.\u201d"}),(0,r.jsx)("p",{children:"(While this may be true, the paper may still improve upon the state of the art for a challenging and important problem. It may lead to further developments that, in turn, lead to approaches applicable in practice. Alternatively, the paper may be reporting an interesting negative result that refutes a commonly held belief/misconception within the community.)"}),(0,r.jsx)("p",{children:"\u201cThe paper reports a precision measure of 46%, which though still too low for most practical applications, is a significant improvement with respect to the state of the art on this challenging and important problem. I think that further improvements can follow from this work, and can eventually yield more precise techniques that are applicable in practice.\u201d"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"OR"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"\u201cThe paper reports a precision measure of 46%, indicating that Deep Learning methods are outperformed by much simpler classifiers for this task. This is quite a surprising negative result! The ablation study provides very useful insights into why this is the case.\u201d"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"OR"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"\u201cThe paper reports a precision measure of 46%, which is too imprecise to be useful in practice, and offers only a single percentage point improvement over the baselines tested. On the other hand, recall drops by several percentage points compared to these baselines. Given the somewhat incremental nature of the proposal, and the arguable performance improvement over the baseline method, I lean towards rejecting this paper.\u201d"}),(0,r.jsx)("p",{children:"\u201cI recommend rejecting the paper. Though the approach is new and proves effective, it is also trivial and fairly obvious. It was not difficult to come up with this approach.\u201d"}),(0,r.jsx)("p",{children:"(Exploring and reporting on \u201cobvious\u201d lines of research is important to advance the community, and often an approach that appears \u201cobvious\u201d is only so in retrospect. Such ideas that provide new insights through simplification are often crucial ideas for advancement. How easy or difficult it was to come up with the approach is subjective and speculative.)"}),(0,r.jsx)("p",{children:"\u201cThe approach is not only effective, but it is also quite natural and elegant. It is surprising that nobody has thought of this approach before, and I commend the authors for not only coming up with this idea, but evaluating and publishing it.\u201d"}),(0,r.jsx)("p",{children:"\u201cI think the paper should be rejected as discussion on related works is selective and brief. I can name around 30 to 40 references that were not discussed. Also the new benchmark that the authors created by hand only contains 10,000 examples, which is insufficient for training deep neural networks.\u201d"}),(0,r.jsx)("p",{children:"(Goals appear unrealistic. Due to space reasons, conference papers cannot reference and discuss every potentially related work. Even dedicated surveys will sometimes miss references. No specific missing references are mentioned. Creating an even larger benchmark by hand appears to demand too much of the authors. Having more than 10,000 examples is an arbitrary goal: if the authors had 20,000, would this be enough, or would the review still ask for more? What would be enough, and why?)"}),(0,r.jsx)("p",{children:"\u201cThe paper does not discuss all of the papers in the area, but rather focuses on more recent approaches to the problem using similar machine learning methods. This is understandable for space reasons, but I would recommend at least including the seminal works by Boe et al [A] and Foe et al. [B], and if space permits, works by Koe et al. [C,D] as well."}),(0,r.jsx)("p",{children:"It is commendable that the authors create a new benchmark of 10,000 examples for this problem, which is a useful contribution to the community! However, the dataset by Toe et al. [A] contains 50,000 examples, and is commonly used for training deep neural networks. If the authors\u2019 dataset could somehow be extended in future to a similar size, perhaps using a similar methodology on a crowdsourcing platform, it could replace that dataset with much higher-quality examples."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-semibold mt-4",children:"Do not try to de-anonymize authors"}),(0,r.jsxs)("p",{children:["We ask reviewers not to go out of their way to try to specifically deanonymize authors. Such examples include reviewing commit histories on repositories, looking up owners or web domains, looking up metadata in documents provided in repositories, searching for unpublished versions of the papers, etc. If the paper reveals any of the authors\u2019 identities or affiliations, or strongly hints at the same, or links to resources claimed to be theirs that are published under their authorship, this may become grounds for rejection. This may include referencing their previous publications in the first person, using examples in the paper involving their affiliation, referencing supplemental material directly from the paper that directly indicates their identity, etc. If you are unsure if something is a breach of the ",(0,r.jsx)("a",{href:"https://www.acm.org/diversity-inclusion/words-matter",target:"_blank",style:{color:"#e94607"},children:"dual anonymous"})," (i.e, both authors and reviewers are anonymous) review process, please note it in your review and discuss it with other PC/SPC/Chairs."]}),(0,r.jsx)("p",{children:"EXAMPLES TO AVOID"}),(0,r.jsx)("p",{children:"\u201cPerforming a WHOIS request on the domain of the website linked from the paper, I found out that the author is Jane Doe, whose DBLP profile suggests that she has worked in related areas. Thus I am rejecting the paper for breaching the dual anonymous policy.\u201d"}),(0,r.jsx)("p",{children:"EXAMPLE TO FOLLOW"}),(0,r.jsx)("p",{children:"(Do not do this.)"}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-semibold mt-4",children:"Be honest about your understanding of the paper"}),(0,r.jsx)("p",{children:"Of all the guidelines, this can be the hardest to follow. As much as we can try to avoid this situation, it can happen that you are assigned a paper that is a bit outside your comfort zone or area of expertise. Or you may be assigned a paper in your area that contains a large amount of technical detail you cannot verify in the time given. Please do not give up right away. Try your best to understand as much as you can of the paper, and to provide a recommendation based on what you understood. Be honest in the review text about what you understood, and what you didn\u2019t understand. It is possible that someone more expert in the area might find the paper really interesting and worthwhile. Conversely, and perhaps even more commonly, your lack of understanding might well be the paper\u2019s fault: it might be the case that the paper uses unhelpful notation, over-complicates technical detail, is poorly written, etc."}),(0,r.jsx)("p",{children:"Even if you do not have much experience in the particular sub-area, be wary of papers where you struggled to follow the motivation, overall technical ideas, and main results. These should be expressed in a manner that the broader ISWC audience can understand. Be particularly wary of papers for which other reviewers also expressed major difficulties understanding (something that can only be detected if reviewers are honest about their understanding of the paper). If the SPC or Chairs feel that a more expert review is necessary, they will solicit it (something that again depends on reviewers being honest about how much you understood)."}),(0,r.jsx)("p",{children:"If you did not fully understand a paper, please consider lowering your confidence score. When assigning the score, please take into account the following aspects:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside",children:[(0,r.jsx)("li",{children:"Your depth of understanding of the paper."}),(0,r.jsx)("li",{children:"How well you know the literature in the area."}),(0,r.jsx)("li",{children:"How certain you are about your recommendation."})]}),(0,r.jsxs)("p",{children:["Please try to be honest and fair when selecting your confidence, which is intended to be a measure of the previous three points only (and not your repute as a researcher). The scores can be interpreted as follows (",(0,r.jsx)("a",{href:"https://brenocon.com/blog/2014/02/what-the-acl-2014-review-scores-mean/",target:"_blank",style:{color:"#e94607"},children:"based on guidelines for ACL 2014"}),")."]}),(0,r.jsxs)("ul",{className:"list-disc list-inside",children:[(0,r.jsx)("li",{children:"5: (expert) Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work and have published on this topic."}),(0,r.jsx)("li",{children:"4: (high) Quite sure. I tried to check the important points carefully and am familiar with related work. It\u2019s unlikely, though conceivable, that I missed something that should affect my ratings."}),(0,r.jsx)("li",{children:"3: (medium) Pretty sure and willing to defend my evaluation, but there\u2019s a chance I missed something. Although I have a good feel for this area in general, I did not carefully check all the paper\u2019s details, e.g., the math, experimental design, or novelty."}),(0,r.jsx)("li",{children:"2: (low) It is quite probable that I missed some details, didn\u2019t understand some central points, or can\u2019t be sure about the novelty of the work, since the topic is peripheral to my own interests."}),(0,r.jsx)("li",{children:"1: (none) Not my area, or the paper is very hard to understand. My evaluation is an educated guess based on general understanding of science and scientific writing."})]}),(0,r.jsx)("p",{children:"While in an ideal world all reviews on a paper would provide genuinely expert comments and recommendations, in practice, this is quite a rare situation, even for experienced reviewers/researchers. In case of lower confidence, we encourage you to indicate in the review (or the internal comments to PC/SPC) issues relating to your understanding of the paper, your knowledge of the area, or doubts you may have about the recommendation. Such comments may be crucial for making fair decisions on which papers to accept, and which to reject."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Suggested Review Structure"}),(0,r.jsx)("p",{children:"Reviewers may develop their own style of review over time, and no individual style is \u201cbest\u201d. But if you are a relative newcomer to reviewing, and are looking for guidance on how to structure your review, consider adopting the following structure:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside",children:[(0,r.jsx)("li",{children:"Overview: Summarise the paper in your own words in a short, concise paragraph. While the authors (presumably) already know what their paper is about, this demonstrates to the authors, other reviewers, and chairs the extent to which you understood the paper, and what your personal perspective of the paper is. If you can provide a good overview, the authors will tend to value your opinion more. It is also a good exercise to ensure that you understand the paper. (In case there are parts of the paper you did not understand, clarify them here.)"}),(0,r.jsx)("li",{children:"Strengths: Summarise around three main strengths of the paper as concise bullet points. Being able to expand on the positive aspects of the paper can be encouraging to authors, and can also help them to improve their work by building upon those strengths."}),(0,r.jsx)("li",{children:"Weaknesses: Summarise around three main weaknesses of the paper as concise bullet points. You do not need to go into too much detail yet. Do not include minor issues here. Consider criteria as listed in the call and in the questions of the review form (e.g., relevance, impact, clarity, reproducibility) when preparing the list of weaknesses."}),(0,r.jsx)("li",{children:"Detailed comments: Discuss in more detail each of the weaknesses. As a guide, you could aim for a paragraph on each weakness. Relate each weakness to specific aspects in the paper. Relate them to the criteria in the call for papers, if necessary. Be constructive, polite and factual. Always try to clarify how the authors could realistically address these weaknesses, providing details. If you cannot clearly justify your reason for listing a weakness here, remove it."}),(0,r.jsx)("li",{children:"Recommendation: Explicitly state your recommendation (reject, borderline, accept, etc.). Relate your recommendation to the aforementioned strengths and weaknesses. Almost every paper, even strong ones, have weaknesses. Not all weaknesses are grounds for rejection. Some might refer to limitations that could be addressed for future work. Other weaknesses might be adequately addressed as part of the camera-ready version (e.g., being more upfront about certain limitations). In case you accept, make clear what improvements (if any) you expect for a camera ready version. In case you recommend a rejection, provide a summary of directions in which the authors could improve their work."}),(0,r.jsx)("li",{children:"Minor comments: Provide here minor comments that seem to have an easy and uncontroversial fix, such as spelling mistakes, grammatical mistakes, bugs in notation. In case such errors are frequent, you can opt to provide around three or four illustrative examples, and also list the general issue as a weakness above (e.g., if frequently poor grammar makes the paper very difficult to understand, make that a key weakness)."})]}),(0,r.jsx)("p",{children:"Please note that the ISWC 2025 review form will include an explicit section in which you can summarise the strengths and weaknesses of the paper, and justify your recommendation."})]})]}),Dt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 tracking-wide",children:"Supplemental Material Statement Guide"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Key Points:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"All papers submitted to the ISWC 2025 Research and In-Use Tracks must include a Supplemental Material Statement (even if to explain why such material cannot be published in whole or part)"}),(0,r.jsx)("li",{children:"It is expected that supplemental material is made (anonymously) available to reviewers as part of the initial submission, in anticipation of the review process, not after."}),(0,r.jsx)("li",{children:"Reviewers are not obliged to review supplemental material in detail. Papers should thus be self-contained."})]}),(0,r.jsx)("p",{children:"Please find more details below."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Reproducibility"}),(0,r.jsx)("p",{children:"Reproducibility is a key goal of scientific research, referring to the ability to independently replicate or verify the results presented in scholarly publications. In the context of computer science, providing access to supplemental material, such as code, datasets, proofs, etc., greatly facilitates reproducibility. This not only supports the independent verification of results but can also increase the impact of a work by allowing other researchers to reuse and build upon such supplemental material. An important goal for ISWC is thus to continue improving the reproducibility of all papers."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Supplemental vs. Paper Content"}),(0,r.jsx)("p",{children:"We expect all submissions to be self-contained to be self-contained, meaning that the body of the paper should provide a clear statement of their claims and clear argumentation regarding how these claims are substantiated by the results or theoretical arguments. This includes any details that are important for interpreting the results, which may include the specifications of the machines used for experiments, key statistics about datasets, important configurations or hyper-parameter settings, details about the metrics used, etc. In the case of theoretical papers, this would include proofs or sketches thereof for all theorems, lemmas, etc."}),(0,r.jsx)("p",{children:"Supplemental material then includes the resources needed to reproduce and verify the results reported in the paper that cannot feasibly be included in the paper itself. This may include source code, datasets, models, full versions of proofs, unaggregated experimental results, detailed configurations, documentation, and more besides."}),(0,r.jsx)("p",{children:"We strongly encourage authors to make supplemental material available under open licenses and in repositories that provide long-term availability (arXiv, Github, Zenodo, Figshare, etc.)."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Purpose of the Supplemental Material Statement"}),(0,r.jsx)("p",{children:"While it has become increasingly common for papers to include links to supplemental material to help verify the results they present, often this is done in an ad hoc manner that differs from paper to paper. In cases where supplemental material is not provided, it is sometimes not explicitly stated why this is the case."}),(0,r.jsx)("p",{children:"In order to make it easier for readers to find supplemental material, to understand what is provided and what is not provided, and why, we ask all authors to include a standardized Supplemental Material Statement at the end of their paper that:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside ml-6",children:[(0,r.jsx)("li",{children:"lists all supplemental resources required to reproduce or otherwise verify the results presented in the paper;"}),(0,r.jsx)("li",{children:"points to locations where those resources can be found;"}),(0,r.jsx)("li",{children:"if applicable, justifies why certain resources cannot be made available (e.g., the privacy, technical or legal concerns involved), or indicates the conditions under which they can be made available (if any);"}),(0,r.jsx)("li",{children:"if applicable, states that no supplemental material is required for reproducibility or verification."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Format of the Supplemental Material Statement"}),(0,r.jsx)("p",{children:"The Supplemental Material Statement should be placed at the end of the paper, just before the References (and before Acknowledgements, if present). It counts within the 15-page limit. It should be formatted as an inline paragraph with an italicized heading:"}),(0,r.jsx)("p",{children:"Supplemental Material Statement: Source code is available \u2026"}),(0,r.jsx)("p",{children:"In LaTeX, this can be achieved with the markup:"}),(0,r.jsx)("p",{children:"\\\\paragraph*{Supplemental Material Statement:} Source code is available \u2026"}),(0,r.jsx)("p",{children:"In Word, authors can simply replicate the formatting shown above."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Content of the Supplemental Material Statement"}),(0,r.jsx)("p",{children:"The Supplemental Material Statement should point to the location of all supplemental resources made available for the purposes of reproducing or verifying the results presented in the paper. The authors must be careful to ensure that it is clear (either from the statement, or the resource linked from the statement) what versions, configurations, dependencies, steps, etc., are needed to reproduce the results of the paper using these resources. Some example templates of statements to include are:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside ml-6",children:[(0,r.jsx)("li",{children:"Source code for our System X is available from \u2026"}),(0,r.jsx)("li",{children:"Datasets X, Y, Z are available from \u2026"}),(0,r.jsx)("li",{children:"Query sets X, Y, Z are available from \u2026"}),(0,r.jsx)("li",{children:"Full proofs of Theorems X, Y, Z can be accessed from \u2026"}),(0,r.jsx)("li",{children:"Source code for Baselines X, Y, Z is available from \u2026"}),(0,r.jsx)("li",{children:"The raw data used to generate Figure X, Y and Tables A, B are available from \u2026"})]}),(0,r.jsx)("p",{children:"Pointers to resources can be provided either directly in the text, as footnotes, or as bibliographical references; for example:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside ml-6",children:[(0,r.jsx)("li",{children:"Source code for MyRDF is available from Github.1"}),(0,r.jsx)("li",{children:"Source code for MyRDF is available from Github [1]."}),(0,r.jsx)("li",{children:"Source code for MyRDF is available from Github at https://github.com/anonauthor/MyRDF."})]}),(0,r.jsx)("p",{children:"If multiple resources are available at one location, statements can be combined, for example, to state that \u201cDatasets A, B and query sets X, Y are available from \u2026\u201d."}),(0,r.jsx)("p",{children:"In case supplemental resources are submitted via EasyChair, we ask that authors mention this, but also mention how the resources will be made available after review (without specifying a specific location). For example:"}),(0,r.jsx)("ul",{className:"list-disc list-inside ml-6",children:(0,r.jsx)("li",{children:"Full proofs of Theorem X and Y are attached with the submission in EasyChair and, if accepted, will be published on arXiv in an extended version of the paper."})}),(0,r.jsx)("p",{children:"In such cases, the authors of accepted papers are expected to update the statement accordingly for the camera-ready version."}),(0,r.jsx)("p",{children:"In case a resource cannot be published, we ask that the authors to clarify this in the statement, summarize why it cannot be published, and include details about the conditions under which the resource can be accessed (if any); for example:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside ml-6",children:[(0,r.jsx)("li",{children:"Source code for our System X cannot be made available due to plans to commercialize the software."}),(0,r.jsx)("li",{children:"Dataset X cannot be made available as it incorporates private user data. However, an anonymized version may be made available, for the sole purpose of replicating the results of this paper, upon contact with the authors."})]}),(0,r.jsx)("p",{children:"In the case of a completely self-contained work with no supplemental material (e.g., a theoretical paper with full proofs in the body of the paper), it is sufficient to write:"}),(0,r.jsx)("ul",{className:"list-disc list-inside ml-6",children:(0,r.jsx)("li",{children:"No supplemental material is required for reproducibility or verification."})}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Examples of Supplemental Material Statement"}),(0,r.jsx)("p",{children:(0,r.jsx)("b",{children:"Example 1:"})}),(0,r.jsx)("p",{children:"Supplemental Material Statement: Source code for MyRDF and the queries used in Section 4 are available from Github1. Full proofs of Theorems 1 and 2 are attached with the submission on EasyChair and, if accepted, will be published on arXiv in an extended version of the paper. The MyPublications ontology is available from Zenodo [4]. The MyHealth dataset cannot be made available as it incorporates private user data."}),(0,r.jsx)("hr",{}),(0,r.jsx)("p",{children:"1 https://github.com/anonauthor/MyRDF"}),(0,r.jsx)("p",{children:"References"}),(0,r.jsx)("p",{children:"..."}),(0,r.jsx)("p",{children:"[4] Anonymous Authors. MyPublications Dataset. Zenodo doi:10.5281/zenodo.12345678. (2022) https://doi.org/10.5281/zenodo.4035223"}),(0,r.jsx)("p",{children:"..."}),(0,r.jsx)("p",{children:(0,r.jsx)("b",{children:"Example 2:"})}),(0,r.jsx)("p",{children:"Supplemental Material Statement: No supplemental material is required for reproducibility or verification."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Review of the Supplemental Material Statement"}),(0,r.jsx)("p",{children:"Papers without a supplemental material statement may be rejected without review."}),(0,r.jsx)("p",{children:"Reviewers will be asked to review the supplemental material statement in order to verify that it does not omit discussion of any resources that would be necessary to reproduce or verify the results of the paper, that the resources are indeed available at the locations indicated, and that all reasonable efforts have been made to make all supplemental material available."}),(0,r.jsx)("p",{children:"Reviewers are not obliged to review the content of the supplemental material in detail; for this reason, it is important that the paper be self-contained. However, reviewers should be able to access the supplemental material during the review process and are welcome to make comments about the material. This means that authors must provide reviewers access to the supplemental material from the original submission. This supplemental material should not reveal the identity of the authors."}),(0,r.jsxs)("p",{children:["There are multiple ways in which supplemental material can be made available anonymously, including uploading the material to EasyChair (up to 100MB), using anonymous Github accounts, ",(0,r.jsx)("a",{href:"https://ineed.coffee/post/how-to-disclose-data-for-double-blind-review-and-make-it-archived-open-data-upon-acceptance",target:"_blank",style:{color:"#e94607"},children:"suppressing author details from Figshare or Zenodo repositories until after review"}),", etc."]})]})]}),Wt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 tracking-wide",children:"Resources Availability Statement Guide"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Key Points:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"All papers submitted to the ISWC 2025 Resources Track must include a resource availability statement. Papers without a resource availability statement may be desk rejected."}),(0,r.jsx)("li",{children:"Resources must be available along with the initial submission, in anticipation of the review process."}),(0,r.jsx)("li",{children:"Reviewers are requested to review the resource as well as the paper."}),(0,r.jsx)("li",{children:"Papers should be self-contained."})]}),(0,r.jsx)("p",{children:"Please find more details below."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Usability and Reproducibility"}),(0,r.jsx)("p",{children:"Usability of a resource as well as a clear understanding how a resource came about is a key component of progress in scientific research, to use such a resource competently in new research independently or to extend such a resource presented in scholarly publications. In the context of computer science, providing access to such material, such as ontologies, code, and datasets, greatly facilitates progress in research and reproducibility. This supports the independent verification of results, and can increase the impact of a work by allowing other researchers to reuse and build upon such resources. An important goal for ISWC is to continue improving the reproducibility of all papers, and usability and reusability of the resources described in the Resource track papers."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Resources vs. Paper Content"}),(0,r.jsx)("p",{children:"All papers submitted to the ISWC 2025 Resources Track need to  be self-contained, meaning that the body of the paper should provide a clear statement of their claims and clear argumentation regarding how these claims are substantiated by evidence. This includes any details that are important for interpreting the resource, such as the specifications of the machines used for experiments on the resource, key statistics about datasets, important configurations or hyper-parameter settings, details about the metrics used, details about how data was collected, etc."}),(0,r.jsx)("p",{children:"The resource must include the materials reported in the resources paper that cannot feasibly be included in the paper itself. Please refer to the \u201cResources of interest\u201d section of the CfP for this track for a list of categories of resources that may be suitable for this track. We strongly encourage authors to make the resource available under open licenses and in repositories that provide long-term availability and have a persistent URI (Zenodo, Figshare, institutional repository, etc.). See the \u201cAvailability\u201d section of the Resources Track CfP for details"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Purpose of the Resource Availability Statement"}),(0,r.jsx)("p",{children:"While it has become increasingly common for papers to include links to supplemental material to help verify the results they present, often this is done in an ad hoc manner that differs from paper to paper, even in Resources Track papers."}),(0,r.jsx)("p",{children:"To make it easier for readers to find the resource, to understand what is provided and what is not provided, and why, we ask all authors to include a standardized Resource Availability Statement at the end of their paper that:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside ml-6",children:[(0,r.jsx)("li",{children:"lists all resources presented in the paper;"}),(0,r.jsx)("li",{children:"points to locations where those resources can be found;"}),(0,r.jsx)("li",{children:"if applicable, justifies why certain resources cannot be made available (e.g., the privacy, technical or legal concerns involved), or indicates the conditions under which they can be made available (if any)."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Format of the Resource Availability Statement"}),(0,r.jsx)("p",{children:"The Resource Availability Statement should be placed at the end of the paper, just before the References (and before Acknowledgements, if present). It counts within the 15 page limit. It should be formatted as an inline paragraph with an italicized heading:"}),(0,r.jsx)("p",{children:"Resource Availability Statement:Source code is available \u2026"}),(0,r.jsx)("p",{children:"In LaTeX, this can be achieved with the markup:"}),(0,r.jsx)("p",{children:"\\\\paragraph*{Resource Availability Statement:} Source code is available \u2026"}),(0,r.jsx)("p",{children:"In Word, authors can simply replicate the formatting shown in the box above."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Content of Resource Availability Statements"}),(0,r.jsx)("p",{children:"The Statement should point to the location of all resources made available as presented in the paper. The authors must be careful to ensure that it is clear (either from the statement, or the resource linked from the statement) what versions, configurations, dependencies, steps, etc., are needed to use the resource. Some example templates of statements to include are:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside ml-6",children:[(0,r.jsx)("li",{children:"Source code for our System X is available from \u2026"}),(0,r.jsx)("li",{children:"Datasets X, Y, Z are available from \u2026"}),(0,r.jsx)("li",{children:"Query sets X, Y, Z are available from \u2026"}),(0,r.jsx)("li",{children:"Source code for Baselines X, Y, Z is available from \u2026"}),(0,r.jsx)("li",{children:"The raw data used to generate Figure X, Y and Tables A, B are available from \u2026"})]}),(0,r.jsx)("p",{children:"Pointers to resources can be provided either directly in the text of the statement, as footnotes, or as bibliographical references; for example:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside ml-6",children:[(0,r.jsx)("li",{children:"Source code for OurX is available from Github.1"}),(0,r.jsx)("li",{children:"Source code for OurX is available from Github [1]."}),(0,r.jsx)("li",{children:"Source code for OurX is available from Github at https://github.com/ThisIsUs/OurX."})]}),(0,r.jsx)("p",{children:"If multiple resources are available at one location, statements can be combined, for example: \u201cDatasets A, B and query sets X, Y are available from \u2026\u201d. As per CfP, resources must not be submitted via EasyChair. In the unlikely case that a resource cannot be published openly, the authors must clarify this in the statement, summarizing why it cannot be published, and include details about the conditions under which the resource can be accessed; for example:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside ml-6",children:[(0,r.jsx)("li",{children:"Source code for our System X cannot be made available due to plans to commercialize the software."}),(0,r.jsx)("li",{children:"Dataset X cannot be made available as it incorporates private user data. However, a suitably anonymized version may be made available under a licence, upon contact with the authors."})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Examples of Resource Availability Statements"}),(0,r.jsx)("p",{children:"Resource Availability Statement: Source code for OurX and the queries used in Section 4 are available from Github1. The OurOntoX ontology is available from Zenodo [4]. The MyHealth dataset cannot be made available as it incorporates private user data."}),(0,r.jsx)("hr",{}),(0,r.jsx)("p",{children:"1 https://github.com/ThisIsUs/OurX"}),(0,r.jsx)("p",{children:"References"}),(0,r.jsx)("p",{children:"..."}),(0,r.jsx)("p",{children:"[4] This, I.U. OurOntoX Ontology. Zenodo doi:10.5281/zenodo.12345678. (2022) https://doi.org/10.5281/zenodo.4035223"}),(0,r.jsx)("p",{children:"..."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Review of the Resource Availability Statement"}),(0,r.jsx)("p",{children:"Papers without a resource availability statement may be desk rejected."}),(0,r.jsx)("p",{children:"Reviewers will be asked to review the Resource Availability Statement in order to verify that it does not omit any resources that are presented as novel resources in the paper, that the resources are indeed available at the locations indicated, and that all reasonable efforts have been made to make all relevant material available."}),(0,r.jsx)("p",{children:"Reviewers are expected to review the content of the material. Nonetheless, it is important that the paper is self-contained, reporting on the resource and the context of its creation (refer to the full list of criteria in the CfP). Reviewers thus have to be able to access the resource during the review process, and are expected to make comments about the material. This means that authors must provide reviewers access to the resource from the original submission. Since this track is NOT anonymous, revealing the identity of the authors is expected."})]})]}),Mt=()=>(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("h1",{className:"text-3xl font-bold text-center text-[#e94607]",children:"Sponsorship"}),(0,r.jsxs)("div",{className:"mt-4 text-lg",children:[(0,r.jsx)("p",{children:"Sponsors will have the opportunity to reach over 400-500 experts in the fields of semantic web technologies, including researchers and industry practitioners such as developers and engineering managers. "}),(0,r.jsx)("p",{children:"We are pleased to announce five levels of sponsorship: Bronze, Silver, Gold, Platinum and Diamond. In addition, we offer several \u2018\xe0 la carte\u2019 options tailored to your company profile and needs and linked to specific aspects of the conference."})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Diamond (9.000$ / 1.400.000\xa5)"}),(0,r.jsxs)("ol",{children:[(0,r.jsx)("li",{children:"Job posting for your company on the conference website"}),(0,r.jsx)("li",{children:"Logo displayed prominently on the conference website"}),(0,r.jsx)("li",{children:"Logo displayed before keynote talks and between talks"}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Logo displayed during opening and closing sessions"})}),(0,r.jsx)("li",{children:"Acknowledgment of support in ISWC 2025 proceedings"}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Three social media posts advertising webpage (as a sponsor) between June 2025 and the conference days"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Three free registrations"})}),(0,r.jsx)("li",{children:"30-sec video/demo/talk that you provide to be played before each keynote session"}),(0,r.jsx)("li",{children:"Opportunity to be named as sponsor for the prize of one of the best paper awards at the conference (best research paper, best in-use paper, best resource, best student paper, best doctoral, best demo or poster) \u2013 priority on choosing the preferred awards (among the ones not assigned already)"}),(0,r.jsx)("li",{children:"Access to the Job Fair CV repository and a table at the Job Fair event at the conference, conditioned to enough interest for it from sponsors (and candidate)"}),(0,r.jsx)("li",{children:"Promotional banquet at the conference venue (if interested)"}),(0,r.jsx)("li",{children:"Promotional material at the conference venue"}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Sponsored industry talk at the conference (same duration of paper presentations) illustrating uses cases related to the conference topics (the topic of the talk is discussed with sponsor chairs in advance) (1\u2013page abstract submitted in advance and approved by the Program Chairs / \u201csponsored talk\u201d explicitly indicated in the program, not included in the proceedings)"})})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Platinum (6.000 $ / 930.000 \xa5)"}),(0,r.jsxs)("ol",{children:[(0,r.jsx)("li",{children:"Job posting for your company on the conference website"}),(0,r.jsx)("li",{children:"Logo displayed prominently on the conference website"}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Logo displayed before keynote talks and between talks"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Logo displayed during the opening speech"})}),(0,r.jsx)("li",{children:"Acknowledgement of support in ISWC 2025 proceedings"}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Two social media posts advertising webpage (as a sponsor) between June 2025 and the conference days"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Two free registrations"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"30-sec video/demo/talk that you provide to be played before each keynote session"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Opportunity to be named as sponsor for the prize of one of the best paper awards at the conference (best research paper, best in-use paper, best resource, best student paper, best demo or poster) \u2013 choice of award is on a first-come first-served basis."})}),(0,r.jsx)("li",{children:"Access to the Job Fair CV repository and a table at the Job Fair event at the conference, conditioned to enough interest for it from sponsors (and candidate)"}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Promotional banquet at the conference venue (if interested)"})}),(0,r.jsx)("li",{children:"Promotional material at the conference venue"})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Gold (4.000 $ / 620.000\xa5)"}),(0,r.jsxs)("ol",{children:[(0,r.jsx)("li",{children:"Job posting for your company on the conference website"}),(0,r.jsx)("li",{children:"Logo displayed prominently on the conference website"}),(0,r.jsx)("li",{children:"Logo displayed between talks"}),(0,r.jsx)("li",{children:"Acknowledgement of support in ISWC 2025 proceedings"}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"One social media post advertising webpage (as a sponsor) between June 2025 and the conference days"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Access to the Job Fair CV repository and a table at the Job Fair event at the conference, conditioned to enough interest for it from sponsors (and candidate)"})}),(0,r.jsx)("li",{children:"One free registration"}),(0,r.jsx)("li",{children:"Promotional material at the conference venue"})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Silver (2.500 $ / 390.000\xa5)"}),(0,r.jsxs)("ol",{children:[(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Job posting for your company on the conference website"})}),(0,r.jsx)("li",{children:"Logo displayed prominently on the conference website"}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Logo displayed between talks"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Acknowledgement of support in ISWC 2025 proceedings"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"One free registration"})}),(0,r.jsx)("li",{children:"Promotional material at the conference venue"})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Bronze (1.500 $ / 230.000\xa5)"}),(0,r.jsxs)("ol",{children:[(0,r.jsx)("li",{children:"Logo displayed prominently on the conference website"}),(0,r.jsx)("li",{children:"Promotional material at the conference venue"})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"\xc0 la carte Sponsorship Opportunities"}),(0,r.jsxs)("h3",{children:["Doctoral Consortium Sponsor ",(0,r.jsx)("b",{children:"[exclusive] (1.000 $ / 160.000\xa5)"})]}),(0,r.jsxs)("ol",{children:[(0,r.jsx)("li",{children:"Logo displayed prominently on the conference website"}),(0,r.jsx)("li",{children:"Acknowledgment of support in the Doctoral Consortium proceedings"})]}),(0,r.jsx)("br",{}),(0,r.jsxs)("h3",{children:["Posters and Demo Reception ",(0,r.jsx)("b",{children:"(500 $ / 80.000\xa5)"})]}),(0,r.jsxs)("ol",{children:[(0,r.jsx)("li",{children:"Banner during the event"}),(0,r.jsx)("li",{children:"Sponsor's table and chair for demos"})]})]})]}),Gt=a.p+"static/media/google_logo.08b4ebfd25145471fde1.png",Ot=a.p+"static/media/lore_star_logo.d741fd15e27954bf9003.png",Ft=a.p+"static/media/IIJ_logo.182c4db3e2395acb9d3c.jpg",zt=a.p+"static/media/metaphacts-logo-standard.9f9adbf50506174d775b.png",Kt=a.p+"static/media/JWE_River_Logo.1a485d79767aeb12f62f.jpg",qt=a.p+"static/media/swsa_logo.3f96eb5d67680db2422c.png",_t=a.p+"static/media/Videolectures_logo.cfa73b0eda9d934ddcd8.png",Ht=()=>(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("h1",{className:"text-3xl font-bold text-center text-[#e94607]",children:"Sponsors"}),(0,r.jsxs)("div",{className:"sponsor-level",children:[(0,r.jsx)("h2",{className:"text-3xl font-bold text-[#e94607]",children:"Platinum"}),(0,r.jsx)("hr",{className:"border-t-2 border-[#e94607] my-2"}),(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"metaphacts"}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("a",{href:"https://metaphacts.com/",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("img",{src:zt,alt:"metaphacts Logo",className:"logo-high-res",width:"300"})})}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"text-3xl font-bold text-[#e94607]",children:"Gold"}),(0,r.jsx)("hr",{className:"border-t-2 border-[#e94607] my-2"}),(0,r.jsxs)("div",{className:"sponsor-info mt-4",children:[(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"eBay"}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("a",{href:"https://jobs.ebayinc.com/us/en/",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("img",{src:"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/EBay_logo.svg/880px-EBay_logo.svg.png",alt:"ebay Logo",className:"logo-high-res",width:"300"})})})]}),(0,r.jsxs)("div",{className:"sponsor-info mt-4",children:[(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"Google"}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("a",{href:"https://www.google.com",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("img",{src:Gt,alt:"Google Logo",className:"logo-high-res",width:"300"})})})]}),(0,r.jsx)("h2",{className:"text-3xl font-bold text-[#e94607]",children:"Silver"}),(0,r.jsx)("hr",{className:"border-t-2 border-[#e94607] my-2"}),(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"Lore Star"}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("a",{href:"https://lorestar.it/",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("img",{src:Ot,alt:"Lore Star Logo",className:"logo-high-res",width:"300"})})}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"IIJ - Internet Initiative Japan"}),(0,r.jsx)("br",{}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("a",{href:"https://www.iij.ad.jp/en/",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("img",{src:Ft,alt:"IIJ Logo",className:"logo-high-res",width:"250"})})}),(0,r.jsx)("h2",{className:"text-3xl font-bold text-[#e94607]",children:"Student Support"}),(0,r.jsx)("hr",{className:"border-t-2 border-[#e94607] my-2"}),(0,r.jsxs)("p",{className:"text-sm mb-4",children:["Sponsored by: ",(0,r.jsx)("em",{children:"Artificial Intelligence Journal"})]}),(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"Artificial Intelligence Journal"}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("img",{src:"https://aij.ijcai.org/wp-content/uploads/2021/07/ARTINT_Logo2_c_web_more.jpg",alt:"Artificial Intelligence Journal Logo",className:"logo-high-res"})}),(0,r.jsxs)("p",{className:"text-sm mb-4",children:["Sponsored by: ",(0,r.jsx)("em",{children:"Semantic Web Science Association (SWSA)"})]}),(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"Semantic Web Science Association (SWSA)"}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("img",{src:qt,alt:"Semantic Web Science Association (SWSA) Logo",className:"logo-high-res"})}),(0,r.jsx)("h2",{className:"text-3xl font-bold text-[#e94607]",children:"Best Paper Award"}),(0,r.jsx)("hr",{className:"border-t-2 border-[#e94607] my-2"}),(0,r.jsxs)("p",{className:"text-sm mb-4",children:["Sponsored by: ",(0,r.jsx)("em",{children:"Springer"})]}),(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"Springer"}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("img",{src:"https://www.springer.com/public/images/springer-logo.svg",alt:"Springer Logo",className:"logo-high-res h-[100px]"})}),(0,r.jsx)("h2",{className:"text-3xl font-bold text-[#e94607]",children:"Best Student Paper Award"}),(0,r.jsx)("hr",{className:"border-t-2 border-[#e94607] my-2"}),(0,r.jsxs)("p",{className:"text-sm mb-4",children:["Sponsored by: ",(0,r.jsx)("em",{children:"Journal of Web Semantics"})]}),(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"Journal of Web Semantics"}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("img",{src:"https://ars.els-cdn.com/content/image/X15708268.jpg",alt:"Journal of Web Semantics Logo",className:"logo-high-res h-[300px]"})}),(0,r.jsx)("h2",{className:"text-3xl font-bold text-[#e94607]",children:"Best Resource Paper Award"}),(0,r.jsx)("hr",{className:"border-t-2 border-[#e94607] my-2"}),(0,r.jsxs)("div",{className:"sponsor-info mt-4",children:[(0,r.jsx)("a",{href:"https://journals.riverpublishers.com/index.php/JWE/index",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"River Publishers"})}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("a",{href:"https://www.linkedin.com/company/560004/admin/dashboard/",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("img",{src:Kt,alt:"Riber Publisher Logo",className:"logo-high-res",width:"300"})})})]}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"text-3xl font-bold text-[#e94607]",children:"Contributors"}),(0,r.jsx)("hr",{className:"border-t-2 border-[#e94607] my-2"}),(0,r.jsxs)("div",{className:"sponsor-info mt-4",children:[(0,r.jsx)("a",{href:"https://videolectures.net/",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("h3",{className:"text-lg font-semibold text-center",children:"Videolectures"})}),(0,r.jsx)("div",{className:"sponsor-logos flex justify-center items-center gap-8",children:(0,r.jsx)("a",{href:"https://videolectures.net/",target:"_blank",rel:"noopener noreferrer",children:(0,r.jsx)("img",{src:_t,alt:"Videolectures Logo",className:"logo-high-res",width:"300"})})})]})]})]})]}),Bt=()=>(0,r.jsx)(r.Fragment,{children:(0,r.jsxs)("div",{className:"flex justify-center items-center min-h-screen",children:[" ",(0,r.jsxs)("div",{className:"grid grid-cols-1 lg:grid-cols-8 gap-x-0 mx-2 my-10 w-full max-w-6xl",children:[" ",(0,r.jsx)("div",{className:"m-2 lg:col-span-8 flex flex-col justify-center items-center shadow-[rgba(7,_65,_210,_0.1)_0px_9px_30px]",children:(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 mt-12",children:[(0,r.jsx)("div",{className:"text-white mt-8 bg-[#e94607] w-2/3 py-2 text-center rounded-lg text-lg font-semibold transition mx-auto",children:"Important Dates"}),(0,r.jsx)("div",{className:"bg-white p-6 lg:p-12 rounded-lg shadow-md",children:(0,r.jsx)(d,{})})]})})]})]})}),Ut=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Workshops"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:"The ISWC conference serves as the premier venue for presenting groundbreaking research, innovative systems, and application results in areas such as the Semantic Web, Knowledge Graphs, and Linked Data. Each year, ISWC attracts high-quality submissions and participants from academia and industry, bringing together researchers from diverse fields including artificial intelligence, databases, natural language processing, machine learning, information systems, human-computer interaction, and web science. These experts explore and develop cutting-edge methods and technologies to enhance the way we access, interpret, and utilize information on the Web."}),(0,r.jsx)("p",{children:"Workshops at ISWC play a critical role in fostering focused, intensive scientific exchange on specific topics aligned with the conference\u2019s overarching themes. They provide a unique venue for exploring emerging ideas, discussing novel perspectives on established research, and engaging with related research communities. We encourage proposals for workshops that will inspire meaningful dialogue and collaboration among ISWC attendees, providing a platform to advance research and innovation in this dynamic field."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important dates include:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsxs)("li",{children:["Submission deadline: ",(0,r.jsx)("b",{children:"February 18, 2025"})]}),(0,r.jsxs)("li",{children:["Notification to proposers: ",(0,r.jsx)("b",{children:"March 11, 2025"})]}),(0,r.jsxs)("li",{children:["Workshop website and CfP available online: ",(0,r.jsx)("b",{children:"April 8, 2025"})]}),(0,r.jsxs)("li",{children:["Workshop program with list of accepted papers available online: ",(0,r.jsx)("b",{children:"August 29, 2025"})]}),(0,r.jsxs)("li",{children:["Workshop days: ",(0,r.jsx)("b",{children:"November 2-3, 2025"})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Workshop topics"}),(0,r.jsx)("p",{children:"We invite proposals for four types of workshops, each designed to foster innovation and collaboration within the Semantic Web and Knowledge Graph community:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Novel:"})," Workshops focused on emerging topics that are expected to gain importance in the Semantic Web and Knowledge Graph community in the coming years. Proposers should clearly articulate why the topic is becoming increasingly significant and demonstrate its potential to attract substantial submissions and participation. Proposals will be primarily evaluated based on the timeliness of the topic and its potential for future impact."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Crossover:"})," Workshops exploring the interplay and convergence between ISWC and other research communities (e.g., \u201cX meets Semantic Web/Knowledge Graphs\u201d). Proposers, ideally including representatives from both communities, must explain the relevance of connecting the two fields, outline common challenges, and highlight the value of fostering collaboration between them. Proposals will be assessed on their ability to bridge scientific communities and the value of the envisioned cross-disciplinary collaboration."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Established:"})," Workshops focusing on specific aspects of Semantic Web and Knowledge Graph research that have already demonstrated the ability to attract a significant number of submissions and participants, contributing meaningfully to scientific progress. Such proposals should justify the continuation of the workshop series, highlight its focused scope, and demonstrate its ongoing impact. Proposals will be evaluated based on the arguments for continuation and evidence of past success."]})]}),(0,r.jsx)("p",{children:"Workshop proposals of all types are encouraged to promote the vitality and innovation of the Semantic Web and Knowledge Graph community."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Review Criteria"}),(0,r.jsx)("p",{children:"Workshop proposals should focus on research topics that meet the following criteria:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"The topic aligns with the broader scope of ISWC 2025, emphasizing Semantic Web standards and technologies, knowledge representation, and graph data models as central elements."}),(0,r.jsx)("li",{children:"The proposal demonstrates a clear emphasis on a specific technology, challenge, or application area."}),(0,r.jsx)("li",{children:"The topic has the potential to engage a diverse and sufficiently broad audience, including participants beyond the typical ISWC community."}),(0,r.jsx)("li",{children:"The workshop format is dynamic, engaging, and well-suited for the intended audience. It incorporates interactive sessions beyond traditional paper presentations, such as roundtables, debates, Q&A sessions, roadmapping, or hackathons."})]}),(0,r.jsx)("p",{children:"The decision to accept or reject a workshop proposal will be based on its overall quality, relevance, and potential to appeal to a substantial portion of the Semantic Web and Knowledge Graph community. Additional considerations, such as overlap with other workshop proposals, will also influence the final decision."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Submission Guidelines"}),(0,r.jsxs)("p",{children:["Workshop proposals should be submitted via EasyChair at ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",style:{color:"#e94607"},children:"this link"}),"."]}),(0,r.jsxs)("p",{children:["Submissions must be in English and formatted as a single PDF document no longer than 4 pages, adhering to the LNCS guidelines. Detailed formatting instructions are available in ",(0,r.jsx)("a",{href:"https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines",style:{color:"#e94607"},children:"Springer\u2019s Author Instructions"}),"."]}),(0,r.jsx)("p",{children:"All workshop proposals should include the following sections:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:(0,r.jsx)("strong",{children:"Workshop Title and Acronym"})}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Workshop Type:"})," Indicate whether the workshop is novel or established."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Proposed Length:"})," Specify whether the workshop will be half-day or full-day."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Abstract:"})," Provide a concise 200-word summary describing the purpose of the workshop."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Topics:"})," Specify the topics of interest that will be covered. Proposals should focus on a specific and selective theme, more narrow than the main conference's broader scope. Proposals with significant thematic overlap with others may be merged or rejected."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Chairs:"})," Provide the names, affiliations, email addresses, homepages, and short biographies of each chair. Highlight their expertise in the workshop topic and their experience organizing relevant events. Proposals should have multiple chairs (ideally from different institutions) to ensure diverse perspectives. A maximum of five organizers is recommended, with a balance of junior and senior researchers."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Organisational Requirements:"})," List any specific equipment needed beyond standard projectors (e.g., poster stands, boards, markers). Workshop proposers are encouraged to bring their own materials if necessary, as equipment availability will be confirmed with local organizers."]})]}),(0,r.jsxs)("p",{className:"text-md lg:text-lg font-[300]",children:["For ",(0,r.jsx)("b",{children:"novel"}),", ",(0,r.jsx)("b",{children:"crossover"}),", and ",(0,r.jsx)("b",{children:"established workshops"}),", include:"]}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Workshop Format:"})," For other workshop types, describe the structure and mix of events, such as paper presentations, invited talks, panels, demos, and discussions. Innovative formats are encouraged to foster rich interactions."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Link to Challenges:"})," Indicate if the workshop proposers are also submitting to the Call for Challenges."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Review Policy:"})," Specify the review process for contributions (e.g., open review, double-anonymous, single-anonymous)."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Publication Policy:"})," Outline plans for preserving workshop outcomes, such as publishing papers in an online repository like CEUR or inviting selected papers to a journal special issue."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Program Committee:"})," Include a list of potential Program Committee members with affiliations. At least 50% of PC members should be confirmed. Diversity in gender, location, and institution is strongly encouraged, as well as efforts to include underrepresented and underserved groups."]})]}),(0,r.jsxs)("p",{children:["For ",(0,r.jsx)("b",{children:"novel"})," and ",(0,r.jsx)("b",{children:"crossover workshops"}),", include:"]}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Motivation:"}),"  Explain why the topic is timely and relevant to ISWC participants."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Audience and Community:"}),"  Identify the target audience and estimate potential attendance. Demonstrate the existence of an interested community, referencing recent papers on the workshop's topic and explaining why it would attract submissions."]})]}),(0,r.jsxs)("p",{children:["For ",(0,r.jsx)("b",{children:"established workshops"}),", include:"]}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Continuation:"})," Justify the continuation of the workshop. Highlight emerging topics, recent developments, or new challenges that make the workshop relevant."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Past Workshops:"})," Summarize the workshop series\u2019 development over the past 3\u20135 years, including quantitative data on submissions, accepted papers, and attendance."]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Requirements upon Acceptance"}),(0,r.jsx)("p",{className:"text-md lg:text-lg font-[300]",children:"Accepted workshops will need to adhere to the following requirements:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Workshop Web Page:"})," Organizers must prepare a workshop web page with a detailed call for papers (where applicable) and information about the workshop's structure, format, and timelines."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Timeline for Deadlines:"})," Organizers should adhere to the indicative timeline for internal workshop deadlines provided by ISWC. Workshops can allow for a maximum deadline extension of one week. These strict deadlines are necessary to align with the overall conference organization."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Organizational Responsibilities:"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:["Workshop organizers for novel, crossover, and established, are responsible for:",(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Conducting the reviewing process for submitted contributions (if applicable)."}),(0,r.jsx)("li",{children:"Publicizing their workshop to attract submissions and participation."}),(0,r.jsx)("li",{children:"Publishing proceedings (e.g., electronically on CEUR) for traditional workshop types."})]})]}),(0,r.jsx)("li",{children:"While ISWC workshop and local chairs will assist with local arrangements, organizers are expected to handle these responsibilities independently."})]})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Participation Requirements:"}),"At least one workshop organizer must register for the conference by the early bird registration deadline and attend the workshop in person."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Cancellation Policy:"}),"Workshops may be canceled at the discretion of the workshop and tutorial track chairs if:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"The workshop receives an insufficient number of submissions."}),(0,r.jsx)("li",{children:"Organizers fail to register by the early registration deadline."})]})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Timeline Template for Workshop Organizers"}),(0,r.jsx)("p",{children:"All workshops will adhere to a common timeline as follows (all deadlines are 23:59 AoE):"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:["Workshop website and CfP available online: ",(0,r.jsx)("b",{children:"April 8, 2025"})]}),(0,r.jsxs)("li",{children:["Workshop paper submissions: ",(0,r.jsx)("b",{children:"August 2, 2025"})]}),(0,r.jsxs)("li",{children:["Workshop paper acceptance notification and accepted papers published on website: ",(0,r.jsx)("b",{children:"August 29, 2025"})]}),(0,r.jsxs)("li",{children:["Workshop days: ",(0,r.jsx)("b",{children:"November 2-3, 2025"})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Workshop Chairs"}),(0,r.jsx)("p",{children:"Blerina Spahiu - University of Milano-Bicocca, Italy"}),(0,r.jsx)("p",{children:"Juan Sequeda - data.world, USA"}),(0,r.jsxs)("p",{children:["Contact: ",(0,r.jsx)("a",{href:"mailto:iswc2025-ws@easychair.org",style:{color:"#e94607"},children:"iswc2025-ws@easychair.org"})]})]})]})]}),Jt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Tutorials"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:"The International Semantic Web Conference 2025 is pleased to announce the Call for Tutorials. Continuing the tradition of excellence, the 2025 edition will feature a comprehensive tutorial program serving the diverse interests and expertise of our audience. These tutorials aim to provide attendees with insights into foundational and cutting-edge topics, practical applications, and the latest advancements in Semantic Web, Knowledge Graphs, and Linked Data technologies."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important Dates"}),(0,r.jsx)("p",{children:"All deadlines are 23:59 Anywhere on Earth (AoE)."}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-light",children:[(0,r.jsxs)("li",{children:["Submission deadline: ",(0,r.jsx)("b",{children:"June 3, 2025"})]}),(0,r.jsxs)("li",{children:["Notification to proposers: ",(0,r.jsx)("b",{children:"June 17, 2025"})]}),(0,r.jsxs)("li",{children:["Tutorial website online: ",(0,r.jsx)("b",{children:"July 15, 2025"})]}),(0,r.jsxs)("li",{children:["Materials available on the website (if any): ",(0,r.jsx)("b",{children:"August 8, 2025"})]}),(0,r.jsxs)("li",{children:["Tutorial days: ",(0,r.jsx)("b",{children:"November 2-3, 2025"})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Tutorial Topic and Format"}),(0,r.jsx)("p",{children:"Tutorials are an excellent opportunity for participants to expand their expertise in a subject area: for early-career researchers, they can serve as a gateway to foundational or advanced topics, particularly those tied to research methodologies and Semantic Web technologies. For experienced researchers, tutorials can provide an avenue to refine their knowledge, acquire specialized skills, or explore new methodologies that enhance their existing research areas. For industry practitioners, these sessions can offer insights and the foundational tools needed to kickstart innovative projects and applications."}),(0,r.jsx)("p",{children:"For ISWC attendees, we envision tutorials of the following types:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Tutorials introducing core concepts and established practices in Semantic Web and Knowledge Graph domains (e.g., RDF, OWL, SPARQL, SHACL, and linked data principles) or foundational research methodologies (e.g., FAIR principles, Open Science practices)."}),(0,r.jsx)("li",{children:"Tutorials exploring intersections between Semantic Web/Knowledge Graph technologies and other fields (e.g., big data, machine learning, generative AI) to examine how they complement each other and the potential for innovative applications."}),(0,r.jsx)("li",{children:"Tutorials focusing on cutting-edge trends, specific tools, or applications within the Semantic Web and Knowledge Graph space."})]}),(0,r.jsx)("p",{children:"The tutorials will be held during the pre-conference days, November 2nd and 3rd, divided into four slots each day (9:00-10:40, 11:10-12:50, 14:10-15:50, 16:20-18:00). The following formats are proposed for tutorials programs:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Half-day tutorials:"})," Two slots in either the morning or afternoon, ideal for concise, targeted introductions to a topic."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Full-day tutorials:"})," Covering all four slots with three breaks, designed for in-depth exploration of topics or interconnected themes, similar to a condensed course."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Special sessions:"})," Highly focused tutorials lasting a single slot, perfect for niche topics of significant relevance or timeliness, often led by recognized experts or authoritative figures in the field."]})]}),(0,r.jsx)("p",{children:"Tutorials should be dynamic and engaging, avoiding exclusively lecture-based formats. At least half of the session time should involve interactive elements, such as hands-on activities, group discussions, or collaborative exercises."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Review Criteria"}),(0,r.jsx)("p",{className:"text-md lg:text-lg font-light",children:"Tutorials proposals will be evaluated based on their quality and appeal to a broad segment of the Semantic Web and Knowledge Graph community. Proposals should meet the following standards:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-light",children:[(0,r.jsx)("li",{children:"The tutorial topic aligns with the general scope of the conference."}),(0,r.jsx)("li",{children:"The proposal clearly defines a specific focus on a technology, challenge, or application."}),(0,r.jsx)("li",{children:"There is compelling evidence of substantial interest within the community."}),(0,r.jsx)("li",{children:"The proposed format integrates interactive or collaborative elements."}),(0,r.jsx)("li",{children:"The tutorial fits within the broader program, offering complementary insights and avoiding significant overlap with other accepted sessions (mergers may be suggested for similar proposals)."})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Submission Instructions"}),(0,r.jsxs)("p",{children:["Tutorial proposals should be submitted via EasyChair at ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",style:{color:"#e94607"},children:"https://easychair.org/conferences/?conf=iswc2025"}),"."]}),(0,r.jsxs)("p",{children:["Submissions must be in English and formatted as a single PDF document no longer than 4 pages, adhering to the LNCS guidelines. Detailed formatting instructions are available at ",(0,r.jsx)("a",{href:"https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines",style:{color:"#e94607"},children:"Springer\u2019s Author Instructions"}),"."]}),(0,r.jsx)("p",{children:"All tutorial proposals should include the following sections:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-light",children:[(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Content, format, and program:"})}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Title and acronym:"})," Provide a concise, descriptive title and an appropriate acronym for the tutorial."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Abstract:"})," A 200-word summary highlighting the tutorial's purpose, goals, and core content."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Detailed description:"})," Include an overview of the tutorial's content, the expected learning outcomes, and a description of the presentation and interaction style (e.g., hands-on, discussion-based, lecture)."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Motivation:"})," Explain why the topic is timely and particularly relevant for ISWC participants. Address how this tutorial differentiates itself from or complements similar tutorials at other events."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Format:"})," Specify the tutorial length (full day, half day, or special session) with a clear justification for the chosen format. If proposing a full-day session, explain why a half-day format would not suffice."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Schedule:"})," Provide a detailed timeline of the tutorial program, breaking it into specific slots. Proposers are encouraged to structure the program in self-contained slots to enable participants to switch between tutorials during breaks if needed."]})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Tutorial type and intended audience:"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Type: Indicate whether the tutorial is introductory, specialized/advanced, application/tool-focused, or domain-specific."}),(0,r.jsx)("li",{children:"Level: Specify the level of the tutorial (beginner, intermediate, advanced)."}),(0,r.jsx)("li",{children:"Target Audience: Define the intended audience, including the estimated number of participants and their profiles."}),(0,r.jsx)("li",{children:"Prerequisites: Outline any prior knowledge or skills required for attendees to fully engage with the tutorial content."})]})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Presenters\u2019 information:"}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Provide the name, affiliation, email address, homepage, and a brief biography (one paragraph) for each presenter."}),(0,r.jsx)("li",{children:"Highlight each presenter\u2019s expertise in the tutorial topic, their teaching background, and prior experience with tutorials or similar events."})]})]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Materials:"}),"Describe the materials to be used during the tutorial (e.g., slides, handouts, software, online resources). Indicate when the materials will be made available and under what conditions (e.g., openly licensed, restricted to attendees, time-limited access)."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Previous editions and related events (if applicable):"}),"Provide links to previous editions of the tutorial or similar events, along with materials from those sessions. Include data such as the number of attendees and feedback received to justify the continuation of the tutorial in 2025."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Other requirements:"}),"Specify any audio-visual or technical needs, such as specific software, hardware, or internet access. Mention any special room setups or additional requirements needed to facilitate the tutorial."]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Requirements Upon Acceptance"}),(0,r.jsx)("p",{className:"text-md lg:text-lg font-light",children:"Accepted tutorials will be required to create a dedicated tutorial webpage that provides detailed information about the program and any relevant materials that participants may need to download or review prior to or during the event. The suggested timeline for setting up the webpage is outlined in the \u201cImportant dates\u201d section."}),(0,r.jsx)("p",{children:"For tutorials involving software or online services, the following guidelines are strongly recommended:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Clear prerequisites and step-by-step instructions for downloading/installing software or registering for online services should be made available on the tutorial webpage well in advance. This ensures participants have sufficient time to prepare before the tutorial begins."}),(0,r.jsx)("li",{children:"Allocate time at the beginning of the tutorial to guide participants through any necessary installation or registration processes. Organisers should not assume that all attendees will arrive fully prepared."}),(0,r.jsx)("li",{children:"Develop a contingency plan to address potential issues such as limited Wi-Fi bandwidth (e.g., providing USB drives with large files) or the unavailability of online services (e.g., pre-recorded videos of demonstrations)."})]}),(0,r.jsx)("p",{className:"text-md lg:text-lg font-light",children:"All tutorial presenters are required to register for the conference by the early bird registration deadline and attend the tutorial in person."}),(0,r.jsx)("p",{children:"The tutorial and workshop track chairs reserve the right to cancel tutorials if the organisers fail to complete the registration process in a timely manner."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Tutorial Chairs"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Blerina Spahiu"})," - University of Milano-Bicocca, Italy"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Juan Sequeda"})," - data.world, USA"]}),(0,r.jsxs)("p",{className:"text-md lg:text-lg font-light",children:["Contact: ",(0,r.jsx)("a",{href:"mailto:iswc2025-ws@easychair.org",style:{color:"#e94607"},children:"iswc2025-ws@easychair.org"})]})]})]})]}),Qt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Call for Dagstuhl Style Workshops"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("p",{children:"Inspired by the Special Session at ISWC 2024 and the Dagstuhl Seminar model, these workshops are designed to encourage in-depth discussions on challenges or emerging topics within a half-day or full-day event format. The goal is to create a collaborative and open environment for brainstorming and exploring new directions, similar to the spirit of Dagstuhl Seminars. These workshops will prioritize dynamic discussions and the presentation of fresh ideas and ongoing research, rather than requiring participants to submit papers or give formal presentations."}),(0,r.jsx)("p",{children:"Proposers should focus on assembling a diverse group of core participants who are expected to attend this workshop, including senior researchers, early-career researchers, and practitioners. The workshop will be open to all attendees of the conference. The workshop structure should enable open dialogue and interdisciplinary exchange, ensuring an optimal group size for meaningful interaction. While shorter than traditional Dagstuhl Seminars, these workshops should emulate their emphasis on fostering creativity, collaboration, and innovation in a relaxed yet focused setting. This is ultimately a WORKshop."}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Submission Guidelines"}),(0,r.jsxs)("p",{children:["Workshop proposals should be submitted via EasyChair at ",(0,r.jsx)("a",{href:"https://easychair.org/conferences/?conf=iswc2025",style:{color:"#e94607"},children:"https://easychair.org/conferences/?conf=iswc2025"}),"."]}),(0,r.jsxs)("p",{children:["Submissions must be in English and formatted as a single PDF document no longer than 4 (four) pages, adhering to the LNCS guidelines. Detailed formatting instructions are available at ",(0,r.jsx)("a",{href:"https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines",style:{color:"#e94607"},children:"Springer\u2019s Author Instructions"}),"."]}),(0,r.jsxs)("p",{children:["The Dagstuhl-style workshops proposal should include the following sections:",(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Workshop Title and Acronym"})}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Workshop Type:"})," Indicate whether the workshop is novel or established."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Proposed Length:"})," Specify whether the workshop will be half-day or full-day."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Abstract:"})," Provide a concise 200-word summary describing the purpose of the workshop."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Topics:"})," Specify the topics of interest that will be covered. Proposals should focus on a specific and selective theme, more narrow than the main conference's broader scope. Proposals with significant thematic overlap with others may be merged or rejected."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Chairs:"})," Provide the names, affiliations, email addresses, homepages, and short biographies of each chair. Highlight their expertise in the workshop topic and their experience organizing relevant events. Proposals should have multiple chairs (ideally from different institutions) to ensure diverse perspectives. A maximum of five organizers is recommended, with a balance of junior and senior researchers."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Organisational Requirements:"}),"  List any specific equipment needed beyond standard projectors (e.g., poster stands, boards, markers). Workshop proposers are encouraged to bring their own materials if necessary, as equipment availability will be confirmed with local organizers."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Motivation and Objectives:"})," Highlight the key challenges or emerging topics the workshop seeks to address. Explain the importance and timeliness of the topic for the Semantic Web, Knowledge Graph, and related communities."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Expected Results/Outcomes:"})," Explain what are the expected results and outcomes of this workshop, and how you expect to achieve them."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Workshop Format:"})," Describe the structure of the workshop. Dagstuhl-style workshops should prioritize open discussions, brainstorming, and collaborative sessions rather than formal presentations. For example, are there a set of research questions that the organizers would like to cover? Or are the topics based on position statements submitted by expected attendees? Or is this an ",(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Open_space_technology",target:"_blank",style:{color:"#e94607"},children:"Open Spaces"})," approach? Provide a tentative schedule showcasing activities like group discussions, breakout sessions, and plenary dialogues."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Target Audience and Participation:"})," Specify the intended mix of participants, including senior researchers, early-career researchers, and practitioners. Explain how diverse expertise and perspectives will contribute to the workshop\u2019s success."]})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Requirements upon Acceptance"}),(0,r.jsx)("p",{children:"Accepted Dagstuhl-style workshops, will need to adhere to the following requirements:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Workshop Web Page:"})," The page should emphasize the open, interactive format and highlight the key challenges or topics to be discussed."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Timeline for Deadlines:"})," Organizers should adhere to the indicative timeline for internal workshop deadlines provided by ISWC. Workshops can allow for a maximum deadline extension of one week. These strict deadlines are necessary to align with the overall conference organization."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Organizational Responsibilities:"})," Organizers should document outcomes through collaborative reports or summaries to share insights with the wider community."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Participation Requirements:"})," At least one workshop organizer must register for the conference by the early bird registration deadline and attend the workshop in person. Organizers are expected to play an active role in facilitating discussions and ensuring productive engagement among participants."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Cancellation Policy:"}),"  Workshops may be canceled at the discretion of the workshop and tutorial track chairs if:",(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsx)("li",{children:"Organizers fail to register by the early registration deadline."}),(0,r.jsx)("li",{children:"In the case of Dagstuhl-style workshops, cancellations may also occur if the proposed participant pool lacks sufficient diversity or representation from the intended communities."})]})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Important Dates"}),(0,r.jsx)("p",{children:"All deadlines are 23:59 Anywhere on Earth (AoE)."}),(0,r.jsxs)("ul",{className:"list-disc ml-6",children:[(0,r.jsxs)("li",{children:["Submission deadline: ",(0,r.jsx)("b",{children:"July 8, 2025"})]}),(0,r.jsxs)("li",{children:["Notification to proposers: ",(0,r.jsx)("b",{children:"July 11, 2025"})]}),(0,r.jsxs)("li",{children:["Workshop website online: ",(0,r.jsx)("b",{children:"July 25, 2025"})]}),(0,r.jsxs)("li",{children:["Workshop days: ",(0,r.jsx)("b",{children:"November 2-3, 2025"})]})]}),(0,r.jsx)("h3",{style:{color:"#e94607"},className:"text-lg font-medium mt-4",children:"Workshop Chairs"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Blerina Spahiu"})," - University of Milano-Bicocca, Italy"]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Juan Sequeda"})," - data.world, USA"]}),(0,r.jsxs)("p",{children:["Contact: ",(0,r.jsx)("a",{href:"mailto:iswc2025-ws@easychair.org",style:{color:"#e94607"},children:"iswc2025-ws@easychair.org"})]})]})]})]}),Vt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"ISWC 2025 Host: Nara, Where Ancient Japan Comes to Life"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Join Us for an Unforgettable ISWC Conference in Nara, Japan"}),(0,r.jsxs)("p",{children:["We are thrilled to welcome researchers, practitioners, and enthusiasts from around the world to the ",(0,r.jsx)("b",{children:"24th International Semantic Web Conference (ISWC 2025)"})," in Nara, Japan. As one of the leading conferences in semantic web technologies, ISWC serves as a premier platform for cutting-edge research, industry insights, and networking opportunities."]}),(0,r.jsxs)("p",{children:["This will be the third time ISWC is held in Japan, following ",(0,r.jsx)("b",{children:"ISWC 2004 in Hiroshima"})," and ",(0,r.jsx)("b",{children:"ISWC 2016 in Kobe"}),". With Japan\u2019s long-standing contributions to semantic web research and technology, hosting ",(0,r.jsx)("b",{children:"ISWC 2025 in Nara"})," offers a unique setting where tradition and innovation seamlessly merge."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Why Nara? A City of History and Innovation"}),(0,r.jsxs)("p",{children:["Nara, the ancient capital of Japan, is a city where history and innovation coexist harmoniously. The conference will take place at the ",(0,r.jsx)("a",{href:"https://www.nara-cc.jp/english/",target:"_blank",style:{color:"#e94607"},children:"Nara Prefectural Convention Center"}),", a state-of-the-art facility that opened in 2020. Centrally located in Nara City, between ",(0,r.jsx)("b",{children:"Nara Park"})," and ",(0,r.jsx)("b",{children:"Heijo Palace Site"}),", the venue is surrounded by UNESCO World Heritage sites that embody the region\u2019s deep cultural heritage."]}),(0,r.jsx)("p",{children:"Beyond its historical significance, Nara is also embracing technological advancements, making it an ideal backdrop for ISWC 2025. The city\u2019s fusion of tradition and modernity, combined with the cutting-edge facilities of the Nara Prefectural Convention Center, will provide a thought-provoking environment for discussions on the future of the semantic web."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Easy Access to the Conference Venue"}),(0,r.jsx)("p",{children:"Nara is easily accessible from major airports, ensuring a smooth journey for both international and domestic attendees."}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"From Kansai International Airport (KIX):"})," 90 minutes by airport bus, 100 minutes by train."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"From Osaka International Airport (Itami Airport - ITM):"})," 70 minutes by airport bus, 110 minutes by train."]})]}),(0,r.jsx)("p",{children:"With excellent public transportation options and direct airport connections, reaching the Nara Prefectural Convention Center is convenient and efficient. Additionally, limousine buses provide direct access from both Kansai International Airport and Osaka International Airport to the venue, further simplifying travel for attendees."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Key Attractions for Attendees"}),(0,r.jsxs)("p",{children:["While attending ISWC 2025, take the opportunity to explore ",(0,r.jsx)("b",{children:"Nara\u2019s iconic landmarks:"})]}),(0,r.jsxs)("ul",{className:"list-disc ml-16 text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Todaiji Temple & the Great Buddha"})," \u2013 One of Japan\u2019s most famous temples, home to a massive bronze Buddha statue."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Nara Park"})," \u2013 Walk among the friendly, freely roaming deer, considered sacred messengers in Japanese culture."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Kasuga Taisha Shrine"})," \u2013 A beautiful Shinto shrine renowned for its atmospheric lantern-lit pathways."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Yoshikien Garden"})," \u2013 A serene traditional garden offering a peaceful retreat."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Naramachi"})," \u2013 A historic district filled with charming old merchant houses, boutique shops, and tea houses."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Heijo Palace Ruins"})," \u2013 A site reflecting the grandeur of Nara\u2019s past as Japan\u2019s capital."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Yakushiji Temple"})," \u2013 A magnificent Buddhist temple known for its symmetrical layout and stunning pagodas, representing early Japanese architecture."]})]}),(0,r.jsxs)("p",{children:["For a deeper cultural experience, consider ",(0,r.jsx)("b",{children:"a traditional tea ceremony"})," or a visit to local artisans\u2019 workshops."]}),(0,r.jsxs)("p",{children:["For more information about Nara\u2019s attractions, visit the ",(0,r.jsx)("a",{href:"https://www.visitnara.jp/",target:"_blank",style:{color:"#e94607"},children:"Official Nara Travel Guide"}),"."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"The Perfect Getaway After the Conference"}),(0,r.jsx)("p",{children:"Extend your stay and explore more of Japan\u2019s wonders:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside text-md lg:text-lg font-[300]",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Kyoto (30 minutes from Nara)"})," \u2013 Visit the world-famous ",(0,r.jsx)("b",{children:"Kinkaku-ji (Golden Pavilion), Fushimi Inari Shrine"}),", and ",(0,r.jsx)("b",{children:"Arashiyama Bamboo Forest"}),"."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Osaka (45 minutes from Nara)"})," \u2013 Experience the vibrant nightlife, indulge in delicious street food, and visit ",(0,r.jsx)("b",{children:"Osaka Castle"}),"."]})]}),(0,r.jsx)("p",{children:"Whether you're passionate about history, technology, or simply seeking a memorable travel experience, Nara and its surroundings have something special for everyone."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Be Part of ISWC 2025 in Nara!"}),(0,r.jsxs)("p",{children:["Don\u2019t miss this opportunity to be part of ",(0,r.jsx)("b",{children:"ISWC 2025 in Nara!"})," Mark your calendars, submit your research, and get ready to engage in groundbreaking discussions in the heart of Japan\u2019s ancient capital."]}),(0,r.jsxs)("p",{children:["For more details, visit the ",(0,r.jsx)("b",{children:"official ISWC 2025 website"})," and follow us on ",(0,r.jsx)("b",{children:"social media"})," for updates. ",(0,r.jsx)("b",{children:"See you in Nara!"})]})]})]})]}),Yt=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"I am presenting my Work at ISWC - what should I expect?"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsxs)("p",{children:["The International Semantic Web Conference (ISWC 2025) opens on November 2nd in Nara, Japan. With the conference just around the corner, here\u2019s a guide to help all our ",(0,r.jsx)("b",{children:"PRESENTERS"})," and ",(0,r.jsx)("b",{children:"ORGANIZERS"})," prepare - from registration and travel to sessions, posters, demos, and more."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"\ud83d\udccc Contents"}),(0,r.jsxs)("ul",{className:"list-disc ml-10",children:[(0,r.jsx)("li",{children:"Attending"}),(0,r.jsx)("li",{children:"Workshops and Tutorials"}),(0,r.jsx)("li",{children:"Dagstuhl-Style Workshops"}),(0,r.jsx)("li",{children:"Semantic Web Challenges"}),(0,r.jsx)("li",{children:"Doctoral Consortium (DC)"}),(0,r.jsx)("li",{children:"Plenary Paper Presentations"}),(0,r.jsx)("li",{children:"Journal Sessions"}),(0,r.jsx)("li",{children:"Posters, Demos, and Minute Madness"}),(0,r.jsx)("li",{children:"Job Fair"})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Attending ISWC 2025"}),(0,r.jsx)("h3",{className:"font-semibold mt-4",children:"Registration and Travel"}),(0,r.jsxs)("p",{children:["Registration is available ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/atttending/registration",target:"_blank",children:"online"}),"."]}),(0,r.jsxs)("p",{children:["All practical information about the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/atttending/venueandaccomodation",target:"_blank",children:"venue, travel, and accommodation"})," can be found on the conference website. Attendees are encouraged to verify their ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/attending/visa",target:"_blank",children:"VISA requirements"})," for entry into Japan."]}),(0,r.jsx)("h3",{className:"font-semibold mt-4",children:"Presenting Work"}),(0,r.jsxs)("p",{children:["The full conference ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/schedule",target:"_blank",children:"schedule"})," is available online. Participants may also add the ",(0,r.jsx)("a",{href:"https://calendar.google.com/calendar/u/0/embed?src=017a4b6e9aaca94f78d8253062136e7e4fcd64c21ebfdf3555f5ddae33f7f3b9@group.calendar.google.com&ctz=Asia/Tokyo&mode=agenda&dates=20251102/20251106",target:"_blank",children:"Google Calendar"})," to their accounts. Whova details will be released soon."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Workshops and Tutorials"}),(0,r.jsxs)("p",{children:["The ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/workshops",target:"_blank",children:"workshops"})," and ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/tutorials",target:"_blank",children:"tutorials"})," are planned on the pre-conference days."]}),(0,r.jsxs)("p",{children:["You can check when yours is scheduled in the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/schedule",target:"_blank",children:"schedule"}),", but please refer to your workshop/tutorial organizers for detailed instructions about the event, as each event has its own internal design."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Dagstuhl-Style Workshops"}),(0,r.jsxs)("p",{children:["This year, ISWC will feature 4 ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/dagstuhl",target:"_blank",children:"Dagstuhl-style"})," workshops, all marked in the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/schedule",target:"_blank",children:"schedule"})," with the prefix DS."]}),(0,r.jsx)("p",{children:"Each of them will have dedicated sessions in the pre-conference days. These sessions are designed to encourage in-depth discussions on challenges or emerging topics."}),(0,r.jsx)("p",{children:"During the main conference days, each of the four workshops will have a 90-minute session open to all participants."}),(0,r.jsxs)("p",{children:["You can check when yours is scheduled ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/schedule",target:"_blank",children:"schedule"}),", but please refer to your workshop/tutorial organizers for detailed instructions about the event, as each event has its own internal design."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Semantic Web Challenges"}),(0,r.jsxs)("p",{children:["Each Semantic Web Challenge will have its own session during the pre-conference days \u2013 you can check the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/schedule",target:"_blank",children:"schedule"})," for when yours is planned, but for details of each specific event, each challenge organizer will design the session as they see fit - refer to them detailed instructions about the event."]}),(0,r.jsxs)("p",{children:["Everyone who has contributed a solution to one of the challenges will be offered a poster slot during the Poster and Demo session, ",(0,r.jsx)("b",{children:"during the main conference days"})," (Nov 4th, 18:30 local time). There will be a section dedicated to these posters, and the poster board (H1800 \xd7 W974) will have a marker \u201cSemanticWebChallenge\u201d on it."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Doctoral Consortium (DC)"}),(0,r.jsx)("p",{children:"If you are in the cohort of students selected for this event, congratulations! It will be a full-day event on Nov 3rd. Anything else that you need to know/prepare is communicated to you directly by the DC chairs. Enjoy the day and make the most of it!"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Plenary Paper Presentations"}),(0,r.jsx)("p",{children:"Each 90-minute session in the main program (marked with S1\u2026S15) will feature:"}),(0,r.jsxs)("ul",{className:"list-disc ml-10",children:[(0,r.jsx)("li",{children:"4 papers from the main tracks (Research, Resource, In-Use), with 20 minutes each (15 minutes + 5 for QA)."}),(0,r.jsx)("li",{children:"1 paper from the Industry track, with 10 minutes (7 minutes + 3 for QA)."})]}),(0,r.jsx)("p",{children:"If you are one of the presenters for an Industry Track paper, we will also offer you the possibility to display a paper during the posters and demo session. There will be a section dedicated to these posters, and the poster board (H1800 \xd7 W974) will have a marker \u201cindustry\u201d on it."}),(0,r.jsx)("p",{children:"For your reference, our 15 main sessions are the following:"}),(0,r.jsxs)("ul",{className:"list-disc ml-10",children:[(0,r.jsx)("li",{children:"S1 Benchmarks"}),(0,r.jsx)("li",{children:"S2 Analytics, Concept Learning"}),(0,r.jsx)("li",{children:"S3 Graph Completion and Link Prediction"}),(0,r.jsx)("li",{children:"S4 SHACL and Data Quality"}),(0,r.jsx)("li",{children:"S5 Entity Recognition, Alignment and Resolution"}),(0,r.jsx)("li",{children:"S6 Knowledge Integration"}),(0,r.jsx)("li",{children:"S7 Reasoning, Query Generation and Processing"}),(0,r.jsx)("li",{children:"S8 Knowledge Graphs I"}),(0,r.jsx)("li",{children:"S9 Knowledge Graphs II"}),(0,r.jsx)("li",{children:"S10 Temporal Knowledge, Explainability"}),(0,r.jsx)("li",{children:"S11 Embeddings"}),(0,r.jsx)("li",{children:"S12 Knowledge and Ontology Engineering"}),(0,r.jsx)("li",{children:"S13 RDF, Triple Stores, Semantic Technologies"}),(0,r.jsx)("li",{children:"S14 Prediction, Discovery, Interoperability"}),(0,r.jsx)("li",{children:"S15 Knowledge Graphs and LLMs"})]}),(0,r.jsxs)("p",{children:["and you can check the paper assignment and the planned timing on our ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/schedule",target:"_blank",children:"schedule"}),"."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Journal Sessions"}),(0,r.jsxs)("p",{children:["We will feature 2 journal sessions during the main conference days. Each journal session lasts 90 minutes and is marked in the ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/schedule",target:"_blank",children:"schedule"})," with the letter J."]}),(0,r.jsxs)("ul",{className:"list-disc ml-10",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"J JWS:"})," The Journal of Web Semantics (JWS) is an interdisciplinary forum at the intersection of the Semantic Web, Knowledge Graphs (KGs), and Artificial Intelligence (AI), with a strong emphasis on both theoretical and applied research. ",(0,r.jsx)("b",{children:"The session"})," will be structured as a panel of the duration of 90 minutes. The panel will be inspired by a recent special issue published by the ",(0,r.jsx)("a",{href:"https://www.sciencedirect.com/special-issue/108TVL5VQML",target:"_blank",children:"Journal of WebSemantics"}),"."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"J TGDK:"})," ",(0,r.jsx)("a",{href:"https://www.dagstuhl.de/tgdk",target:"_blank",children:"Transactions on Graph Data & Knowledge"})," is a Diamond Open Access (Diamond OA) journal published by Dagstuhl Publishing, with financial support from the Semantic Web Science Association (SWSA). ",(0,r.jsx)("b",{children:"The session"})," will start with an overview of the journal, then feature short presentations/pitches of selected papers published with TGDK by their authors. There will be some time at the end for attendees to ask questions relating to the journal, to propose ideas, etc."]})]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Posters and Demos and Minute Madness"}),(0,r.jsx)("p",{children:"The Minute Madness and the Poster and Demo session will be on Tuesday, Nov 4th, starting at 17:15 local time."}),(0,r.jsxs)("p",{children:["Note: all posters and demos have an assigned ID. These are 3-character codes starting with P or D, and they are different from the EasyChair ID. You can find your assigned ID on our website ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/acceptedpapers",target:"_blank",children:"accepted"}),"."]}),(0,r.jsx)("h3",{className:"font-semibold mt-4",children:"Minute Madness"}),(0,r.jsx)("p",{children:"As part of the Posters & Demos track, we will hold a One-Minute Madness session."}),(0,r.jsx)("p",{children:"Each accepted submission from the (Poster and Demo track only) gets exactly 60 seconds to pitch the work to the audience. This is your chance to grab attention and motivate participants to visit your poster/demo!"}),(0,r.jsx)("p",{children:"Please prepare ONE slide (no animations, videos, or transitions), with your assigned ID, title, and author(s) clearly visible."}),(0,r.jsx)("p",{children:"Please strictly use the following convention to name your file:"}),(0,r.jsx)("p",{children:(0,r.jsx)("b",{children:"AssigneID_FirstAuthorSurname.pdf or AssigneID_FirstAuthorSurname.pptx"})}),(0,r.jsxs)("p",{children:["and send it to ",(0,r.jsx)("a",{href:"mailto:iswc2025-pd@easychair.org",children:"iswc2025-pd@easychair.org"})," by Friday, 31 October."]}),(0,r.jsx)("p",{children:"Presentations will follow the order of assigned IDs, with posters first, then demos. Please line up before the session and get on stage as soon as your slide appears on the main screen."}),(0,r.jsx)("p",{children:"If you cannot present, please inform us in advance."}),(0,r.jsx)("h3",{className:"font-semibold mt-4",children:"Posters and Demos"}),(0,r.jsxs)("p",{children:["The Posters and Demos session will start immediately after the Minute Madness session. You can set up your poster/demo in the morning of the day. Your assigned ID will be attached to your poster board. Please do not remove the ID because the committee may rely on it to vote for the Best Poster and Demo Award. You can find your assigned ID online  ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/program/acceptedpapers",target:"_blank",children:"accepted"}),"."]}),(0,r.jsx)("p",{children:"For both Posters and Demos, we will provide a poster board (H1800 \xd7 W974) with pins. For each Demo paper, we will further provide a table (W1500 \xd7 D600 \xd7 H720), a power supply (500W \xd7 2), and an LCD display (around 20 inches)."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Job Fair"}),(0,r.jsx)("p",{children:"As in previous years, you can voluntarily share your CV with ISWC sponsor companies."}),(0,r.jsx)("p",{children:"Representatives from these companies will be available to chat with interested applicants during one designated coffee break of the main conference days. It will be marked in the calendar closer to the conference days."}),(0,r.jsxs)("p",{children:["To share your CV, simply complete this form ",(0,r.jsx)("a",{href:"https://docs.google.com/forms/d/e/1FAIpQLSfMm0dkh1s-tPE9g41xn0nAsm12oyDIPzEZQGqLeMOuiIWusg/viewform?usp=dialog",target:"_blank",children:"jobfair"}),", and the Job Fair Chair will ensure that eligible sponsors have access to it."]})]})]})]}),Xt=a.p+"static/media/ISWC_HEAD.216bbd0c2f633af74c3f.png",Zt=a.p+"static/media/ISWC1.547931b6dd43eade896d.png",$t=a.p+"static/media/ISWC2.34c2ee991b39badf1a73.png",ea=a.p+"static/media/ISWC3.277a346ad206040f9277.png",ta=()=>(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("img",{src:Xt,alt:"ISWC Header",className:"rounded-xl my-4"}),(0,r.jsx)("h1",{className:"font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"ISWC under the Nature Navigator lens"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("strong",{children:"Author:"})," Angelo Salatino, Research Fellow at the Knowledge Media Institute of the Open University (UK)"]}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"The International Semantic Web Conference (ISWC) is a leading annual event that brings together researchers, practitioners, and industry leaders in semantic web technologies. The conference promotes collaboration and knowledge exchange, focusing on innovative approaches to data interoperability, knowledge representation, and intelligent information retrieval. Participants discuss the development and application of semantic web standards, tools, and methodologies for integrating and utilizing diverse data sources. By showcasing cutting-edge research and practical implementations, ISWC aims to drive the advancement and adoption of the semantic web across various domains and industries, ultimately improving the way information is accessed and used in an increasingly interconnected digital world."}),(0,r.jsx)("p",{children:"To learn more about ISWC\u2019s history, we explored all the 1,564 published articles from the main track from 2002 to 2024, published in LNCS proceedings. We collected the paper DOIs and fed them into the Nature Navigator tool, developed by Springer Nature (see Appendix for further information). "}),(0,r.jsxs)("p",{children:["You can explore this research autonomously using ",(0,r.jsx)("a",{href:"https://navigator.nature.com/the-international-semantic-web-conference_2",target:"_blank",style:{color:"#e94607"},children:"Nature Navigator"})," (free access with login), but to pique your interest, here are some of the insights we found."]}),(0,r.jsx)("p",{children:"The figure below shows the distribution of publications over time. Records were registered in 2006, 2017, and 2011 with 85-86 papers. Interestingly, all three editions were held in Europe: Athens (2006), Bonn (2011), and Vienna (2017)."}),(0,r.jsx)("img",{src:Zt,alt:"Distribution of ISWC papers",className:"rounded-xl my-4"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("strong",{children:"Fig. 1. Distribution of ISWC papers in LNCS proceedings from 2002 to 2024."}),"."]}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"The conference papers were divided into six primary themes. The majority of papers fell under the Semantic Web Technologies and Applications category (762 papers, 49%), followed closely by Knowledge Graphs and Embedding Techniques (755 papers, 48%) and Ontology and Reasoning in Knowledge Bases (703 papers, 45%). A smaller but still substantial number of papers were categorized under Semantic Web and Information Retrieval (678 papers, 43%) and RDF Data and SPARQL Query Processing (541 papers, 35%). The smallest category was Semantic Web Services and Composition, with only 203 papers (13%)."}),(0,r.jsx)("p",{children:"The sum of the subtopics is higher than the total papers analysed because one paper can be classified with more than one subtopic."}),(0,r.jsx)("img",{src:$t,alt:"Main topics of ISWC",className:"rounded-xl my-4"}),(0,r.jsx)("p",{children:(0,r.jsx)("strong",{children:"Fig. 2. Main topics of ISWC and their associated papers in parenthesis. "})}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"The cumulative distribution of papers across the six highlighted themes in the following figure shows varying research trends over time. Semantic Web Technologies and Applications (purple line), Ontology and Reasoning in Knowledge Bases (blue), and Semantic Web and Information Retrieval (cyan) all showed consistent, linear growth throughout the two decades. Knowledge Graphs and Embedding Techniques (red line) grew more slowly initially but sharply increased around 2011, eventually reaching the level of the previous three themes in a shorter time frame. RDF Data and SPARQL Query Processing (yellow) followed a similar pattern to Knowledge Graphs and Embedding Techniques (red), but research in this area appears to have slowed down around 2019. Semantic Web Services and Composition (green) showed a linear increase from 2002 to 2013, then plateaued and nearly ceased."}),(0,r.jsx)("img",{src:ea,alt:"Cumulative distribution of papers",className:"rounded-xl my-4"}),(0,r.jsx)("p",{children:(0,r.jsx)("strong",{children:"Fig. 3. Cumulative distribution of papers for ISWC\u2019s six main topics."})}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"How did the papers presented at ISWC 2024 relate to the six main global trends? To investigate this, all 11 session names from the 2024 main tracks\u2013each containing 4 thematically coherent papers\u2013were selected and mapped to these six general topics (see Table below). It is worth noting that we did not force a one-to-one mapping, acknowledging that sessions could contribute to multiple topics. From the mapping, we can observe that the most addressed topic is \u201cKnowledge Graphs and Embedding Techniques\u201d, involving sessions on Data Integration, Information Extraction, and Entity Linking. It ensures Data Quality, uses Machine Learning for Graphs and Link Prediction for analysis and completion, and leverages Language Models for enhanced KG interaction and representation, often using embeddings. Interestingly, no session from ISWC 2024 addressed Semantic Web Services and Composition, confirming the claim above."}),(0,r.jsx)("div",{className:"overflow-x-auto my-6",children:(0,r.jsxs)("table",{className:"table-auto border border-gray-300 w-full",children:[(0,r.jsx)("thead",{style:{backgroundColor:"#e94607",color:"white"},children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{className:"px-4 py-2 border border-gray-300",children:"Main Topics"}),(0,r.jsxs)("th",{className:"px-4 py-2 border border-gray-300",children:[(0,r.jsx)("a",{href:"https://iswc.umbc.edu/program/schedule/",target:"_blank",style:{color:"#e94607"},children:"Main Tracks' Session Titles"})," from ISWC 2024"]})]})}),(0,r.jsxs)("tbody",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border px-4 py-2",children:"Semantic Web Technologies and Applications"}),(0,r.jsx)("td",{className:"border px-4 py-2",children:"Data Integration, Web Data, Digital Trust"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border px-4 py-2",children:"Knowledge Graphs and Embedding Techniques"}),(0,r.jsx)("td",{className:"border px-4 py-2",children:"Data Integration, Entity Linking, Information Extraction, Machine Learning for Graphs, Data Quality, Link Prediction, Language Models"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border px-4 py-2",children:"Ontology and Reasoning in Knowledge Bases"}),(0,r.jsx)("td",{className:"border px-4 py-2",children:"Ontologies, Data Quality, Link Prediction"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border px-4 py-2",children:"Semantic Web and Information Retrieval"}),(0,r.jsx)("td",{className:"border px-4 py-2",children:"Entity Linking, Information Extraction, Language Models, Web Data, Querying"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border px-4 py-2",children:"RDF Data and SPARQL Query Processing"}),(0,r.jsx)("td",{className:"border px-4 py-2",children:"Querying, Ontologies, Data Integration"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"border px-4 py-2",children:"Semantic Web Services and Composition"}),(0,r.jsx)("td",{className:"border px-4 py-2",children:"\u2013"})]})]})]})}),(0,r.jsx)("p",{children:"The data showed that 2,985 unique researchers contributed to ISWC, from 616 unique organisations across 46 countries. The largest category was Semantic Web Technologies and Applications (1,050 authors, 35%), followed by Knowledge Graphs and Embedding Techniques (838 authors, 28%). A smaller but substantial number of researchers were categorized under SPARQL Query Processing (537 authors, 18%), Ontology and Reasoning in Knowledge Bases (526 authors, 18%), and Semantic Web and Information Retrieval (453 authors, 15%), and RDF Data. The smallest number of authors (224, 8%) contributed to the Semantic Web Services and Composition category."}),(0,r.jsx)("p",{children:"The top 50 authors in terms of publication numbers across all topics represent a wide range of countries. While Germany, the UK, and the US lead the way with multiple authors, they are closely followed by China, Italy, Spain, the Netherlands, Austria, Ireland, and Switzerland."}),(0,r.jsx)("p",{children:"The top 10 institutions in terms of published papers include Karlsruhe Institute of Technology (DE), Vrije Universiteit Amsterdam (NL), University of Oxford (UK), University of Manchester (UK), Leipzig University (DE), The Open University (UK), Stanford University (US), University of Bonn (DE), University of Southampton (UK), University of Mannheim (DE)."}),(0,r.jsx)("p",{children:"Here, we have only presented general statistics, and we refrained from diving into a more detailed analysis. Feel free to use Nature Navigator to explore more advanced statistics, enabling you to further dissect the six themes into more specific topics. Additionally, you can identify the experts on those topics, track their development over time, and discover the key papers associated with them. I strongly encourage researchers who are unfamiliar with the conference to use this tool to find experts in their particular subfield and connect with them in person at the conference in Nara - you will be surprised by how welcoming the Semantic Web community is, especially towards newcomers."}),(0,r.jsx)("p",{children:"Speaking of ISWC 2025, it is hard to predict this edition\u2019s trends, although many at ISWC 2024, in Baltimore, suggested that Semantic Web technologies will increasingly contribute to AI, including GraphRAG and agents."}),(0,r.jsx)("p",{children:"Once the 2025 proceedings are published, we intend to conduct another analysis to compare them with the 2024 proceedings and reflect on the changes."}),(0,r.jsxs)("p",{children:["Explore ISWC on Nature Navigator ",(0,r.jsx)("a",{href:"https://navigator.nature.com/the-international-semantic-web-conference_2",target:"_blank",style:{color:"#e94607"},children:"here"}),"."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},children:"Appendix"}),(0,r.jsxs)("p",{children:["To create the ISWC topic within  ",(0,r.jsx)("a",{href:"https://navigator.nature.com",target:"_blank",style:{color:"#e94607"},children:"Nature Navigator"}),", we created a file containing all ISWC papers' DOIs (one per line) from 2002 to 2024. In this case, we only included the papers available in LNCS proceedings. Hence, this excludes all workshop papers, doctoral consortium, and industry track, which are usually published through alternative outlets like CEUR.ws."]}),(0,r.jsxs)("p",{children:["You can download the list of DOIs from here ",(0,r.jsx)("a",{href:"https://github.com/angelosalatino/iswc-paper-dois",target:"_blank",style:{color:"#e94607"},children:"https://github.com/angelosalatino/iswc-paper-dois"})]})]})]}),aa=a.p+"static/media/community_1.52c46154e49d4a2a33b8.png",na=a.p+"static/media/community_2.e7e7a115aa85af35e085.png",ia=a.p+"static/media/community_3.3d21b67973e4501e4f43.png",sa=a.p+"static/media/community_4.351baf281c0c09581fe1.png",ra=a.p+"static/media/community_5.ad9c01a0a534d19fd221.png",oa=a.p+"static/media/community_6.86638daccb2dcb3a79ac.png",la=a.p+"static/media/community_7.01c695b244af201c3d95.png",ca=a.p+"static/media/community_8.11713e3d9de542690cc1.jpeg",da=a.p+"static/media/community_9.63c640fea0809ddd2396.jpeg",ha=a.p+"static/media/community_10.1ee0a184ac658c235a1a.png",ua=a.p+"static/media/community_11.3205c8b7721e29520625.png",pa=a.p+"static/media/community_12.e9f5784fd1e28fee5172.jpeg",ma=a.p+"static/media/community_13.adc26e26c7749508dcc7.jpeg",ga=a.p+"static/media/community_14.a59c6178fb78527657d4.jpeg",fa=a.p+"static/media/community_15.0fc2600e4e0589f8fa57.jpeg",ba=a.p+"static/media/community_16.c9f3a1858354afdaf4d1.png",ya=a.p+"static/media/community_17.68e24f946bf8b6104d9a.png",xa=a.p+"static/media/community_18.131d13e3f71b343d8872.jpeg",va=a.p+"static/media/community_19.ded8a51fed7ffccad1dc.jpeg",wa=a.p+"static/media/community_20.0dec997558bf0b3e28fe.jpeg",ja=a.p+"static/media/community_21.a30cceca149fc4581fac.jpeg",ka=a.p+"static/media/community_22.f89a35833710139904da.jpeg",Sa=a.p+"static/media/community_23.2137f1df1c3248893a84.png",Na=a.p+"static/media/community_24.c17d0be855b86255381b.png",Ca=a.p+"static/media/community_25.7e80524e36ac91cbae04.jpeg",Ta=a.p+"static/media/community_26.f9d05b9f1cecfb7baabf.jpeg",Aa=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"A community that fosters meaningful connections"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsxs)("p",{children:["Over the years, ",(0,r.jsx)("b",{children:"ISWC (International Semantic Web Conference)"})," has brought together a vibrant, global community of researchers, developers, and enthusiasts passionate about the Semantic Web. More than just a venue for academic exchange, ISWC has fostered countless collaborations, sparked innovative ideas, and built lasting friendships."]}),(0,r.jsx)("p",{children:"Beyond the technical sessions and paper presentations, ISWC is also known for its unforgettable social events - scenic excursions, lively banquets, and moments of fun that bring the community closer together. From shared laughter during excursions to memorable evenings at conference dinners, these experiences have become just as meaningful as the research itself."}),(0,r.jsx)("p",{children:"In this post, we take a moment to look back through the eyes of past attendees - who have generously shared their memories, photos, and reflections. Their stories capture the energy, camaraderie, and spirit that make ISWC a highlight of the year for so many in the Semantic Web community."}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex items-center gap-4",children:[(0,r.jsx)("div",{className:"w-24 h-24 overflow-hidden",children:(0,r.jsx)("img",{src:aa,alt:"Anna Lisa Gentile",className:"object-cover w-full h-full"})}),(0,r.jsxs)("p",{className:"text-lg font-semibold",children:["Anna Lisa Gentile"," ",(0,r.jsx)("span",{className:"font-normal italic text-gray-600",children:"\u2013 Senior Research Scientist, IBM Research, US"})]})]}),(0,r.jsx)("p",{children:"I\u2019ve been attending ISWC for nearly 15 years now."}),(0,r.jsx)("p",{children:"I can't help but smile at all the fantastic memories. Sure, the scientific sessions have always been great, and I still remember nervously presenting my paper in Sydney in 2013, with lots of the scientists I admire in the audience. But what makes ISWC unforgettable for me are all the connections I made. ISWC has been so much more than just talks and presentations year after year - there are always fun activities that bring people together."}),(0,r.jsx)("p",{children:"One of my most memorable ISWC events is the Bike Ride from my IBM office in San Jose, California, to the conference venue of ISWC 2018 in Monterey. Together with 13 other fellow ISWC-ers, we rode for two days, even stopping for a jump in the sea in Santa Cruz. Unforgettable! "}),(0,r.jsx)("img",{src:na,alt:"Group Picture",className:"rounded-xl my-4"}),(0,r.jsx)("img",{src:ia,alt:"Group Picture",className:"rounded-xl my-4"}),(0,r.jsx)("img",{src:sa,alt:"Group Picture",className:"rounded-xl my-4"}),(0,r.jsx)("img",{src:ra,alt:"Group Picture",className:"rounded-xl my-4"}),(0,r.jsxs)("p",{children:["Another event close to my heart is the ",(0,r.jsx)("a",{href:"http://iswc2018.semanticweb.org/ada-lovelace-celebration/index.html",target:"_blank",style:{color:"#e94607"},children:" ISWC Ada Lovelace Day celebration"}),". To honor the achievements of our Semantic Web women, we organized a Wikipedia edit-a-thon to create pages for those in our community who didn't have a page yet \u2013 we proudly added a few during the event, including ",(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Natasha_Noy",style:{color:"#e94607"},target:"_blank",children:"Natasha Noy"})," and ",(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Lora_Aroyo",style:{color:"#e94607"},target:"_blank",children:"Lora Aroyo"}),"."]}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex items-center justify-end p-0 m-0 w-full",children:[(0,r.jsxs)("div",{className:"text-right text-lg font-semibold leading-snug",children:["Sabrina Kirrane"," ",(0,r.jsx)("span",{className:"font-normal italic text-gray-600",children:"\u2013 Associate Professor, Institute for Complex Networks, Vienna University of Economics and Business, Austria"})]}),(0,r.jsx)("div",{className:"w-24 h-24 overflow-hidden flex-shrink-0 ml-2",children:(0,r.jsx)("img",{src:oa,alt:"Sabrina Kirrane",className:"object-cover w-full h-full block"})})]}),(0,r.jsx)("p",{className:"text-right",children:"My first organizing committee role was sponsorship co-chair for ISWC 2017 in Vienna. Anyone who has taken on this role will tell you it\u2019s not an easy job. The highlight for me was the jam session on the first day of the conference. The entire Texan-themed evening, including cowboy hats and a cocktail bar, was kindly sponsored by data.world. The turnout was fantastic, our ISWC musicians and singers were amazing, and the atmosphere was simply electric! "}),(0,r.jsx)("p",{lassName:"text-right",children:"Since then I\u2019ve co-organized the doctoral consortium in 2018, co-coordinated the workshops and tutorials in 2020, and co-chaired the panel in 2024. Each role was a learning opportunity where I was presented with different challenges and opportunities. I very much appreciate the significant impact these roles and the various individuals I have interacted with along the way have played in my own academic journey. It really is a true honor to take on the research track co-chair role for 2025!"}),(0,r.jsx)("img",{src:la,alt:"Group Picture",className:"rounded-xl my-4 h-[500px]"}),(0,r.jsx)("img",{src:ca,alt:"Group Picture",className:"rounded-xl my-4 h-[500px]"}),(0,r.jsx)("img",{src:da,alt:"Group Picture",className:"rounded-xl my-4 h-[500px]"}),(0,r.jsx)("img",{src:ha,alt:"Group Picture",className:"rounded-xl my-4 h-[500px]"}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex items-center gap-4",children:[(0,r.jsx)("div",{className:"w-24 h-24 overflow-hidden",children:(0,r.jsx)("img",{src:ua,alt:"Cogan Shimizu",className:"object-cover w-full h-full"})}),(0,r.jsxs)("p",{className:"text-lg font-semibold",children:["Cogan Shimizu"," ",(0,r.jsx)("span",{className:"font-normal italic text-gray-600",children:"\u2013 Assistant Professor at Wright State University in the Department of Computer Science & Engineering, USA"})]})]}),(0,r.jsx)("p",{children:"I started my ISWC journey in 2017 (Vienna), where I presented my first paper ever at the Workshop on Ontology Design and Patterns. I\u2019m in the red \u2013 all the way to the right. I have distinctly fond memories of the experience, but most importantly, I learned \u2013 and experienced \u2013 how incredibly welcoming the community was. Indeed, Axel Polleres picked me out of the random Vienna crowd to get me to the right buildings (if I remember correctly the main conference was held in a different place than the workshops, and I missed that memo)."}),(0,r.jsx)("img",{src:pa,alt:"Group Picture",className:"rounded-xl my-4"}),(0,r.jsx)("p",{children:"Over the years since then, I\u2019ve tried to attend as much as possible, either to present my research or stay engaged with the community, as well as the cohorts of DaSe Lab members that came before and after me, and culminating in three generations of PhD students (DaSe Lab, KASTLE Lab, and KRACR Lab) at ISWC 2024 in Baltimore!"}),(0,r.jsx)("img",{src:ma,alt:"Group Picture",className:"rounded-xl my-4"}),(0,r.jsx)("p",{children:"Monterey \u2013 Cogan Shimizu, Michelle Cheatham, MD Sarker, Lu Zhou"}),(0,r.jsxs)("div",{className:"flex flex-col gap-8 w-full",children:[(0,r.jsxs)("div",{className:"flex w-full",children:[(0,r.jsxs)("div",{className:"w-1/2 flex flex-col items-center",children:[(0,r.jsx)("div",{className:"w-full h-[500px] overflow-hidden",children:(0,r.jsx)("img",{src:ga,alt:"Auckland group",className:"w-full h-full object-cover rounded-xl"})}),(0,r.jsx)("p",{className:"text-center text-sm mt-2 px-4",children:"Auckland, with previous DaSe graduates (Adila Krisnadhi, left; Raghava Mutharaju, right)."})]}),(0,r.jsxs)("div",{className:"w-1/2 flex flex-col items-center",children:[(0,r.jsx)("div",{className:"w-full h-[500px] overflow-hidden",children:(0,r.jsx)("img",{src:fa,alt:"Athens group",className:"w-full h-full object-cover rounded-xl"})}),(0,r.jsx)("p",{className:"text-center text-sm mt-2 px-4",children:"Athens \u2013 Raghava Mutharaju, Saeid Mahdavinejad, Cogan Shimizu"})]})]}),(0,r.jsxs)("div",{className:"w-full",children:[(0,r.jsx)("div",{className:"w-full h-[700px] overflow-hidden",children:(0,r.jsx)("img",{src:ba,alt:"ISWC 2024 group",className:"w-full h-full object-cover rounded-xl"})}),(0,r.jsx)("p",{className:"text-center text-sm mt-2 px-4",children:"Members of the Data Semantics Laboratory, KONKORDANT Laboratory, KRACR Lab, and KASTLE Lab \u2013 a growing cohort (and three generations) of knowledge engineering research, connecting at ISWC 2024!"})]})]}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex items-center justify-end p-0 m-0 w-full",children:[(0,r.jsxs)("div",{className:"text-right text-lg font-semibold leading-snug",children:["Blerina Spahiu"," ",(0,r.jsx)("span",{className:"font-normal italic text-gray-600",children:"\u2013 Associate Professor, Bicocca University, Italy"})]}),(0,r.jsx)("div",{className:"w-24 h-24 overflow-hidden flex-shrink-0 ml-2",children:(0,r.jsx)("img",{src:ya,alt:"Blerina Spahiu",className:"object-cover w-full h-full block"})})]}),(0,r.jsx)("p",{className:"text-right",children:"I\u2019ll never forget my first ISWC back in 2015. I was a PhD student at the time, and it was held in Pennsylvania, USA. It was also the first time I got to experience the Semantic Web community in person. I was honestly a bit nervous going in. You know, stepping into a big international conference as a newbie can feel overwhelming. But the community? So warm, so welcoming. People were kind, open, and genuinely excited to connect and share ideas. It didn\u2019t take long before I felt right at home. And the social event? An absolute blast! It was full of laughter, dancing, and just pure fun. I remember thinking, \u201cWow, this field isn\u2019t just intellectually exciting! It\u2019s also full of really awesome people.\u201d"}),(0,r.jsx)("div",{className:"w-full flex justify-end",children:(0,r.jsx)("div",{className:"w-[900px] overflow-hidden",children:(0,r.jsx)("img",{src:xa,alt:"Group Picture",className:"w-full h-full object-cover rounded-xl"})})}),(0,r.jsx)("br",{}),(0,r.jsx)("div",{className:"w-full flex justify-end",children:(0,r.jsx)("div",{className:"w-[400px] overflow-hidden",children:(0,r.jsx)("img",{src:va,alt:"Group Picture",className:"w-full h-full object-cover rounded-xl"})})}),(0,r.jsx)("p",{className:"text-right",children:"That first ISWC still holds a special place in my heart. It wasn\u2019t just a conference, it was the moment I truly felt part of the community. ISWC 2018, held in beautiful Monterey, California, holds a very special place in my heart. It was one of those conferences where everything felt just right\u2014the venue, the energy, the talks, the ocean breeze just outside the sessions. "}),(0,r.jsx)("div",{className:"flex flex-col gap-8 w-full",children:(0,r.jsxs)("div",{className:"flex w-full",children:[(0,r.jsx)("div",{className:"w-1/2 flex flex-col items-center",children:(0,r.jsx)("div",{className:"w-full h-[500px] overflow-hidden",children:(0,r.jsx)("img",{src:wa,alt:"Auckland group",className:"w-full h-full object-cover rounded-xl"})})}),(0,r.jsx)("div",{className:"w-1/2 flex flex-col items-center",children:(0,r.jsx)("div",{className:"w-full h-[500px] overflow-hidden",children:(0,r.jsx)("img",{src:ja,alt:"Athens group",className:"w-full h-full object-cover rounded-xl"})})})]})}),(0,r.jsx)("p",{className:"text-right",children:"But more than that, it was the people who made it unforgettable. We shared laughs over coffee breaks, inspiring conversations during the sessions, and quiet reflections during walks by the shore."}),(0,r.jsx)("p",{className:"text-right",children:"Looking back now, I cherish those moments more than ever. It reminds me that conferences are not only about research and papers but about the human connections that form around them."}),(0,r.jsx)("div",{className:"w-full flex justify-end",children:(0,r.jsx)("div",{className:"w-[500px] overflow-hidden",children:(0,r.jsx)("img",{src:ka,alt:"Group Picture",className:"w-full h-full object-cover rounded-xl"})})}),(0,r.jsx)("p",{className:"text-right",children:"Blerina Spahiu, Anisa Rula, Amrapali Zaveri (RIP) at the Monterey Aquarium for the social dinner at ISWC 2018."}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex items-center gap-4",children:[(0,r.jsx)("div",{className:"w-24 h-24 overflow-hidden",children:(0,r.jsx)("img",{src:Sa,alt:"Juan Sequeda",className:"object-cover w-full h-full"})}),(0,r.jsxs)("p",{className:"text-lg font-semibold",children:["Juan Sequeda"," ",(0,r.jsx)("span",{className:"font-normal italic text-gray-600",children:"\u2013 Principal Scientist & Head of AI Lab at data.world, USA. A co-host of Catalog & Cocktails."})]})]}),(0,r.jsx)("p",{children:"ISWC has been my academic home since the beginning of my Ph.D. I attended my first conference in 2008 in Karlsruhe and since then, I\u2019ve only missed the one in Shanghai. It\u2019s a uniquely eclectic and diverse community\u2014intellectually, scientifically, and in terms of its people."}),(0,r.jsx)("p",{children:"At that first 2008 conference, I attended a tutorial on Linked Data, and in the final 10 minutes, a student gave the coolest part of that tutorial. That student was Olaf Hartig and since then we\u2019ve been best friends. I also gave a poster presentation on the early work I had just started in my Ph.D. Later, I learned that someone who visited my poster remembered me years afterward\u2014Professor George Fletcher. Nearly 10 years later, we ended up collaborating on various projects. He first met me at that poster, and that memory stayed with him. This is why I\u2019m such a strong advocate for poster sessions\u2014they\u2019re a powerful way to share your ideas, test your elevator pitch, and engage with a wide variety of people in a short time."}),(0,r.jsx)("p",{children:"Another memorable moment was in 2014 in Riva del Garda, when I was nominated for the Best Paper Award. One of the selection criteria involved how well the paper was presented, so I focused intensely on my presentation. I practiced and even asked professors at the conference to review my slides and give me feedback. Their insights helped me polish my talk, and I believe that played a big role in winning the award."}),(0,r.jsx)("p",{children:"The social side of this conference is also incredibly special. After the 2015 conference in Bethlehem, Pennsylvania, I celebrated my 30th birthday by going to New York City with close friends from the community for several days of celebrations. Another standout memory is the boat party during the 2013 conference in Sydney with the band formed by our colleagues. We then ended up dancing salsa in the harbor till early morning. "}),(0,r.jsx)("p",{children:"All of this highlights a central truth: science is a social process. The Semantic Web community has become not only my scientific and professional network but also a close-knit group of friends. Among all the conferences I attend, this is one of the most lively and meaningful."}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex items-center justify-end p-0 m-0 w-full",children:[(0,r.jsxs)("div",{className:"text-right text-lg font-semibold leading-snug",children:["Gong Cheng"," ",(0,r.jsx)("span",{className:"font-normal italic text-gray-600",children:"\u2013 professor at the School of Computer Science, Nanjing University, China"})]}),(0,r.jsx)("div",{className:"w-24 h-24 overflow-hidden flex-shrink-0 ml-2",children:(0,r.jsx)("img",{src:Na,alt:"Gong Cheng",className:"object-cover w-full h-full block"})})]}),(0,r.jsx)("p",{className:"text-right",children:"The year 2019 remains unforgettable to me\u2014not just for the thrill of my first bungee jumping experience in the Southern Hemisphere, but also for marking my debut as a member of the ISWC organizing committee. The Posters & Demos session has always been my favorite conference highlight, with its vibrant mix of relaxed atmosphere, diverse presentations, and engaging interactions. Let\u2019s work together to make this session another success in 2025, this time in the world\u2019s other hemisphere!"}),(0,r.jsx)("div",{className:"w-full flex justify-end",children:(0,r.jsx)("div",{className:"w-[700px] overflow-hidden",children:(0,r.jsx)("img",{src:Ca,alt:"Group Picture",className:"w-full h-full object-cover rounded-xl"})})}),(0,r.jsx)("br",{}),(0,r.jsx)("div",{className:"w-full flex justify-end",children:(0,r.jsx)("div",{className:"w-[700px] overflow-hidden",children:(0,r.jsx)("img",{src:Ta,alt:"Group Picture",className:"w-full h-full object-cover rounded-xl"})})}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Thank You to Our Storytellers!"}),(0,r.jsx)("p",{children:"A heartfelt thank you to everyone who shared their ISWC memories and photos for this post. Your stories not only highlight the richness of the ISWC experience but also help preserve the spirit of the community for years to come. We are grateful for your time, reflections, and the glimpse into what makes ISWC meaningful to each of you."}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Your Turn to Make Memories \u2013 Onward to ISWC 2025!"}),(0,r.jsx)("p",{children:"As we look ahead to ISWC 2025, these shared memories remind us what makes this conference truly special - not just the cutting-edge research, but the people, the connections, and the moments that span continents and careers. Whether you are presenting a paper, diving into a workshop, or simply exploring new ideas, ISWC offers a unique space to grow, collaborate, and be inspired."}),(0,r.jsx)("p",{children:"Let these reflections from past years be your invitation to fully engage with everything ISWC has to offer. Say hello to someone new, join that excursion, attend that social event, ask that question - because often, the most memorable moments happen beyond the slides."}),(0,r.jsxs)("p",{children:["We can\u2019t wait to see the memories you\u2019ll create at ",(0,r.jsx)("b",{children:"ISWC 2025!"})]})]})]})]}),La=()=>(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("h1",{className:"text-3xl font-bold text-center text-[#e94607]",children:"VISA Information"}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Exemption of Visa (Short-Term Stay)"}),(0,r.jsxs)("div",{className:"mt-4 text-lg",children:[(0,r.jsx)("p",{children:"Nationals of certain countries and regions are exempt from obtaining a visa for short-term stays in Japan. The list of exempt countries and further details on visa exemptions can be found on the official website of the Ministry of Foreign Affairs of Japan:"}),(0,r.jsx)("ul",{className:"ul-disc lg:text-lg",children:(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://www.mofa.go.jp/j_info/visit/visa/short/novisa.html",children:"Visa Exemptions for Short-Term Stay"})})}),(0,r.jsx)("p",{children:"If your country is not listed under the visa exemption agreement, or if you are unsure about your visa requirements, please check with your nearest Japanese embassy or consulate."})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Visa Application Information for ISWC2025 Participants"}),(0,r.jsxs)("div",{className:"mt-4 text-lg",children:[(0,r.jsx)("p",{children:"Visa support letters will only be issued to:"}),(0,r.jsxs)("ol",{children:[(0,r.jsxs)("li",{children:["Individuals known to the organization (notification from a member of ",(0,r.jsx)("a",{href:"https://iswc2025.semanticweb.org/#/organizing_committee",children:"the organizing committee"})," is required)."]}),(0,r.jsx)("li",{children:"Speakers or presenters at the conference."}),(0,r.jsx)("li",{children:"Committee members."}),(0,r.jsx)("li",{children:"Attendees who have paid the full registration fee."})]}),(0,r.jsx)("p",{children:"For attendees in the fourth category, we may request additional documents and/or certificates to verify the provided information and assess whether the applicant is expected to attend the scientific and technical conference. If we are not confident in the validity of the provided information or the likelihood of attendance, we will not issue an invitation letter."})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Visa Application Information"}),(0,r.jsxs)("div",{className:"mt-4 text-lg",children:[(0,r.jsx)("p",{children:"Details on how to apply for a visa to enter Japan can be found on the following websites:"}),(0,r.jsxs)("ul",{className:"ul-disc lg:text-lg",children:[(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"http://www.mofa.go.jp/j_info/visit/visa/",children:"Ministry of Foreign Affairs of Japan \u2013 Visa Information"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"http://www.mofa.go.jp/j_info/visit/visa/process/short.html",children:"Visa Application Process \u2013 Short-Term Stay"})})]})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Requesting a Visa Support Letter"}),(0,r.jsxs)("div",{className:"mt-4 text-lg",children:[(0,r.jsxs)("p",{children:["To request a visa support letter, please send an email to ",(0,r.jsx)("a",{href:"mailto:iswc2025-reg@easychair.org",children:"iswc2025-reg@easychair.org"})," with the following information included in the body of the email:"]}),(0,r.jsxs)("ul",{className:"ul-disc lg:text-lg",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Full name"}),"(as written in the passport)"]}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Job title"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Mailing address"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Nationality"})}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Date of birth"})}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Gender"})," (Male/Female)"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Are you a speaker/presenter?"})," (Yes or No)"]}),(0,r.jsx)("li",{children:(0,r.jsx)("b",{children:"Title of session/paper/workshop you are speaking/presenting at"})}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Itinerary:"})," Please fill in ",(0,r.jsx)("a",{href:"/Itinerary_Template.xlsx",download:!0,className:"inline-flex items-center gap-2 text-primary hover:underline",children:"Itinerary_Template.xlsx"})," (dates, planned activities, name of hotel)"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("b",{children:"Do you require a hard copy of the letter?"})," (Please note that hard copies will take additional processing time.)"]})]}),(0,r.jsx)("p",{children:"Electronic visa support letters will be issued promptly upon verification of paid registration. If you require an original signed letter via regular mail, you must request it in advance."})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Invitation Letter Details"}),(0,r.jsxs)("div",{className:"mt-4 text-lg",children:[(0,r.jsx)("p",{children:"The invitation letter will include the following information:"}),(0,r.jsxs)("ul",{className:"ul-disc lg:text-lg",children:[(0,r.jsx)("li",{children:"Conference dates, title, and location"}),(0,r.jsx)("li",{children:"The requester\u2019s role (committee member, speaker, presenter, or attendee)"}),(0,r.jsx)("li",{children:"Confirmation that the requester has paid the full registration fee"})]}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Note:"})," Invitation letters will not be issued to individuals who have not completed their registration payment."]})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Contact Information"}),(0,r.jsx)("p",{children:"For any inquiries, please contact:"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:"mailto:iswc2025-reg@easychair.org",children:"iswc2025-reg@easychair.org"})}),(0,r.jsx)("p",{children:"Kouji Kozaki (Local Organizing Chairs)"})]})]}),Ia=()=>(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("h1",{className:"text-3xl font-bold text-center text-[#e94607]",children:"Student Grants"}),(0,r.jsx)("p",{style:{fontWeight:"bold"},children:"Update: All available funding has now been fully allocated, and we are unable to provide any additional funding at this time. Should new funding opportunities become available, we will share an update."}),(0,r.jsx)("p",{children:"If you are a student interested in attending ISWC 2025, you may be eligible to apply for travel grants to support the costs of travel and lodging. This year, travel grants are funded by the Semantic Web Science Association (SWSA)."}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Funding Disclaimer"}),(0,r.jsx)("p",{children:"Please note that this is a form of financial support, not an award or prize. It is intended to assist students who do not have other means of covering their travel-related expenses. If your institution is able to fully fund your trip, we kindly ask that you refrain from applying, so that the limited resources can be directed to those with genuine financial need."}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Eligibility Criteria"}),(0,r.jsx)("p",{children:"You must currently be a student at a higher education institution; and have an ISWC 2025 submission that has been accepted to either the doctoral consortium, the main conference, workshops, tutorials, the poster/demo session, or the Semantic Web challenge (you may have submissions to more than one of these categories). If additional funds are available, we will also consider supporting students who do not have papers at the conference."}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Selection Criteria"}),(0,r.jsxs)("ul",{className:"ul-disc lg:text-lg",children:[(0,r.jsx)("li",{children:"Priority to students with papers in the doctoral symposium and the main track"}),(0,r.jsx)("li",{children:"Priority to students from underrepresented groups"}),(0,r.jsx)("li",{children:"Students with posters, demos, workshops, tutorials, and Semantic Web challenge papers if money is left"}),(0,r.jsx)("li",{children:"Students without a paper if there is money left"})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Application Process"}),(0,r.jsxs)("ul",{className:"ul-disc lg:text-lg",children:[(0,r.jsxs)("li",{children:["Fill out and submit the ISWC 2025 Student Travel Award Application Form on ",(0,r.jsx)("a",{href:"https://easychair.org/conferences?conf=iswc2025",target:"_blank",children:"easychair"}),", choosing \u201cStudent Grants\u201d when making a new submission"]}),(0,r.jsxs)("li",{children:["Ask your supervisor to email the student grants chairs using the following email address ",(0,r.jsx)("i",{children:"iswc2025-students@easychair.org"}),", confirming that you are a current student under their supervision and that you will be attending ISWC 2025. The subject of the email should be ",(0,r.jsx)("i",{children:"\u201cISWC 2025 Student Travel Award Application Verification for {YOUR FULL NAME}\u201d"}),". The text should read ",(0,r.jsx)("i",{children:"\u201cI confirm that {YOUR FULL NAME} is a student that is currently under my supervision at {INSTITUTION NAME} and that they will be attending ISWC 2025 to present work that they completed under my supervision. {SUPERVISOR NAME}\u201d"})]})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Timeline"}),(0,r.jsxs)("ul",{className:"ul-disc lg:text-lg",children:[(0,r.jsx)("li",{children:"Application opening date: July 9th 2025"}),(0,r.jsx)("li",{children:"Deadline for submission: Sep 15th 2025 (or earlier if funds are no longer available)"}),(0,r.jsx)("li",{children:"Notification of results: Sep 30th 2025 (latest)"})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Terms and Conditions"}),(0,r.jsxs)("ul",{className:"ul-disc lg:text-lg",children:[(0,r.jsx)("li",{children:"Attend the conference"}),(0,r.jsx)("li",{children:"Reimbursement after the conference"}),(0,r.jsx)("li",{children:"Keep all receipts"})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"Student Grants and Activities Chairs"}),(0,r.jsx)("p",{children:"Contact: iswc2025-students@easychair.org"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"Ines Akaichi - Vienna University of Economics and Business, Vienna, Austria"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"Atsuko Yamaguchi - Tokyo City University, Tokyo, Japan"})]})]}),Pa=a.p+"static/media/satoshi_sekine.cc9d5b174df14454013e.png",Ra=a.p+"static/media/Dr_Denny_Vrandecic.d61f3c347b4f4e5d62c5.jpg",Ea=a.p+"static/media/rachel_adams.8629f2c4c9b0e1918ac6.png",Da=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Keynote Speakers"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Keynote Talk: Rachel Adams"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Large Language Models and the AI Divide: Challenges and Pathways for Globally Equitable AI"}),(0,r.jsx)("p",{children:"Large Language Models (LLMs) have become a defining technology of our time, promising to transform knowledge access, communication, and productivity. Yet, their development and governance remain concentrated in a handful of institu- tions and geographies, raising critical questions about equity, justice, and global power. For Africa and the wider Global Majority, LLMs present a paradox: they hold the potential to expand access to information, enable innovation in local languages, and support inclusive development, but they also risk deepening ex- isting asymmetries of data, infrastructure, and governance."}),(0,r.jsx)("p",{children:"In this talk, I will explore the limitations and challenges of LLMs as they intersect with African and Global Majority contexts. I will highlight three critical areas of concern: (1) the epistemic exclusions embedded in training data that marginalize local knowledge systems and languages; (2) the infrastructural and resource dependencies that make access costly and uneven; and (3) the governance gaps that allow external models and actors to shape socio-technical futures with limited accountability to local communities. To move beyond critique, this talk will also outline pathways for governance and intervention that can help ensure LLMs are used to empower rather than exploit. These include developing regionally grounded ethical frameworks, advancing open and locally adapted models, building public\u2014private research collaborations, and embedding fairness and transparency into technical standards. Crucially, it calls for a re-imagining of AI governance not merely as risk mitigation, but as an opportunity to redis- tribute power, democratize innovation, and foreground the values of justice and dignity in technological futures."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Speakers's Bio"}),(0,r.jsx)("img",{src:Ea,alt:"Rachel Adams",className:"rounded-xl my-4 h-[500px]"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("a",{href:"https://www.globalcenter.ai/about/rachel-adams",target:"_blank",children:"Rachel Adams"}),", PhD, is the Founding CEO of the ",(0,r.jsx)("a",{href:"https://www.globalcenter.ai/",target:"_blank",children:"Global Centre on AI Governance"}),". She is the author of The New Empire of AI: The Future of Global Inequality (Polity Press, 2024). She is an Assistant Research Professor of the Leverhulme Center for the Future of Intelligence, University of Cambridge, and an Honorary Research Fellow of The Ethics Lab at the University of Cape Town. She holds degrees in English Literature, International Human Rights Law and Philosophy. Her PhD was published as a book: Transparency: New Trajectories in Law (Routledge, 2020). Rachel previously served as the Director of AI and Global Programmes at Research ICT Africa. Before joining RIA, she spent five years at the Human Sciences Research Council (HSRC) of South Africa, where she led various projects on AI in Africa and was the lead author of the book Human Rights and the Fourth Industrial Revolution in South Africa (HSRC Press, 2021). Prior to her appointment at the HSRC, Rachel was the Senior Researcher for Civil and Political Rights at the South African Human Rights Commission. Rachel serves on numerous international expert committees, including for UNESCO, the UN, UNDP, WEF, the Gates Foundation, and the Global Partnership on AI."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Keynote Talk: Satoshi Sekine"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Building Safety on Large Language Model"}),(0,r.jsx)("p",{children:"I will introduce the activities on AI Safety, mostly conducted at the Research and Development Center for Large Language Models, National Institute of Informatics (NII-LLMC). At our institute, we are developing LLM from scratch (i.e., from pre-training) in order to ensure transparency through elucidation of the learning principles of generative AI models, and carry out R&D that contributes to the advancement of generative AI models. Safety is one of the most crucial components, and the technologies to embody the safety will be educational for many industrial partners developing LLMs. We will introduce AnswerCarefully, a  dataset for promoting the safety and appropriateness of Japanese LLM outputs. The dataset consists of 1,800 pairs of questions and reference answers, where the questions require special attention in answering. It covers a wide range of risk categories established in prior English language datasets, but the data samples are original in that they are manually created to reflect the socio-cultural context of LLM usage in Japan. We show that using this dataset for instruction to fine-tune a Japanese LLM led to improved output safety without compromising the utility of general responses. We also report the results of a safety evaluation of 12 Japanese LLMs using this dataset as a benchmark. Finally, we describe the latest update on the dataset, which provides English translations and annotations of the questions, aimed at facilitating the derivation of similar datasets in different languages and regions. We will also introduce other activities, including the development of a misinformation and disinformation dataset, Jailbreak data set, fine-tuning and DPO tuning for safety, a large human evaluation experiment, and so on."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Speakers's Bio"}),(0,r.jsx)("img",{src:Pa,alt:"Satoshi Sekine",className:"rounded-xl my-4 h-[500px]"}),(0,r.jsx)("p",{children:"Satoshi Sekine is a professor at the Large Language Model Research and Development Center at the National Institute of Informatics, Japan. He received PhD at New York University in 1998. He has been working on Natural Language Processing, in particular Information Extraction, Named Entity, Question Answering, and, most recently development of data for LLM, and other related topics. He has his own research venture, LanguagrCraft, and has been working with different companies as a regular employee or a visitor, including Panasonic, SONY-CSL, Microsoft Research, and Rakuten, among others."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Keynote Talk: Denny Vrande\u010di\u0107"}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Wikipedia and the Semantic Web - Celebrating 20 years of co-development, and the future"}),(0,r.jsx)("p",{children:"In 2005, the very first papers proposed integrating Semantic Web technologies in the nascent Wikipedia ecosystem. This wasn\u2019t just a convergence; it ignited two decades of mutual inspiration and benefit. From this crucible, the work in semantic wikis drew inspiration. Semantic MediaWiki particularly, which found global adoption at Google, Microsoft, NASA, and beyond. Wikipedia became the bedrock for pioneering knowledge graphs, including DBpedia, Freebase, and Yago. These pivotal experiences directly fueled the development of Google\u2019s Knowledge Graph, a term that has since found ubiquitous adoption, and, critically, Wikidata, a project that has become an indispensable, living component of Wikipedia itself. With over half a million global contributors, Wikidata stands as the world\u2019s most-edited wiki, powering one of, if not the, most widely-used public SPARQL endpoint. Its software, Wikibase, has spawned a federation of knowledge graphs, serving diverse domains from museums to language preservation. Furthermore, Wikidata\u2019s evolution into lexicographic data (inspired by ontologies such as OntoLex and Lemon) laid the groundwork for projects such as Wikifunctions and Abstract Wikipedia, a vision first unveiled right here at ISWC 2018 and now an ocial Wikimedia Foundation project."}),(0,r.jsx)("p",{children:"This takes us to the present and future: Abstract Wikipedia collaboratively confronts the inherent expressivity gap in knowledge graphs, while Wikipedia\u2019s foundational role in training and the current use of language models can not be overstated. This creates a tantalising confluence of large language models and knowledge graphs, hinting at profound opportunities - and critical challenges - for Wikipedia, the Web, and beyond. As this rich history promises many more years of co-development and mutual inspiration, we will conclude with a forward-looking sketch of open research questions and exciting upcoming opportunities."}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Speakers's Bio"}),(0,r.jsx)("img",{src:Ra,alt:"Denny Vrande\u010di\u0107",className:"rounded-xl my-4 h-[500px]"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Denny_Vrande%C4%8Di%C4%87",target:"_blank",children:"Denny Vrande\u010di\u0107"})," is Head of Special Projects at the Wikimedia Foundation and visiting Professor at King\u2019s College London. He leads the Abstract Wikipedia project, which aims to give many more people the ability to contribute to, collaborate on, and read knowledge in their own language. Previously, he was an ontologist for the Google Knowledge Graph and researcher in Google AI, founder of Wikidata, co-creator of Semantic MediaWiki, and a member of the Board of Trustees of the Wikimedia Foundation. He received his PhD from KIT on the topic of Ontology Evaluation. He previously worked at KIT, CNR, USC ISI, Wikimedia Deutschland, and Google. He received the Knowledge Graph Conference Lifetime Achievement Award in 2023 and was co-research track chair of ISWC in 2018."]})]})]})]}),Wa=a.p+"static/media/guha.48fde7578fd48bb5ac96.png",Ma=a.p+"static/media/ora.869a831e9ca21241ce88.png",Ga=a.p+"static/media/natasha.8a0bb38099e5e5705e5d.png",Oa=a.p+"static/media/tara.55980d25af7bb0bd7b6d.png",Fa=a.p+"static/media/elena.0856dff9a5ddfed3c812.png",za=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"ISWC2025 Panel"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Reimagining Knowledge: The Future and Relevance of Symbolic Representation in the Age of LLMs"}),(0,r.jsx)("p",{children:"As large language models (LLMs) continue to reshape the landscape of artificial intelligence, the role of symbolic representation, once central to knowledge modeling and reasoning, faces renewed scrutiny and exciting possibilities."}),(0,r.jsx)("p",{children:'This panel, "Reimagining Knowledge: The Future and Relevance of Symbolic Representation in the Age of LLMs," brings together leading thinkers at the intersection of machine learning, knowledge engineering, and AI in the broader sense to explore the evolving relationship between symbolic and machine-learning paradigms. Through a multidisciplinary dialogue, panelists will examine whether symbolic structures remain essential for interpretability, reasoning, and alignment in modern AI systems or if they are being eclipsed by the impressive but opaque capabilities of LLMs.'}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Panel Chair"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Ramanathan_V._Guha",target:"_blank",style:{color:"#e94607"},children:"Ramanathan V. Guha"})}),(0,r.jsx)("img",{src:Wa,alt:"Ramanathan V. Guha",className:"rounded-xl my-4 h-[300px]"}),(0,r.jsxs)("p",{children:[(0,r.jsx)("b",{children:"Ramanathan V. Guha"})," recently joined Microsoft as CVP and Technical Fellow. Earlier, he spent time at ",(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Google",target:"_blank",style:{color:"#e94607"},children:"Google"}),", ",(0,r.jsx)("a",{href:"https://www.research.ibm.com/labs/almaden/",target:"_blank",style:{color:"#e94607"},children:"IBM Almaden"}),", ",(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Netscape",target:"_blank",style:{color:"#e94607"},children:"Netscape"}),", ",(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Apple_Advanced_Technology_Group",target:"_blank",style:{color:"#e94607"},children:"Apple ATG"}),", and ",(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Microelectronics_and_Computer_Technology_Corporation",target:"_blank",style:{color:"#e94607"},children:"MCC"}),". He also started multiple companies, including Epinions and Alpiri."]}),(0,r.jsx)("p",{children:"Guha is the creator of widely used web standards such as RSS, RDF, and Schema.org. His research interests include Knowledge Representation, Structured data on the Web, Trust networks, and Web Monetization."}),(0,r.jsxs)("p",{children:["At Microsoft, he recently conceived and developed ",(0,r.jsx)("a",{href:"https://news.microsoft.com/source/features/company-news/introducing-nlweb-bringing-conversational-interfaces-directly-to-the-web/",target:"_blank",style:{color:"#e94607"},children:"NLWeb"}),"."]}),(0,r.jsx)("h2",{style:{color:"#e94607"},className:"text-xl font-semibold mt-6",children:"Panelists:"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Ora_Lassila",target:"_blank",style:{color:"#e94607"},children:"Ora Lassila"})}),(0,r.jsx)("img",{src:Ma,alt:"Ora Lassila",className:"rounded-xl my-4 h-[300px]"}),(0,r.jsx)("p",{children:"Ora Lassila, Principal Technologist at  Amazon Web Services and co-chair of the W3C RDF-star Working Group"}),(0,r.jsx)("p",{children:"Ora Lassila is a Principal Technologist in the Amazon Neptune graph database team and the co-chair of the W3C RDF-star Working Group. He was one of the creators of the original Semantic Web vision and was a co-author of the original RDF specification. His main interest is to make people understand that sharing data is not just about sharing the physical bits but also sharing the meaning of those bits, and he sees ontologies and knowledge graphs as a means to do that. He is also interested in improving the alignment between RDF graphs and Labeled Property Graphs."}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Natasha_Noy",target:"_blank",style:{color:"#e94607"},children:"Natasha Noy"})}),(0,r.jsx)("img",{src:Ga,alt:"Natasha Noy",className:"rounded-xl my-4 h-[300px]"}),(0,r.jsx)("p",{children:"Natasha Noy, Research Scientist, Google"}),(0,r.jsx)("p",{children:"Natasha Noy is a Research Scientist at Google. She focuses on making structured data more accessible and usable. She is the team leader for Dataset Search, a web-based search engine for all datasets. Natasha worked at Stanford Center for Biomedical Informatics Research before joining Google, where she made significant contributions to ontology building and alignment, as well as collaborative ontology engineering."}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:"https://www.linkedin.com/in/tara-raafat-phd-1038315/",target:"_blank",style:{color:"#e94607"},children:"Tara Raafat"})}),(0,r.jsx)("img",{src:Oa,alt:"Tara Raafat",className:"rounded-xl my-4 h-[300px]"}),(0,r.jsx)("p",{children:"Tara Raafat, Head of Metadata and Knowledge Graph Strategy, CTO Office at Bloomberg LP"}),(0,r.jsx)("p",{children:"Tara Raafat is Head of Metadata and Knowledge Graph Strategy in Bloomberg\u2019s CTO Office, where she leads the development of Bloomberg\u2019s enterprise Knowledge Graph and semantic metadata strategy, aligning it with AI and data integration initiatives to advance next-generation financial intelligence. With over 15 years of expertise in semantic technologies, she has designed and implemented knowledge-driven solutions across multiple domains including but not limited to  finance, telemedicine, regulatory compliance, and insurance. "}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:"https://en.wikipedia.org/wiki/Elena_Simperl",target:"_blank",style:{color:"#e94607"},children:"Elena Simperl"})}),(0,r.jsx)("img",{src:Fa,alt:"Elena Simperl",className:"rounded-xl my-4 h-[300px]"}),(0,r.jsx)("p",{children:"Elena Simperl, Professor of Computer Science at King\u2019s College London and Director of Research at the Open Data Institute"}),(0,r.jsx)("p",{children:"Elena Simperl is a Professor of Computer Science at King\u2019s College London, where she co-directs the King's Institute for Artificial Intelligence. She is also the Director of Research at the Open Data Institute, a Fellow of the British Computer Society and the Royal Society of Arts, and a Hans Fischer Senior Fellow. Elena\u2019s work is at the intersection between AI and social computing. She features in the top 100 most influential scholars in knowledge engineering of the last decade and the Women in AI 2000 ranking. Elena co-chairs the Croissant working group in ML Commons, developing an open standard to improve data portability, discovery and use in AI. She is the president of the Semantic Web Science Association."})]})]})]}),Ka=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"ISWC 2025 Awards"}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsxs)("section",{className:"mb-6",children:[(0,r.jsx)("h2",{className:"text-2xl font-semibold",children:"SWSA Distinguished Dissertation Award 2025"}),(0,r.jsxs)("p",{children:["The recipient of this year's ",(0,r.jsx)("a",{href:"https://swsa.semanticweb.org/content/swsa-distinguished-dissertation-award",children:" SWSA Distinguished Dissertation Award"})," is ",(0,r.jsx)("strong",{children:"Bo Xiong"})," with their thesis on \u201cGeometric Relational Embeddings\u201d. Bo will receive the award at ISWC 2025, which includes a complimentary registration to the conference, a certificate, and a \u20ac 1,000 payment."]})]}),(0,r.jsxs)("section",{className:"mb-6",children:[(0,r.jsx)("h2",{className:"text-2xl font-semibold",children:"Test-of-time Paper Award 2025"}),(0,r.jsx)("p",{children:"To be announced at the opening ceremony of the conference.."})]}),(0,r.jsxs)("section",{className:"mb-6",children:[(0,r.jsx)("h2",{className:"text-2xl font-semibold",children:"Best Research Paper"}),(0,r.jsx)("p",{children:"To be announced at the closing ceremony of the conference."})]}),(0,r.jsxs)("section",{className:"mb-6",children:[(0,r.jsx)("h2",{className:"text-2xl font-semibold",children:"Best Resource Paper"}),(0,r.jsx)("p",{children:"To be announced at the closing ceremony of the conference."})]}),(0,r.jsxs)("section",{className:"mb-6",children:[(0,r.jsx)("h2",{className:"text-2xl font-semibold",children:"Best In-Use Paper"}),(0,r.jsx)("p",{children:"To be announced at the closing ceremony of the conference."})]}),(0,r.jsxs)("section",{className:"mb-6",children:[(0,r.jsx)("h2",{className:"text-2xl font-semibold",children:"Best Poster"}),(0,r.jsx)("p",{children:"To be announced at the closing ceremony of the conference."})]}),(0,r.jsxs)("section",{children:[(0,r.jsx)("h2",{className:"text-2xl font-semibold",children:"Best Demo"}),(0,r.jsx)("p",{children:"To be announced at the closing ceremony of the conference."})]})]})]})]}),qa=()=>{const e=[{title:"3rd Knowledge Base Construction from Pre-trained Language Models Workshop",organizers:"Duygu Sezen Islako\u011flu, Jan-Christoph Kalo, Simon Razniewski and Sneha Singhania",description:"Language models (LMs), such as chatGPT, BARD, and T5, have demonstrated remarkable outcomes in numerous AI applications. Research has shown that these models implicitly capture vast amounts of factual knowledge within their parameters, resulting in an impressive performance in knowledge-intensive applications. The seminal paper ``Language Models as Knowledge Bases?'' sparked interest in the spectrum between language models and knowledge graphs, leading to a diverse range of interesting research on the usage of LMs for knowledge base construction. This research includes: (1) utilizing pre-trained LMs for knowledge base completion and construction tasks, (2) performing information extraction tasks, like entity linking and relation extraction, and (3) utilizing knowledge graphs to support LM applications. In this third edition of the LM-KBC workshop, we aim to continue last year's very successful 2nd edition of the LM-KBC workshop.",website:"https://lm-kbc.github.io/workshop2025",social_medias:[{social_media:"@lm_kbc (X)",social_media_url:"https://x.com/lm_kbc"}]},{title:"20th International Workshop on Ontology Matching (OM-2025)",organizers:"Sven Hertling, Huanyu Li, Cassia Trojahn, Pavel Shvaiko, Oktie Hassanzadeh, J\xe9r\xf4me Euzenat and Ernesto Jimenez-Ruiz",description:"Ontology matching is a key interoperability enabler for the Semantic Web, as well as a useful technique in some classical data integration tasks dealing with the semantic heterogeneity problem. It takes ontologies as input and determines as output an alignment, that is, a set of correspondences between the semantically related entities of those ontologies. These correspondences can be used for various tasks, such as ontology merging, data interlinking, query answering or navigation over knowledge graphs. Thus, matching ontologies enables the knowledge and data expressed with the matched ontologies to interoperate. The workshop has the following goals: - To bring together leaders from academia, industry and user institutions to assess how academic advances are addressing real-world requirements. The workshop will strive to improve academic awareness of industrial and final user needs, and therefore, direct research towards those needs. Simultaneously, the workshop will serve to inform industry and user representatives about existing research efforts that may meet their requirements. The workshop will also investigate how the ontology matching technology is going to evolve, especially with respect to data interlinking, process matching, web table and knowledge graph matching tasks. - To conduct an extensive and rigorous evaluation of ontology matching and instance matching (link discovery) approaches through the OAEI (Ontology Alignment Evaluation Initiative) 2025 campaign. OAEI 2025, besides real-world specific matching tasks, will introduce a new Circular Economy track. Therefore, the ontology matching evaluation initiative itself will provide a solid ground for discussion of how well the current approaches are meeting business needs. - To examine similarities and differences from other, old, new and emerging, techniques and usages, such as process matching, web table matching or knowledge embeddings.",website:"https://om.ontologymatching.org/2025/"},{title:"Workshop on Actionable Knowledge Representation and Reasoning for Robots (AKR\u2265)",organizers:"Michael Beetz, Philipp Cimiano, Ken Fukuda, Michaela K\xfcmpel, Enrico Motta, Ilaria Tiddi, Jan-Philipp T\xf6berg and Takanori Ugai",description:"We propose a second edition for the Actionable Knowledge Representation and Reasoning for Robots workshop, focused on how robots can perform common sense reasoning to make sense of their environment, parameterize their actions and plan accordingly. Current robots are challenged by the dynamic nature of these environments, which requires them to deal with new situations, tasks, objects and goals they might not have experience with. As robots can't be pre-programmed for all possible variations, it is an important question to investigate how they can be equipped with the ability to acquire and apply commonsense knowledge to improve their sensemaking capabilities and reason about task execution. This can lead to more versatile robots, as they can tackle novel situations through reasoning instead of retraining. Given the availability of many commonsense knowledge resources on the Web, and the ability of large language models to extract and generate knowledge, this is a timely research topic. Our workshop will combine classical workshop elements (presentation of contributed papers, invited speakers) with hands-on tutorials to learn how symbolic knowledge can be put into action in existing robot architectures. Based on last year's experience, we expect to get approximately 8 submissions and 20-30 workshop participants.",website:"https://kr3-workshop.net/"},{title:"5th International Workshop on Scientific Knowledge Representation, Discovery, and Assessment (Sci-K 2025)",organizers:"Anna Jacyszyn, Andrea Mannocci, Francesco Osborne, Georg Rehm, Angelo Salatino, Sonja Schimmler and Lise Stork",description:"In the last decades, there has been a surge in the volume of published scientific articles and related research objects (e.g., data sets, software, models), a trend that is expected to continue. The Sci-K workshop aims to provide a forum for researchers and practitioners from different disciplines to present, educate from, and guide research related to scientific knowledge. Specifically, we foresee three main challenging themes. Representation. There is an urge for Scientific Knowledge Graphs (SKGs), that offer flexible, context-sensitive, fine-grained, and machine-actionable representations of scholarly knowledge that are simultaneously structured, interlinked, and semantically rich. The key challenge in this area is the development of ontologies and methodologies that can capture the conceptualisation, representation, and interoperability of scholarly knowledge across different SKGs. Discovery. It is crucial that scholarly information is easily findable, discoverable, and visible so that it can be mined and organised within SKGs. Current challenges are related to discovering and extracting entities and concepts, integrating information from heterogeneous sources, identifying duplicates, finding connections between entities, and identifying conceptual inconsistencies. Assessment. Due to the continuous growth in the volume of research outputs, we need reliable and comprehensive indicators of scientific impact and merit for the diverse scientific outputs and actors.",website:"https://sci-k.github.io/2025/",social_medias:[{social_media:"@scik_workshop (X)",social_media_url:"https://x.com/scik_workshop"},{social_media:"LinkedIn",social_media_url:"https://www.linkedin.com/groups/10083235/"}]},{title:"Wikidata Workshop",organizers:"Nicolas Ferranti, Marcelo de Oliveira Costa Machado, Jorao Gomes Junior, Simon Raznievski, Axel Polleres, and Markus Kr\xf6tzsch",description:"Wikidata, an open knowledge base maintained by the Wikimedia Foundation, plays a crucial role in structuring data for projects, such as Wikipedia and Wiktionary. Over the years, the Wikidata Workshop has addressed key challenges such as data quality, multilingualism, and collaborative knowledge graph dynamics. For its fifth edition, we expand the scope to include discussions on the intersection of Wikidata and Generative AI, while continuing to explore established topics. We welcome contributions on knowledge augmentation, data curation, reasoning, and the broader impact of generative AI on Wikidata. By bringing together researchers and practitioners, this workshop fosters discussions on the evolving role of knowledge graphs in an AI-driven world.",website:"https://wikidataworkshop.github.io/2025/",social_medias:[{social_media:"@ISWC_Wikidata (X)",social_media_url:"https://x.com/ISWC_Wikidata"}]},{title:"SeMatS 2025 \u2013 Second International Workshop on Semantic Materials Science",organizers:"Andre Valdestilhas, Huanyu Li, Patrick Lambrix and Harald Sack",description:"Advanced technological solutions are pivotal for leveraging data in innovative research, but compatibility issues in scientific data hinder progress. Interoperability and efficient data access are crucial, and the Semantic Web emerges as a powerful solution. Historically, the intersection between Semantic Web (SW) technologies, and Materials Science and Engineering (MSE) dates back before the formalization of the Semantic Web concept in 2001. For instance, the creation of the Plinius ontology in 1994 provided a language-independent conceptual construction kit for the chemical composition of materials. Recent conferences in the MSE domain, such as the FEMS-Euromat (European Congress and Exhibition on Advanced Materials and Processes) and MSE congress, show a significant increase in Semantic Web applications, with over ten SW-related presentations in 2022, more than 20 in 2023 and the previous edition of the SeMats workshop in 2024 counted 10 accepted contributions. This growing adoption prompts a focus on attracting participants at the intersection of both areas. Expanding Semantic Web technologies to the Materials Science domain can enhance research outcomes by enabling the uniform consideration of heterogeneous data. It improves traceability and reproducibility and facilitates automatable data management solutions. The primary objective of the proposed workshop is to gather works applying Semantic Web Technologies in Materials Science, making these technologies accessible to a broader community. The workshop aims to provide an overview of existing approaches, identify relevant works, and bring together Materials Science and Semantic Web stakeholders for collaboration and innovation. Join us in exploring the transformative possibilities of Semantic Web Technologies in Materials Science, paving the way for a more interconnected and efficient research landscape.",website:"https://sites.google.com/view/semats2025"},{title:"2nd International Workshop on Retrieval-Augmented Generation Enabled by Knowledge Graphs (RAGE-KG 2025)",organizers:"Daniil Dobriy, Sanju Tiwari, Jennifer D'Souza, Nandana Mihindukulasooriya and Francesco Osborne",description:"Retrieval-Augmented Generation Enabled by Knowledge Graphs (RAGE-KG) aims to explore the state of the art and go beyond in integrating Retrieval-Augmented Generation (RAG) with the Semantic Web infrastructure as well as the synergies between Large Language Models (LLMs) and the Linked Open Data (LOD) ecosystem. The workshop seeks to foster innovative RAG and GraphRAG architectures relying on Semantic Web standards and new approaches to make LOD usable by LLMs, enhancing their ability to generate reliable, verifiable and context-aware responses based on structured, decentralized and authoritative data sources. The workshop is majorly focused on techniques for fine-tuning, prompting and otherwise integrating LLMs with KGs. Additionally, it will examine the development and application of RAG architectures across various use cases and provide a platform to advance research and innovation in this dynamic field. Building on the success and strong attendance of the last year, this year's workshop will include dynamic elements: (a) Pecha Kucha presentations of scientific research -- the backbone of the workshop, (b) industry papers and guest speakers showcasing the real-world applications of the technology and (c) a structured research matchmaking session stimulating collaborations and producing vision statements which will be included in the proceedings.",website:"https://2025.rage-kg.org ",social_medias:[{social_media:"Bluesky",social_media_url:"https://bsky.app/profile/rage-kg.bsky.social"},{social_media:"Mastodon",social_media_url:"https://mastodon.social/@ragekg"},{social_media:"LinkedIn",social_media_url:"https://www.linkedin.com/company/rage-kg"},{social_media:"X",social_media_url:"https://x.com/rage_kg"}]},{title:"16th Workshop on Ontology Design and Patterns (WOP 2025)",organizers:"Hande Kucuk McGinty, Cogan Shimizu, Valentina Presutti, Eva Blomqvist and Pascal Hitzler",description:"We propose the 16th edition of the Workshop on Ontology Design and Patterns (WOP). The workshop series covers issues related to quality in ontology design and ontology design patterns (ODPs) for data and knowledge engineering in Semantic Web. The increased attention to ODPs in recent years through their interaction with emerging trends of the Semantic Web, such as knowledge graphs, can be attributed to their benefit for knowledge engineers and Semantic Web developers. Such benefits come in the form of direct links to requirements, reuse, guidance, and better communication. The workshop's aim is thus not just: 1) providing an arena for discussing patterns, pattern-based ontologies, systems, datasets, but also 2) broadening the pattern community by developing its own ``discourse'' for discussing and describing relevant problems and their solutions. A recent development in the Semantic Web community is that the general idea of \"pattern\" has begun to appear in different but related forms, and at WOP 2025, we intend to continue to include these new trends. We propose a full-day workshop consisting of three parts: a keynote, presentations of contributed papers, and a community session discussing joint long-term initiatives, with break-out sessions addressing specific problems.",website:"https://odpa.github.io/workshop-on-ontology-design-and-patterns/2025/index.html"},{title:"HAIBridge 2025: 1st Workshop on Bridging Hybrid Intelligence and the Semantic Web",organizers:"Alexis Ellis, Subhashini Ganapathy, Fjoll\xeb Novakazi and Cogan Shimizu",description:'The principled integration of Hybrid Intelligence (HI) -- which combines human and artificial intelligence -- with the Semantic Web presents novel opportunities for enhancing decision-making, knowledge representation, and collaborative problem-solving. This workshop promotes the exploration at the intersection of these domains, focusing on how semantic technologies (e.g., ontologies, knowledge graphs, and linked data) can improve the adaptability, explainability, and reasoning capabilities of hybrid intelligence systems. Topics include human-AI collaboration, trustworthy AI, context-aware knowledge management, and real-world applications in areas such as healthcare, finance, and smart cities. At "Smarter Together: Bridging Hybrid Intelligence and the Semantic Web," participants will engage across disciplinary boundaries, fostering interdisciplinary collaboration toward more robust, intelligent, transparent, and ethical AI-driven systems. The workshop will generally consist of a keynote, interactive discussions and breakouts, and brief, but informative, state-of-the-art research presentations.',website:"https://sites.google.com/view/iswc-haibridge25/home"}],[t,a]=(0,n.useState)([]),i=(0,n.useRef)([]),s=e=>{a((t=>t.includes(e)?t.filter((t=>t!==e)):[...t,e]))};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex flex-col pt-10 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-8 tracking-wide text-center",children:"Accepted Workshops"}),(0,r.jsx)("div",{className:"overflow-x-auto",children:(0,r.jsxs)("table",{className:"min-w-full table-auto border-collapse text-left text-sm lg:text-base",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Workshop Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Organizers"})]})}),(0,r.jsx)("tbody",{children:e.map(((e,t)=>(0,r.jsxs)("tr",{className:"border-b",children:[(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200 font-semibold",children:(0,r.jsx)("div",{onClick:()=>(e=>{i.current[e]&&(i.current[e].scrollIntoView({behavior:"smooth",block:"start"}),s(e))})(t),className:"hover:underline text-[#e94607]",children:e.title})}),(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200",children:e.organizers})]},t)))})]})}),(0,r.jsx)("br",{}),e.map(((e,a)=>(0,r.jsxs)("div",{ref:e=>i.current[a]=e,id:`details-${a}`,className:"p-4 border rounded-lg",children:[(0,r.jsxs)("div",{onClick:()=>s(a),className:"flex items-center gap-2 p-2 rounded",children:[(0,r.jsx)("span",{className:"transform transition-transform "+(t.includes(a)?"rotate-90":"rotate-0"),children:"\xbb"}),(0,r.jsx)("span",{className:"font-bold text-[#e94607] hover:underline",children:e.title})]}),t.includes(a)&&(0,r.jsxs)("div",{className:"mt-2",children:[(0,r.jsx)("h2",{children:"Organizers"}),(0,r.jsx)("p",{children:e.organizers}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Description"}),(0,r.jsx)("p",{children:e.description}),e.website&&(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Website"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:e.website,target:"_blank",rel:"noopener noreferrer",children:e.website})})]}),e.social_medias&&(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Social Media"}),e.social_medias.map(((e,t)=>(0,r.jsx)(r.Fragment,{children:(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:e.social_media_url,target:"_blank",rel:"noopener noreferrer",children:e.social_media})})})))]})]})]},a)))]})]})},_a=()=>{const e=[{title:"Trust, Autonomy and Accountability in PKG-Based Agentic AI (TAPAI)",organizers:"John Domingue, Aidan Hogan, Luis-Daniel Ibanez, Oshani Seneviratne and Maria-Esther Vidal",description:"This workshop will address how personal knowledge graphs (PKGS) can help to engender trust, autonomy and accountability in the context of agentic artificial intelligence. The question of how AI agents could leverage personal data to provide higher levels of automation and personalization for users has not been well-explored. While foundational models can be trained on public corpora of text, the recent emergence of computer-using agents, personal agents, etc., raise questions about how the user\u2019s personal data can be used, and concerns about how they could be abused, in such a setting. Can AI agents be trusted with personal and potentially highly-sensitive user information? How can users maintain autonomy over their personal data in such a setting? How can AI agents and providers be held accountable when personal data are abused? In this session, we will address research questions regarding the use of PKGs to provide users with enhanced control and safety guarantees regarding how AI agents access and use their personal data.",website:"https://tapai-iswc25.github.io",social_medias:[{social_media:"#TAPAI"}]},{title:"Explainable AI using Ontologies and Knowledge Graphs",organizers:"Raghava Mutharaju and Manas Gaur",description:"AI systems are now ubiquitous. They are used in a variety of applications and domains such as healthcare, finance, security, travel, and e-commerce. Ensuring transparency and explainability is vital, not only for user trust but also for legal compliance. In the proposed workshop, we will discuss the role of ontologies and knowledge graphs in particular, but knowledge representation techniques in more general terms, for Explainable AI (XAI). While traditional explainability techniques rely on statistical cues, ontologies and knowledge graphs enable semantic grounding, facilitating richer and more accurate justifications. The need for such methods is underscored by regulatory frameworks like the EU AI Act and GDPR, which mandate the provision of meaningful explanations, particularly in high-risk and automated decision-making contexts. The discussion in the workshop will be organized around key themes such as the foundations of symbolic explainability, technical integration with black-box models, user-centered explanation design, evaluation methods, and cross-domain applications. We will have breakout sessions to discuss these themes. The outcome of the discussions can drive future research and is also helpful for researchers new to the field.",website:""},{title:"Are Ontologies Still Relevant in the Era of LLMs?",organizers:"Raghava Mutharaju, Cogan Shimizu, and Valentina Tamma",description:"Ontologies are one of the key mechanisms for capturing domain knowledge in the form of important concepts and the relationships between them. It requires time, effort, and expertise to build the ontologies. They have been proven to be effective for applications involving data integration, question answering, recommendations, and explanation generation. However, Large Language Models (LLMs) trained on massive amounts of data are another source of knowledge. They are able to find interesting statistical patterns, memorize, and answer questions. On the other hand, they struggle with consistency and are prone to hallucinations. Given these trade-offs between ontologies and LLMs, in this workshop, we would like to explore three key questions -- a) applications/tasks that need grounded and high-quality curated knowledge in the form of ontologies (and LLMs just do not work in these cases), b) applications/tasks that were traditionally making use of ontologies but can now be handled very well by LLMs, and c) applications/tasks that need a combination of ontologies and LLMs. Discussion around these topics can drive future research and would also be very helpful for researchers new to the field.",website:""},{title:"ReAGENT-SW: Realising Autonomous Generative agENTs for the Semantic Web",organizers:"Ora Lassila, Valentina Tamma, and Ilaria Tiddi",description:"The original vision of the Semantic Web, articulated in the seminal Scientific American article by Berners-Lee, Hendler, and Lassila, placed autonomous agents at the heart of the Web\u2019s evolution: agents capable of discovering, reasoning over, and acting upon structured, linked data to assist users, automate tasks, collaborate across services, and facilitate knowledge-driven decision-making. These agents were conceived as proactive participants in a globally distributed, machine-readable ecosystem. However, two decades later and despite significant progress in ontologies, reasoning technologies, and the creation of a vast Linked Data cloud, autonomous agents that truly reason with and act upon structured knowledge remain elusive. The recent emergence of generative AI systems has revived interest in this vision; introducing new capabilities for communication, abstraction, and interaction, although often lacking semantic grounding, verifiability, or goal-driven autonomy. This Dagstuhl-style workshop aims to bring together researchers and practitioners to critically examine how recent developments can be harnessed to revisit and realise the agent-focussed vision of the Semantic Web. Through discussion that integrates relevant disciplines across the Semantic Web, artificial intelligence, multi-agent systems, and robotics, we will explore what opportunities generative AI introduces for autonomous agents capable of semantically grounded, context-aware, and interoperable decision-making, what challenges remain, and how we can build such agents - both in digital spaces and real-world environments.",website:"https://reagent-sw.github.io/"}],[t,a]=(0,n.useState)([]),i=(0,n.useRef)([]),s=e=>{a((t=>t.includes(e)?t.filter((t=>t!==e)):[...t,e]))};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex flex-col pt-10 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-8 tracking-wide text-center",children:"Accepted Dagstuhl Workshops"}),(0,r.jsx)("div",{className:"overflow-x-auto",children:(0,r.jsxs)("table",{className:"min-w-full table-auto border-collapse text-left text-sm lg:text-base",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Workshop Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Organizers"})]})}),(0,r.jsx)("tbody",{children:e.map(((e,t)=>(0,r.jsxs)("tr",{className:"border-b",children:[(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200 font-semibold",children:(0,r.jsx)("div",{onClick:()=>(e=>{i.current[e]&&(i.current[e].scrollIntoView({behavior:"smooth",block:"start"}),s(e))})(t),className:"hover:underline text-[#e94607]",children:e.title})}),(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200",children:e.organizers})]},t)))})]})}),(0,r.jsx)("br",{}),e.map(((e,a)=>(0,r.jsxs)("div",{ref:e=>i.current[a]=e,id:`details-${a}`,className:"p-4 border rounded-lg",children:[(0,r.jsxs)("div",{onClick:()=>s(a),className:"flex items-center gap-2 p-2 rounded",children:[(0,r.jsx)("span",{className:"transform transition-transform "+(t.includes(a)?"rotate-90":"rotate-0"),children:"\xbb"}),(0,r.jsx)("span",{className:"font-bold text-[#e94607] hover:underline",children:e.title})]}),t.includes(a)&&(0,r.jsxs)("div",{className:"mt-2",children:[(0,r.jsx)("h2",{children:"Organizers"}),(0,r.jsx)("p",{children:e.organizers}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Description"}),(0,r.jsx)("p",{children:e.description}),e.website&&(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Website"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:e.website,target:"_blank",rel:"noopener noreferrer",children:e.website})})]}),e.social_medias&&(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Social Media"}),e.social_medias.map(((e,t)=>(0,r.jsx)(r.Fragment,{children:(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:e.social_media_url,target:"_blank",rel:"noopener noreferrer",children:e.social_media})})})))]})]})]},a)))]})]})},Ha=()=>{const e=[{title:"Shaping Knowledge and Interoperable Graphs",organizers:"Jose Emilio Labra Gayo",description:"Since Google introduced the use of Knowledge Graphs to enhance search functionality and organize information internally, their adoption and application have grown significantly. Various technologies have been developed to implement Knowledge Graphs, with RDF-based triplestores being a cornerstone of the Semantic Web, while Property Graphs are also widely used in the context of graph databases. Wikidata, a well-known Knowledge Graph, provides RDF data through its SPARQL query service, but its data model closely resembles Property Graphs, incorporating features like qualifiers and references. The recent introduction of RDF 1.2 (formerly known as RDF-Star) aims to bridge the gap between RDF and Property Graphs by enabling statements about statements, offering greater flexibility. Data quality is a critical aspect of Knowledge Graphs, often ensured through validation against predefined data models or shapes. This tutorial will explore several approaches developed for describing and validating RDF, such as Shape Expressions (ShEx) and Shapes Constraint Language (SHACL). Notably, the Data Shapes Working Group has been tasked this year with developing SHACL 1.2, aligning it with RDF 1.2. We will briefly outline these approaches, highlighting their similarities, differences, and recent advancements. For Property Graphs, proposals like PGSchema, PShEx, and ProGS have emerged, with GQL recently offering a way to define typed graphs. Wikidata has adopted Entity Schemas, which are based on ShEx, alongside its own property constraint system, and a proposal called WShEx is also under consideration. This tutorial will delve into the various types of Knowledge Graphs and the methods used for their validation. Additionally, we will examine practical applications of these technologies, such as inferring shapes from existing data and generating compliant subsets of Knowledge Graphs.",website:"https://www.validatingrdf.com/tutorial/iswc2025/",social_medias:[]},{title:"Testing Knowledge Graph Applications (TestKG)",organizers:"Eduard Kamburjan, Tobias John, Einar Broch Johnsen and Dominic Steinh\xf6fel",description:"Knowledge graphs (KGs) are supported by a rich and ever-growing ecosystem of standards, technologies and software tools. For the quality of the KGs application, software reliability in this ecosystem is as important as the quality and reliability of the data, in particular if KGs are used to improve confidence in an overall application, e.g., to counteract gaps. But while the quality of the underlying software tools is critical, developers of new applications operating on KGs, as well as maintainers of legacy software have little tool and methodological support. This tutorial aims to provide information about automated testing for programs that operate on RDF and OWL inputs. It will introduce basic testing theory that describes different options to setup testing oracles and input generators, as well as describe the concrete challenges and possible solutions for KGs. The hands-on part will introduce two concrete approaches, namely mutation-based and language-based input fuzzing, to generate RDF or OWL targeting a specific application. The participants will develop two automated testing suites for a knowledge graph construction tool, and use state-of-the-art input fuzzers.",website:"https://edkamb.github.io/TestKG/",social_medias:[]},{title:"Referring Expressions in Artificial Intelligence and Knowledge Representation Systems",organizers:"David Toman",description:"The tutorial introduces the audience to the concept of referring expressions, formulae that can be used to communicate identities of otherwise abstract objects. The formalism provides foundations for a successful and unambiguous exchange of information about individuals between agents sharing common knowledge about such individuals, a task that is indispensable in most modern applications of knowledge representation and semantic technologies.",website:"https://cs.uwaterloo.ca/~david/iswc25/",social_medias:[]},{title:"An Introduction to RDF and SPARQL 1.2 (RDF/SPARQL 1.2)",organizers:"Ruben Taelman, Enrico Franconi, Pierre-Antoine Champin and Ora Lassila",description:"The RDF 1.1 and SPARQL 1.1 specifications are foundational to Knowledge Graphs and Semantic Web research. More than a decade after their last versions were released as W3C recommendations, they are scheduled to receive an update to version 1.2. For the last 3 years, the RDF-star Working Group has been working on these updates, with as primary focus the ability to make statements about other statements. The goal of this tutorial is to provide a crash course into RDF 1.2 and SPARQL 1.2, for people that already know RDF 1.1 and SPARQL 1.1. We will discuss the history and motivations for this update, explain the new triple terms and reification concepts, and give an overview of the other changes that were included in the relevant specifications. As outcomes, participants will understand the motivations for these changes, and they will be able to make use of it in their future work.",website:"https://www.w3.org/Talks/2025/iswc-tutorial-rdfsparql-12/",social_medias:[]},{title:"OWL or SHACL: A Beginner\u2019s Guide to Making the Right Choice",organizers:"Davide D'Amico and Tara Raafat",description:"As knowledge graphs become increasingly integral to enterprise data strategies, the adoption of semantic technologies continues to grow. However, one question arises repeatedly: Should I use Web Ontology Language (OWL), SHApes Constraint Language (SHACL), or a combination of both? This tutorial addresses that question by introducing the core concepts, their practical purposes, and real-world applications of OWL and SHACL, with a focus on understanding when each technology is most appropriate to use. Using a dataset from the museum domain, the session will guide participants through key use cases that demonstrate the distinct strengths and weaknesses of these technologies, as well as where they overlap. Through an example-driven, hands-on approach, attendees will explore how modeling, inference, and data validation are influenced by the use of OWL and SHACL. Participants will collaboratively analyze various problem scenarios to determine the most suitable language(s) for addressing each challenge. The tutorial will involve building ontologies, defining SHACL shapes, and validating data using open source tools. By the end of the session, attendees will have gained practical experience and a clear understanding of how to apply OWL and SHACL effectively in diverse knowledge graph development contexts.",website:"https://semanticmasterclass.github.io/iswc2025/",social_medias:[{social_media:"Tara Raafat LinkedIn",social_media_url:"https://www.linkedin.com/in/tara-raafat-phd-1038315"},{social_media:"Davide D'Amico LinkedIn",social_media_url:"https://www.linkedin.com/in/davide~damico"}]},{title:"Building Streaming and Cross-Environment Data Processing Pipelines with RDF-Connect",organizers:"Ieben Smessaert, Arthur Vercruysse, Juli\xe1n Rojas and Pieter Colpaert",description:"RDF-Connect is a novel, language-agnostic framework for building provenance-aware, streaming data pipelines that integrate heterogeneous processors across languages. It aims to facilitate the construction, maintenance, and reusability of modular, interoperable pipelines for complex, semantically rich data workflows. Data processing pipelines are essential for modern data-centric systems, such as knowledge graphs, LLMs, and machine learning systems. Developers and researchers need flexible, interoperable tools for creating multilingual data processing pipelines. To meet this need, we present a comprehensive tutorial that blends conceptual foundations with hands-on experience. Participants will learn how to use RDF-Connect to design and execute reusable, extensible, and transparent streaming pipelines. Participants will construct a streaming data processing pipeline from real-world data: generating a weather forecast knowledge graph for Nara, Japan from the Japan Meteorological Agency. They will: (i) Construct a machine learning pipeline using processors in multiple programming languages, (ii) Create custom data processors for diverse endpoints, (iii) Explore provenance tracking using RDF and PROV-O ontology. By the end of the tutorial, participants from varied backgrounds, including Python, JavaScript, and Java developers, will gain practical experience in building language-agnostic, semantically rich data processing pipelines. This tutorial not only introduces RDF-Connect but also opens new avenues for interdisciplinary data transformation strategies in Semantic Web research and development.",website:"https://rdf-connect.github.io/Tutorial-ISWC2025/",social_medias:[{social_media:"GitHub",social_media_url:"https://github.com/rdf-connect"}]},{title:"SODa WissKI Bits Tutorial: Ontology-Driven Semantic Modeling and FAIR Publishing with WissKI",organizers:"Canan Hastik, Gudrun Schwenk and Mark Fichtner",description:"This tutorial introduces participants to ontology-driven semantic modeling and FAIR data publishing through the open-source research environment WissKI. Participants will follow a structured, activity-based learning path based on the TaDiRAH taxonomy, focusing on real-world collection building and Linked Data integration. Using established Semantic Web technologies such as RDF, OWL, SPARQL, and the CIDOC Conceptual Reference Model (CRM), the session offers hands-on experience in modeling cultural heritage entities, creating collection scenarios, and exporting interoperable data. The tutorial is particularly relevant for researchers, data stewards, and ontology engineers working on domain-specific knowledge graphs and LOD infrastructures.",website:"https://liascript.github.io/course/?https://raw.githubusercontent.com/soda-collections-objects-data-literacy/SODa_WissKI-ISWC25Bits/refs/heads/main/didacticConcept/SODa_WissKI-ISWC25Bits_didacticConcept.md#1",social_medias:[{social_media:"SODa LinkedIn",social_media_url:"https://www.linkedin.com/company/soda-zentrum"},{social_media:"Fedihum Mastodon",social_media_url:"https://fedihum.org/@SODa"}]},{title:"GeoKG 2025 Introduction to geospatial knowledge graphs",organizers:"Sergios Anestis Kefalidis, Manolis Koubarakis, Konstantinos Plas and Cogan Shimizu",description:"In the last two decades, knowledge graphs (KGs) have seen increased interest thanks to their suitability for representing relations (edges) between entities (nodes), and their semi-structured nature, which eases the integration of diverse, heterogeneous data sources. This tutorial will introduce its audience to geospatial knowledge graphs (GeoKGs) i.e., knowledge graphs that combine thematic (e.g., \u201cNara is the capital city of the Nara prefecture and has an estimated population of 367,353 according to World Population Review\u201d) and geospatial knowledge (e.g., \u201cthe coordinates of Nara are 34\xb041\u2032 04\u2032\u2032N and 135\xb048\u203218\u2032\u2032E\u201d or \u201cNara is within the region Kansai\u201d)",website:"https://ai-team-uoa.github.io/GeoKG-2025-ISWC/",social_medias:[]},{title:"QUALIDATA - Linked Data Quality in Practice",organizers:"Gianluca Demartini, Maria Angela Pellegrino, Anisa Rula and Gabriele Tuozzo",description:"This tutorial offers a comprehensive introduction to data quality in the Semantic Web, combining theory and hands-on practice. It covers quality dimensions, FAIR principles, and their application to Linked Data. Participants engage in interactive activities, explore the KGHeartBeat tool through practical tasks, and reflect on broader quality issues such as bias and its practical implications. It targets researchers, practitioners, and developers seeking both foundational understanding and applied skills in quality-aware Linked Data practices.",website:"https://gabrielet0.github.io/QUALIDATA/",social_medias:[]},{title:"Key Facets in Modern Knowledge Graph Representation Learning (KeyKGRL)",organizers:"Joyce Whang",description:"Knowledge graph representation learning (KGRL) aims to convert entities and relations into feature vectors, thereby facilitating their effective integration into contemporary AI models. This half-day tutorial explores the ongoing research avenues and key aspects being investigated in the latest KGRL research. In particular, this tutorial provides a review of seminal works in KGRL from four different perspectives: (1) KGRL methods incorporating multimodal data in generating knowledge representations, (2) inductive KGRL methods that allow inference on new KGs without retraining KGRL models, (3) KG foundation models that pretrain a KGRL model using various KGs and apply it to different KGs, and (4) representation learning methods on hyper-relational KGs that extend the vanilla KGs to represent enriched information. Along with four lecturing sessions, two hands-on exercise sessions will also be provided, where audiences can run the KGRL methods and analyze the results. As long as they have a basic background in machine learning and non-trivial programming skills, all the materials will be easy to follow.",website:"https://bdi-lab.github.io/keykgrl_iswc2025/",social_medias:[]}],t=[{title:"AI4EIA: A Practical and Hands-on Guide to Enterprise Information Architecture - From AI-Driven Ontology Modeling to Knowledge Graph Insights via Conversational AI",organizers:"metaphacts GmbH, Walldorf, Germany",description:"",website:"https://github.com/iswc-conf/iswc2025/blob/main/public/tutorials/2025_ISWC_Tutorial.pdf",social_medias:[]}],[a,i]=(0,n.useState)([]),s=(0,n.useRef)([]),o=e=>{i((t=>t.includes(e)?t.filter((t=>t!==e)):[...t,e]))},l=e=>{s.current[e]&&(s.current[e].scrollIntoView({behavior:"smooth",block:"start"}),o(e))};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex flex-col pt-10 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-8 tracking-wide text-center",children:"Accepted Tutorials"}),(0,r.jsx)("div",{className:"overflow-x-auto",children:(0,r.jsxs)("table",{className:"min-w-full table-auto border-collapse text-left text-sm lg:text-base",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Tutorial Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Organizers"})]})}),(0,r.jsx)("tbody",{children:e.map(((e,t)=>(0,r.jsxs)("tr",{className:"border-b",children:[(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200 font-semibold",children:(0,r.jsx)("div",{onClick:()=>l(t),className:"hover:underline text-[#e94607]",children:e.title})}),(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200",children:e.organizers})]},t)))})]})}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-8 tracking-wide text-center",children:"Sponsored Tutorials"}),(0,r.jsx)("div",{className:"overflow-x-auto",children:(0,r.jsxs)("table",{className:"min-w-full table-auto border-collapse text-left text-sm lg:text-base",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Tutorial Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Organizers"})]})}),(0,r.jsx)("tbody",{children:t.map(((e,t)=>(0,r.jsxs)("tr",{className:"border-b",children:[(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200 font-semibold",children:(0,r.jsx)("div",{onClick:()=>l(`spt-${t}`),className:"hover:underline text-[#e94607]",children:e.title})}),(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200",children:e.organizers})]},`spt-${t}`)))})]})}),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),e.map(((e,t)=>(0,r.jsxs)("div",{ref:e=>s.current[t]=e,id:`details-${t}`,className:"p-4 border rounded-lg",children:[(0,r.jsxs)("div",{onClick:()=>o(t),className:"flex items-center gap-2 p-2 rounded",children:[(0,r.jsx)("span",{className:"transform transition-transform "+(a.includes(t)?"rotate-90":"rotate-0"),children:"\xbb"}),(0,r.jsx)("span",{className:"font-bold text-[#e94607] hover:underline",children:e.title})]}),a.includes(t)&&(0,r.jsxs)("div",{className:"mt-2",children:[(0,r.jsx)("h2",{children:"Organizers"}),(0,r.jsx)("p",{children:e.organizers}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Description"}),(0,r.jsx)("p",{children:e.description}),e.website&&(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Website"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:e.website,target:"_blank",rel:"noopener noreferrer",children:e.website})})]})]})]},t))),(0,r.jsx)("br",{}),(0,r.jsx)("br",{}),t.map(((e,t)=>(0,r.jsxs)("div",{ref:e=>s.current[`spt-${t}`]=e,id:`details-spt-${t}`,className:"p-4 border rounded-lg",children:[(0,r.jsxs)("div",{onClick:()=>o(`spt-${t}`),className:"flex items-center gap-2 p-2 rounded",children:[(0,r.jsx)("span",{className:"transform transition-transform "+(a.includes(`spt-${t}`)?"rotate-90":"rotate-0"),children:"\xbb"}),(0,r.jsx)("span",{className:"font-bold text-[#e94607] hover:underline",children:e.title})]}),a.includes(`spt-${t}`)&&(0,r.jsxs)("div",{className:"mt-2",children:[(0,r.jsx)("h2",{children:"Organizers"}),(0,r.jsx)("p",{children:e.organizers}),e.website&&(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Website"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:e.website,target:"_blank",rel:"noopener noreferrer",children:e.website})})]})]})]},`spt-${t}`)))]})]})},Ba=()=>{const e=[{title:"LM-KBC: Knowledge Base Construction from Pretrained Language Models (4th Edition)",organizers:"Jan-Christoph Kalo, Tuan-Phong Nguyen, Simon Razniewski and Bohui Zhang",description:"Large language models (LLMs) have advanced a range of semantic tasks and have also shown promise for knowledge extraction from the models itself. Although several works have explored this ability in a setting called probing or prompting, the viability of knowledge base construction from LMs remains underexplored. In the 4th edition of the LM-KBC challenge, we ask participants to build actual disambiguated knowledge bases from LMs, for given subjects and relations. In crucial difference to existing probing benchmarks like LAMA (Petroni et al., 2019), we make no simplifying assumptions on relation cardinalities, i.e., a subject-entity can stand in relation with zero, one, or many object-entities. Furthermore, submissions need to go beyond just ranking predicted surface strings and materialize disambiguated entities in the output, which will be evaluated using established KB metrics of precision and recall.\nnThis year's edition contains two breaking changes: (i) Disallowing fine-tuning, and (ii) disallowing external corpora, thus making this a true exploration of knowledge within a given LLM.",website:"https://lm-kbc.github.io/challenge2025/",social_media:"@lm_kbc (X)",social_media_url:"https://x.com/lm_kbc"},{title:"SemTab 2025: Semantic Web Challenge on Tabular Data to Knowledge Graph Matching",organizers:"Marco Cremaschi, Fabio D'Adda, Fidel Azanzi Jiomekong, Ernesto Jimenez-Ruiz and Oktie Hassanzadeh",description:"SemTab 2025 is the seventh edition of the Semantic Web Challenge on Tabular Data to Knowledge Graph Matching, continuing its tradition at ISWC since 2019. This year's challenge focuses on the role of Large Language Models (LLMs) in the semantic annotation of tabular data, evaluating their effectiveness in mapping table elements to concepts in a Knowledge Graph (KG). Participants will tackle key tasks such as cell-to-entity matching, column-to-class matching, and column-pair-to-property matching using updated datasets, including MammoTab and Secutable (Cybersecurity domain). The competition encourages both open-source solutions and the use of smaller LLMs, offering a dedicated ranking and prizes for these categories. Join us to advance the field of Semantic Table Interpretation (STI) and explore innovative approaches to data integration, cleaning, and knowledge discovery!",website:"https://sem-tab-challenge.github.io/2025/"},{title:"LLMs4OL 2025: The 2nd Large Language Models for Ontology Learning Challenge at ISWC 2025",organizers:"Hamed Babaei Giglou, Jennifer D'Souza, Nandana Mihindukulasooriya, Andrei Aioanei and S\xf6ren Auer",description:"The LLMs4OL Challenge explores the potential of Large Language Models (LLMs) in Ontology Learning (OL)\u2014a crucial process for structuring web knowledge and improving Semantic Web interoperability. Traditional ontology learning methods often struggle with scalability and adaptability, while LLMs offer new opportunities for automating knowledge extraction, taxonomy discovery, and ontology construction. This challenge focuses on enhancing ontology-based knowledge reuse rather than isolated knowledge generation. \nThis challenge expanded into four tasks of ontology learning: Terminology Extraction, Term Typing, Taxonomy Discovery, and Non-Taxonomic Relation Extraction. While fine-tuned LLMs have shown strong performance, their effectiveness across multi-domain scenarios remains an open challenge.  The second LLMs4OL Challenge introduces benchmarking datasets containing approximately 50 or more curated ontologies to support the development of LLM-based solutions. These datasets and approaches from participants from previous years will be made available as a Python library to provide a solid foundation for participants. ",website:"https://sites.google.com/view/llms4ol2025"},{title:"Agentic Pipeline Optimization for the Semantic Web",organizers:"Kaushik Roy",description:"TBD"}],[t,a]=(0,n.useState)([]),i=(0,n.useRef)([]),s=e=>{a((t=>t.includes(e)?t.filter((t=>t!==e)):[...t,e]))};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex flex-col pt-10 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-8 tracking-wide text-center",children:"Accepted Challenges"}),(0,r.jsx)("div",{className:"overflow-x-auto",children:(0,r.jsxs)("table",{className:"min-w-full table-auto border-collapse text-left text-sm lg:text-base",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Challenge Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 w-1/4",children:"Organizers"})]})}),(0,r.jsx)("tbody",{children:e.map(((e,t)=>(0,r.jsxs)("tr",{className:"border-b",children:[(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200 font-semibold",children:(0,r.jsx)("div",{onClick:()=>(e=>{i.current[e]&&(i.current[e].scrollIntoView({behavior:"smooth",block:"start"}),s(e))})(t),className:"hover:underline text[#e94607]",children:e.title})}),(0,r.jsx)("td",{className:"align-top p-4 border border-gray-200",children:e.organizers})]},t)))})]})}),(0,r.jsx)("br",{}),e.map(((e,a)=>(0,r.jsxs)("div",{ref:e=>i.current[a]=e,id:`details-${a}`,className:"p-4 border rounded-lg",children:[(0,r.jsxs)("div",{onClick:()=>s(a),className:"flex items-center gap-2 p-2 rounded",children:[(0,r.jsx)("span",{className:"transform transition-transform "+(t.includes(a)?"rotate-90":"rotate-0"),children:"\xbb"}),(0,r.jsx)("span",{className:"font-bold text-[#e94607] hover:underline",children:e.title})]}),t.includes(a)&&(0,r.jsxs)("div",{className:"mt-2",children:[(0,r.jsx)("h2",{children:"Organizers"}),(0,r.jsx)("p",{children:e.organizers}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Description"}),(0,r.jsx)("p",{children:e.description}),e.website&&(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Website"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:e.website,target:"_blank",rel:"noopener noreferrer",children:e.website})})]}),e.social_media&&(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Social Media"}),(0,r.jsx)("p",{children:(0,r.jsx)("a",{href:e.social_media_url,target:"_blank",rel:"noopener noreferrer",children:e.social_media})})]})]})]},a)))]})]})},Ua=()=>{const e="https://whova.com/static/frontend/xems/js/embed/embedagenda.js?eid=IFdnyZrwLbH67w3FIfuAO-dVynWi058nPp86kVvXP9c%3D&host=https://whova.com";return(0,n.useEffect)((()=>{const t=document.createElement("script");return t.src=e,t.type="text/javascript",t.id="embeded-agenda-script",t.async=!0,document.body.appendChild(t),()=>{const e=document.getElementById("embeded-agenda-script");e&&document.body.removeChild(e)}}),[e]),(0,r.jsx)("div",{children:(0,r.jsx)("div",{title:"Whova event and conference app",id:"whova-agendawidget",children:(0,r.jsx)("p",{id:"whova-loading",children:"Loading..."})})})},Ja=()=>{const e={margin:"8px 0",color:"#333"};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex flex-col pt-10 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:px-32 px-8 overflow-visible",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Schedule"}),(0,r.jsx)(Ua,{}),(0,r.jsx)("div",{style:{display:"flex",padding:"5px"},children:(0,r.jsxs)("div",{style:{width:"560px"},children:[(0,r.jsxs)("p",{style:e,children:[(0,r.jsx)("strong",{children:"WS"})," - workshop"]}),(0,r.jsxs)("p",{style:e,children:[(0,r.jsx)("strong",{children:"T"})," - tutorial"]}),(0,r.jsxs)("p",{style:e,children:[(0,r.jsx)("strong",{children:"DS"})," - Dagsthul style workshop"]}),(0,r.jsxs)("p",{style:e,children:[(0,r.jsx)("strong",{children:"SWC"})," - Semantic Web Challenge"]}),(0,r.jsxs)("p",{style:e,children:[(0,r.jsx)("strong",{children:"J"})," - Journal Session"]}),(0,r.jsxs)("p",{style:e,children:[(0,r.jsx)("strong",{children:"S"})," - Main track Session"]})]})})]})]})},Qa="data:image/png;base64,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",Va=()=>(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("h1",{className:"text-3xl font-bold text-center text-[#e94607]",children:"Code of Conduct"}),(0,r.jsx)("div",{className:"flex justify-center mt-8 mb-8",children:(0,r.jsx)("img",{src:Qa,alt:"Semantic Web Science Association",className:"w-full max-w-3xl rounded-xl shadow-md"})}),(0,r.jsxs)("div",{className:"text-lg space-y-4 whitespace-pre-line",children:[(0,r.jsx)("p",{children:"The International Semantic Web Conference (ISWC) is organized by the Semantic Web Science Association (SWSA) as a forum to encourage rich interactions and promote the free exchange of ideas to benefit the community. SWSA welcomes conference participants that foster inclusion and respect to all members of the community."}),(0,r.jsx)("p",{children:"Our association is dedicated to providing a respectful and inclusive conference experience for everyone. Respectful behavior is always assumed and expected of community members during all conference events, online discussions about conference topics, and networking events held after hours. Conference participants are expected to interact with others in a respectful and courteous manner, regardless of age, race, ethnicity, national origin, ancestry, gender, sexual orientation, gender identity, gender presentation, physical appearance, religious affiliation, creed, marital status, differing abilities, medical conditions, personal characteristics, or technology choices."}),(0,r.jsx)("p",{children:"Abusive, racist, sexist, homophobic, intimidating, harassing, or threatening behavior towards any other conference participant or directed at any organizer, student volunteer, sponsor, conference staff or locals, will not be tolerated."}),(0,r.jsx)("p",{children:"SWSA disapproves of offensive actions, aggressive acts, or comments that intimidate or disparage others. SWSA will not tolerate any kind of harassment, including but not limited to:"}),(0,r.jsxs)("ul",{className:"ul-disc",children:[(0,r.jsx)("li",{children:"Verbal attacks, accusations, bullying, or offensive comments"}),(0,r.jsx)("li",{children:"Aggressive or intimidatory questioning"}),(0,r.jsx)("li",{children:"Sustained disruption during presentations and other events"}),(0,r.jsx)("li",{children:"Unwelcome sexual attention"}),(0,r.jsx)("li",{children:"Inappropriate physical contact"}),(0,r.jsx)("li",{children:"Deliberate intimidation or stalking, both in person and online"}),(0,r.jsx)("li",{children:"Sexual and racist images and materials in public spaces"}),(0,r.jsx)("li",{children:"Ignoring, encouraging, or advocating any of the above behaviors"})]}),(0,r.jsx)("p",{children:"SWSA expects all community members to endorse this code of conduct, and to prevent and discourage any undesired behaviors actively. Everyone should feel empowered to politely engage when themselves or others are disrespected, and to raise awareness and understanding of this code of conduct. Conference participants asked to stop any unacceptable behavior are expected to comply immediately."}),(0,r.jsx)("p",{children:"To report any behavior that makes you or others uncomfortable, please contact (by email or in person) any of the SWSA members, who are committed to treating such reports confidentially."}),(0,r.jsx)("p",{children:"Those violating these rules may be sanctioned or expelled from the conference without a refund at the discretion of SWSA."}),(0,r.jsx)("p",{children:"Sponsors are also subject to the code of conduct in events, images, and other materials."}),(0,r.jsx)("p",{children:"This code of conduct complements all legal rights that apply to particular situations."}),(0,r.jsx)("h2",{className:"h2-border-bottom",children:"References"}),(0,r.jsx)("div",{className:"mt-4 text-lg",children:(0,r.jsxs)("ul",{className:"ul-disc lg:text-lg",children:[(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"http://confcodeofconduct.com/",target:"_blank",children:"confcodeofconduct.com"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://www.w3.org/Consortium/cepc/",children:"W3C Code of Ethics and Professional Conduct"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://www.aclweb.org/adminwiki/index.php?title=Anti-Harassment_Policy",children:"ACL Anti-Harassment Policy"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://www.iscb.org/ismbeccb2015-general-info/ismbeccb2015-coc",target:"_blank",children:"ISMB ECCB Code of Conduct"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://chi2017.acm.org/diversity-inclusion-statement.html",target:"_blank",children:"ACM CHI Diversity Statement"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://sites.google.com/view/aiide2017/home/code-of-conduct?authuser=0",target:"_blank",children:"AIIDE 2017 Code of Conduct"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"http://www.humancomputation.com/2017/codeofconduct.html",target:"_blank",children:"Human Computation CoC"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"http://www.ifaamas.org/harassment.html",children:"IFAAMAS Harassment Policy"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://github.com/Polymer/polymer/wiki/Code-of-Conduct",target:"_blank",children:"Polymer GitHub CoC"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"http://geekfeminism.wikia.com/",target:"_blank",children:"Geek Feminism Wiki"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"http://geekfeminism.wikia.com/wiki/Timeline_of_incidents",target:"_blank",children:"Timeline of Incidents"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://implicit.harvard.edu/implicit/takeatest.html",target:"_blank",children:"Harvard Implicit Bias Tests"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://www.projectcallisto.org/",target:"_blank",children:"Project Callisto"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"http://swsa.semanticweb.org/content/code-conduct-iswc",target:"_blank",children:"SWSA Code of Conduct"})})]})}),(0,r.jsx)("br",{}),(0,r.jsxs)("p",{children:["Source: ",(0,r.jsx)("a",{href:"http://swsa.semanticweb.org/content/code-conduct-iswc",target:"_blank",children:"http://swsa.semanticweb.org/content/code-conduct-iswc"})]})]})]})]}),Ya=a.p+"static/media/venue_map.ab36a16addb7659cd7eb.png",Xa=()=>(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("h1",{className:"text-3xl font-bold text-center text-[#e94607]",children:"Venue and Accommodations"}),(0,r.jsx)("h2",{children:"Venue"}),(0,r.jsxs)("p",{children:["The conference will take place at the ",(0,r.jsx)("a",{href:"https://www.nara-cc.jp/english/#access",target:"_blank",rel:"noopener noreferrer",children:"Nara Prefectural Convention Center"}),", a state-of-the-art facility that opened in 2020. Centrally located in Nara City, between Nara Park and Heijo Palace Site, the venue is surrounded by UNESCO World Heritage sites that embody the region\u2019s deep cultural heritage."]}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"The venue is easily accessible from major airports, ensuring a smooth journey for both international and domestic attendees."}),(0,r.jsx)("br",{}),(0,r.jsxs)("ul",{className:"ul-disc",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("a",{href:"https://www.kansai-airport.or.jp/en",target:"_blank",rel:"noopener noreferrer",children:"From Kansai International Airport (KIX)"}),": 90 minutes by airport bus, 100 minutes by train."]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("a",{href:"https://www.osaka-airport.co.jp/en",target:"_blank",rel:"noopener noreferrer",children:"From Osaka International Airport (Itami Airport - ITM)"}),": 70 minutes by airport bus, 110 minutes by train."]})]}),(0,r.jsx)("br",{}),(0,r.jsxs)("p",{children:["With excellent public transportation options and direct airport connections, reaching the Nara Prefectural Convention Center is convenient and efficient. Additionally, limousine buses provide direct access from both ",(0,r.jsx)("a",{href:"https://www.kate.co.jp/en/timetable/detail/NR?_fsi=8m9qr56S",target:"_blank",rel:"noopener noreferrer",children:"Kansai International Airport"})," and ",(0,r.jsx)("a",{href:"https://www-hankyu-kankobus-co-jp-e.athp.transer.com/limousine/timetable/T/#from",target:"_blank",rel:"noopener noreferrer",children:"Osaka International Airport"})," to the venue, further simplifying travel for attendees."]}),(0,r.jsx)("div",{className:"flex justify-center mt-8 mb-8",children:(0,r.jsx)("img",{src:Ya,alt:"Venue Map",className:"w-full max-w-3xl rounded-xl shadow-md"})}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"Hotels"}),(0,r.jsx)("br",{}),(0,r.jsx)("h3",{children:"Hotels near the venue"}),(0,r.jsxs)("ul",{className:"ul-disc",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("a",{href:"https://www.marriott.com/en-us/hotels/osajw-jw-marriott-hotel-nara/overview/",target:"_blank",rel:"noopener noreferrer",children:"JW Marriott Hotel Nara"})," (next to the venue)"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("a",{href:"https://www.novotelnara.com/en/",target:"_blank",rel:"noopener noreferrer",children:"Novotel Nara"})," (5-minute walk)"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("a",{href:"https://www.worldheritage.co.jp/annex/en/",target:"_blank",rel:"noopener noreferrer",children:"Hotel Asyl Nara Annex"})," (7-minute walk)"]}),(0,r.jsxs)("li",{children:[(0,r.jsx)("a",{href:"https://hotel.nara-royal.co.jp/en/",target:"_blank",rel:"noopener noreferrer",children:"Nara Royal Hotel"})," (10-minute walk) - ",(0,r.jsx)("b",{children:"Gala Dinner venue"})," (Wednesday, 5 November 2025)"]})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h3",{children:"Hotels around Kintetsu Shin-Omiya Station (15-minute walk from the venue)"}),(0,r.jsxs)("ul",{className:"ul-disc",children:[(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://www.toyoko-inn.com/search/detail/00183?lcl_id=en",target:"_blank",rel:"noopener noreferrer",children:"Toyoko Inn Nara Shin-Omiya Ekimae"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://www.superhoteljapan.com/en/s-hotels/nara/",target:"_blank",rel:"noopener noreferrer",children:"SUPER HOTEL Nara Shin-omiya Station"})}),(0,r.jsx)("li",{children:(0,r.jsx)("a",{href:"https://www.nara-halftime.com/en/index.html",target:"_blank",rel:"noopener noreferrer",children:"HOTEL HALFTIME"})})]}),(0,r.jsx)("br",{}),(0,r.jsx)("h3",{children:"Other Hotels"}),(0,r.jsxs)("p",{children:["Many hotels are located near ",(0,r.jsx)("strong",{children:"Kintetsu Nara Station"})," and ",(0,r.jsx)("strong",{children:"JR Nara Station"}),"."]}),(0,r.jsxs)("ul",{className:"ul-disc",children:[(0,r.jsxs)("li",{children:[(0,r.jsx)("strong",{children:"Kintetsu Nara Station"})," is the next station to ",(0,r.jsx)("strong",{children:"Kintetsu Shin-Omiya"})," (the nearest station to the venue)."]}),(0,r.jsxs)("li",{children:["From ",(0,r.jsx)("strong",{children:"JR Nara Station"}),", the venue is a 20-25 minutes walk or 12 minutes by bus and on foot."]})]})]})]}),Za=()=>(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("h1",{className:"text-3xl font-bold text-center text-[#e94607]",children:"Registration"}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:'After reviewing the conditions below, please proceed with your registration by clicking the "Register" button at the bottom of the page.'}),(0,r.jsx)("h3",{className:"text-xl font-semibold mt-4 mb-1",children:"Main Conference"}),(0,r.jsxs)("table",{className:"w-full mb-6 border border-gray-300 text-sm",children:[(0,r.jsx)("thead",{className:"bg-gray-100",children:(0,r.jsxs)("tr",{children:[(0,r.jsx)("th",{className:"p-2 border"}),(0,r.jsxs)("th",{className:"p-2 border",children:["Early Fee",(0,r.jsx)("br",{}),"(to Sep. 16th, 2025)"]}),(0,r.jsxs)("th",{className:"p-2 border",children:["Regular Fee",(0,r.jsx)("br",{}),"(to Oct. 31st, 2025)"]}),(0,r.jsx)("th",{className:"p-2 border",children:"Onsite Fee"})]})}),(0,r.jsxs)("tbody",{children:[(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"p-2 border",children:"Regular"}),(0,r.jsx)("td",{className:"p-2 border",children:"110,000 JPY"}),(0,r.jsx)("td",{className:"p-2 border",children:"125,000 JPY"}),(0,r.jsx)("td",{className:"p-2 border",children:"145,000 JPY"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"p-2 border",children:"Academic*"}),(0,r.jsx)("td",{className:"p-2 border",children:"95,000 JPY"}),(0,r.jsx)("td",{className:"p-2 border",children:"110,000 JPY"}),(0,r.jsx)("td",{className:"p-2 border",children:"130,000 JPY"})]}),(0,r.jsxs)("tr",{children:[(0,r.jsx)("td",{className:"p-2 border",children:"Student"}),(0,r.jsx)("td",{className:"p-2 border",children:"70,000 JPY"}),(0,r.jsx)("td",{className:"p-2 border",children:"85,000 JPY"}),(0,r.jsx)("td",{className:"p-2 border",children:"105,000 JPY"})]})]})]}),(0,r.jsxs)("p",{className:"mb-6 italic",children:["* ",(0,r.jsx)("b",{children:"Academic registration"})," refers to persons that are affiliated with a University or Research Institute. It does not refer to persons from industry for whom the Regular registration fee applies."]}),(0,r.jsx)("h3",{className:"text-xl font-semibold mt-4 mb-1",children:"Pre-conference Days, Nov. 2-3 (Workshops/Tutorials/Ph.D. Symposium)"}),(0,r.jsx)("p",{children:"Additional Fee:          30,000 JPY"}),(0,r.jsx)("p",{children:"Available only to Main Conference registrants. This option allows them to also attend the Pre-conference Days (Nov. 2-3)."}),(0,r.jsx)("h3",{className:"text-xl font-semibold mt-4 mb-1",children:"Pre-conference Days, Nov. 2-3 (Workshops/Tutorials/Ph.D. Symposium) ONLY"}),(0,r.jsx)("p",{children:"Fee:          60,000 JPY"}),(0,r.jsx)("p",{children:"This ticket is for those NOT registered for the Main Conference."}),(0,r.jsx)("p",{children:'To attend both, please register and pay for both "the Main Conference (Nov. 4-6)" and "the Pre-conference Days (Nov. 2-3) option".'}),(0,r.jsx)("h3",{className:"text-xl font-semibold mt-4 mb-1",children:"Additional Gala Dinner Ticket for an Accompanying Persons"}),(0,r.jsx)("p",{children:"Fee:          10,000 JPY"}),(0,r.jsx)("p",{children:(0,r.jsx)("b",{children:"Note"})}),(0,r.jsxs)("ul",{className:"list-disc list-inside mb-6",children:[(0,r.jsxs)("li",{children:["If you wish to ",(0,r.jsx)("b",{children:"attend both the Main Conference (Nov. 4-6) and the Pre-conference Days (Nov. 2-3)"}),", please ensure you select both the appropriate ",(0,r.jsx)("b",{children:'"Main Conference Registration fee"'})," and ",(0,r.jsx)("b",{children:'"the Pre-conference Days, Nov. 2-3 (Workshops / Tutorials / Ph.D. Symposium) option"'}),", and proceed with payment accordingly."]}),(0,r.jsxs)("li",{children:["If you wish to attend ",(0,r.jsx)("b",{children:"ONLY the Pre-conference Days (Nov. 2-3)"}),", please select ",(0,r.jsx)("b",{children:'"the Pre-conference Days, Nov. 2-3 (Workshops / Tutorials / Ph.D. Symposium) ONLY"'}),"."]})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mt-6 mb-2",children:"Main Conference Registration includes:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside mb-6",children:[(0,r.jsx)("li",{children:"Access to all main conference sessions (4\u20136 November 2025)"}),(0,r.jsx)("li",{children:"Lunch and coffee breaks during the main conference (4\u20136 November)"}),(0,r.jsx)("li",{children:"Conference materials"}),(0,r.jsx)("li",{children:"Posters & Demos session and reception on Tuesday, 4 November 2025"}),(0,r.jsx)("li",{children:"Gala Dinner on Wednesday, 5 November 2025"}),(0,r.jsx)("li",{children:"Access to the exhibition area"})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mt-6 mb-2",children:"Pre-conference Days option includes:"}),(0,r.jsxs)("ul",{className:"list-disc list-inside mb-6",children:[(0,r.jsx)("li",{children:"Access to Workshops/Tutorials/Ph.D. Symposium sessions (2\u20133 November 2025)"}),(0,r.jsx)("li",{children:"Lunch and coffee breaks during both days (2\u20133 November)"})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mt-6 mb-2",children:"Additional Gala Dinner Ticket for an Accompanying Persons includes:"}),(0,r.jsx)("ul",{className:"list-disc list-inside mb-6",children:(0,r.jsx)("li",{children:"Gala Dinner (Wednesday, 5 November 2025)"})}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mt-6 mb-2",children:"Terms & Conditions"}),(0,r.jsxs)("ul",{className:"list-disc list-inside mb-6",children:[(0,r.jsx)("li",{children:"All registration fees are listed in Japanese Yen (JPY/\uffe5) and include tax."}),(0,r.jsx)("li",{children:"Payment in any other currency will not be accepted."}),(0,r.jsx)("li",{children:"The applicable fee is based on the date of receipt of both the registration request and payment. If either is received after midnight (Japan Standard Time) on the relevant deadline date, the higher fee will apply."}),(0,r.jsxs)("li",{children:["A confirmation email including a ",(0,r.jsx)("b",{children:"receipt"})," and a ",(0,r.jsx)("b",{children:"QR code"})," will be sent after your registration is completed."]}),(0,r.jsxs)("li",{children:["Please present the ",(0,r.jsx)("b",{children:"QR code"})," at the registration desk at the conference venue."]})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mt-6 mb-2",children:"Payment Details"}),(0,r.jsxs)("ul",{className:"list-disc list-inside mb-6",children:[(0,r.jsx)("li",{children:"Registration fees can be paid by credit card."}),(0,r.jsx)("li",{children:"Accepted cards: VISA, MasterCard, American Express, and JCB."}),(0,r.jsx)("li",{children:"Payment is confirmed at the time of registration."})]}),(0,r.jsx)("h2",{className:"text-2xl font-semibold mt-6 mb-2",children:"Cancellation & Alteration Policy"}),(0,r.jsxs)("ul",{className:"list-disc list-inside mb-6",children:[(0,r.jsxs)("li",{children:["All cancellations or changes must be made in writing via email to: ",(0,r.jsx)("b",{children:"iswc2025-reg@easychair.org"})]}),(0,r.jsxs)("li",{children:["Cancellation fees apply as follows:",(0,r.jsxs)("ul",{className:"ul-circle list-inside ml-6 mt-2",children:[(0,r.jsx)("li",{children:"Until September 2, 2025: A refund will be issued after deducting a 6% processing fee from the total registration fee."}),(0,r.jsx)("li",{children:"From September 3, 2025 onward: No refund will be issued"})]})]})]}),(0,r.jsx)("div",{className:"text-center",children:(0,r.jsx)("a",{href:"https://app.payvent.net/embedded_forms/show/6856133c004fb3266a6f163a?locale=en",target:"_blank",className:"inline-block bg-[#e94607] text-white font-bold text-lg py-3 px-8 rounded-lg shadow-md hover:bg-[#c83c06] transition-colors duration-300",children:"Register"})})]})]}),$a=()=>(0,r.jsxs)("div",{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsxs)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:[(0,r.jsx)("div",{className:"container mx-auto px-4 lg:px-8 lg:pb-12 mt-12",children:(0,r.jsx)("h1",{className:"text-3xl font-bold text-center text-[#e94607]",children:"SWSA Distinguished Dissertation Award"})}),(0,r.jsx)("div",{className:"flex justify-center mt-8 mb-8",children:(0,r.jsx)("img",{src:Qa,alt:"Semantic Web Science Association",className:"w-full max-w-3xl rounded-xl shadow-md"})}),(0,r.jsxs)("div",{className:"text-md lg:text-lg font-[300] lg:mx-10 sm:mx-2",children:[(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"The Semantic Web Science Association (SWSA) invites applications for the 2025 SWSA Distinguished Dissertation Award. "}),(0,r.jsx)("p",{children:"The award will be presented during ISWC 2025."}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"Eligibility: "}),(0,r.jsx)("p",{children:"Eligible doctoral dissertations are those that present innovative research results related to the combination of semantics, data, and the Web, which have been awarded a PhD strictly between January 01, 2024 and June 30, 2025, and which have not previously been nominated for this award. The selection of the dissertation will be based on the originality, significance, and impact of the work. Evidence of such impact includes (but is not limited to) publications at highly selective conferences and journals in the field."}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"Award committee: "}),(0,r.jsx)("p",{children:"The award committee, which will comprise two members of SWSA and a number of external experts, will be the final arbiter in the decision process. The award committee may decide to consult additional external assessors and reserves the right not to award the prize if the applications do not meet the expected quality level."}),(0,r.jsx)("br",{}),(0,r.jsx)("p",{children:"The award:"}),(0,r.jsx)("p",{children:'The award includes a certificate and a 1000 euros payment. A free registration to ISWC 2025 will also be covered. In addition, IOS Press will invite the winner to publish the dissertation as a book in the "Studies on the Semantic Web" series.'}),(0,r.jsx)("br",{}),(0,r.jsx)("h2",{children:"HOW TO APPLY"}),(0,r.jsxs)("p",{children:["Please refer to the application guidelines and instructions on the ",(0,r.jsx)("a",{href:"https://swsa.semanticweb.org/content/swsa-distinguished-dissertation-award",target:"_blank",rel:"noopener noreferrer",children:"SWSA page"})]})]})]})]}),en=[{title:"Attributes, Taxonomies and Semantic alignment for Automated Research Software Classification",authors:"Jenifer Tabita Ciuciu-Kiss",abstract:"Research software (RS) plays a critical role in computational science, yet remains poorly categorized and difficult to discover or reuse. This research explores RS classification by investigating how textual and metadata attributes can be leveraged to develop scalable, interpretable classification methodologies. Existing taxonomies are evaluated through alignment with scientific knowledge graphs to identify redundancies and structural gaps. Labeled datasets are constructed by linking publications to software repositories, and RS attributes, such as README files, abstracts, and source code features are benchmarked using multiple machine learning models and embedding strategies. A methodology that integrates semantic enrichment and transformer-based models is proposed for robust RS classification. Preliminary findings highlight the informativeness of publication abstracts for classification tasks and expose limitations in current community-defined taxonomies."},{title:"Viewsari: Enabling New Perspectives on the Renaissance with a Knowledge Graph of Giorgio Vasari\u2019s The Lives",authors:"Sarah Rebecca Ondraszek",abstract:"In the digital humanities (DH), semantic technologies have been recognized as providing the necessary bits and pieces to represent the complex and often ambiguous nature of humanities data. Despite this growing interest, a lack of practical frameworks for modeling the complex, usually multifaceted, multimodal, and multilingual historical sources remains. This paper presents Viewsari, an ongoing Ph.D. project aiming to build a knowledge graph (KG) based on Giorgio Vasari\u2019s Lives of the Most Excellent Painters, Sculptors, and Architects (1568), referred to as The Lives. This collection of biographies of important Renaissance artists, recounting tales of their lives and describing their artistic styles and works, is widely regarded as the first modern work of art history. With it, Vasari shaped the canon of the Italian Renaissance. Viewsari draws on information extraction and aims to contextualize annotations from Vasari\u2019s The Lives and its translations, addressing the challenges of working with complex, multilingual historical texts. Situated at the intersection of DH and the Semantic Web, it demonstrates how modular, pattern-driven ontology development in the DH, leveraging Ontology Design Patterns (ODPs) and the eXtreme Design (XD) methodology, can support the structured representation and exploration of information across different editions and linguistic versions. The central goal is to conceptualize reusable requirements and best practices for ontology development and KG construction in the DH, improving the use of semantic technologies in the field. Viewsari contributes a prototypical framework for the enrichment and interconnection of multifaceted cultural heritage texts, independent of the form of representation or language of the source, so that different versions can be analyzed at a large scale."},{title:"Large Language Models as Assistants for Ontology Engineering",authors:"Javad Saeedizade",abstract:"Ontology engineering is often a complex, time-consuming and costly process that relies heavily on expert engineers. Even experienced ontology engineers introduce errors, such as incompleteness in terms of requirements, and falling into common ontology pitfalls, underscoring the challenge of producing high-quality ontologies. This PhD proposal aims to address these issues by creating an LLM-based assistant for both ontology development and ontology evaluation. The envisioned assistant will offer suggestions during conceptual modelling, pattern-based suggestions for class and property definitions, and real-time validation checks to identify modelling errors. By embedding these capabilities into a unified tool, the research seeks to reduce dependence on expert intervention, enabling mid-level and novice ontology engineers and organisations to develop reliable ontologies more independently, while simultaneously accelerating the workflow of expert ontologists. The outcome of this work will be a software tool that supports and streamlines the ontology engineering lifecycle---facilitating creation, error detection, and quality assessment---thereby making ontology creation faster, less error-prone, and more accessible to non-experts."},{title:"Towards Provable Provenance and Privacy-Preserving Queries in Decentralised Data Architectures",authors:"Jesse Wright",abstract:"This work develops a standardised declarative query language (data sublanguage) for accessing graph database(s) alongside zero-knowledge verifiable provenance statements \u2013 including of data sourcing, integrity and derivations. Supported queries include 'Is Jesse over 21 according to facts issued by EU or UK governments' \u2013 the verifiable response reveals only the answer: 'yes.' This query language is first implemented in query engine(s) which evaluate queries over a locally indexed graph database. Support is then added for queries over the union of data residing across independent and potentially malicious graph-databases; by developing algorithms and architectures which minimize data disclosure between sources when planning and executing queries."},{title:"Extracting problem-solving knowledge from LLMs with reasoning abilities",authors:"Maxime Haurel",abstract:"Automatic Knowledge Acquisition (AKA) aims to automate the process between domain experts and knowledge engineers, that is to create a domain Knowledge Base (KB). Such automation is necessitated because the collaboration between domain experts and knowledge engineers is costly. Modern approaches use Large Language Models (LLMs) simulating domain experts to create ontologies and knowledge graphs. Recently, LLMs with reasoning abilities received attention due to their great performances on several benchmarks. These LLMs output reasoning traces that lead to the answer. This early stage PhD thesis (started 7 months ago) focuses on the use of those reasoning traces in the automatic construction of a Knowledge Base (KB), under the assumption that they express the knowledge necessary to solve the problem prompted to the LLM. To achieve this, a first step consists in obtaining from the LLM reasoning traces that are expressed in a well-defined formalism. The results of our initial experiments show that, while some models are able to generate reasoning traces backed by formally expressed knowledge, there is still room for improvement. The remainder of this PhD will therefore involve improving LLMs with reasoning abilities to increase their capability to express the knowledge they used for problem solving in a way that is exploitable for AKA, coherent, and valid."},{title:"Quality Without Borders: A Modular Approach to Unified Knowledge Graph Assessment",authors:"Gabriele Tuozzo",abstract:"Knowledge Graphs (KGs) have emerged as critical infrastructure for data integration and semantic enrichment across diverse domains, from scientific research to enterprise applications. However, quality assessment of KGs remains fragmented due to the coexistence of isolated evaluation paradigms, including KG-specific quality frameworks, the FAIR principles, and the 5-star open data scheme. This fragmentation limits metric reusability and impedes the development of unified quality assessment strategies across the Semantic Web ecosystem. This three-year doctoral research proposes the design of a comprehensive Shared Framework that formally aligns existing quality assessment paradigms for KGs. The framework establishes systematic mappings between KG quality dimensions, FAIR principles, and the 5-star open data scheme, enabling the reuse and extension of existing quality assessment tools to efficiently evaluate FAIRness and openness without computational redundancy. A preliminary mapping analysis between KG quality dimensions and FAIR principles reveals significant alignment opportunities while exposing critical gaps, particularly in Findability aspects. Empirical evaluation of existing catalogs, such as the LOD Cloud, confirms widespread Findability issues including broken links, empty datasets, and missing KGs. To address these challenges, the research proposes a modular, automated KG aggregator employing multiple discovery strategies\u2014crawler-based indexing, search engine APIs, repository harvesting, and Large Language Model guidance\u2014to ensure comprehensive and timely coverage. The research contributes to establishing unified approaches for KG quality assessment and supports broader efforts toward FAIR, open, and high-quality Linked Data. The long-term vision includes developing an interactive 'KG Weather Station' dashboard providing real-time, actionable insights on KG quality, FAIR compliance, and openness for both technical and non-technical stakeholders across the Semantic Web ecosystem."},{title:"A Knowledge-Guided Hybrid Learning Framework for Semantic Constraint Integration in Time Series Models",authors:"Simon Burbach",abstract:"Current time series models often operate solely on sensor data, lacking the contextual understanding that domain knowledge provides. This limitation particularly exists in domains like maritime operations or medical monitoring, where sensor data are often noisy, incomplete, or ambiguous. To address this gap, this doctoral research proposes a hybrid learning framework that integrates semantic knowledge from ontologies, domain texts, and expert-defined rules into the modeling process as formal constraints. The framework comprises three main building blocks: (1) learning joint representations from heterogeneous sources such as time series, structured knowledge, and unstructured text; (2) extracting and formalizing semantic knowledge into symbolic or functional constraints; and (3) fusing these components into a hybrid framework, where formal constraints complement machine-learned patterns. Initial work has been conducted in the maritime domain and will be extended to medical datasets for cross-domain evaluation."},{title:"SLAi: Symbolic Language for Artificial Intelligence Systems",authors:"Alexis Ellis",abstract:"The rapid integration of Artificial Intelligence systems (AI) into our daily lives creates challenges with the transparency, explainability, and collaborative communication of these systems. There is a clear separation in understanding between interdisciplinary research groups, stakeholders, developers, and everyday end-users. Creating a common 'language' benefits not only current conversations centering AI, but future conversations and directions. With a common 'language,' the spectrum of AI end-users can voice their concerns and opinions, resulting in its end-users becoming more active contributors to the conversation. This research builds a common (visual) language framework that utilizes a symbology rooted in ontology for representing components of AI systems."},{title:"Enhancing Recommendation Systems Using Large Language Models and Personalized Knowledge Graphs",authors:"Fernando Spadea",abstract:"We investigate how large language models (LLMs), when paired with interpretable and user-controlled personalized knowledge graphs (PKGs), can power privacy-preserving, decentralized recommendation systems. This work lays the groundwork for more intelligent and user-aligned personal digital assistants that respects user autonomy and data sovereignty. A key focus of our research is exploring how LLMs can be fine-tuned in federated settings to balance personalization with privacy. To this end, we evaluate several fine-tuning methods and compare their performance to select the best one. Early results indicate that LLMs fine-tuned to use PKGs can outperform symbolic and embedding-based KGC models (e.g., KBGAT, HAKE) in both centralized and federated contexts, and that fine-tuning with Kahneman-Tversky Optimization (KTO) is more resilient to lopsided data distributions."},{title:"Open Knowledge Extraction from Dialogue Using In-Context Learning",authors:"Kelsey Rook",abstract:"While Open Information Extraction and Knowledge Graph construction have become viable tasks over formal texts such as research papers and news articles, they remain poorly suited to extracting knowledge from natural human conversation. Dialogue presents unique challenges for information extraction: information is often distributed across multiple dialogue turns and perspectives, and conversational acts such as clarification, disagreement, and hedging complicate the identification of factual assertions. Despite the increasing availability of conversational data, dialogue remains an underutilized source of structured knowledge. In my dissertation research, I aim to investigate how the structural and functional features of dialogue can be leveraged to improve Open Knowledge Extraction using large language models. I propose four core contributions: (1) The formalization of the task of Open Knowledge Extraction from Dialogue, (2) the creation of a dataset towards this task, (3) a perspective-aware ontology of dialogue, and (4) methods for in-context learning for Open Knowledge Extraction from Dialogue. I aim to evaluate the performance of my approach against current approaches such as fine-tuning, and demonstrate the utility of dialogue-aligned knowledge graphs and the dialogue ontology on downstream tasks involving machine understanding of human conversation."},{title:"Examining the Representation of Uncertainty in Knowledge Graphs for Copolymer Chemistry",authors:"Sarah T. Bachinger",abstract:"In copolymer chemistry, researchers aim to create molecules with desirable properties. The experimental process towards a successful synthesis inherently contains uncertainties in different forms and can be described as a structured trial-and-error process. Using ontologies to describe this domain could help in predicting the synthesis setup and conserve resources. In this thesis project, we want to examine how the representation of different uncertainties in the ontology can increase the prediction success. Guided by four research questions, we detail our approach consisting of expert interviews, mapping of uncertainties from the interviews to known representations on Knowledge Graphs (KGs), implementation of a novel uncertainty representation in KGs, and its evaluation."}],tn=[{title:"Formalizing Repairs for Wikidata Constraint Violations: A Taxonomy and Empirical Analysis",authors:"Nicolas Ferranti, Axel Polleres, Dayane Guimaraes and Jairo Souza",abstract:"Collaboratively maintained knowledge graphs like Wikidata rely on property constraints to detect data inconsistencies. This paper systematically formalizes potential repairs for Wikidata constraint violations, presenting a comprehensive taxonomy of repair strategies encompassing both instance-level (A-box) and terminological-level (T-box) changes. T-box repairs, which alter constraint definitions or Wikidata's class hierarchy, can simultaneously address multiple violations and, to the best of our knowledge, have not been investigated in detail before. We observe repairs over time and evaluate how specific patterns within our taxonomy are applied in practice. Our analysis of historical data reveals insights into the prevalence of repair patterns in Wikidata's collaborative environment. The results indicate that T-box repairs are particularly relevant for certain constraint types and the overall consolidation of Wikidata, where modifying constraint definitions can reduce the number of recurring violations."},{title:"Beyond Manual Labels: Unsupervised Graph-Based Explanations for Error Analysis in Image Classifiers",authors:"Youmna Ismaeil, Jan Hendrik Metzen, Trung-Kien Tran, Hendrik Blockeel and Daria Stepanova",abstract:"Training datasets often contain subtle but irrelevant patterns that bias image classifiers and limit their generalization. Prior research has focused on detecting biases in misclassified data using manually defined dimensions, such as age or gender. However, these approaches often rely on manually predefined dimensions and overlook biases present in correctly classified data, making them labor-intensive and limiting their coverage. We propose an unsupervised framework that leverages commonsense knowledge and open-source foundation models to automatically derive semantic dimensions and their values, identifying biases that influence correct and incorrect classifications of data. Using these dimensions and values, we construct scene graphs and identify distinctive graph patterns for correctly and incorrectly classified data, uncovering how combinations of semantic dimensions impact classifier decisions. Evaluations confirm that our scene graphs are of high quality, as they include information from manual annotations while being denser and more informative than manually constructed graphs. Moreover, our framework demonstrates high predictive accuracy, effectively identifying patterns responsible for correct and incorrect classifications, with F1 scores ranging from 0.72 to 0.96. It also proves effective for error analysis and proactive bias detection in datasets."},{title:"GLIDE: Knowledge Graph Linking using Distance-Aware Embeddings",authors:"Alexander Becker, Axel-Cyrille Ngonga Ngomo and Mohamed Ahmed Sherif",abstract:"The number of datasets on the web of data increases continuously. However, the knowledge contained therein cannot be fully utilized without finding links between the entities contained in these datasets. Equivalent entities cannot be identified solely by checking the equivalence of IRIs because of the different origins and naming schemes of different data providers. Yet, such equivalences can be discovered by computing the similarity of their attributes. In this paper we propose GLIDE, an approach that links entities from two different datasets by embedding a joint model of these datasets enriched by additional relations describing the similarity of literals. The joint model is embedded into a latent vector space while paying attention to juxtaposing similar literals. We evaluate our approach against state-of-the-art algorithms using real-world datasets commonly used in link discovery literature. The results show that GLIDE outperforms all baselines on 5 of 7 datasets with perfect or near-perfect accuracy. Our approach achieves its best performance on datasets that feature several literals with similarities. Our experiments indicate that researchers should not only pay attention to equal literals in knowledge graph embedding but should also be aware of the distance between similar literals."},{title:"CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting",authors:"David Maria Schmidt, Raoul Schubert and Philipp Cimiano",abstract:'Language interpretation is a compositional process, in which the meaning of more complex linguistic structures is inferred from the meaning of their parts. Large language models possess remarkable language interpretation capabilities and have been successfully applied to interpret questions by mapping them to SPARQL queries. An open question is how systematic this interpretation process is. Toward this question, in this paper, we propose a benchmark for investigating to what extent the abilities of LLMs to interpret questions are actually compositional. For this, we generate three datasets of varying difficulty based on graph patterns in DBpedia, relying on Lemon lexica for verbalization. Our datasets are created in a very controlled fashion in order to test the ability of LLMs to interpret structurally complex questions, given that they have seen the atomic building blocks. This allows us to evaluate to what degree LLMs are able to interpret complex questions for which they "understand" the atomic parts. We conduct experiments with models of different sizes using both various prompt and few-shot optimization techniques as well as fine-tuning. Our results show that performance in terms of macro F1 degrades from 0.45 over 0.26 down to 0.09 with increasing deviation from the samples optimized on. Even when all necessary information was provided to the model in the input, the F1 scores do not exceed 0.57 for the dataset of lowest complexity. We thus conclude that LLMs struggle to systematically and compositionally interpret questions and map them into SPARQL queries.'},{title:"Language Models as Ontology Encoders",authors:"Hui Yang, Jiaoyan Chen, Yuan He, Yongsheng Gao and Ian Horrocks",abstract:"OWL (Web Ontology Language) ontologies which are able to formally represent complex knowledge and support semantic reasoning have been widely adopted across various domains such as healthcare and bioinformatics. Recently, ontology embeddings have gained wide attention due to its potential to infer plausible new knowledge and approximate complex reasoning. However, existing methods face notable limitations: geometric model-based embeddings typically overlook valuable textual information, resulting in suboptimal performance, while the approaches that incorporate text, which are often based on language models, fail to preserve the logical structure. In this work, we propose a new ontology embedding method OnT, which tunes a Pretrained Language Model (PLM) via geometric modeling in a hyperbolic space for effectively incorporating textual labels and simultaneously preserving class hierarchies and other logical relationships of Description Logic EL. Extensive experiments on four real-world ontologies show that OnT consistently outperforms the baselines including the state-of-the-art across both tasks of prediction and inference of axioms. OnT also demonstrates strong potential in real-world applications, indicated by its robust transfer learning abilities and effectiveness in real cases of constructing a new ontology from SNOMED CT."},{title:"Ontology-enhanced Knowledge Graph Completion using Large Language Models",authors:"Wenbin Guo, Xin Wang, Jiaoyan Chen, Zhao Li and Zirui Chen",abstract:"Large Language Models (LLMs) have been extensively adopted in Knowledge Graph Completion (KGC), showcasing significant research advancements. However, as black-box models driven by deep neural architectures, current LLM-based KGC methods rely on implicit knowledge representation with parallel propagation of erroneous knowledge, thereby hindering their ability to produce conclusive and decisive reasoning outcomes. We aim to integrate neural-perceptual structural information with ontological knowledge, leveraging the powerful capabilities of LLMs to achieve a deeper understanding of the intrinsic logic of the knowledge. We propose an ontology enhanced KGC method using LLMs --- OL-KGC. It first leverages neural perceptual mechanisms to effectively embed structural information into the textual space, and then uses an automated extraction algorithm to retrieve ontological knowledge from the knowledge graphs (KGs) that needs to be completed, which is further transformed into a textual format comprehensible to LLMs for providing logic guidance. Finally, KnoenKGC integrates the structural information of the KG with ontological knowledge using LLMs for triple classification. We conducted extensive experiments on three widely-used benchmarks --- FB15K-237, UMLS and WN18RR. The experimental results demonstrate that KnoenKGC significantly outperforms existing mainstream KGC methods across multiple evaluation metrics, achieving state-of-the-art performance. The implementation of the algorithm and related data have been open-sourced."},{title:"HypKG: Hypergraph-based Knowledge Graph Contextualization for Precision Healthcare",authors:"Yuzhang Xie, Xu Han, Ran Xu, Xiao Hu, Jiaying Lu and Carl Yang",abstract:"Knowledge graphs (KGs) are important products of the semantic web, which are widely used in various application domains. Healthcare is one of such domains where KGs are intensively used, due to the high requirement for knowledge accuracy and interconnected nature of healthcare data. However, KGs storing general factual information often lack the ability to account for important contexts of the knowledge such as the status of specific patients, which are crucial in precision healthcare. Meanwhile, electronic health records (EHRs) provide rich personal data, including various diagnoses and medications, which provide natural contexts for general KGs. In this paper, we propose HypKG, a framework that integrates patient information from EHRs into KGs to generate contextualized knowledge representations for accurate healthcare predictions. Using advanced entity-linking techniques, we connect relevant knowledge from general KGs with patient information from EHRs, and then utilize a hypergraph model to \u201ccontextualize\u201d the knowledge with the patient information. Finally, we employ hypergraph transformers guided by downstream prediction tasks to jointly learn proper contextualized representations for both KGs and patients, fully leveraging existing knowledge in KGs and patient contexts in EHRs. In experiments using a large biomedical KG and two real-world EHR datasets, HypKG demonstrates significant improvements in healthcare prediction tasks across multiple evaluation metrics. Additionally, by integrating external contexts, HypKG can learn to adjust the representations of entities and relations in KG, potentially improving the quality and real-world utility of knowledge."},{title:"AdaGCRAG: Adaptive Graph-Chunk Retrieval for Lightweight RAG",authors:"Yanqiu Zhang, Zhen Xu and Dongdong Huo",abstract:"Retrieval-Augmented Generation (RAG) mitigates hallucinations of large language models (LLMs) and improves factual accuracy by incorporating external knowledge during inference. However, existing RAG approaches face critical limitations in resource-constrained environments: (1) dense retrieval often introduces irrelevant or redundant content due to semantic overlap in vector space, (2) graph-based methods still depend on sophisticated reasoning capabilities that exceed the capacity of Small Language Models (SLMs). To address these challenges, we propose Adaptive Graph-Chunk RAG (AdaGCRAG), a lightweight, local, and query-adaptive RAG framework that integrates chunk-level retrieval with graph-structured reasoning. AdaGCRAG categorizes each input into Simple Specific Question (Simple SQ), Complex Specific Question (Complex SQ), or Abstract Question (Abstract Q) and adaptively controls the retrieval granularity and reasoning depth. It leverages Qwen3\u2019s dual-mode reasoning to minimize computation for simple tasks while enabling graph-based multi-hop inference for complex ones. A triple-level reranking module filters noisy subgraphs before fusion with dense retrieval results. AdaGCRAG runs efficiently on a single RTX 3070 GPU, making it suitable for personal agents and offline assistants. Experiments across five Question Answering (QA) benchmarks show consistent improvements over state-of-the-art lightweight RAG systems, achieving improvements of 9.5%, 6.9%, and 6.8% on HotpotQA, MultihopRAG, and MuSiQue, respectively, demonstrating its effectiveness under limited-resource settings. Our implementation is available at: https://anonymous.4open.science/r/AdaGCRAG."},{title:"FastER: On-Demand Entity Resolution in Property Graphs",authors:"Shujing Wang, Sibo Zhao, Shiqi Miao, Selasi Kwashie, Michael Bewong, Junwei Hu, Vincent M. Nofong and Zaiwen Feng",abstract:'Entity resolution (ER) is the problem of identifying and linking database records that refer to the same real-world entity. Traditional ER methods use batch processing, which becomes impractical with growing data volumes due to high computational costs and a lack of real-time capabilities. In many applications, users need to resolve entities for only a small portion of their data, making full data processing unnecessary\u2014a scenario known as "ER-on-demand". This paper proposes FastER, an efficient ER-on-demand framework for property graphs. Our approach uses graph differential dependencies (GDD) as a knowledge-encoding language to design effective filtering mechanisms that leverage both the structural and attribute semantics of graphs. We construct a blocking graph from the filtered subgraphs to reduce the number of candidate entity pairs that require comparison. Additionally, FastER incorporates Progressive Profile Scheduling (PPS), allowing the system to incrementally produce results throughout the resolution process. Extensive evaluations on multiple benchmark datasets demonstrate that FastER significantly outperforms state-of-the-art ER methods in computational efficiency and real-time processing for on-demand tasks, without compromising quality or reliability. We make FastER publicly available at the Github link: https://anonymous.4open.science/r/On_Demand_Entity_Resolution-9DFB'},{title:"Efficient Updates for Worst-Case Optimal Join Triple Stores",authors:"Alexander Bigerl, Liss Heidrich, Nikolaos Karalis and Axel-Cyrille Ngonga Ngomo",abstract:"It has been recently shown that worst-case optimal joins can significantly speed up query processing in RDF triple stores, especially in analytical workloads. However, this increase in query speed comes at the expense of updates being slow or not supported at all. We see this limited compatibility with updates as a key reason for the slow adoption of worst-case optimal joins in triple stores. In this paper, we address this challenge by presenting a fast, incremental insertion and deletion algorithm for the hypertrie, a worst-case optimal join data structure. This update algorithm can be used for offline bulk updates as well as online updates. Our evaluation on realistic update loads from DBpedia and scaling update sizes on Wikidata shows that the online performance of our algorithm is comparable to or better than that of traditional triple stores."},{title:"Parameter-efficient Federated Knowledge Graph Embedding Learning and Unlearning",authors:"Xiangrong Zhu, Yuexiang Xie, Yang Liu, Yaliang Li and Wei Hu",abstract:"Knowledge graph (KG) embedding aims to learn vector representations for entities and relations. To support distributed training and privacy protection, federated KG embedding collaboratively learns an embedding model among multiple organizations without directly sharing raw data. A federated KG embedding framework should be capable of incorporating both learning and unlearning paradigms, due to the dynamic nature of KGs and the potential need for visibility adjustment by KG owners. However, there are still several challenges in developing a federated KG embedding framework, including overcoming the communication and computation overhead caused by the huge number of entities and controlling the scope of influence when unlearning. In this paper, we propose a novel parameter-efficient federated KG embedding learning and unlearning framework, named PFLU. Specifically, we incorporate an anchor-based federated KG embedding technique to reduce computation and communication overhead when transferring knowledge. We address the anchor selection problem by formulating it as a maximum coverage problem and designing a greedy strategy for its resolution. Besides, to achieve a desirable balance between propagation and retention of unlearning effects, we adopt a two-stage mechanism consisting of structural and semantic unlearning. Extensive experiments on widely-used datasets show the superior parameter efficiency of PFLU over several baselines in both federated KG embedding learning and unlearning. Furthermore, we provide empirical evidence and discussions to show the effectiveness of the proposed anchor selection strategy."},{title:"The Graph Language: How Knowledge Graphs Speak to Large Language Models",authors:"Giuseppe Pirr\xf2",abstract:'Large Language Models (LLMs) excel at reasoning but benefit from grounding provided by Knowledge Graphs (KGs), although integrating these two knowledge representation paradigms is challenging. We introduce GRALAN (The Graph Language), a novel framework that enables KGs to "speak" directly in the LLM\u2019s semantic space through relational tokens\u2014learned representations that preserve KG structure and semantics. GRALAN\u2019s trainable graph language mediator generates structured relational tokens that can be fed into any frozen LLM, creating a versatile foundation for diverse knowledge-intensive applications, including reasoning, recommendation, and knowledge discovery. While this approach has broad implications across multiple domains, we demonstrate its effectiveness in question-answering as a concrete use case, where we re-frame the task as entity classification over nodes of a question-focused subgraph. Experiments across multiple benchmarks show that GRALAN significantly outperforms existing methods, particularly on complex multi-hop reasoning tasks, establishing a new paradigm for KG-LLM integration that maintains structural fidelity while leveraging LLMs\u2019 reasoning capabilities'},{title:"Are quality dimensions correlated? An empirical investigation",authors:"Maria Angela Pellegrino, Anisa Rula and Gabriele Tuozzo",abstract:"Data quality is a complex and multidimensional concept, hierarchically organized into categories, dimensions, and metrics. Although theoretical correlations among quality dimensions have been proposed, they have not yet been empirically validated. This study addresses this gap by systematically investigating whether such correlations hold in practice, comparing theoretical assumptions with empirical, data-driven insights over a five-quarter longitudinal analysis. Leveraging outputs from a freely available quality assessment tool, the findings challenge some prior assumptions, e.g., the relationship between timeliness and accuracy, while uncovering new correlations, including a positive association between interpretability and intrinsic-related dimensions. Through this empirical evidence, this work refines existing data quality models, enhances best practices for dataset management, and informs future efforts to optimize quality assessment frameworks in the Semantic Web."},{title:"SAT-Based Bounded Fitting for the Description Logic ALC",authors:"Maurice Funk, Jean Christoph Jung and Tom Voellmer",abstract:"Bounded fitting is a general paradigm for learning logical formulas from positive and negative data examples, that has received considerable interest recently. We investigate bounded fitting for the description logic ALC and all its syntactic fragments. We show that the related size-restricted fitting problem is NP-complete for any such fragment as well as for ALC, even in the special case of a single positive and a single negative example. By design, bounded fitting comes with probabilistic guarantees in Valiant's PAC learning framework. In contrast, we show that other classes of algorithms for learning ALC concepts do not provide such guarantees. In addition, we show how size-restricted fitting for ALC can be reduced to propositional satisfiability and present an implementation of bounded fitting using this reduction and a SAT solver. We discuss optimizations of our SAT-encoding and compare our implementation to other concept learning tools."},{title:"ProgKGC: Progressive Structure-Enhanced Semantic Framework for Knowledge Graph Completion",authors:"Zhuang Li, Yingwen Wu, Yachao Yuan and Jin Wang",abstract:"Knowledge graph completion (KGC) aims to predict missing links between entities based on known relational facts. Text-based methods typically leverage pretrained language models to extract semantic representations of entities, and some of these methods further incorporate graph structure information to enhance the representations. Despite these advances, current approaches face two significant limitations: insufficient integration of semantic and structural information, and incomplete neighborhood context representation that neglects tail-entity perspectives. In this work, we introduce a progressive semantic framework enhanced by structural signals, which is trained in stages by first establishing robust semantic representations and then gradually integrating graph attention to incorporate structural context. It also includes a bidirectional neighborhood aggregation mechanism that captures both head- and tail-entity contexts to enrich relational understanding. Experiments on two public datasets demonstrate the effectiveness of our method in improving KGC performance while keeping the architecture simple and lightweight."},{title:"Proxy-Enriched Imputation on Contextually Incomplete Web Tables",authors:"Denis Nagel, Jonas Mei\xdfner, Niklas Kiehne and Wolf-Tilo Balke",abstract:"Structured data in the form of Web tables and open data repositories lays the foundation for the Semantic Web. However, quality concerns are often raised, mostly with respect to accuracy and completeness. While missing value imputation is the go-to solution to fill in blanks, (1) it can only approximate known unknowns and (2) struggles if values are missing not at random. As a remedy, this paper combines semantically rich narratives with proven-quality knowledge graphs to dynamically assess the completeness of individual data sets while accounting for the user's intent, too. Having determined which values are actually missing, we leverage state-of-the-art NLP techniques to identify functionally dependent attributes as proxies for later value imputation. Being functionally dependent (at least to some degree), these attributes provide the necessary context in the sense of relatedness allowing for more sophisticated imputation techniques. As a proof of concept we demonstrate our approach's benefits in a real world setting using real-life narratives on the open data repository of the World Health Organization."},{title:"Query-aware Dynamic Representation Learning for Temporal Knowledge Graph Reasoning",authors:"Juan Chen, Zixuan Li, Wei Zhang and Yuanzhuo Wang",abstract:"Temporal Knowledge Graph (TKG) reasoning, which predicts future queries based on historical facts, has garnered significant attention. Existing methods learn dynamic representations of entities and then predict queries based on these representations. However, they primarily learns these representations from historical facts without considering the information in the queries. Actually, queries can highlight relevant historical facts, thereby enabling the model to learn more task-specific and accurate dynamic representations. Moreover, concurrent queries often exhibit structural dependencies and can facilitate more precise and coherent predictions. Motivated by these, we propose a Query-aware Dynamic Representation Learning (QDRL), a method that adaptively incorporates query information into the dynamic representation learning process. Specifically, to capture the structural dependencies among concurrent queries, QDRL employs a CNN-based query encoder to generate query representations, which are subsequently integrated into the dynamic entity representations via a Transformer-based temporal encoder. In addition, acknowledging that some static background knowledge of entities is not explicitly represented in TKG, we leverage Large Language Models (LLMs) to construct a comprehensive background knowledge graph. By modeling this graph, QDRL generates more informative initial representations of entities, leading to improved dynamic representations. TKG reasoning experiments on five benchmark datasets demonstrate the significant improvement of the proposed QDRL method, with up to 5.41\\% and 16.96\\% performance improvement in MRR on entity and relation prediction tasks, respectively, compared to the state-of-the-art baselines."},{title:"Leveraging Open Path from Pruned Graph for Link Prediction on Knowledge Graphs",authors:"Xingyu Liu, Yuyin Lu and Yanghui Rao",abstract:"Real-world Knowledge Graphs (KGs) are inherently incomplete, necessitating effective link prediction to infer missing facts and enhance their utility in knowledge-driven applications. While embedding-based methods falter in inductive scenarios with unseen entities, GNN-based link predictors sacrifice interpretability despite their expressive power. Path-based alternatives address these limitations through transparent reasoning patterns, yet conventional implementations relying on Closed Paths (CPs) between entity pairs face severe path scarcity in sparse KGs. To overcome this bottleneck, we propose Open Path from Pruned Graph enhanced Link Predictor (OPPGLP), a novel framework that integrates GNN-derived relational patterns with path-based reasoning. Specifically, OPPGLP consists of an OPPG module followed by an encoder. The OPPG module decodes implicit relational patterns discovered by GNNs into explicit high-quality Open Paths (OPs) through interpretable representation analysis, while the transformer-based encoder processes these OPs along with CPs to perform link prediction. Comprehensive evaluations across three public datasets demonstrate state-of-the-art performance of our OPPGLP in 5 out of 6 transductive and inductive settings. Ablation analysis confirms the performance gains from OPs, while case study  provides interpretable reasoning traces, establishing our method's dual advantage in accuracy and explainability."},{title:"Neuro-Symbolic Adaptive Query Processing over Knowledge Graphs",authors:"Chang Qin and Maribel Acosta",abstract:"In adaptive query processing (AQP), the query plan is ad- justed based on actual execution conditions. AQP has proven effective in dynamic querying environments, such as knowledge graphs (KGs) on the web. The technique known as eddies enables tuple-wise adaptivity by dynamically reordering query operators at runtime. Eddies operate under a predefined symbolic routing policy, which determines the next operator to process each tuple. Although various routing policies have been proposed, their effectiveness varies across queries, and choosing a suboptimal policy can significantly degrade performance. To address this challenge, we propose a neuro-symbolic AQP approach that combines representation learning and supervised learning to predict the optimal routing policy for a given query. Experimental results on synthetic and real-world KGs demonstrate that our method achieves high precision in predicting optimal policies, is efficient to train and use at inference time, and generalizes well to queries with constants not seen during training."},{title:"FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic",authors:"Yiwen Peng, Thomas Bonald and Fabian Suchanek",abstract:"Knowledge graph alignment is the task of matching equivalent entities (that is, instances and classes) and relations across two knowledge graphs. Most existing methods focus on pure entity-level alignment, computing the similarity of entities in some embedding space. They lack interpretable reasoning and need training data to work. In this paper, we propose FLORA, a simple yet effective method that (1) is unsupervised, i.e., does not require training data, (2) provides a holistic alignment for entities and relations iteratively, (3) is based on fuzzy logic and thus delivers interpretable results, (4) provably converges, (5) allows dangling entities, i.e., entities without a counterpart in the other KG, and (6) achieves state-of-the-art results on major benchmarks."},{title:"Measuring the Impact of Narrative Complexity on Knowledge Graph Embeddings",authors:"In\xe8s Blin, Ilaria Tiddi and Annette Ten Teije",abstract:"In this work, we study how semantic narrative enrichment and syntactic encoding affect the performance of knowledge graph embedding models. Narratives are central to human understanding, yet their structured representation in knowledge graphs remains challenging due to their semantic and structural complexity. Although traditional knowledge graphs use binary relations, they struggle to capture richer narrative elements, such as roles and causality. More complex knowledge graph syntaxes such as RDF-star, reification, singleton or n-ary properties offer greater modeling flexibility, but their impact on downstream tasks such as link prediction remains unclear. We define a six-level categorization of narrative semantics and use it to construct a suite of structured knowledge graphs using four syntactic representations. Using different embedding models, we evaluate how semantic and syntactic factors influence the embedding quality. We find that semantic features such as properties and subevents generally enhance performance, while roles tend to have a detrimental effect. On the syntactic side, although differences were not statistically significant across all metrics, reification and RDF-star achieved the strongest results on average."},{title:"Revisiting Link Prioritization for Efficient Traversal in Structured Decentralized Environments",authors:"Ruben Eschauzier, Ruben Taelman and Ruben Verborgh",abstract:"Decentralized environments distribute personal data across numerous small, independent data sources; a necessity driven by legal and socio-economic constraints that prevent the technologically more convenient central aggregation. Link Traversal-based Query Processing (LTQP) is a query technique that respects these constraints by iteratively discovering and accessing data sources while enabling fine-grained access control.  Unfortunately, current LTQP implementations are slow due to limited prior knowledge of queried data and the high volume of HTTP requests required. While link prioritization algorithms have been studied for Linked Open Data (LOD), their performance in structured decentralized environments remains untested. Evaluating this performance is essential to establish a baseline as a reference point for improving future implementations.  To measure prioritization performance, we formally define the R\xb3 metric, extend it to continuous efficiency, and account for real-world scenarios. Furthermore, we provide modular and open-source implementations of the prioritization algorithms from the literature. Finally, using the R\xb3 metric with existing metrics from the literature, we benchmark these link prioritization algorithms in a simulated Solid environment.  In this paper, we report the benchmark results, provide a thorough analysis, and lessons learned for future work.  We find that existing prioritization algorithms fail to leverage the structure in structured decentralized environments to improve performance, with no method outperforming the look-up order produced by a FIFO queue.  We conclude that general-purpose prioritization algorithms do not work in structured decentralized environments without explicitly incorporating the structural information."},{title:"Compact Answers to Temporal Path Queries",authors:"Muhammad Adnan, Diego Calvanese, Julien Corman, Anton Dign\xf6s, Werner Nutt and Ognjen Savkovi\u0107",abstract:"We study path-based graph queries that in addition to navigation over edges also perform navigation over time. This allows one to ask questions about the dynamics of networks, like traffic movement, cause effect relationships, or spread of diseases. In this setting, graphs consist of triples annotated with validity intervals while a query produces pairs of nodes where each pair is associated with a binary relation over time. For instance, such a pair could be two airports and the relation could map potential departure times to possible arrival times. An open question is how to represent such a relation in a compact form and how to maintain such properties during query evaluation. We investigate four compact representations of answers to a such a query that rely on alternative ways of encoding sets of intervals over both discrete and dense time. We discuss their respective advantages and drawbacks, in terms of conciseness, uniqueness, and computational cost. Notably, the most refined encoding guarantees that query answers over dense time can be finitely represented."},{title:"Graph Querying or Similarity Search? Both!",authors:"Vicente Calisto, Sebasti\xe1n Ferrada, Gonzalo Navarro, Juan L. Reutter, Juan Pablo S\xe1nchez and Domagoj Vrgoc",abstract:"Extracting information from knowledge graphs is a significant algorithmic challenge, especially when dealing with multimodal knowledge graphs that integrate images, text, and/or videos. While current graph management systems can efficiently evaluate graph queries, they struggle with multimedia data. To address this, systems rely on metadata, such as vector embeddings, for similarity search. While both graph pattern evaluation and similarity search work well independently, real-world applications often require their combination to retrieve media based on both the graph structure and specific similarity criteria.  This paper studies the problem of querying multimodal knowledge graphs by combining graph patterns with similarity constraints. We formalize this as an extraction task where some nodes in the graph pattern are filtered by similarity, and then the results must be ordered by a similarity score. While a straightforward approach is to evaluate the graph pattern first and then sort by similarity, we introduce alternative algorithms that evaluate both tasks jointly, leveraging indexes for efficient similarity computation. Our implementation employs an approximate version of these indexes, and our experiments show that graph database systems can efficiently integrate semantic similarity constraints into their queries."},{title:"GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs",authors:"Sebastian Walter and Hannah Bast",abstract:"We propose a new approach for generating SPARQL queries on RDF knowledge graphs from natural language questions or keyword queries, using a large language model. Our approach does not require fine-tuning. Instead, it uses the language model to explore the knowledge graph by strategically executing SPARQL queries and searching for relevant IRIs and literals. We evaluate our approach on a variety of benchmarks (for knowledge graphs of different kinds and sizes) and language models (of different scales and types, commercial as well as open-source) and compare it with existing approaches. On Wikidata we reach state-of-the-art results on multiple benchmarks, despite the zero-shot setting. On Freebase we come close to the best few-shot methods. On other, less commonly evaluated knowledge graphs and benchmarks our approach also performs well overall. We conduct several additional studies, like comparing different ways of searching the graphs, incorporating a feedback mechanism, or making use of few-shot examples."},{title:"Large Language Models Assisting Ontology Evaluation",authors:"Anna Sofia Lippolis, Mohammad Javad Saeedizade, Robin Keskis\xe4rkk\xe4, Eva Blomqvist, Andrea Giovanni Nuzzolese and Aldo Gangemi",abstract:"Ontology evaluation through functional requirements\u2014such as testing via competency question (CQ) verification\u2014is a well-established yet costly, labour-intensive, and error-prone endeavour, even for ontology engineering experts. In this work, we introduce OE-Assist, a novel framework designed to assist ontology evaluation through automated and semi-automated CQ verification. By presenting and leveraging a dataset of 1,393 CQs paired with corresponding ontologies and ontology stories, our contributions present, to our knowledge, the first systematic investigation into large language model (LLM)-assisted ontology evaluation, and include: (i) evaluating the effectiveness of a LLM-based approach for automatically performing CQ verification against a manually created gold standard, and (ii) developing and assessing an LLM-powered framework to assist CQ verification with Prot\xe9g\xe9, by providing suggestions. We found that automated LLM-based evaluation with o1-preview and o3-mini perform at a similar level to the average user\u2019s performance. Through a user study on the framework with 19 knowledge engineers from eight international institutions, we also show that LLMs can assist manual CQ verification and improve user accuracy, especially when suggestions are correct. Additionally, participants reported a marked decrease in perceived task difficulty. However, we also observed a reduction in human performance when the LLM provided incorrect guidance, showing a critical trade-off between efficiency and accuracy in assisted ontology evaluation."},{title:"UpSHACL: Targeted Constraint Validation for Updates over Knowledge Graphs",authors:"Zenon Zacouris, Jin Ke and Maribel Acosta",abstract:"Knowledge Graphs (KGs) evolve frequently through updates that reflect new information or corrections, but such changes can compromise data quality constraints. For KGs modelled in RDF, such constraints can be expressed with the Shapes Constraint Language (SHACL). Current SHACL engines are tailored to validating static graphs but are inefficient for KGs under updates, as they require re-validating the entire graph after each update. In this paper, we present UpSHACL, an approach for efficient SHACL validation after updates. UpSHACL introduces a formal model to identify the subgraph affected by an update and constructs a reduced subgraph that can be validated using existing SHACL engines. Our algorithm, implemented with SPARQL over RDF triple stores, integrates seamlessly with Semantic Web technologies. Experimental results show that UpSHACL achieves up to 10\xd7 speedup over static validation, with performance gains increasing on larger KGs."},{title:"Link Prediction Under Non-targeted Attacks: Do Soft Labels Always Help?",authors:"Adel Memariani, Michael R\xf6der, Arnab Sharma, Caglar Demir and Axel-Cyrille Ngonga Ngomo",abstract:"Knowledge Graph Embedding (KGE) models rely on precise factual information to learn effective representations. These learned representations support many downstream tasks, with link prediction being a primary application. However, recent studies have shown that noise in training data can compromise the effectiveness of knowledge graph embeddings. Therefore, KGEs are highly vulnerable to data poisoning attacks. Typically current attacks on KGEs are studied under targeted scenarios, where target facts and the model are assumed to be known beforehand. Yet, this information is not often available in real-world scenarios. Thus, more realistic scenarios involve non-targeted but malicious perturbations aimed at reducing the overall model performance. In this paper, we focus on enhancing the robustness of link prediction approaches in non-targeted settings. To mitigate the harmful impact of the noisy data, we explore soft-label loss functions as a strategy for reducing overconfidence in model predictions. We performed a thorough evaluation on six state-of-the-art models and five benchmark datasets, with different noise ratios introduced into each dataset. Our results show that soft labels commonly improve the robustness of KGE models across various noise ratios."},{title:"Scalable Reasoning with Real Facts via Constrained Generation",authors:"Riccardo Pozzi, Matteo Palmonari, Andrea Coletta, Luigi Bellomarini, Jens Lehmann and Sahar Vahdati",abstract:"Knowledge gaps and hallucinations are important problems for Large Language Models (LLMs) that may lack sufficient information to fulfill user instructions, resulting in unreliable responses. Existing approaches, such as Retrieval-Augmented Generation (RAG) and tool use, aim to address these issues by incorporating external knowledge. Yet, they depend on additional models or services, resulting in complex pipelines, potential error propagation, and often requiring the model to process a large number of tokens. In this paper we present a scalable method that enables LLMs to access external knowledge without relying on retrievers or auxiliary models. Our approach uses constrained generation with a prebuilt prefix-tree index. Triples from a Knowledge Graph are verbalized in textual facts, tokenized, and indexed in a prefix-tree structure for efficient access. During inference, to acquire external knowledge, the LLM generates facts with constrained generation which allows only sequences of tokens that form a real fact. We evaluate our proposal on Question Answering and show that it scales to large knowledge bases (800 million facts), adapts to domain-specific data, and improves performance on questions where internal model knowledge is lacking. These gains come with minimal generation-time overhead."},{title:"Controlled Query Evaluation under Epistemic Dependencies: Algorithms and Experiments",authors:"Lorenzo Marconi, Flavia Ricci and Riccardo Rosati",abstract:"We investigate Controlled Query Evaluation (CQE) over ontologies, where information disclosure is regulated by epistemic dependencies (EDs), a family of logical rules recently proposed for the CQE framework. In particular, we combine EDs with the notion of optimal GA censors, i.e. maximal sets of ground atoms that are entailed by the ontology and can be safely revealed. We focus on answering Boolean unions of conjunctive queries (BUCQs) with respect to the intersection of all optimal GA censors\u2014an approach that has been shown in other contexts to ensure strong security guarantees with favorable computational behavior. First, we characterize the security of this intersection-based approach and identify a class of EDs (namely, full EDs) for which it remains safe. Then, for a subclass of EDs and for DL-Lite_R ontologies, we show that answering BUCQs in the above CQE semantics is in AC^0 in data complexity by presenting a suitable, detailed first-order rewriting algorithm. Finally, we report on experiments conducted in two different evaluation scenarios, showing the practical feasibility of our rewriting function."},{title:"KROMA: Ontology Matching with Knowledge Retrieval and Large Language Models",authors:"Lam Nguyen, Erika Barcelos, Roger French and Yinghui Wu",abstract:"Ontology Matching (OM) is a cornerstone task of semantic interoperability, yet existing systems often rely on handcrafted rules or specialized models with limited adaptability. We present KROMA, a novel OM framework that harnesses Large Language Models (LLMs) within a Retrieval\u2011Augmented Generation (RAG) pipeline, to dynamically enrich the semantic prompt context of OM tasks with structural, lexical, and definitional knowledge. To optimize both accuracy and efficiency, KROMA integrates a bisimilarity\u2011based concept matching and a lightweight ontology refinement step, which prune candidate concepts and substantially reduce the communication overhead from invoking LLMs. Using a variety of benchmark datasets, we experimentally verify that knowledge retrieval and context\u2011augmented LLMs effectively improve ontology matching outperforms both traditional OM systems and state-of-the-art LLM\u2011based OM methods, with comparable communication overhead. Our study highlights the feasibility and benefit of the proposed optimization techniques (targeted knowledge retrieval, prompt enrichment, and ontology refinement) for ontology matching at scale."},{title:"A Domain-Independent Approach for Semantic Table Interpretation",authors:"Binh Vu, Craig Knoblock and Fandel Lin",abstract:"Understanding the semantic structure of tabular data is essential for data integration and discovery. Specifically, the goal is to annotate columns in a tabular source with types and relationships between them using classes and predicates of a target ontology. Previous work either requires trained labeled data or exploits the overlapping data between the table data and a knowledge graph to predict types and relationships. However, they cannot be used in a new domain with limited labeled data. To address this issue, we propose a novel distant supervision approach to estimate a score reflecting the semantic relatedness between a table column and an ontology class or property using the table metadata and data. Our empirical evaluation demonstrates that our approach significantly outperforms strong baselines."},{title:"SHACL Validation under Graph Updates",authors:"Shqiponja Ahmetaj, George Konstantinidis, Magdalena Ortiz, Paolo Pareti and Mantas \u0160imkus",abstract:"SHACL (SHApe Constraint Language) is a W3C standardized constraint language for RDF graphs. In this paper, we study SHACL validation in RDF graphs under updates. We present a SHACL-based update language that can capture intuitive and realistic modifications on RDF graphs and study the problem of static validation under such updates. This problem asks to verify whether every graph that validates a SHACL specification will still do so after applying a given update sequence. More importantly, it provides a basis for further services for reasoning about evolving RDF graphs.  Using a regression technique, that embeds the update actions into SHACL constraints, we show that static validation under updates can be reduced to (un)satisfiability of a shapes graph in (a minor extension of) SHACL. We analyze the computational complexity of the static validation problem for SHACL and some key fragments. Finally, we present a prototype implementation that performs static validation under updates and other static analysis tasks on SHACL shapes graphs and demonstrate its behavior through preliminary experiments."},{title:"Parallel Reasoning in Sequoia",authors:"Alexander Furmston, David Tena Cucala, Jieying Chen and Bernardo Cuenca Grau",abstract:"Description Logic (DL) ontologies underpin many Semantic Web applications. Consequence-based reasoning, which integrates techniques from hypertableau and resolution, has proved effective for tasks such as consistency checking and classification in both lightweight and expressive DLs. However, existing reasoners often fall short when applied to large, complex ontologies commonly found in domains such as healthcare and industry. In this paper, we extend the state-of-the-art consequence-based reasoner Sequoia to support parallel reasoning, improving its scalability by leveraging system architectures with multiple cores. We explore and evaluate two parallelisation strategies for consequence-based reasoners: message passing and thread pools, and demonstrate their application within the Sequoia reasoner. Our extensive empirical evaluation shows that thread pool-based implementations achieve superior performance and resource efficiency, offering up to 2.46x speedup over the baseline on hard ontologies. We also explore the effect of increasing the number of available cores or restricting the expressivity of the ontology on the performance of our implementations."}],an=[{title:"mmRAG: A Modular Benchmark for Retrieval-Augmented Generation over Text, Tables, and Knowledge Graphs",authors:"Chuan Xu, Qiaosheng Chen, Yutong Feng and Gong Cheng",abstract:"Retrieval-Augmented Generation (RAG) has emerged as a powerful paradigm for enhancing the capabilities of large language models. However, existing RAG evaluation predominantly focuses on text retrieval and relies on opaque, end-to-end assessments of generated outputs. To address these limitations, we introduce mmRAG, a modular benchmark designed for evaluating multi-modal RAG systems. Our benchmark integrates queries from six diverse question-answering datasets spanning text, tables, and knowledge graphs, which we uniformly convert into retrievable documents. To enable direct, granular evaluation of individual RAG components---such as the accuracy of retrieval and query routing---beyond end-to-end generation quality, we follow standard information retrieval procedures to annotate document relevance and derive dataset relevance. We establish baseline performance by evaluating a wide range of RAG implementations on mmRAG."},{title:"RDFMutate: Mutation-Based Generation of Knowledge Graphs",authors:"Tobias John, Einar Broch Johnsen and Eduard Kamburjan",abstract:"This paper introduces RDFMutate, the first mutation-based tool to generate RDF knowledge graphs. RDFMutate enables developers to analyze the robustness of applications that operate on RDF, by gen- erating variants of seed knowledge graphs, which are mutated according to a set of mutation operations and SHACL constraints. In contrast to existing tools to generate synthetic RDF graphs, RDFMutate provides a mutation-based approach that is accessible for both researchers and ap- plication developers, by providing a framework to define mutation rules and flexible selection of generated graphs."},{title:"Sparqloscope: A generic benchmark for the comprehensive and concise performance evaluation of SPARQL engines",authors:"Hannah Bast, Johannes Kalmbach, Christoph Ullinger and Robin Textor-Falconi",abstract:"We provide a new benchmark, called Sparqloscope, for evaluating the query performance of SPARQL engines. The benchmark combines three unique features, which separates it from other such benchmarks: 1. Sparqloscope is generic in the sense that it can be applied to any given RDF dataset and it will then produce a comprehensive benchmark for that particular dataset. Existing benchmarks are either synthetic, designed for a fixed dataset, or require query logs. 2. Sparqloscope is comprehensive in that it considers most features of the SPARQL 1.1 query language that are relevant in practice. In particular, it also considers advanced features like EXISTS, various SPARQL functions for numerical values, strings, and dates, language filters, etc. 3. Sparqloscope is specific in the sense that it aims to evaluate relevant features in isolation and as concisely as possible. In particular, the benchmark generated for a given knowledge graph consists of only around 100 very carefully crafted queries, the results of which can and should be studied individually and not in aggregation. Sparqloscope is free and open-source software and easy to use. As a showcase we use it to evaluate the performance of three high-performing SPARQL engines (Virtuoso, MillenniumDB, QLever) on two widely used RDF datasets (DBLP and Wikidata)."},{title:"cnChemNER\uff1aA Dataset for Chinese Chemical Named Entity Recognition",authors:"Haoran Zhang, Tingxin Jiang, Hongxia Jin, Ying Yang, Xiaowang Zhang and Zhiyong Feng",abstract:"Due to the inherent challenges in dataset construction, no comprehensive Chinese Chemical Named Entity Recognition (CNER) dataset has been publicly released to date. As a result, there is a scarcity of domain-specific Chinese datasets in the field of chemistry, impeding progress in key intelligent chemistry tasks such as reaction mechanism analysis, automatic literature classification, and cross-lingual terminology alignment. This work addresses this gap by introducing the first large-scale Chinese CNER dataset\u2014cnChemNER\u2014which leverages granted Chinese patents as a data source to develop a rule-based, patent-oriented automatic extraction framework. The dataset comprises 76,245 annotated chemical entities spanning four primary categories, which are further divided into 73 fine-grained subcategories. The experimental results validate the effectiveness of using patents as a data source, with language models trained on cnChemNER demonstrating superior performance across precision, recall, and F1-score metrics. cnChemNER bridges a critical gap in Chinese chemical corpora and represents a significant advancement in terms of annotation granularity, semantic structure, and domain-specific adaptability. We anticipate that cnChemNER will serve as a valuable resource for enhancing model performance in cross-lingual chemical text processing. Additionally, it can support downstream tasks in related vertical domains such as biomedicine and materials science."},{title:"Virtual Knowledge Graphs over Earth Observation Data",authors:"Albulen Pano, Davide Lanti and Diego Calvanese",abstract:"Earth Observation (EO) data publication and dissemination continues to grow driven by the increase in satellite launches. openEO is one of the most well known platform to query EO data (in the form of datacubes) using web API. To be truly valuable, Earth Observation (EO) data often needs to be combined with other data sources, like relational databases. Knowledge graphs offer a way to bridge the semantic gap between EO data and these additional sources. However, the execution of integrated queries can run into scalability issues due to the enormous volume of EO data. In this paper, we propose addressing this challenge through the use of Virtual Knowledge Graphs---a paradigm that presents data to end-users as a knowledge graph, while keeping the data in its original sources rather than materializing it in graph form. We show the feasibility of our approach by implementing a prototype solution and test it over real world openEO examples."},{title:"ExeKGLib: A Platform for Machine Learning Analytics based on Knowledge Graphs",authors:"Antonis Klironomos, Baifan Zhou, Zhipeng Tan, Zhuoxun Zheng, Mohamed H. Gad-Elrab, Heiko Paulheim and Evgeny Kharlamov",abstract:"Nowadays machine learning (ML) practitioners have access to numerous ML libraries available online. Such libraries can be used to create ML pipelines that consist of a series of steps where each step may invoke up to several ML libraries that are used for various data-driven analytical tasks. Development of high-quality ML pipelines is non-trivial; it requires training, ML expertise, and careful development of each step. At the same time, domain experts in science and engineering may not possess such ML expertise and training while they are in pressing need of ML-based analytics. In this paper, we present our ExeKGLib, a Python library enhanced with a graphical interface layer that allows users with minimal ML knowledge to build ML pipelines. This is achieved by relying on knowledge graphs that encode ML knowledge in simple terms accessible to non-ML experts. ExeKGLib also allows improving the transparency and reusability of the built ML workflows and ensures that they are executable. We show the usability and usefulness of ExeKGLib by presenting real use cases."},{title:"HealthEQKG: A Knowledge Graph and Data Model for Health Equity Research",authors:"Navapat Nananukul and Mayank Kejriwal",abstract:"Owing to the expense of healthcare and aging demographics, health inequity has emerged as a critical challenge in the United States, leading to significant disparities in health outcomes and unequal access to care in different communities. Understanding the complex associations between the distribution of healthcare providers, clinician characteristics, and socioeconomic conditions in their community of practice is essential to developing policies to close health inequity gaps. However, research in this domain is challenging due to the fragmentation of relevant datasets (including by the government), and the difficulty of using these datasets in a semantically unified manner. To address this challenge, we introduce HealthEQKG, an open-source knowledge graph (KG) specifically designed to support both qualitative and quantitative health equity research. Supported by a compact underlying ontology, HealthEQKG integrates two national-level (but independent) government agency datasets containing physician data and socioeconomic data, followed by data augmentation through the use of established Semantic Web resources like DBpedia Spotlight. The complete KG contains 72,658 physicians and 28,346 Area Deprivation Indices for zip codes across the US. Through a series of fifteen competency questions, and two use-cases, we demonstrate its utility as a queryable public resource for public health policymakers and researchers."},{title:"A Domain Ontology for Ishikawa Diagrams to Enhance Root Cause Analysis",authors:"Christian Fleiner, Duo Yang, Simon Vandevelde and Joost Vennekens",abstract:"Ishikawa diagrams, also known as fishbone or cause-and-effect diagrams, are a widely known visual tool for performing root cause analysis (RCA). Although Ishikawa diagrams originated in the manufacturing sector, the tool is also actively used in other areas such as healthcare or business due to its simple structure, which requires little or no training beforehand. Though Ishikawa diagrams are valuable sources of knowledge, they lack rich semantics to effectively process them. As a result, knowledge engineers tend to ignore Ishikawa diagrams and choose other means to collect knowledge, although domain experts are familiar with the RCA tool and it is highly accepted. This paper presents the Ishikawa diagram ontology which enables the explicit modeling of Ishikawa diagrams as visual artifacts, their encoded knowledge and the process of their creation by reusing and extending existing ontologies. The ontology was developed using the LOT methodology. We have created a dataset of Ishikawa diagrams and describe a fictional use case to illustrate the intended use of the presented ontology."},{title:"Co-creating an Ontology of Online Gender-Based Harms: An Interdisciplinary Perspective",authors:"Miriam Fernandez, Alba Catalina Morales Tirado, Angel Pavon-Perez, Keely Duddin, Min Zhang, Ksenia Bakina, Arosha Bandara, Rose Capdevila, Lisa Lazard and Olga Jurasz",abstract:"The rising prevalence and complexity of online harms, particularly those disproportionately affecting women, demand urgent, interdisciplinary, and socio-technical responses. Despite increasing awareness and policy action, current responses remain fragmented across disciplinary silos, limiting the development of cohesive and effective interventions. This paper presents our efforts to co-create a comprehensive Gender-aware Ontology of Online Harms as a shared knowledge structure to bridge disciplinary perspectives and inform practice across sectors, including policing, law, behavioural science, and technology. Our ontology aims to capture the full spectrum of gender-based online harms, their sociotechnical enablers and inhibitors, and their manifestations in online contexts. The development process employs a co-creation approach grounded in collaborative ontology engineering and iterative stakeholder engagement. It has been driven by discipline-specific Personas and Competency Questions to ensure relevance, usability, and impact across diverse domains. We argue that this work represents a crucial step toward formalising a shared understanding of online harms to support policy reform, technological innovation, and survivor support."},{title:"COTTAS: Columnar Triple Table Storage for Efficient and Compressed RDF Management",authors:"Juli\xe1n Arenas-Guerrero and Sebasti\xe1n Ferrada",abstract:"One of the main challenges in working with RDF data is its verbosity, as repeated IRIs and IRI prefixes lead to large files that are costly to store and process. HDT, a binary RDF format, addresses this by compressing data while supporting efficient triple pattern evaluation without decompression. However, its performance is highly dependent on index alignment with query patterns. In this paper, we introduce COTTAS, a storage model that encodes RDF graphs directly into the open-source Apache Parquet columnar format. COTTAS represents RDF as a triple table and leverages block range indexes (zone maps) to achieve high compression ratios and fast query execution over compressed data. We also provide pycottas, an open-source Python library that enables compression of RDF data into COTTAS format and supports efficient querying by translating triple patterns into SQL queries over COTTAS files. This implementation facilitates the adoption of COTTAS for managing RDF graphs. Experiments on the WDBench and DBpedia benchmarks show that COTTAS reduces storage requirements around 50% with respect to HDT and exhibits competitive triple pattern evaluation, with less performance volatility across pattern types."},{title:"Benchmarking Knowledge Editing using Logical Rules",authors:"Tatiana Moteu Ngoli, N'Dah Jean Kouagou, Hamada Zahera and Axel-Cyrille Ngonga Ngomo",abstract:"The increasing use of large language models across domains reveals and effectuates a growing need for regularly updated knowledge in foundation models. However, retraining these models is often prohibitively expensive. Knowledge editing is hence becoming an increasingly popular means to maintain foundation models up-to-date or even correct erroneous assertions they propagate. However, it is still unclear how current knowledge editing approaches really perform, as current evaluation studies are mostly limited to validating the recall of edited facts with no regard for their logical consequences. To overcome this limitation, we present a new benchmark for knowledge editing that includes multi-hop questions generated using logical rules to evaluate the effectiveness of knowledge editing methods. Our findings reveal that while existing knowledge editing approaches can accurately insert assertions into large language models, they often fail to inject entailed knowledge. In particular, our experiments on the popular approaches ROME and FT suggest a considerable performance gap of up to 24% between evaluations on directly edited knowledge and on entailed knowledge, hence highlighting the need for semantics-aware evaluation frameworks for knowledge editing."},{title:"SSBD Ontology: A Two-Tier Approach for Interoperable Bioimaging Metadata",authors:"Yuki Yamagata, Koji Kyoda, Hiroya Itoga, Emi Fujisawa and Shuichi Onami",abstract:"Advanced bioimaging technologies have enabled large-scale capture of multidimensional data, yet effective metadata management and interoperability remain significant challenges. To address these needs, we propose a new ontology-driven framework for the Systems Science of Biological Dynamics Database (SSBD). We propose an ontology-driven framework for the Systems Science of Biological Dynamics Database (SSBD) that adopts a two-tier architecture. The core layer provides a class-centric structure referencing existing biomedical ontologies, supporting both SSBD:repository\u2014focused on rapid dataset publication with minimal metadata\u2014and SSBD:database\u2014enhanced with biological and imaging-related annotations. Meanwhile, the instance layer houses actual imaging datasets as RDF instances. This layered approach aligns flexible instance-based repositories with robust ontological classes, enabling seamless integration and advanced semantic queries. By coupling flexibility with rigor, the SSBD Ontology promotes interoperability, data reuse, and the discovery of novel biological mechanisms. Moreover, our solution aligns with the REMBI guidelines and fosters compatibility. Ultimately, our approach contributes to establishing a FAIR data ecosystem across the bioimaging community."},{title:"From Legal Texts to Structured Knowledge: A Comprehensive Pipeline for Legal Text Summarization",authors:"Ahmad Sakor, Kuldeep Singh and Maria-Esther Vidal",abstract:"This paper introduces a comprehensive and generalizable pipeline for legal text summarization, with the low-resource Arabic language serving as a use case. Designed to bridge the gap between raw legal documents and structured knowledge representation, our approach leverages a dataset of 24,656 Moroccan legal cases, encompassing data extraction and processing, LLM-assisted annotations for gold-standard summaries, and a knowledge distillation approach to transfer summarization capabilities from a teacher model to a fine-tuned smaller LLM to produce structured, JSON-formatted summaries adhering to a specific template. Our fine-tuning approach achieves substantial performance improvement over the base LLM specifically on Moroccan legal text summarization and structured output generation, with evaluation metrics demonstrating an increase in summarization precision of up to 26\\%. Furthermore, we extend the application of this resource by constructing an interactive knowledge graph that visualizes relationships between cases, legal principles, and parties involved, enabling advanced queries and legal trend analysis. The publicly available dataset and fine-tuned model as resources enable reproducibility and offer a scalable solution for structuring legal knowledge in low-resource languages like Arabic."},{title:"SHACL Dashboard: Analyzing Data Quality Reports over Large-Scale Knowledge Graphs",authors:"Johannes M\xe4kelburg, Zenon Zacouris, Jin Ke and Maribel Acosta",abstract:"Validating knowledge graphs (KGs) ensures their quality and reliability in real-world applications. The Shapes Constraint Language (SHACL) has emerged as a recommended standard for validating RDF KGs, by defining structured constraints. Many organizations leverage SHACL validation and its reports to detect problems, guide corrections, and improve data quality. Yet, large-scale KGs often produce extensive validation reports, making manual analysis infeasible. To address this challenge, we present SHACL Dashboard, a novel online tool for visualization and multidimensional analysis of SHACL validation reports. It provides an interactive user interface featuring detailed violation summaries, analytical plots, and fine-grained insights into individual constraints. These functionalities enable users to efficiently understand validation results, identify problematic areas, and take precise corrective actions on their data."},{title:"MontoFlow \u2013 A Maritime Ontology Framework for Modeling Ship Sensory Systems",authors:"Pavle Ivanovic, Simon Burbach and Maria Maleshkova",abstract:"The increasing operational demands in maritime contexts, particularly during time-sensitive missions like search and rescue, necessitate reliable, intelligent support systems. These systems depend on semantically structured and interoperable models to integrate and interpret complex sensor data as well as facilitate informed decision-making. We introduce MontoFlow, a semantic integration framework that combines dynamic data access with domain-specific knowledge representation. It links static properties with dynamic sensory measurements, forming the foundation for advanced maritime diagnostics. At its core, MontoFlow incorporates the SHIP Ontology, a maritime-focused SSN/SOSA extension that provides a comprehensive semantic model describing onboard sensors, vessel components, and their observations. We illustrate the practical relevance and rationale behind the development of MontoFlow through real-world examples, with emphasis on ship maintenance and onboard anomaly detection. The SHIP Ontology is thoroughly evaluated based on domain coverage and a use case in the maritime context, demonstrating both high quality and practical applicability. This work presents a reusable and extensible resource for semantically enriching maritime sensory data, supporting advanced analytics and dynamic data monitoring."},{title:"MammoTab 25: A Large-Scale Dataset for Semantic Table Interpretation -- Training, Testing, and Detecting Weaknesses",authors:"Marco Cremaschi, Federico Belotti, Jennifer D'Souza and Matteo Palmonari",abstract:"The paper presents MammoTab 25, a new dataset comprising approximately 838k Wikipedia tables extracted from over 61M Wikipedia pages and semantically annotated through Wikidata. Each table in MammoTab 25 is accompanied by fine\u2011grained metadata, including column typing, NIL flags, and statistics, and by four prompt templates, making the resource simultaneously suitable for training, fine\u2011tuning, and stress\u2011testing Large Language Models (LLMs). MammoTab 25 covers, in a single benchmark, all key challenges for the semantic interpretation of tables, such as disambiguation issues, homonymy and acronym presence, NIL-mentions, and large web-table sizes; the tags attached to every table let researchers isolate and diagnose specific failure cases with precision. The corpus is delivered with an open\u2011source pipeline that can be re\u2011run on future Wikipedia dumps, ensuring long\u2011term sustainability and up\u2011to\u2011date annotations. MammoTab 25 already supports, and will continue to support, a public leaderboard that evaluates the STI capabilities of state\u2011of\u2011the\u2011art and upcoming LLMs, providing the community with a live yardstick of progress."},{title:"GeoOutageKG: A Multimodal Geospatiotemporal Knowledge Graph for Multiresolution Power Outage Analysis",authors:"Ethan Frakes, Yinghui Wu, Roger French and Mengjie Li",abstract:"Detecting, analyzing, and predicting power outages is crucial for grid risk assessment and disaster mitigation. Numerous power outages occur each year, exacerbated by extreme weather events such as hurricanes and severe thunderstorms. Existing outage data are typically reported at the county level, limiting their spatial resolution and making it difficult to capture localized outage patterns. However, it offers excellent temporal granularity, with updates available as frequently as every 15 minutes. In contrast, night-time light (NTL) satellite image data provides significantly higher spatial resolution and enables a more comprehensive spatial depiction of outages, enhancing the accuracy of assessing the geographic extent and severity of power loss after disaster events. However, these satellite data are only available on a daily basis. Integrating spatiotemporal visual and time-series data sources into a unified multimodal knowledge representation can substantially improve power outage detection, analysis, and predictive reasoning. In this paper, we propose GeoOutageKG, a multimodal knowledge graph that integrates diverse data sources, including nighttime light satellite image data, high-resolution spatiotemporal power outage maps, and county-level timeseries outage reports in the U.S. We describe our method for constructing GeoOutageKG by aligning the source data with a developed ontology, GeoOutageOnto. Currently, GeoOutageKG includes over 10 million individual outage records spanning from 2014 to 2024, 300,000 NTL images spanning from 2012 to 2024, and 15,000 outage maps. GeoOutageKG is a novel, modular and reusable semantic resource that enables robust multimodal data integration. We demonstrate its use through multiresolution analysis of geospatiotemporal power outages. GeoOutageKG is available at \\url{https://github.com/UCF-HENAT/GeoOutageKG}. All image files and additional metadata are available at \\url{https://doi.org/10.17605/OSF.IO/QVD8B}."},{title:"gpuRDF2vec -- Scalable RDF2Vec using GPUs",authors:"Martin B\xf6ckling and Heiko Paulheim",abstract:"Generating Knowledge Graph (KG) embeddings at web scale remains challenging. Among existing techniques, RDF2vec combines effectiveness with strong scalability. We present gpuRDF2vec, an open source library that harnesses modern GPUs and supports multi-node execution to accelerate every stage of the RDF2vec pipeline. Extensive experiments on both synthetically generated graphs and real-world benchmarks show that gpuRDF2vec achieves up to a substantial speedup over the currently fastest alternative, i.e., jRDF2vec. In a single-node setup, our walk-extraction phase alone outperforms pyRDF2vec, SparkKGML, and jRDF2vec by a substantial margin using random walks on large/ dense graphs, and scales very well to longer walks, which typically lead to better quality embeddings. Our implementation of gpuRDF2vec enables practitioners and researchers to train high-quality KG embeddings on large-scale graphs within practical time budgets and builds on top of Pytorch Lightning for the scalable word2vec implementation."},{title:"Are LLMs Really Knowledgeable for Knowledge Graph Completion?",authors:"Yang Liu, Zequn Sun, Zhoutian Shao, Yuanning Cui and Wei Hu",abstract:"Knowledge Graph (KG) completion aims to infer new facts from existing knowledge. While recent efforts have explored leveraging large language models (LLMs) for this task, it remains unclear whether LLMs truly understand KG facts or how they utilize such knowledge in reasoning. In this work, we investigate these questions by proposing ProbeKGC,, a benchmark dataset that reformulates KG completion as multiple-choice question answering with systematically controlled option difficulties. Empirical results show that LLMs often produce inconsistent answers when the same question is presented with varying distractor difficulty, suggesting a reliance on shallow reasoning such as elimination rather than genuine knowledge recall. To better quantify model confidence and knowledge grasp, we introduce Normalized Knowledge Divergence (NKD), a novel metric that complements accuracy by capturing distributional confidence in answer selection. We further analyze the influence of selection biases on LLM predictions and highlight that LLMs do not always fully exploit their stored knowledge. Finally, we evaluate three enhancement strategies and provide insights into potential directions for improving KG completion."}],nn=[{title:"Enhancing Transparency in Smart Grids: the SENSE Framework",authors:"Katrin Ehrenm\xfcller, Konrad Diwold, Tobias Schwarzinger, Gernot Steindl, Wolfgang Pr\xfcggler, Fajar J. Ekaputra and Marta Sabou",abstract:"Modern power grids become ever more complex due to the integration of renewable energy sources and decentralized energy production, among other factors. This presents significant challenges for monitoring, diagnosing, and explaining grid anomalies. To address such setting, the SENSE framework generates contextualized, user-centred explanations of anomalous events in smart grids. To that end, it makes use of semantic web technologies in order to integrate sensor data with domain expert knowledge, to handle system events, and to derive relevant explanations. We evaluate SENSE in two use cases: a real-world smart charging garage and a simulated local energy community. Our evaluation shows that SENSE delivers accurate explanations, with an average accuracy of 82%, while being perceived as highly usable by domain experts. The results demonstrate the potential of semantic web technologies to increase transparency in smart grids leading to important, longer-term economic and environmental impacts."},{title:"Federated FAIR Semantic Artefacts Discovery and Search with OntoPortal Federation",authors:"Clement Jonquet, Syphax Bouazzouni, Guillaume Alviset, Nicola Fiore, Naouel Karam, Bilel Kihal, Christelle Pierkot, Martina Pulieri and Ilaria Rosati",abstract:"The explosion in the number of ontologies and semantic artefacts has come with the importance of developing Semantic Artefact Catalogues to support diverse research communities to harvest, share and serve these artefacts as FAIR objects. However, the lack of interoperability of these catalogues hampers cross disciplinary studies and make semantic stakeholders work quite cumbersome juggling back and forth from one tool to another. Here, we define Semantic Artefact Catalogues interoperability and report on three approaches studied. We present the implementation of the OntoPortal Fed-eration, i.e., the technical and collaboration processes engaged to federate multiple OntoPortal-based catalogues. We showcase how AgroPortal, EcoPortal, EarthPortal, and BiodivPortal, have been federated and now ena-ble federated browsing and search, facilitating seamless access to distribut-ed semantic artefacts and ontologies across their respective disciplines: agri-food, ecology, earth sciences and biodiversity. We discuss technical challenges and governance decisions and conclude by outlining future di-rections toward a sustainable and community-driven OntoPortal-based se-mantic layer for open science data infrastructures."},{title:"Open Government Data as Multi-dimensional 5 Star Data: cube.link",authors:"Michael Luggen, Benedikt Hitz, Julien Audiffren, Djellel Difallah, Jean-Luc Cochard and Philippe Cudre-Mauroux",abstract:"Many governments have made commitments to publish data collected and created by taxpayers as Open Government Data (OGD). Yet a common challenge is that data producers are not always the end-users, leading to inefficiencies, gaps, and inconsistencies in how data is used and interpreted. Data can be published at different levels of quality. For instance, smart cities can produce data collections via networks of sensors from power grids to transportation, whereas data extraction from documents can be highly noisy. A common pattern, however, is that this data describes spatio-temporal phenomena with multidimensional facets pertaining to real-world entities. Having a common ontology for such observations can help standardize their downstream usage. This paper introduces the effort made by the Swiss Government to create an ecosystem that allows one to publish open government data in a pragmatic and efficient manner, while maintaining the goal of publishing high-quality data that are integrated and interoperable. The paper introduces the domain-independent ontology RDF Cube Schema (https://cube.link), which is supported by open-source tools to publish, integrate, and validate diverse data sources, as well as multiple end-user tools for providing and visualizing data. With underlying statistics, we show the usage of these tools by both data providers and data consumers with two deployment use cases around the world."},{title:"Using Semantic Technologies in the Railway Domain: The Register of Infrastructure (RINF) System",authors:"Jhon Toledo, Daniel Do\xf1a, Edna Ruckhaus, Oscar Corcho, Marina Aguado, Dragos Patru, Ghislain Atemezing and Polymnia Vasilopoulou",abstract:"The European Union Agency for Railways (ERA) maintains the knowledge-graph-based \u201cRegister of Infrastructure (RINF) System\u201d, based on a knowledge graph that follows an ontology (the ERA ontology), which is constructed using XML-to-RDF RML mappings, and validated using SHACL. Several applications consume this knowledge graph, allowing users to search for railway infrastructure elements, explore them on a map, and perform compatibility checks of railway vehicles on a certain route (in this case, with an additional knowledge graph that contains data from the European Register of Authorized Types of Vehicles - ERATV -). Data providers such as Infrastructure Managers (IMs) or National Registration Entities (NREs) can upload XML or RDF data, and Railway Undertakings (RUs) may receive notifications when changes are made to infrastructure elements in specific member states. As functionalities were added, challenges arose with respect to new ontology modeling requirements (based on legal requirements), propagation of changes in the semantic artifacts, URI design for RINF resources, harmonization of RINF and ERATV reference data, implementation and execution of mappings, and issues in the performance of SPARQL queries and SHACL validations. In this paper we describe the current status of the knowledge graph and applications, and reflect on the main challenges and lessons learned from this development and deployment."},{title:"Semantic-Aware Streaming Learning for Anomalous Event Detection in Power Grids",authors:"Lorenzo Iovine, Matteo Belcao, Giacomo Ziffer, Gabriele Paludetto and Emanuele Della Valle",abstract:"The growing adoption of smart grid technologies is turning power grids into data-rich environments, where continuous sensor streams capture complex and evolving operational states. Anomalous event detection in this context is particularly challenging due to the structural complexity of the grid and the non-stationary nature of sensor data. To address these challenges, we propose a semantic-aware approach that integrates real-time sensor streams with contextual information of the power grid, a knowledge graph (KG) as in International Electrotechnical Commission's standards. Our method employs Chimera, a semantic data analytics platform, and models capable of incremental learning and adaptation. We publish as open-data a comprehensive data-stream. We comparatively evaluate four scenarios: (1) only streaming events; (2) streaming events enriched with explicit features from the KG; (3) streaming events enriched with graph embeddings of KG's subgraphs; and (4) a combination of the last two. Experiments demonstrate the superior performances of models learned exploiting semantics in the KG."},{title:"A DataOps Toolbox Enabling Continuous Semantic Integration of Devices for Edge-Cloud AI Applications",authors:"Mario Scrocca, Marco Grassi, Alessio Carenini, Darko Anicic, Jean-Paul Calbimonte and Irene Celino",abstract:"The implementation of AI-based applications in complex environments often requires the collaboration of several devices spanning from edge to cloud. Identifying the required devices and configuring them to collaborate is a challenge relevant to different scenarios, like industrial shopfloor, road infrastructure, and healthcare therapy. We discuss the design and implementation of a DataOps toolbox leveraging Semantic Web technologies and a low-code mechanism to address heterogeneous data interoperability requirements in the development of such applications. The toolbox supports a continuous semantic integration approach to tackle various types of devices, data formats, and semantics, as well as different communication interfaces. The paper presents the application of the toolbox to three use cases from different domains, the DataOps pipelines implemented, and how they guarantee interoperability of static nodes' information and runtime data exchanges. Finally, we discuss the results from the piloting activities in the use cases and the lessons learnt."},{title:"Exploiting LLMs and Semantic Technologies to Build a Knowledge Graph of Historical Mining Data",authors:"Craig Knoblock, Binh Vu, Basel Shbita, Yao-Yi Chiang, Xiao Lin, Goran Muric, Pothula Punith Krishna, Jiyoon Pyo, Adriana Trejo-Sheu and Meng Ye",abstract:"To support data-driven decision-making in the assessment of critical mineral resources, we present Minmod, a large-scale knowledge graph built using semantic web technologies. Minmod integrates heterogeneous mining data from mining reports, scientific databases, and academic literature, modeling over 680,000 mineral site records across more than 190 commodities. Central to our approach is the use of ontologies and RDF representations to structure and unify data, enabling semantic interoperability and automated reasoning. We apply large language models (LLMs) to extract structured entities from unstructured sources, predict deposit types, and annotate tabular data with ontology-aligned semantics. Our system employs D-REPR to map diverse data sources into RDF and leverages SPARQL-compatible triple stores for querying and exploration. We use language models to perform high-precision entity resolution across datasets, and we demonstrate how semantic normalization supports applications such as mineral prospectivity mapping and grade-tonnage modeling. Minmod showcases the power of combining LLMs with semantic web principles to deliver a scalable, explainable, and reproducible framework for mineral resource intelligence."}],sn=[{title:"Anomaly Detection and Diagnosis of Vehicle Steering Systems Using a Knowledge Graph-based Approach",authors:"Qiushi Cao, Patelis Alexandros and Irlan Grangel Gonz\xe1lez",abstract:"In the automotive industry, data-driven techniques have been widely used for the early detection of vehicle field issues. During data analysis processes, data heterogeneity is a crucial pain point that causes huge manual effort and time delay. To mitigate this pain point, in this paper we demonstrate a knowledge graph-based approach for the early detection of vehicle technical issues for automotive steering systems. The proposed approach enables semantic data integration, by which the efficiency of data Extract, Transform, Load (ETL) process is significantly improved. Based on the developed knowledge graph system, data visualization dashboards and Large Language Model (LLM) solutions can be easily developed to gain insights for failure-cause-effect analysis. The proposed knowledge graph-based approach has gained significant efficiency improvement. The time and manual efforts for data ETL and integration have been reduced up to 70\\%. The use of standardized domain ontologies enables the re-usability of the proposed approach for other use cases or products. Our work highlights the importance of industrial knowledge graphs for tackling data heterogeneity and data quality issues when developing data-driven applications."},{title:"Building a Canonical Register of Public Sector Entities: Semantic Linking of Procurement Data at Scale",authors:"Roberto Avogadro, Ian Makgill, Aleena Thomas, Ahmet Soylu and Dumitru Roman",abstract:"Public procurement generates over $13 trillion annually, yet data about public buyers and suppliers remains fragmented, inconsistent, and difficult to link across jurisdictions. This paper presents a practical industrial solution developed by Spend Network within the European project enRichMyData to semantically enrich and reconcile procurement data at scale. The proposed pipeline combines large language models (LLMs) with knowledge graphs (KGs) to create and maintain a canonical register of public sector entities. It supports multilingual, cross-border integration and is designed to serve both public transparency and commercial applications.The pipeline has been evaluated on a manually curated benchmark of 1,000 procurement-related entities and demonstrates high precision and scalability in real-world settings"},{title:"Knowledge-Augmented Security Risk Identification for OT Container Deployments",authors:"Yannick Landeck, Dian Balta, Tomas Bueno Momcilovic, Martin Wimmer and Christian Knierim",abstract:"Container deployments in operational technology (OT) environments pose unique security challenges, especially when privileged configurations are used. Traditional risk identification methods often fall short in addressing the complexity, dynamic nature, and interdisciplinary collaboration required in these settings. We propose a knowledge augmentation approach that combines semantic modelling, automated reasoning, and tool support to enhance security risk identification. Our approach is demonstrated through an industrial case study, highlighting its practical application. We also examine how large language models (LLMs) can support the instantiation and integration of the approach, improving usability and scalability."},{title:"Empowering Supply Chain Risk Monitoring with Ontology-Guided Knowledge Graph Extraction by LLMs",authors:"Shuhan Zheng, Keita Mizushina and Ken Naono",abstract:"With business globalization and increasing product complexity, companies often operate supply chains distributed around the world. Such globally distributed supply chains face various disruption risks, highlighting the need for procurement officers to effectively monitor these risks. A popular paradigm is to apply information extraction technologies to open data for risk extraction. Here, we introduce an ontology-guided method for supply chain risk extraction that leverages large language models. Our method iteratively extracts a supply chain risk knowledge graph from unstructured open data, guided by a user-specified ontology. We also developed knowledge graph verification and formatting modules. Our wholistic methods enable consistent and automated identification and extraction of risk knowledge, thereby empowering procurement officers to monitor supply chain risks."},{title:"Semantic Technology in Your Pocket",authors:"Peter Crocker, Ian Horrocks and Yavor Nenov",abstract:"In January 2025, Samsung announced the launch of the Personal Data Engine (PDE) on their flagship Galaxy S25 smartphone. The PDE uses semantic technology in the form of the RDFox Knowledge Graph system to provide on-device AI capabilities to client applications. This almost certainly represents the largest ever deployment of semantic technology, with millions of users now carrying a semantic reasoning engine in their pocket."},{title:"RODEOS \u2014 Robotic Data Ecosystem Semantic Model: Bridging Siloed Robot Systems",authors:"Maximilian St\xe4bler, Lukas Sohlbach, Felix Weidinger, Steffen Turnbull, Jorge Marx-Gom\xe9z, Chris Schlueter-Langdon and Frank K\xf6ster",abstract:"Industry robotics across automotive paint shops, pharmaceutical clean-rooms, and e-commerce warehouses still relies on bespoke data mappings: every new robot arrives with proprietary file formats, capability vocabularies, and safety descriptors, forcing engineering teams into multi-week manual integration cycles. To address this cost and agility gap, we introduce RODEOS\u2014RObotic Data EcOsystem Semantic Model, an emerging, vendor-neutral semantic blueprint co-defined by a consortium of 24 industrial partners. RODEOS extends the W3C DCAT-3 core with robotics-specific classes for raw data, model assets, and executable services, while preserving the lightweight authoring demands voiced in interviews with 17 experts drawn from research institutes, industrial end-users, robotics and automation suppliers, system integrators, IT-infrastructure providers, and the machinery-industry association\u2014thereby capturing a truly holistic cross-domain requirements profile. We propose a prototype \u201csemantic assistant\u2019\u2019 based on large language models to translate domain narratives into candidate semantic descriptions, enabling non-ontologists to curate the descriptions interactively."},{title:"FAIR Vocabulary Management at Scale: TERN's Implementation for Ecological Data Integration",authors:"Junrong Yu, Javier Sanchez Gonzalez, Edmond Chuc and Siddeswara Mayura Guru",abstract:"The Terrestrial Ecosystem Research Network (TERN) is Australia's national collaborative research infrastructure that collects, collates, and publishes key terrestrial ecosystem parameters across space and time. TERN observes ecosystems across multiple scales using satellite remote sensing, drones, in situ sensors, and human observations, whilst also publishing data from partnering institutes. This multi-source approach creates significant data management challenges, particularly in harmonising data from various sources. Most published datasets contain parameter names without adequate documentation about their meaning, and the same parameters are occasionally measured at different scales. Machine-readable controlled vocabularies provide the foundation for semantic interoperability, enabling data exchange with a shared understanding of the meaning of terms used. This paper describes the development and management of controlled vocabularies in the context of the data infrastructure managed by TERN. In addition, the paper provides an overview of different vocabulary types developed and their use in downstream applications."},{title:"An Explainable Natural Language Framework for Identifying and Notifying Target Audiences In Enterprise Communication",authors:"V\xedtor Louren\xe7o, Mohnish Dubey, Yunfei Bai, Audrey Depeige and Vivek Jain",abstract:"In large-scale maintenance organizations, identifying subject matter experts and managing communications across complex entities relationships poses significant challenges that traditional communication approaches fail to address effectively. We propose a novel framework that combines RDF graph databases with LLMs to process natural language queries for precise audience targeting, while providing transparent reasoning through a planning-orchestration architecture. Our solution enables users to formulate intuitive queries about equipment, manufacturers, maintenance engineers, and facilities, delivering explainable results that maintain trust in the system while improving communication efficiency across the organization."},{title:"Mitigating Undesired Conditions in Flexible Production with Product-Process-Resource Asset Knowledge Graphs",authors:"Petr Novak, Stefan Biffl, Marek Obitko and Petr Kadera",abstract:"Contemporary industrial cyber-physical production systems (CPPS) composed of robotic workcells face significant challenges in the analysis of undesired conditions due to the flexibility of Industry 4.0 that disrupts traditional quality assurance mechanisms. This paper presents a novel industry-oriented semantic model called Product-Process-Resource Asset Knowledge Graph (PPR-AKG), which is designed to analyze and mitigate undesired conditions in flexible CPPS. Built on top of the well-proven Product-Process-Resource (PPR) model originating from ISA-95 and VDI-3682, a comprehensive OWL ontology addresses shortcomings of conventional model-driven engineering for CPPS, particularly inadequate undesired condition and error handling representation. The integration of semantic technologies with large language models (LLMs) provides intuitive interfaces for factory operators, production planners, and engineers to interact with the entire model using natural language. Evaluation with the use case addressing electric vehicle battery remanufacturing demonstrates that the PPR-AKG approach efficiently supports resource allocation based on explicitly represented capabilities as well as identification and mitigation of undesired conditions in production. The key contributions include (1) a holistic PPR-AKG model capturing multi-dimensional production knowledge, and (2) the useful combination of the PPR-AKG with LLM-based chatbots for human interaction."},{title:"Graph-Driven Validation Framework of Clinical Study Reports Using Semantic Technologies",authors:"Hanuragav Muthiah Giri and Gopinath Viswanathan",abstract:"Regulators demand that every listing, summary table and figure in a clinical-study report be consistent and traceable to raw observations. Traditional dual-programming in SAS or Python breaks down when schemas drift, while relational warehouses lose provenance. This paper outlines a knowledge-graph pipeline where an OWL/SHACL ontology governs validation, YAML mappings drive deterministic ETL, and GraphDB enforces constraints. The approach removes repetitive QC, surfaces discrepancies early and gives auditors click-through lineage from any published number to its source."},{title:"Exploring Semantic-Enhanced Property Graphs in Network Operations",authors:"Beyza Yaman, Michael Mackey, Peter Cautley and Declan O'Sullivan",abstract:"Telecommunication networks face significant challenges in performing root cause analysis due to their complexity, data heterogeneity, and high-volume event streams. Traditional semantic models like RDF and flexible property graph models such as LPG offer partial solutions but fall short when applied individually. This paper investigates the Semantic-enhanced Programmable Graph (SPG) approach, specifically through the OpenSPG engine, which integrates the structural advantages of property graphs with semantic constraints inspired by RDF ontologies. We evaluate its applicability in a telecom root cause analysis use case, comparing it to RDF-based modeling. Our findings investigate the applicability of OpenSPG in operational modeling and its limitations in maturity and tooling, offering insights for future semantic-enabled network management solutions."},{title:"Schema-Constrained Grammar-Guided Generation of GQL Queries from Natural Language",authors:"Andre Melo and Jeff Z. Pan",abstract:"Graph databases provide a robust foundation for storing and querying knowledge graphs, making them well-suited for powering intelligent personal assistants. Translating natural language into graph query languages (NL2GQL) enables these assistants to answer user queries by leveraging personal data stored as graphs. To preserve user privacy, on-device processing is preferred, but it comes with strict computational and memory constraints. A major challenge in this setting is ensuring that generated queries comply with user-specific, often custom, graph schemata. In this paper, we explore the business value and challenges of NL2GQL translation in a privacy-sensitive, resource-constrained setting, and propose schema-constrained grammar-guided generation as a potential solution to address these challenges."},{title:"Building Hierarchy-Aware Knowledge Graphs: Ontology-Grounded Triple Extraction with LLMs",authors:"Kudzai Sauka, Gianluigi Bardelloni, Frederik Situmeang and Jigsa Bulto",abstract:"This paper introduces a hierarchy-aware framework, Document_Preprocessing-Extract-Resolve-Merge-Canonicalize (DERMC), for constructing knowledge graphs using large language models (LLMs). It addresses the limitations of naive LLM prompting in creating a knowledge graph, which often results in redundancy, LLM cognitive overload, and inconsistencies across languages. Building on the Extract-Define-Canonicalize (EDC) paradigm, our approach integrates multilingual coreference resolution, hierarchical document parsing, and a RAG-MCP-inspired schema retriever that dynamically narrows candidate relations for each document context, thereby reducing the size of the LLM prompt. The system supports both commercial and local LLM backends, allowing flexible deployment. Preliminary results show improved alignment between flat and hierarchical parsing modes. Full-scale experiments and evaluations, including assessments by industry and knowledge representation experts, are planned to validate performance and quality in enterprise contexts."},{title:"RAGulating Compliance: A Multi-Agent Knowledge Graph for Regulatory Compliance QA",authors:"Hemant Jomraj, Bhavik Agarwal and Viktoria Rojkova",abstract:"Regulatory compliance question answering (QA) requires precise, verifiable information, and domain-specific expertise, posing challenges for Large Language Models (LLMs). In this work, we present a novel multi-agent framework that integrates a Knowledge Graph (KG) of Regulatory triplets with Retrieval-Augmented Generation (RAG) to address these demands. First, agents build and maintain ontology-free KG by extracting subject\u2013predi- cate\u2013object (SPO) triplets from regulatory documents and systematically cleaning, normalizing, deduplicating and updating them. Second, these triplets are embedded and stored along with their corresponding textual sections and metadata in a single enriched vector database, allowing for both graph-based reasoning and efficient information retrieval. Third, an orchestrated agent pipeline leverages triplet-level retrieval for question answering, ensuring high semantic alignment between user queries and the factual \u2019who-did-what-to-whom\u2019 core captured by the graph. Our hybrid system outperforms conventional methods in complex regulatory queries, ensuring factual correctness with embedded triplets, enabling traceability through a unified vector database, and enhancing understanding through subgraph visualization, providing a robust foundation for compliance-driven and broader audit-focused applications."},{title:"Bridging Expert Knowledge and AI: A Semantic Architecture for Manufacturing Knowledge Management using Knowledge Graphs and Large Language Models",authors:"Camilla Hemmer",abstract:"Manufacturing companies face a critical knowledge management crisis where decades of operational expertise remains trapped in expert minds, leading to extended onboarding periods, inefficient decision-making and knowledge loss through retirement. This paper presents the development of a semantic AI assistant system that combines Knowledge Graphs with Large Language Models to transform how manufacturing engineers access and utilize institutional knowledge. The approach addresses the integration of scattered data across incompatible systems through a three-stage pipeline: multi-format document ingestion, knowledge graph construction, and LLM-enhanced natural language querying. Our implementation demonstrates how semantic technologies can address real-world industrial challenges, reducing information retrieval time and creating pathways for knowledge preservation at enterprise scale."}],rn=[{id:"P1",title:"SLM-as-a-Judge with Attention Steering for Detailed Topic Extraction from Academic Literature",authors:"Takahiro Kawamura, Sho Enomoto and Jun-Ichiro Mori",abstract:"This study introduces domain-specific Small Language Models (SLMs) designed to fact-check the outputs of general-purpose Large Language Models (LLMs). The goal is to accurately and automatically extract detailed technical elements from academic papers to build knowledge graphs. Two SLM types were developed: one through continued pre-training and the other using attention steering. Experiments on information extraction in \u2018Fake News Detection\u2019 showed that SLMs improved the sufficiency, accuracy, and stability of extracted information. Future work will involve larger datasets and further knowledge graph construction."},{id:"P2",title:"Avoiding Overpersonalization with Rule-Guided Knowledge Graph Adaptation for LLM Recommendations",authors:"Fernando Spadea and Oshani Seneviratne",abstract:"We present a lightweight neuro-symbolic framework to mitigate over-personalization in LLM-based recommender systems by adapting user-side Knowledge Graphs (KGs) at inference time. Instead of retraining models or relying on opaque heuristics, our method restructures a user\u2019s Personalized Knowledge Graph (PKG) to suppress feature co-occurrence patterns that reinforce Personalized Information Environments (PIEs), i.e., algorithmically induced filter bubbles that constrain content diversity. These adapted PKGs are used to construct structured prompts that steer the language model toward more diverse, Out-PIE recommendations while preserving topical relevance. We introduce a family of symbolic adaptation strategies, including soft reweighting, hard inversion, and targeted removal of biased triples, and a client-side learning algorithm that optimizes their application per user. Experiments on a recipe recommendation benchmark show that personalized PKG adaptations significantly increase content novelty while maintaining recommendation quality, outperforming global adaptation and naive prompt-based methods."},{id:"P3",title:"From Strings to Semantics: A Graph-based Reranking Approach for Annotating Tables using Domain Ontologies",authors:"Nan Liu, Mohamed-Anis Koubaa, Wolfgang Suess and Veit Hagenmeyer",abstract:"As one of the most widely used data storage and exchange formats, tabular data can be challenging to be integrated, interpreted, and reused when they lacks accurate semantic annotations, particularly when data come from heterogeneous sources. However, the annotation process is often time-consuming and requires a deep understanding of the internal structure of the target ontology. Therefore, developing efficient and accurate semi-automatic or fully automatic annotation tools is very important. Most existing approaches often rely on textual similarity to match column headers to ontology terms, and fail to effectively leverage the rich relational semantics representation within the ontology. To address this issue, we propose a reranking approach that combines semantic similarity with ontology structure. Specifically, we first generate a set of candidate ontology terms based on semantic similarity. For each source table header and its candidate ontology terms, we construct subgraphs and train a lightweight Graph Neural Network (GNN) model on these graphs to learn structure-aware representations. These representations are then used to improve the ranking of candidate ontology terms. To validate our approach, we performe experiments on the OAEI dataset. The results demonstrate that our approach improves the Hit@1 by 4% compared to a baseline model that only relies on lexical similarity. This result shows that learning on local subgraphs is a promising direction for ontology alignment and schema matching."},{id:"P4",title:"Systematic Dataset Review: \\\\from Linked Dataset Discoverability to their FAIRness",authors:"Sana Latif and Maria Angela Pellegrino",abstract:"This work presents the \\texttt{Systematic Dataset Review} (shortened as SDR), a systematic, cyclic, and FAIR-aligned process for dataset discovery, curation, and quality assessment, inspired by Systematic Literature Review methodologies. The process consists of three phases: (i) a (multivocal) literature review to identify and document references about datasets; (ii) a Linked Dataset Discoverability phase to curate, filter, and publish datasets as domain-specific Linked Open Data sub-clouds; and (iii) a Quality Assessment phase that enables FAIRness evaluations through automated tools. The framework is adaptable across different use cases: monitoring the quality of existing sub-clouds, enriching current sub-clouds with new datasets, or constructing entirely new thematic sub-clouds. By ensuring transparency, reproducibility, and ongoing quality monitoring, this approach supports the creation of accessible and sustainable dataset ecosystems."},{id:"P5",title:"Towards Actionable Ishikawa Diagrams: An Exploratory Case Study From the Textile Industry",authors:"Christian Fleiner, Simon Vandevelde and Joost Vennekens",abstract:"The Ishikawa diagram is an established tool in the manufacturing domain for conducting a root cause analysis. The Ishikawa diagram ontology was developed to explicitly model Ishikawa diagrams as visual artifacts, their encoded knowledge and the process of their creation. While formalization is an important step for making encoded knowledge accessible, another challenge is to establish reasoning mechanisms to provide decision-support to users. In this paper, we present a reasoning pipeline which resulted from a case study concerning fabric fault detection. The reasoning pipeline is intended to be used in conjunction with the Ishikawa diagram ontology."},{id:"P6",title:"Using LLM to improve Knowledge Graph Entity Matching",authors:"Victor Eiti Yamamoto and Hideaki Takeda",abstract:"Knowledge graphs (KGs) are powerful tools for representing and reasoning over structured information. Entity matching between KGs helps integrate multiple KGs. However, the performance of entity matching tools can be sensitive to parameter settings, such as thresholds. Large language models (LLMs) have emerged as powerful tools for solving reasoning problems and show potential for improving entity alignment. Our approach incorporates two LLM-based steps: filtering and expansion. In the filtering step, an LLM is used to validate entity mappings. The expansion step then uses an LLM to select the correct mapping from a candidate list for any source entity that lacks a corresponding pair after the filtering step. Experiments on the OAEI KG track dataset and matchings with DBpedia datasets show that using an LLM as a filter achieves a low false-negative rate and a favorable false-positive rate, indicating that it can improve precision without significantly lowering recall. However, the expansion step has low precision because the LLM tries to select a corresponding entity even when no correct match exists in the candidate list."},{id:"P7",title:"CE-KG: Citation Enhanced Knowledge Graph via Citation Sentiment Fusion and Evidence Tracing",authors:"Yalan Huang, Xuemei Yang, Bin Zhang and Xiaoli Tang",abstract:'This study proposes a knowledge graph (KG) construction method integrating citation information to address credibility tracing of knowledge claims. By fi-ne-tuning large language models (LLMs), SPO triples are precisely extracted from the "Conclusion" sections of literature abstracts. A dual-level fusion mechanism is developed based on sentiment analysis (Posi-tive/Neutral/Negative) of citation contexts. This approach injects academic evaluation attributes at the paper level and links them to SPO triples. An inno-vative Neo4j-MySQL heterogeneous storage architecture is designed, enabling fine-grained evidence tracing from KG relationships to citation contexts through uniform identifiers. The constructed KG simultaneously provides knowledge claims and supports credibility tracing from the academic communi-ty perspective.'},{id:"P8",title:"KGSynX: Knowledge Graph and Explainable Feedback Guided LLMs for Synthetic Tabular Data Generation",authors:"Ke Yu, Teruaki Hayashi, Yuki Shigoku, Yukari Usukura and Shigeru Ishikura",abstract:"Synthetic tabular data is vital for augmentation, privacy, and performance under limited data, yet most work targets marginal statistics, neglecting downstream utility and explainability in scarce-data scenarios. We propose KGSynX, which builds a knowledge graph from table records and derives graph embeddings to inform LLM prompts. A SHAP\u2011guided feedback loop measures attribution differences between real and generated data and injects targeted corrections into subsequent prompts. Evaluated under the Train-on-Synthetic, Test-on-Real (TSTR) protocol on heart disease, enterprise invoice, and telco churn datasets, KGSynX consistently outperforms baseline in accuracy, F1, and AUC while closing the SHAP attribution gap. By explicitly modeling structure and semantics, KGSynX produces more reliable synthetic datasets for downstream tasks."},{id:"P9",title:"Constructing Cybersecurity Knowledge Graphs for Hybrid LLM\u2013Graph Reasoning on Vulnerabilities",authors:"Julio Vizcarra, Yuta Gempei, Yanan Wang, Takamasa Isohara and Mori Kurokawa",abstract:"In cybersecurity, the threat landscape is composed of complex relations among security data and constantly evolves. To address this challenge, this paper presents a framework for constructing and reasoning over cybersecurity knowledge graphs (KGs) derived from vulnerability reports. Our approach analyzes textual content and structured data sources. To enhance causal reasoning, we explicitly model key causal factors as structured entities and relationships. The resulting KG is further enriched through augmentation using DBpedia, integrating external knowledge to enhance connectivity and context. We evaluate the impact of this augmentation through a comparison, contrasting the content of the original and the augmented graphs. Experimental results demonstrate that the Graph-LLM approach, with augmentation, enhances link prediction and produces higher-quality QA compared to using report descriptions alone. We demonstrate a hybrid reasoning setup integrating LLM-based language understanding with graph inference to answer cybersecurity queries."},{id:"P10",title:"A Semantic Web-Based Infrastructure for Purpose-Driven Retrieval of Life Science Bioresources",authors:"Tatsuya Kushida, Daiki Usuda, Masanobu Yamagata, Norio Kobayashi, Shoichiro Shindo, Tatsuya Yamada, Yuki Yamagata and Hiroshi Masuya",abstract:"In the life sciences, the shared use of research materials for experiments is essential for ensuring reproducibility. Such materials are referred to as biological resources. To support life science research, biological resource centers are operated worldwide as institutional platforms for the provision of these materials. One of the core functions of these centers is disseminating information about available resources. The RIKEN BioResource Research Center, one of the bioresource center in Japan, has been providing a knowledge-based search system for life scientists since 2018. This system employs Semantic Web technologies to deliver detailed biological characteristics of the resources it manages. By integrating bioresource data, public life science datasets, and ontologies through a SPARQL endpoint backend, the system enables researchers to explore available research materials from diverse scientific perspectives via a dedicated search interface. Furthermore, the use of Semantic Web technologies supports sustainable and scalable system operation."},{id:"P11",title:"Tackling the Write-to-Read Web of Data with Trustflows",authors:"Ben De Meester, Julian Andr\xe9s Rojas, Femke Ongenae, Pieter Colpaert and Ruben Verborgh",abstract:"The need for the read\u2013write Linked Data Web is currently implemented as a Create, Read, Update or Delete (CRUD) strategy on resources that implies that agents will read exactly what has once been written. In practice, we notice the following problems when deploying writeable Linked Data nodes in an ecosystem. Data reuse is impeded by diverging data usage requirements from how the data was originally written and by evolving data models. Also, individual data point verification at the read side becomes obligatory due to the absence of an authoritative source that guarantees auditability. We present characteristics of writeable Linked Data nodes (cope with longevity for written data, combine read data using different models, and provide an explicit trust context) as arguments justifying the need for a more complex operational model. We apply a Command Query Responsibility Segregation pattern to decouple write and read interfaces, introduce semantic mappings within the writeable Linked Data node to support evolving data read requirements, and apply Event Sourcing aligned with PROV-O\u2019s Actor-Entity-Activity model to provide an explicit trust context. Applying this operational model \u2013 dubbed \u201cTrustflows\u201d \u2013 to the PACSOI use case showcases the additional affordances of handling data coming in different granularities, from different sources, adhering to different reading requirements."},{id:"P12",title:"Aligning ESG Controversy Data with International Guidelines through Semi-Automatic Ontology Construction",authors:"Tsuyoshi Iwata, Guillaume Comte, Melissa Flores, Ryoma Kondo and Ryohei Hisano",abstract:"The growing importance of environmental, social, and governance data in regulatory and investment contexts has increased the need for accurate, interpretable, and internationally aligned representations of non-financial risks, particularly those reported in unstructured news sources. However, aligning such controversy-related data with principle-based normative frameworks, such as the United Nations Global Compact or Sustainable Development Goals, presents significant challenges. These frameworks are typically expressed in abstract language, lack standardized taxonomies, and differ from the proprietary classification systems used by commercial data providers. In this paper, we present a semi-automatic method for constructing structured knowledge representations of environmental, social, and governance events reported in the news. Our approach uses lightweight ontology design, formal pattern modeling, and large language models to convert normative principles into reusable templates expressed in the Resource Description Framework. These templates are used to extract relevant information from news content and populate a structured knowledge graph that links reported incidents to specific framework principles. The result is a scalable and transparent framework for identifying and interpreting non-compliance with international sustainability guidelines."},{id:"P13",title:"Jelly-Patch: a Fast Format for Recording Changes in RDF Datasets",authors:"Piotr Sowi\u0144ski, Kacper Grzymkowski and Anastasiya Danilenka",abstract:"Recording data changes in RDF systems is a crucial capability, needed to support auditing, incremental backups, database replication, and event-driven workflows. In large-scale and low-latency RDF applications, the high volume and frequency of updates can cause performance bottlenecks in the serialization and transmission of changes. To alleviate this, we propose Jelly-Patch \u2013 a high-performance, compressed binary serialization format for changes in RDF datasets. To evaluate its performance, we benchmark Jelly-Patch against existing RDF Patch formats, using two datasets representing different use cases (change data capture and IoT streams). Jelly-Patch is shown to achieve 3.5\u20138.9x better compression, and up to 2.5x and 4.6x higher throughput in serialization and parsing, respectively. These significant advancements in throughput and compression are expected to improve the performance of large-scale and low-latency RDF systems."},{id:"P14",title:"Bio-KGvec2go: Serving up-to-date Dynamic Biomedical Knowledge Graph Embeddings",authors:"Hamid Ahmad, Heiko Paulheim and Rita T. Sousa",abstract:"Knowledge graphs and ontologies represent entities and their relationships in a structured way, having gained significance in the development of modern AI applications. Integrating these semantic resources with machine learning models often relies on knowledge graph embedding models to transform graph data into numerical representations. Therefore, pre-trained models for popular knowledge graphs and ontologies are increasingly valuable, as they spare the need to retrain models for different tasks using the same data, thereby helping to democratize AI development and enabling sustainable computing.  In this paper, we present Bio-KGvec2go, an extension of the KGvec2go Web API, designed to generate and serve knowledge graph embeddings for widely used biomedical ontologies. Given the dynamic nature of these ontologies, Bio-KGvec2go also supports regular updates aligned with ontology version releases. By offering up-to-date embeddings with minimal computational effort required from users, Bio-KGvec2go facilitates efficient and timely biomedical research."},{id:"P15",title:"Constraint-Aware Ontology Engineering for Information Extraction from Financial Contracts",authors:"Ryoma Kondo, Shamik Kundu, Muneaki Imai, Kyosuke Tomoda, Yuki Takazawa and Ryohei Hisano",abstract:"The automation of business processes is advancing rapidly, particularly in domains governed by complex rule-based documentation such as financial contracts. These documents are highly structured and semantically rich, which makes them well suited for modeling with formal ontologies. Although large language models offer promising capabilities for information extraction, their effectiveness is limited by the challenge of designing consistent prompts across contract types due to a lack of standardized semantic definitions. In this paper, we explore how embedding ontological structures and constraint specifications into prompts can improve the accuracy and reusability of information extraction systems, using confirmation notices for investment transactions as a case study. Our findings show that incorporating semantic constraints into prompts improves performance in language model-based information extraction, highlighting the potential of combining Semantic Web technologies with language models to support accurate and maintainable information extraction from financial contracts."},{id:"P16",title:"Prompt Compression for Dialog Navigation with Need-Oriented Environmental Knowledge Base and Large Language Models",authors:"Hiroaki Shimoma, Sudesna Chakraborty and Takeshi Morita",abstract:"In Embodied AI, navigation agents using Large Language Models (LLMs) often rely on lengthy prompts that include extensive environmental information. This becomes increasingly problematic in complex environments such as the VirtualHome simulator, where incorporating all object data can reduce accuracy and increase computational costs. To address this, we propose a prompt compression technique based on a ``need-oriented'' environmental knowledge base. Our system first infers a user's underlying need from their natural language request using Murray's theory of human needs. It then retrieves only the objects relevant to that need from our knowledge base. A compressed prompt, containing only the user's request and the specific objects, is then sent to the LLM. The results showed this method significantly improves navigation accuracy while reducing prompt length compared to approaches that use all environmental data."},{id:"P17",title:"Interpreting User Needs with LLMs-based Conversational Agents and Knowledge Graphs: An Earth Observation Use Case",authors:"Antoine Dupuy, Nathalie Aussenac-Gilles, Christophe Baehr and Cassia Trojahn",abstract:"Open Science has broadened access to scientific datasets. However, identifying relevant ones to specific user needs remains challenging due to the volume, diversity, and poor metadata. This paper proposes to integrate semantically enriched metadata with LLM agents to interpret natural language queries, to extract user intent, and to generate justifications for retrieved results. Experiments with different LLMs highlight the potential of such approach for scientific dataset retrieval."},{id:"P18",title:"TyRaL: End-to-End Document-level Relation Extraction via Type-Constrained Rule Learning",authors:"Mierzhati Alimu, Xiaowang Zhang and Chaochao Du",abstract:"In recent years, Document-level Relation Extraction (DocRE) has encountered significant challenges in capturing complex entity relationships and reasoning over long-range dependencies. Existing methods primarily focus on learning implicit representations or applying chain-like logical rules, but they often overlook differences in entity types and the significance of type constraints, potentially leading to errors in relation reasoning. This poster introduces a type-constrained enhanced chain-like rule (TC rule) and proposes an end-to-end document-level relation extraction framework (TyRaL) to address this issue. By incorporating a novel rule reasoning module, TyRaL transforms the discrete rule learning problem into a parameter optimization task in continuous space, enabling both explicit and implicit learning of entity type constraint rules and thereby enhancing the model's logical consistency and interpretability. Experimental results on the standard DWIE dataset show that TyRaL significantly outperforms existing rule-enhanced methods in both F1 and Ign F1 metrics. It demonstrates superior logical modeling and semantic reasoning capabilities while offering new perspectives and solutions for research in the DocRE field."},{id:"P19",title:"Human-Friendly Explanation for Ontology-based Concept Similarity: Design and Development",authors:"Watanee Jearanaiwongkul and Teeradaj Racharak",abstract:"While recent neuro-symbolic approaches have enabled interpretable computation of concept similarity in ontologies, translating these formal explanations into human-friendly forms remains a challenge. In this work, we investigate how large language models, particularly ChatGPT and Gemini, can be prompted to generate natural language explanations that justify similarity results in a way that is understandable to end users. Building on a neuro-symbolic framework for measuring concept similarity in Description Logic (DL) ontologies, we explore two types of human-friendly explanations i.e., node-based and path-based explanation. Furthermore, we evaluate LLMs's ability to generate each component of these path-based explanations using our small curated dataset. We evaluate the effectiveness of prompting approaches along different dimensions such as clarity, informativeness, and perceived usefulness through both qualitative analysis and user studies. Our results show the potential and limitations of using LLMs as a tool to bridge the gap between formal similarity reasoning and human interpretability, paving the way for more transparent ontology-driven systems."},{id:"P20",title:"JSimELHExplainer: A Robust JAVA Library for Explainable Semantic Similarity for ELH Description Logic Ontology",authors:"Teeradaj Racharak and Watanee Jearanaiwongkul",abstract:"We present a newly developed Java library that implements a neuro-symbolic framework for computing semantic similarity between concepts in Description Logic ELH ontologies. This library provides an implementation of a hybrid approach combining a structural-based method in ontology reasoning with distributional semantics derived from pre-trained word embeddings. It supports efficient similarity computation and interpretable explanations for the results. Designed with scalability in mind, it guarantees polynomial-time execution and supports large-scale ontologies with thousands of concepts and complex hierarchical structures. For explainability, it produces fine-grained explanations by identifying the contributing primitive and existential concept pairs, as well as the semantic alignments found in the embedding space. These explanations help users understand why a similarity score is given, making the results transparent and auditable. The API is embedding-agnostic and compatible with a wide range of vector space models, including static embeddings (e.g., Word2Vec) and contextualized models (e.g., BERT). This tool enables the development of explainable, knowledge-driven AI systems in domains where both structured ontological modeling and contextual semantic understanding are essential."},{id:"P21",title:"Learned Indexing for Efficient Querying on Knowledge Graphs",authors:"Gaurav Dawra, Aanchal Gupta, Nandika Jain, Yogender Kumar, Jishnu Raj Parashar, Bapi Chatterjee and Raghava Mutharaju",abstract:"Knowledge Graphs are used extensively in several domains across many different applications. They are good at integrating, managing, and extracting value from diverse sources of data. Often, they are very large, with billions of nodes and edges. SPARQL, a W3C standard, is one of the prominent query languages for Knowledge Graphs. Even simple SPARQL queries typically involve several joins. Naturally, such queries applied to large Knowledge Graphs have huge latency. There have been several works on optimizing and finetuning SPARQL queries. However, they do not consider the distribution of the underlying data. Learned indexes provide queries based on data distribution with improved throughput and reduced space. In this work, we introduce a learned index for implementing SPARQL queries in Knowledge Graphs. Our evaluation on two Knowledge Graphs involving a few SPARQL queries led to promising results that encourage further research in this direction."},{id:"P22",title:"SSHOC-NL: Towards a Knowledge Graph for Social Sciences and Humanities",authors:"Andre Valdestilhas, Ronald Siebes and Jacco van Ossenbruggen",abstract:"Social Sciences and (Digital) Humanities (SSH) increasingly benefit from the online availability of datasets, services, and tools provided by their peers and governmental organizations. However, the fragmented and heterogeneous nature of the metadata makes it difficult to assess the complexity of replicating results and the potential reuse of various parts (methodology, tools and data) for follow-up research. For example, a significant effort is required to check the access requirements and quality of the data and to check if the format is compatible with tools that a researcher is familiar with. This paper outlines the vision, structure, and objectives of the Social Science and Humanities Open Cloud for the Netherlands (SSHOC-NL), focusing on its role in building and leveraging a national SSH knowledge graph. By developing a unified data environment, semantic integration tools, and interactive Data Stories, this SSHOC-NL effort transforms disparate data into interconnected scientific knowledge. This work aims to equip Dutch researchers with the tools and skills necessary to navigate complex societal challenges through a rich, semantically linked data landscape, representing a critical step towards realizing the promise of the European Open Science Cloud (EOSC) within the Dutch SSH domain."},{id:"P23",title:"Exploring LLM to extract Knowledge Graph from academic abstracts",authors:"Victor Eiti Yamamoto, Othmane Kabal, Lakshan Karunathilake, Kotaro Nishigori, Vicente Lermanda, Shixiong Zhao, Hiroki Uematsu, Yanming He and Hideaki Takeda",abstract:"Knowledge graphs (KGs) are a powerful tool for representing semantic information. Existing methods depend on the use of human annotation or semi-structured automated methods. However, academic papers and their abstracts are still the main way to carry academic information. The development of LLM leads to new tools to solve semantically heavy problems, so LLM can help to create KGs from texts automatically. In this research, we tested three approaches on three abstracts from computer science. We found that all methods still have room to improve precision and recall. Furthermore, finding a common way to express the same sentence in a triple is one of the significant issues in comparing abstracts"},{id:"P24",title:"Assessing Logical Inference Capabilities of Large Language Models through RDF Schema Entailment Rules: A Multi-Level Evaluation",authors:"Taichi Hosokawa, Sudesna Chakraborty and Takeshi Morita",abstract:"Large language models (LLMs) achieve strong performance in various language tasks, yet their logical inference abilities remain limited. LLMs often rely on pre-trained knowledge rather than explicit inference. Their inference capabilities in ontology languages like RDFS also remain underexplored. This study evaluates LLMs' inference abilities using RDFS entailment rules with two knowledge datasets: real-world data from Linked Open Data and counterfactual data created by systematically altering real-world facts. We propose a novel evaluation methodology assessing LLM outputs. To analyze inference behavior under different conditions, we design a three-level task framework varying rule presentation methods for identical inference tasks. Results show high accuracy on real-world datasets. LLMs sometimes infer missing premises using pre-trained knowledge, suggesting potential for incompletely structured environments. However, accuracy declines with counterfactual datasets and when shifting from pre-combined to multiple separate rules. Performance further drops when models must select appropriate rules from predefined subsets. These findings highlight both strengths and limitations of LLMs in structured, rule-based inference within ontology-driven systems."},{id:"P25",title:"Key Aspect Prediction for Silent Vulnerability Fixes via Semantic Augmentation",authors:"Dongshun He, Linyi Han and Xiaowang Zhang",abstract:"Silent vulnerability fixes pose significant risks to downstream open-source software (OSS) users, as the lack of vulnerability details in fix patches leaves users unaware of potential threats. Previous work predicts the key aspects of vulnerability fixes using an encoder-decoder model to aid users in understanding these fixes. However, their approach overlooks the limited expressiveness of commit messages and the varied intents underlying code changes. In this poster, we propose a semantic-augmented method for key aspect prediction in silent vulnerability fixes. Firstly, we enrich commit semantics by incorporating information from multiple external sources. Then, we design a Chain-of-Thought (CoT) prompt to analyze code semantics at the hunk level and identify security-relevant changes. Finally, we design a task-specific embedding method to represent code diffs and retrieve semantically similar commits, guiding large language models (LLMs) to predict the vulnerability type, root cause, impact, and attack vector. Experiments on our constructed dataset demonstrate that our method outperforms baselines in key aspect prediction across ROUGE-L and METEOR."},{id:"P26",title:"MetaExplainer In Action: An Overview of a Framework to Generate Multi-Type User-Centered Explanations",authors:"Shruthi Chari, Oshani Seneviratne, Prithwish Chakraborty, Pablo Meyer and Deborah McGuinness",abstract:"Explanations are crucial for building trustworthy AI systems, but a gap often exists between the explanations provided by models and those needed by users. Previous research and our interactions with clinicians have shown that users prefer question-driven and diverse explanations. To address this gap, we introduce MetaExplainer, a neuro-symbolic framework designed to generate user-centered, multi-type explanations. Our approach employs a three-stage process: first, we decompose user questions into machine-readable formats using state-of-the-art large language models (LLM); second, we delegate the task of generating system recommendations to model explainer methods; and finally, we synthesize natural language explanations that summarize the explainer outputs. Here, we present an indicative end-end example from the Diabetes (PIMA Indian) tabular dataset. We describe the MetaExplainer's implementation and quantitative and qualitative results of the framework in a separate, longer paper that we link here. Overall, the MetaExplainer is a versatile and traceable neuro-symbolic explanation generation framework addressing a broad range of user questions, positioning MetaExplainer as a promising tool for enhancing AI explainability across multiple domains. Github: \\href{https://github.com/tetherless-world/metaexplainer}{https://github.com/tetherless-world/metaexplainer}."},{id:"P27",title:"Ontologies, Knowledge Graphs, and LLMs: How Do We GET Evaluations Done Right?",authors:"Heiko Paulheim",abstract:"The use of Large Language Models (LLMs) becomes increasingly popular for many tasks in the Semantic Web and Knowledge Graph community, e.g., knowledge graph (KG) construction, ontology learning, and ontology matching. Methods and tools using LLMs for those tasks are often evaluated on existing KGs and ontologies, which are publicly available on the Web. Thus, it can be assumed that the test data has been seen by the LLM, and it is questionable if the results transfer to a case of unseen data (which is where those models are intended to be employed).  In this paper, we question the current evaluation paradigm using public data and propose a different approach, i.e., using a secondary LLM to create ontologies and knowledge graphs for one-time use on the fly. We coin this approach GET (generate--evaluate--trash). This also allows for repeating experiments and computing standard deviations and confidence intervals, which facilitates additional statements about the robustness of different approaches. We demonstrate our suggested approach on the case of taxonomy induction."},{id:"P28",title:"GraphRAG with Knowledge Graphs for Question Answering on Administrative Meeting Records",authors:"Kumi Ushio, Daichi Tsuji and Yohei Kobashi",abstract:"This study introduces a GraphRAG-based question-answering system for Japanese administrative meeting records, addressing challenges in accessing policy-related information. Using the minutes from Japan\u2019s Financial Services Agency, we constructed a lightweight ontology-aware knowledge graph capturing participants, meetings, and utterances, and integrated it with LLMs. The system applies a GraphRAG approach, leveraging graph-based context expansion to integrate related nodes and enrich contextual understanding, combined with dynamic tool selection to support multi-step reasoning. Evaluation with questions showed high accuracy for both simple retrieval and relation-exploration queries. Future work includes improving retrieval accuracy, developing domain-specific ontologies, automating tool generation, and deploying the system as an interactive application."},{id:"P29",title:"Accelerating Drug Discovery through Semantic Data Integration and Machine Learning: From Biomedical Knowledge Graphs to Predictive Models",authors:"Toshiaki Katayama, Shuichi Kawashima, Ryosuke Kojima, Takuto Koyama, Mayumi Kamada and Yuki Moriya",abstract:"We introduce two interoperable resources that facilitate semantic data integration and machine learning in biomedical research: the med2rdf knowledge graph and the Tabulae dataset preparation system. med2rdf transforms heterogeneous biomedical databases into RDF using a unified ontology and publishes them via the RDF Portal with SPARQL endpoints and FAIR-compliant metadata. It addresses key integration issues such as identifier heterogeneity and vocabulary inconsistency. Tabulae builds on this semantic infrastructure by enabling users to generate machine learning\u2013ready tabular datasets from RDF-based sources. It abstracts complex querying and integrates compound and protein features into a unified format. We demonstrate the utility of these resources through a case study on compound\u2013protein interaction (CPI) prediction using Random Forest regression. This illustrates how semantic integration combined with machine learning can support efficient drug discovery. Together, med2rdf and Tabulae provide a scalable and reusable framework for semantic data-driven research in biomedicine."},{id:"P30",title:"An Ontology for the Common Data Format on Football Match Data",authors:"Fajar J. Ekaputra, Gregor K\xe4fer and Matthias Kempe",abstract:"Applications of artificial intelligence (AI) in sports, particularly for football (soccer) has been growing in the last years, e.g., for player recruitments, performance monitoring, as well as player selection. To support such applications, the availability of an integrated, high-quality data is crucial to ensure accurate results. This aspect is especially crucial due to the heterogeneity in data acquired by various stakeholders, e.g., companies and football clubs. Catering for such demand, a recent work proposed a minimal schema for football match data called the common data format (CDF), aiming to ensure the provided data is clear, sufficiently contextualized, and complete to enable common downstream analysis tasks. This paper reports on an initial effort to create the Football Common Data Format (FCDF) ontology as a serialization of the CDF core concepts, with a particular focus on streamlining concepts, properties, and attributes. The FCDF ontology aims to provide a formal, shared conceptualization of CDF as a symbolic model, to facilitate further development of AI in sports, particularly through neurosymbolic AI approaches."},{id:"P31",title:"Unveiling the Butterfly Effect in Knowledge Editing for Large Language Models Using Knowledge Graph-based Analysis",authors:"Patipon Wiangnak, Natthawut Kertkeidkachorn and Kiyoaki Shirai",abstract:"Large Language Models (LLMs), particularly those based on Generative Pre-trained Transformers (GPT), have achieved strong performance in various natural language tasks. However, LLMs are limited by a knowledge cut-off, so their information is not updated. Common methods for updating LLM knowledge, such as fine-tuning, retrieval-augmented generation, and machine unlearning, are often resource-intensive and may introduce unintended effects, including the loss of relevant context or conflicts with existing knowledge. Knowledge Editing (KE) offers a more efficient alternative by enabling precise updates to specific facts without retraining the entire model, while preserving unrelated information. Still, such edits can trigger unexpected ripple effects, known as the Butterfly Effect, where modifying one fact causes errors in related knowledge. In this work, we introduce ButterflyKE, a knowledge graph-based analysis method that probes neighboring knowledge to identify local side effects caused by a single factual update. Using Wikidata as a reference knowledge graph, in ButterflyKE, we extract directly connected triples to provide a structural view of how knowledge propagates after editing. We evaluate three main KE approaches: External Memory-based, Global Optimization-based, and Local Modification-based approaches, using the Llama-3.1-8B-Instruct model. Our findings confirm the presence of the Butterfly Effect in KE, with side effects intensifying as the structural connections increase. To measure this impact, we propose the Butterfly Index, a metric to evaluate editing methods and their influence on surrounding knowledge. ButterflyKE serves as a practical method for extending existing benchmarks and supports a deeper analysis of knowledge integrity in LLM."},{id:"P32",title:"From Culture to Core: Integrating Cultural Heritage Data into Cross-Domain Research Infrastructures",authors:"Tabea Tietz, Linnaea S\xf6hn, Oleksandra Bruns, Joerg Waitelonis, Etienne Posthumus, Jonatan Jalle Steller, Torsten Schrade and Harald Sack",abstract:"Within the National Research Data Infrastructure (NFDI) in Germany, the NFDI4Culture consortium addresses a critical challenge: unifying access to fragmented and semantically heterogeneous cultural heritage (CH) research data scattered across institutions and disciplines. This work presents the NFDI4Culture Ontology (CTO), a strategically designed lightweight, BFO-aligned ontology that successfully bridges the gap to represent CH research resources between specialized domain requirements and interoperability demands across diverse cultural heritage fields including musicology, performing arts, and architecture. CTO extends the established mid-level ontology NFDIcore while maintaining the flexibility essential for capturing domain-specific nuances and is fully integrated into productive research data infrastructures. This contribution demonstrates how domain-specific ontologies can support both highly specialized research needs and broader cross-domain interoperability through modular architecture, and provides insights into proven modeling strategies, integration workflows, and lessons learned from a productive system in the CH domain."},{id:"P33",title:"Comparing Methods for Competency Question Elicitation from Ontology Requirements",authors:"Reham Alharbi, Jacopo de Berardinis, Terry Payne and Valentina Tamma",abstract:"Competency Questions (CQs) are used guide ontology development, yet formulating them in such a was as to align them to the stakeholder needs remains challenging. This paper presents a comparative analysis of three CQ elicitation methods: manual authoring by ontology engineers, template-based instantiation, and automated generation using LLMs (GPT-4.1, Gemini 2.5). Each CQ is evaluated across dimensions of suitability, readability, and complexity. To facilitate this evaluation we introduce AskCQ, a dataset of 204 CQs derived from a shared user story in the cultural heritage domain. Our results show that manually authored CQs are consistently more acceptable, readable, and concise. LLM-generated CQs are more complex and diverse but require refinement. These findings highlight the importance of human expertise and suggest potential hybrid approaches."},{id:"P34",title:"CogNet3: Fusing Dynamic Emotional Knowledge of Personality Homophilous Groups in Real-World Events into Multi-Source Knowledge Graph",authors:"Tong Zhou, Yubo Chen, Kang Liu and Jun Zhao",abstract:"In this paper, we present CogNet3, an extension of the CogNet2 knowledge base, which combines the dynamic emotional knowledge of personality groups towards significant events from real word data on Reddit. It aims to structurally model and correlate the subjective emotional knowledge embedded in events. To model the dynamic and complex multi-dimensional emotional information of different types of people towards complex events, we construct three frames, namely Semantic Event, Homophilous Group, and Group Emotion, which are respectively used to model hierarchical organizational events with emotional information, user groups with representative differences in personality attributes, and the multi-dimensional dynamic emotional distribution between user groups and events. To expand the knowledge scale and enhance scalability, we design a LLM information extraction framework with self-verification capabilities for the automated extraction of subjective knowledge information. As a result, in comparison with CogNet2, CogNet3 increases 462,381 new event instance with emotion association, 21,870 different homophilous groups and up to 4,556,057 emotion distribution instances."}],on=[{id:"D1",title:"Introducing GPTKB to the Semantic Web",authors:"Yujia Hu, Tuan-Phong Nguyen, Shrestha Ghosh, Moritz M\xfcller and Simon Razniewski",abstract:"Knowledge bases (KBs) are a cornerstone of the Semantic Web, yet they still struggle with scale and scope, and their construction and curation still involve a lot of manual effort. Large language models (LLMs) have recently emerged as powerful tools for a range of tasks, yet their potential for automated KB construction is still poorly understood.  In this demonstrator, we showcase GPTKB, a methodology and KB entirely built from GPT-4.1. GPTKB is constructed by massive-recursive LLM knowledge materialization (Hu et al., 2025), using over 9M API calls for $14,000 to construct a 100M-triple knowledge base with over 6M entities.  Our demonstration focuses on two use cases: (i) Link-based KG exploration and (ii) SPARQL-based analysis and comparison to Wikidata. The GPTKB demonstrator is accessible at https://gptkb.org."},{id:"D2",title:"metis: AI Agent Platform for Human-AI Interaction with Knowledge Graphs",authors:"Linn Aung, Aaron Eberhart, Peter Haase, Nicolas Heist, Liubov Kovriguina, David Lamprecht and Nazanin Mashhaditafreshi",abstract:"We present metis, an AI agent platform, that assists users with semantic modeling, search, and discovery across knowledge graphs. It combines the conversational capabilities of Large Language Models (LLMs) with the precision of semantic knowledge graphs, integrating seamlessly with the functionalities of the metaphactory platform, such as semantic search and visualization. metis delivers AI agents that provide generative power, semantic precision & contextual, explainable insights."},{id:"D3",title:"LifeGraph 5: A SPARQL-ing User Interface for Advanced Multimodal Lifelog Querying",authors:"Florian Ruosch and Luca Rossetto",abstract:"Lifelogging, the practice of recording parts of the subjective daily life, generates rich, multimodal data, but poses significant challenges for efficient retrieval. Building upon the LifeGraph series of knowledge graph-based lifelog retrieval systems, this paper presents the fifth iteration, which introduces a novel user interface to facilitate intuitive and powerful querying of lifelogs from multimodal knowledge graphs. We showcase how this frontend, powered by our custom MediaGraph store MeGraS, seamlessly exposes and leverages SPARQL capabilities. Through interactive demonstration scenarios, we illustrate how users can easily construct complex and expressive queries that also include advanced features such as similarity-based search, near-duplicate detection, and dynamic content extraction, all the while using native SPARQL syntax. This work highlights LifeGraph 5's user-centric design and MeGraS's role in bridging gaps between complex knowledge graph operations and accessible multimodal lifelog exploration."},{id:"D4",title:"Towards Reliable Compositional Behavior in QALD Systems",authors:"David Maria Schmidt, Raoul Schubert and Philipp Cimiano",abstract:'Accompanying the Research Track paper "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", we investigate how compositionality is approached in our compositional question answering over linked data (QALD) pipeline "NeoDUDES". This way, we point out how some of the limitations of large language models (LLMs) w.r.t. compositional interpretation of QALD questions can be dealt with by combining LLMs with symbolic methods. In our demo, we show detailed intermediate results from the NeoDUDES pipeline, underlining how the strengths of neural and symbolic approaches can be combined in a fine-grained, compositional pipeline to tackle compositional tasks in a more reliable fashion.'},{id:"D5",title:"Demonstrating MinMod: A Large-scale Knowledge Graph of Historical Mining Data",authors:"Craig Knoblock, Binh Vu, Basel Shbita, Pothula Punith Krishna and Namrata Sharma",abstract:"We demonstrate MinMod, one of the largest knowledge graphs of historical mining data. MinMod is built using scalable machine learning methods to extract hundreds of thousands of records from mining reports, databases, and tables in articles and to normalize and integrate the results into a unified knowledge graph. MinMod also provides tools that enable end-users to explore, curate, and leverage the data to support the prediction of new sources of critical minerals. In this demo, we walk through the process of data extraction and integration into MinMod, demonstrate data exploration and curation, and showcase tools such as the Grade & Tonnage model that assist scientists in mineral assessments."},{id:"D6",title:"CHeCLOUD\u2014the Cultural Heritage Linked Open Data Cloud",authors:"Gabriele Tuozzo, Maria Angela Pellegrino and Antonio Lieto",abstract:"Cultural Heritage (CH) data have become increasingly prominent within the Semantic Web, yet dataset discoverability remains limited due to fragmentation across platforms and lack of a standard platform to give visibility to published data. This demo paper presents the main features of CHeCLOUD (Cultural Heritage Linked Open Data Cloud): the first domain-specific subcloud of the Linked Open Data Cloud specifically devoted to aggregate and enhance access to Knowledge Graphs (KGs) and ontologies related to CH. CHeCLOUD provides a centralized catalog of 192 curated CH KGs and ontologies and compute a FAIR score for each of them, relying on a automatic and periodic assessment of KGHeartBeat. CHeCLOUD currently offers RESTful APIs, metadata browsing, and interactive graph visualizations to support FAIR evaluation. Additionally, CHeCLOUD features a semi-automated submission pipeline that engages users and maintainers through GitHub-based workflows. CHeCLOUD aims to foster reuse, interoperability, and findability within the CH community, while offering a reusable infrastructure to support similar thematic hubs across other domains.  CHeCLOUD URL: http://isislab.it:12280/CHe-cloud/ Demo video: https://shorturl.at/6o0EZ GitHub repository: https://github.com/GabrieleT0/CHe-CLOUD CHeCLOUD REST APIs: https://github.com/GabrieleT0/CHe-CLOUD/tree/main/WebApp"},{id:"D7",title:"It's About Time: Time Functions for Comparing Partial and Floating Time Literals in SPARQL",authors:"Ieben Smessaert, Juli\xe1n Rojas and Pieter Colpaert",abstract:"Working with temporal data on the Semantic Web remains challenging due to SPARQL\u2019s limited support for comparing time literals of different data types and handling floating times without explicit time zones. These issues are especially problematic when dealing with partial time literals (such as xsd:date, xsd:gYearMonth, or xsd:gYear) and floating times, both of which are common in real-world knowledge graphs like Wikidata. To showcase the relevance and urgency of the problem, we gathered and reviewed existing discussions, specifications, draft proposals, and examples from deployed knowledge graphs, providing a consolidated starting point for further community dialogue. We then proposed a solution in the form of a set of SPARQL extension functions\u2014Time Functions\u2014designed to reinterpret time literals as time intervals, enabling consistent and type-agnostic temporal comparisons. These functions are formally described using the Function Ontology (FnO), and implemented in the Comunica query engine, with a publicly available demo application that allows users to interactively explore and test the functions. The demo includes curated example queries that highlight both the limitations of existing SPARQL behavior and how the Time Functions enable more accurate filtering and sorting of temporal data. In addition to providing a technical proposal, we advocate for improved temporal data publishing practices, urging data providers to use accurate data types and explicit time zones to support reliable temporal reasoning in the open-world context of RDF."},{id:"D8",title:"Building Questions and Queries Datasets for Knowledge Graphs: a Demo of Q\xb2Forge",authors:"Yousouf Taghzouti, Franck Michel, Tao Jiang, Louis Felix Nothias and Fabien Gandon",abstract:"In this paper, we present a demo of how Q\xb2Forge addresses the challenge of generating competency questions and corresponding SPARQL queries for any target Knowledge Graph. It iteratively validates those queries with human feedback and LLM as a judge. Q\xb2Forge is open source, generic, extensible and modular. The demo shows the complete pipeline from competency question formulation to query evaluation, supporting the creation of reference question-query sets."},{id:"D9",title:"Fraw: Sampling-Based Approximate Query Processing for Federations of SPARQL endpoints",authors:"Erwan Boisteau-Desdevises, Thi Hoang Thi Pham, Gabriela Montoya, Brice N\xe9delec, Hala Skaf-Molli and Pascal Molli",abstract:"SPARQL federation engines allow users to query multiple SPARQL endpoints as if all RDF data were available through a single virtual endpoint. However, executing complex SPARQL queries over federations while main- taining fast response times remains a major challenge. In this demonstration, we present Fraw, a SPARQL federation engine that supports sampling-based approximate query processing. This approach is particularly useful in scenarios where response time is essential and approximate results are acceptable. We showcase the effectiveness of our engine through an interactive SPARQL query autocompletion use case, where users receive timely suggestions during query authoring, despite the complexity of federated querying."},{id:"D10",title:"Continuation Queries: Embracing Timeouts on Public SPARQL Endpoints",authors:"Thi Hoang Thi Pham, Gabriela Montoya, Brice N\xe9delec, Hala Skaf-Molli and Pascal Molli",abstract:"Public SPARQL endpoints, such as Wikidata, provide essential access points to large-scale knowledge graphs. However, they often suffer from strict timeouts that prevent the retrieval of complete query results. This demonstration presents the first public deployment of PASSAGE, a SPARQL query engine that guarantees query completeness through continuation queries. Instead of failing upon timeout, PASSAGE returns partial results along with a SPARQL continuation query capable of retrieving the missing results. These continuation queries can be chained iteratively until complete results are obtained. For this demo, attendees can interact with a PASSAGE loaded with 13B triples from Wikidata 2025, and observe in details its operation during their query execution."},{id:"D11",title:"Are those URIs so cool? URI Resolution and Content Negotiation in Ontology Repositories",authors:"Clement Jonquet, Imad Eddine Bourouche and Syphax Bouazzouni",abstract:'The Semantic Web relies on persistent, resolvable, and negotiable URIs. However, many ontology URIs fail to meet these expectations, whether for identifying the ontologies themselves or the entities they contain. This paper presents an analysis of more than 1900 URIs from two major ontology repositories (aka. Semantic Artefact Catalogues) \u2013AgroPortal and BioPortal\u2014 revealing that 54% of ontology URIs are not resolvable and that 92% do not support HTTP content negotiation. In response, we introduce a suite of tools and infrastructure enhancements developed within AgroPortal to diagnose and address URI management challenges at no cost for ontology developers and end users. Our approach offers a standalone diagnostic tool, the generation of "twin URIs" that support resolution and negotiation, and mechanisms to enable HTTP redirection. This system applies both to ontology URIs and to content URIs within ontologies. For the latter, our infrastructure returns \u2013in four syntaxes\u2014 only the RDF statements directly related to the resource in question, not the complete source file. We demonstrate the entire system through the AgroPortal web interface and services (http://agroportal.lirmm.fr).'},{id:"D12",title:"GenKD: Generative Knowledge Discovery through Knowledge Graphs and Large Language Models",authors:"Fouad Zablith, Shadi Youssef and Mathieu D'Aquin",abstract:"With the continuous growth of data published on the web, knowledge discovery is getting increasingly challenging. This challenge is mainly driven by the knowledge discovery process that often requires the continuous aggregation and exploration of questions and patterns that span local and external knowledge sources. This work investigates the facilitation of knowledge discovery over distributed sources of knowledge on the web. We present GenKD, a Generative Knowledge Discovery framework that leverages the semantic interconnectedness of knowledge graphs, and the generative capabilities of Large Language Models (LLMs). GenKD enables, through a user-AI collaborative process, the automatic generation of relevant questions, executable queries, and visualizations to uncover patterns from local and external knowledge graph sources. We demonstrate the feasibility of the proposed framework through a case study in the context of bee colonies and stressors."},{id:"D13",title:"DBLPLink 2.0 - An Entity Linker for the DBLP Scholarly Knowledge Graph",authors:"Debayan Banerjee, Tilahun Taffa and Ricardo Usbeck",abstract:'In this work we present an entity linker for DBLP\'s 2025 version of RDF-based Knowledge Graph. Compared to the 2022 version, DBLP now considers publication venues as a new entity type called dblp:Stream. In the earlier version of DBLPLink, we trained KG-embeddings and re-rankers on a dataset to produce entity linkings. In contrast, in this work, we develop a zero-shot entity linker using LLMs using a novel method, where we re-rank candidate entities based on the log-probabilities of the "yes" token output at the penultimate layer of the LLM.'},{id:"D14",title:"TIB AIssistant: a Platform for AI-Supported Research Across Research Life Cycles",authors:"Allard Oelen and S\xf6ren Auer",abstract:"The rapidly growing popularity of adopting Artificial Intelligence (AI), and specifically Large Language Models (LLMs), is having a widespread impact throughout society, including the academic domain. AI-supported research has the potential to support researchers with tasks across the entire research life cycle. In this work, we demonstrate the TIB AIssistant, an AI-supported research platform providing support throughout the research life cycle. The AIssistant consists of a collection of assistants, each responsible for a specific research task. In addition, tools are provided to give access to external scholarly services. Generated data is stored in the assets and can be exported as an RO-Crate bundle to provide transparency and enhance reproducibility of the research project. We demonstrate the AIssistant's main functionalities by means of a sequential walk-through of assistants, interacting with each other to generate sections for a draft research paper. In the end, with the AIssistant, we lay the foundation for a larger agenda of providing a community-maintained platform for AI-supported research."},{id:"D15",title:"Interactive Analysis of Knowledge Graph Validation Results with the SHACL Dashboard",authors:"Johannes M\xe4kelburg, Zenon Zacouris, Jin Ke and Maribel Acosta",abstract:"Validating knowledge graphs (KGs) ensures their quality and reliability in real-world applications. The Shapes Constraint Language (SHACL) has emerged as a recommended standard for validating RDF KGs, by defining structured constraints. Many organizations leverage SHACL validation and its reports to detect problems, guide corrections, and improve data quality. Yet, large-scale KGs often produce extensive validation reports, making manual analysis infeasible. To address this challenge, we present SHACL Dashboard, a novel online tool for visualization and multidimensional analysis of SHACL validation reports. It provides an interactive user interface featuring detailed violation summaries, analytical plots, and fine-grained insights into individual constraints. These functionalities enable users to efficiently understand validation results, identify problematic areas, and take precise corrective actions on their data. A demo version of the SHACL Dashboard is available online at https://purl.org/shacl-dashboard."},{id:"D16",title:"ASK-DBLP: Answering Questions over DBLP",authors:"Tilahun Abedissa Taffa, Patrick Neises, Stefan Ollinger, Patrick Westphal, Marcel R. Ackermann, Debayan Banerjee and Ricardo Usbeck",abstract:"The scholarly knowledge graph (KG) - DBLP is currently serving as a source of structured information for the computer science community. Like most KGs, DBLP provides users with a SPARQL endpoint interface, which enables users to write a SPARQL query. However, not every user is familiar with the SPARQL syntax and the KG schema. Also, the publicly available KG question answering systems over DBLP are not robust enough to reflect the newest changes in the dblp schema. Hence, we propose ASK-DBLP, which allows users to write natural language questions, converts the question to SPARQL, and provides an answer. In the process, ASK-DBLP advises users to reformulate their questions if the question is not sufficiently clear. Besides, it allows users to select the correct entities among the candidate linked entities and update the generated SPARQL accordingly. The resulting SPARQL query can also be modified by the user. Once editing is done, the query can be evaluated, and the results will be shown. In the meantime, if the user confirms the correctness of the SPARQL and the answer, ASK-DBLP updates the training set for further SPARQL generation improvement. ASK-DBLP achieves a competitive performance over the DBLP-QuAD benchmark. The current deployed version of ASK-DBLP is found at~\\url{https://ask-dblp.nliwod.org}."},{id:"D17",title:"An AI Pipeline for Scientific Literacy and Discovery: a Demonstration of Perspicacit\xe9-AI integration with Knowledge Graphs",authors:"Lucas Pradi, Tao Jiang, Matthieu Feraud, Madina Bekbergenova, Yousouf Taghzouti and Louis Felix Nothias",abstract:"Keeping up with the rapid pace of publishing is becoming an increasingly challenging task. Moreover, the interdisciplinary nature of research poses significant challenges for both students and academics. In this demo, we present Perspicacit\xe9-AI Expanded Pipeline: an agentic workflow powered by LLMs that leverages bibliographic knowledge graphs, local and web-based scientific literature searches. The demo highlights how this approach lowers the entry barrier for new researchers and eliminates manual curation of reference lists. The end result is high-quality reports with citations tailored to users' inquiries."},{id:"D18",title:"Towards a novel interface for cinematographic places",authors:"Andrea Nasi, Diego Magro and Vincenzo Lombardo",abstract:"Archives and commercial platforms usually present films as bibliographic resources, with basic attributes such as director, actors, year of production, and language. The film story is often limitedly represented through a synopsis or a short summary of the plot. Our project focuses on a relevant though neglected element of the story: the film places, intended as the narrative places, i.e. the places where the events of the narrative occur, and the displayed locations, i.e. the places that represent the narrative places in the film. The real-world counterparts of film places, once represented in film archives and commercial platforms, could have an impact on practical activities, such as location management, film tourism, the history of urbanism, and cultural archives. This paper presents the demo of the RevIS (Revisualising Italian Silentscapes, 1896-1922) project, for the exploration of the cinematic productions of Italian silent cinema of the early twentieth century. Digital maps display a parallel view of film narrative places and displayed locations, while users can browse the film sequences and access the individual scenes. The dual-map metaphor allows for fleshing out the connection between the plot sequences and the places and relies upon an ontology-based metadata model we have devised for the digital archive of films and places. We also report on a preliminary evaluation of the demo interface, with promising results and expected criticisms."},{id:"D19",title:"GRASP: Generic Reasoning And SPARQL Generation across Knowledge Graphs - Demo System",authors:"Sebastian Walter and Hannah Bast",abstract:"GRASP is the first zero-shot approach for SPARQL-based question answering that, in principle, works for arbitrary given RDF knowledge graphs. In this work, we present and describe a prototypical demo system that implements the GRASP approach. The system also supports general question answering and follow-up questions. We also provide additional evaluations on the IMDb knowledge graph and the TEXT2SPARQL challenge."},{id:"D20",title:"LLMDapCat: An LLM-based Data Catalogue System for Data Sharing and Exploration",authors:"Shang Ferheng Karim, Aisha Kelifa, Amanda Marie Hols\xe6ter Kj\xe6r, Shanshan Jiang, Sondre S\xf8rb\xf8 and Dumitru Roman",abstract:"Good data catalogues are essential for effective data sharing and discovery to cope with the rapid expansion of datasets and scientific literature available on the Web. In this paper, we present LLMDapCAT, an LLM-based metadata and data catalogue system that exploits Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) for efficient data profiling, sharing, and exploration. We demonstrate how the system serves both data providers and consumers: on the one hand, it allows providers to automatically generate standardized and semantically accurate metadata from scientific papers using an LLM and RAG-based pipeline, and to publish them in the catalogue system; on the other hand, it enables consumers to browse available datasets and explore them in chat-like Q&A sessions using an external LLM service. The system can be applied to curate custom domain-specific scientific databases that facilitate search, understanding, and exploration of domain-specific datasets."},{id:"D21",title:"Towards Queryable Verifiable Credentials",authors:"Gertjan De Mulder, Ruben Dedecker, Ben De Meester and Pieter Colpaert",abstract:"With initiatives like the European Digital Identity Wallet, the exchange of verifiable data via digital credentials using digital wallets is reaching mainstream adoption. As digital wallets gain adoption and the ecosystem grows, the current limits to query verifiable data from them in terms of flexibility and interoperability surface: digital credentials can only be directly queried based on JSON keys, thus hampering support for internationalization and alternative semantics. With this work, we present a practical approach to leverage Semantic Web technologies to combine the expressiveness of RDF with the semantic nature of W3C\u2019s recommended Verifiable Credentials and existing wallet protocols like OID4VP. We enable using SPARQL queries to request specific claims within the OID4VP protocol, which are evaluated over the combined RDF representation of the wallet credentials, to return Verifiable Presentations that contain the requested claims using selective disclosure. We applied named graphs with blank node graph names to ensure a uniform and globally unique connection between credential claims and their credential and proof graphs when storing credentials in a wallet Knowledge Graph. To retrieve which claims need to be selectively disclosed from their original credentials, we applied an initial conversion from RDF triple predicates to JSONPath pointers, thus currently supporting only a subset of SPARQL expressivity. Through the addition of a SPARQL query in the OID4VP authorization flow, we enable semantically enriched query evaluation over the stored credentials, opening the way to semantic alignment of multilingual vocabularies and similar ontologies used in different online ecosystems. Future work is needed to improve SPARQL support to query over complex claim requirements, both for mapping the query to JSONPath pointers, and for addressing metadata requirements for requested claims."},{id:"D22",title:"Decentralized based Generative AI Framework with Solid",authors:"Ahmad Cahyono Adi, Dhea Anggita and Kabul Kurniawan",abstract:"Generative AI (GenAI) application becomes increasingly an integral part of daily life, accelerating tasks and enhancing human productivity. As these Large Language Models (LLMs) platforms grow more personalized by learning from increasingly large volume of user (personal) data, it raises significant privacy, trust, and data ownership concerns. Current LLMs applications typically require users to store their personal data centrally on their own propiertary architecture, leading to fragmented user\u2019s data and siloed accross individual platforms. This not only making it difficult to transfer user\u2019s preferences or conversation histories to other GenAI platforms of their choice, but also limits their ability to switch across different GenAI platforms due to their monolitic design. To address these challenges, we propose a decentralized GenAI architecture that provide users full control over their data and privacy through Solid, a standardized interoperable personal data storage framework. We demonstrate a prototype system that integrate multiple LLMs within a single framework without requiring users to centrally store their personal data. We evaluate the system along three dimensions: retrieval-augmented generation (RAG)-based answer quality, multi-turn conversation coherence and qualitative LLMs comparison. Evaluation results show that the framework maintains high-quality responses and coherent conversations, while enabling flexible, cross-model personalization"},{id:"D23",title:"LOAMA: Low-code ODRL Access Management Application",authors:"Wout Slabbinck, Lennert De Rouck, Joachim Van Herwegen, Wouter Termont, Beatriz Esteves and Ruben Verborgh",abstract:"State of the art authorization mechanisms have so far focused on dealing with data management, while leaving policy management and enforcement as an afterthought. Considering that the latter are of the utmost importance to deal not only with low-level technical requirements, but also crucial to deal with legal or economic requirements, we introduce LOAMA, the Low-code ODRL Access Management Application, which can be used to manage ODRL policies in decentralized settings through an Authorization Server. In this paper, beyond a demonstration of the LOAMA User Interface, we provide a overview of the LOAMA architecture, which is based on the User-Managed Access (UMA) specifications. LOAMA abstracts the complexity of managing policies, by providing a tool that people not familiar with policy languages can use the manage their preferences when it comes to access management. Future works includes the expansion of the LOAMA UI to support further ODRL constraints, e.g., to express purpose-based or temporal usage control policies."},{id:"D24",title:"SynSem-Align (Demo): Ontology-Driven KG Extraction via Syntactic Candidate Mining and Paraphrase-Based Equivalence Filtering",authors:"Rikuto Sasaki, Masahito Yasui and Kazuhiro Takeuchi",abstract:"While Large Language Models (LLMs) are powerful for information extraction, the reliability of their output remains a challenge, making human supervision essential. We introduce SynSem-Align, a support tool where LLMs and humans collaborate on knowledge extraction. Our approach integrates three core components: (1) Ontology-Driven filtering to suggest relevant extraction patterns, (2) Syntactic Candidate Mining to precisely identify knowledge candidates using a CKY-based approach over dependency structures, and (3) Paraphrase-Based Equivalence Filtering using an LLM for semantic validation. This integrated workflow enables users to transparently and reliably construct knowledge graphs, demonstrating a practical path towards verifiable knowledge extraction that balances automation with human oversight."}],ln=()=>{const[e,t]=(0,n.useState)([]),a=((0,n.useRef)([]),e=>{t((t=>t.includes(e)?t.filter((t=>t!==e)):[...t,e]))});return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)("div",{className:"mt-[74px] px-4 pt-2 bg-white flex items-center justify-center"}),(0,r.jsx)("br",{}),(0,r.jsxs)("div",{className:"flex flex-col pt-10 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:px-32 px-8 overflow-visible",children:[(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Doctoral Consortium"}),(0,r.jsx)("div",{className:"mb-6",children:(0,r.jsxs)("table",{className:"border-collapse text-left text-sm lg:text-base table-fixed grid-no-grow",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-3/4",children:"Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-1/4",children:"Authors"})]})}),(0,r.jsx)("tbody",{children:en.map(((t,n)=>(0,r.jsxs)("tr",{className:"border-b align-top",children:[(0,r.jsx)("td",{className:"p-4 border border-gray-200 font-semibold text-[#e94607] cursor-pointer hover:underline align-top",onClick:()=>a(`dc-${n}`),children:(0,r.jsxs)("div",{className:"flex items-start gap-2",children:[(0,r.jsx)("span",{className:"inline-block transform transition-transform "+(e.includes(`dc-${n}`)?"rotate-90":"rotate-0"),children:"\u25b6"}),(0,r.jsxs)("div",{className:"flex-1",children:[t.title,e.includes(`dc-${n}`)&&(0,r.jsx)("div",{className:"mt-2 text-gray-800 text-sm whitespace-pre-line",children:t.abstract})]})]})}),(0,r.jsx)("td",{className:"p-4 border border-gray-200 align-top",children:t.authors})]},`dc-${n}`)))})]})})]}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Research Track"}),(0,r.jsx)("div",{className:"mb-6",children:(0,r.jsxs)("table",{className:"border-collapse text-left text-sm lg:text-base table-fixed grid-no-grow",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-3/4",children:"Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-1/4",children:"Authors"})]})}),(0,r.jsx)("tbody",{children:tn.map(((t,n)=>(0,r.jsxs)("tr",{className:"border-b align-top",children:[(0,r.jsx)("td",{className:"p-4 border border-gray-200 font-semibold text-[#e94607] cursor-pointer hover:underline align-top",onClick:()=>a(`research-${n}`),children:(0,r.jsxs)("div",{className:"flex items-start gap-2",children:[(0,r.jsx)("span",{className:"inline-block transform transition-transform "+(e.includes(`research-${n}`)?"rotate-90":"rotate-0"),children:"\u25b6"}),(0,r.jsxs)("div",{className:"flex-1",children:[t.title,e.includes(`research-${n}`)&&(0,r.jsx)("div",{className:"mt-2 text-gray-800 text-sm whitespace-pre-line",children:t.abstract})]})]})}),(0,r.jsx)("td",{className:"p-4 border border-gray-200 align-top",children:t.authors})]},`research-${n}`)))})]})})]}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Resource Track"}),(0,r.jsx)("div",{className:"mb-6",children:(0,r.jsxs)("table",{className:"border-collapse text-left text-sm lg:text-base table-fixed grid-no-grow",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-3/4",children:"Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-1/4",children:"Authors"})]})}),(0,r.jsx)("tbody",{children:an.map(((t,n)=>(0,r.jsxs)("tr",{className:"border-b align-top",children:[(0,r.jsx)("td",{className:"p-4 border border-gray-200 font-semibold text-[#e94607] cursor-pointer hover:underline align-top",onClick:()=>a(`resource-${n}`),children:(0,r.jsxs)("div",{className:"flex items-start gap-2",children:[(0,r.jsx)("span",{className:"inline-block transform transition-transform "+(e.includes(`resource-${n}`)?"rotate-90":"rotate-0"),children:"\u25b6"}),(0,r.jsxs)("div",{className:"flex-1",children:[t.title,e.includes(`resource-${n}`)&&(0,r.jsx)("div",{className:"mt-2 text-gray-800 text-sm whitespace-pre-line",children:t.abstract})]})]})}),(0,r.jsx)("td",{className:"p-4 border border-gray-200 align-top",children:t.authors})]},`resource-${n}`)))})]})})]}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"In-Use Track"}),(0,r.jsx)("div",{className:"mb-6",children:(0,r.jsxs)("table",{className:"border-collapse text-left text-sm lg:text-base table-fixed grid-no-grow",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-3/4",children:"Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-1/4",children:"Authors"})]})}),(0,r.jsx)("tbody",{children:nn.map(((t,n)=>(0,r.jsxs)("tr",{className:"border-b align-top",children:[(0,r.jsx)("td",{className:"p-4 border border-gray-200 font-semibold text-[#e94607] cursor-pointer hover:underline align-top",onClick:()=>a(`inuse-${n}`),children:(0,r.jsxs)("div",{className:"flex items-start gap-2",children:[(0,r.jsx)("span",{className:"inline-block transform transition-transform "+(e.includes(`inuse-${n}`)?"rotate-90":"rotate-0"),children:"\u25b6"}),(0,r.jsxs)("div",{className:"flex-1",children:[t.title,e.includes(`inuse-${n}`)&&(0,r.jsx)("div",{className:"mt-2 text-gray-800 text-sm whitespace-pre-line",children:t.abstract})]})]})}),(0,r.jsx)("td",{className:"p-4 border border-gray-200 align-top",children:t.authors})]},`inuse-${n}`)))})]})})]}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Industry Track"}),(0,r.jsx)("div",{className:"mb-6",children:(0,r.jsxs)("table",{className:"border-collapse text-left text-sm lg:text-base table-fixed grid-no-grow",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-3/4",children:"Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-1/4",children:"Authors"})]})}),(0,r.jsx)("tbody",{children:sn.map(((t,n)=>(0,r.jsxs)("tr",{className:"border-b align-top",children:[(0,r.jsx)("td",{className:"p-4 border border-gray-200 font-semibold text-[#e94607] cursor-pointer hover:underline align-top",onClick:()=>a(`industry-${n}`),children:(0,r.jsxs)("div",{className:"flex items-start gap-2",children:[(0,r.jsx)("span",{className:"inline-block transform transition-transform "+(e.includes(`industry-${n}`)?"rotate-90":"rotate-0"),children:"\u25b6"}),(0,r.jsxs)("div",{className:"flex-1",children:[t.title,e.includes(`industry-${n}`)&&(0,r.jsx)("div",{className:"mt-2 text-gray-800 text-sm whitespace-pre-line",children:t.abstract})]})]})}),(0,r.jsx)("td",{className:"p-4 border border-gray-200 align-top",children:t.authors})]},`industry-${n}`)))})]})})]}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Posters"}),(0,r.jsx)("div",{className:"mb-6",children:(0,r.jsxs)("table",{className:"border-collapse text-left text-sm lg:text-base table-fixed grid-no-grow",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-3/4",children:"Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-1/4",children:"Authors"})]})}),(0,r.jsx)("tbody",{children:rn.map(((t,n)=>(0,r.jsxs)("tr",{className:"border-b align-top",children:[(0,r.jsx)("td",{className:"p-4 border border-gray-200 font-semibold text-[#e94607] cursor-pointer hover:underline align-top",onClick:()=>a(`poster-${n}`),children:(0,r.jsxs)("div",{className:"flex items-start gap-2",children:[(0,r.jsx)("span",{className:"inline-block transform transition-transform "+(e.includes(`poster-${n}`)?"rotate-90":"rotate-0"),children:"\u25b6"}),(0,r.jsxs)("div",{className:"flex-1",children:[t.id,": ",t.title,e.includes(`poster-${n}`)&&(0,r.jsx)("div",{className:"mt-2 text-gray-800 text-sm whitespace-pre-line",children:t.abstract})]})]})}),(0,r.jsx)("td",{className:"p-4 border border-gray-200 align-top",children:t.authors})]},`poster-${n}`)))})]})})]}),(0,r.jsxs)("div",{className:"flex justify-start items-start flex-col pt-10 pb-0 lg:pt-16 lg:pb-4 mb-4 lg:my-6 lg:h-auto lg:px-32 px-8",children:[(0,r.jsx)("p",{style:{color:"#e94607"},className:"text-3xl font-bold mb-4 lg:mx-10 sm:mx-2 tracking-wide text-center",children:"Demos"}),(0,r.jsx)("div",{className:"mb-6",children:(0,r.jsxs)("table",{className:"border-collapse text-left text-sm lg:text-base table-fixed grid-no-grow",children:[(0,r.jsx)("thead",{children:(0,r.jsxs)("tr",{className:"bg-[#f8f8f8] text-[#e94607] font-bold border-b",children:[(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-3/4",children:"Title"}),(0,r.jsx)("th",{className:"p-4 border border-gray-300 grid-no-grow w-1/4",children:"Authors"})]})}),(0,r.jsx)("tbody",{children:on.map(((t,n)=>(0,r.jsxs)("tr",{className:"border-b align-top",children:[(0,r.jsx)("td",{className:"p-4 border border-gray-200 font-semibold text-[#e94607] cursor-pointer hover:underline align-top",onClick:()=>a(`demo-${n}`),children:(0,r.jsxs)("div",{className:"flex items-start gap-2",children:[(0,r.jsx)("span",{className:"inline-block transform transition-transform "+(e.includes(`demo-${n}`)?"rotate-90":"rotate-0"),children:"\u25b6"}),(0,r.jsxs)("div",{className:"flex-1",children:[t.id,": ",t.title,e.includes(`demo-${n}`)&&(0,r.jsx)("div",{className:"mt-2 text-gray-800 text-sm whitespace-pre-line",children:t.abstract})]})]})}),(0,r.jsx)("td",{className:"p-4 border border-gray-200 align-top",children:t.authors})]},`demo-${n}`)))})]})})]})]})]})};function cn(){return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(Fe,{}),(0,r.jsxs)(Se,{children:[(0,r.jsx)(je,{path:"/",element:(0,r.jsx)(h,{})}),(0,r.jsx)(je,{path:"/about",element:(0,r.jsx)(p,{})}),(0,r.jsx)(je,{path:"/organizing_committee",element:(0,r.jsx)(wt,{})}),(0,r.jsx)(je,{path:"/importantdates",element:(0,r.jsx)(Bt,{})}),(0,r.jsx)(je,{path:"/cfp",element:(0,r.jsx)(jt,{})}),(0,r.jsx)(je,{path:"/calls/research",element:(0,r.jsx)(kt,{})}),(0,r.jsx)(je,{path:"/calls/resource",element:(0,r.jsx)(St,{})}),(0,r.jsx)(je,{path:"/calls/in-use",element:(0,r.jsx)(Nt,{})}),(0,r.jsx)(je,{path:"/calls/journaltrack",element:(0,r.jsx)(Ct,{})}),(0,r.jsx)(je,{path:"/calls/posters",element:(0,r.jsx)(Tt,{})}),(0,r.jsx)(je,{path:"/calls/challenges",element:(0,r.jsx)(At,{})}),(0,r.jsx)(je,{path:"/calls/industry",element:(0,r.jsx)(Lt,{})}),(0,r.jsx)(je,{path:"/calls/doctoral",element:(0,r.jsx)(It,{})}),(0,r.jsx)(je,{path:"/calls/workshops",element:(0,r.jsx)(Ut,{})}),(0,r.jsx)(je,{path:"/calls/tutorials",element:(0,r.jsx)(Jt,{})}),(0,r.jsx)(je,{path:"/calls/dagstuhl",element:(0,r.jsx)(Qt,{})}),(0,r.jsx)(je,{path:"/calls/swsa",element:(0,r.jsx)($a,{})}),(0,r.jsx)(je,{path:"/guidelines/html-submission",element:(0,r.jsx)(Pt,{})}),(0,r.jsx)(je,{path:"/guidelines/review",element:(0,r.jsx)(Et,{})}),(0,r.jsx)(je,{path:"/guidelines/supplemental",element:(0,r.jsx)(Dt,{})}),(0,r.jsx)(je,{path:"/guidelines/resources",element:(0,r.jsx)(Wt,{})}),(0,r.jsx)(je,{path:"/guidelines/prior-publications",element:(0,r.jsx)(Rt,{})}),(0,r.jsx)(je,{path:"/program/acceptedpapers",element:(0,r.jsx)(ln,{})}),(0,r.jsx)(je,{path:"/program/keynotespeakers",element:(0,r.jsx)(Da,{})}),(0,r.jsx)(je,{path:"/program/workshops",element:(0,r.jsx)(qa,{})}),(0,r.jsx)(je,{path:"/program/dagstuhl",element:(0,r.jsx)(_a,{})}),(0,r.jsx)(je,{path:"/program/tutorials",element:(0,r.jsx)(Ha,{})}),(0,r.jsx)(je,{path:"/program/challenges",element:(0,r.jsx)(Ba,{})}),(0,r.jsx)(je,{path:"/program/panel",element:(0,r.jsx)(za,{})}),(0,r.jsx)(je,{path:"/program/awards",element:(0,r.jsx)(Ka,{})}),(0,r.jsx)(je,{path:"/program/schedule",element:(0,r.jsx)(Ja,{})}),(0,r.jsx)(je,{path:"/attending/visa",element:(0,r.jsx)(La,{})}),(0,r.jsx)(je,{path:"/attending/studentgrants",element:(0,r.jsx)(Ia,{})}),(0,r.jsx)(je,{path:"/attending/codeofconduct",element:(0,r.jsx)(Va,{})}),(0,r.jsx)(je,{path:"/atttending/venueandaccomodation",element:(0,r.jsx)(Xa,{})}),(0,r.jsx)(je,{path:"/atttending/registration",element:(0,r.jsx)(Za,{})}),(0,r.jsx)(je,{path:"/blogs/host",element:(0,r.jsx)(Vt,{})}),(0,r.jsx)(je,{path:"/blogs/naturenavigator",element:(0,r.jsx)(ta,{})}),(0,r.jsx)(je,{path:"/blogs/community",element:(0,r.jsx)(Aa,{})}),(0,r.jsx)(je,{path:"/blogs/presentingatiswc",element:(0,r.jsx)(Yt,{})}),(0,r.jsx)(je,{path:"/sponsorship/sponsorshippackages",element:(0,r.jsx)(Mt,{})}),(0,r.jsx)(je,{path:"/sponsorship/sponsors",element:(0,r.jsx)(Ht,{})})]}),(0,r.jsx)(ze,{})]})}const dn=e=>{e&&e instanceof Function&&a.e(453).then(a.bind(a,6453)).then((t=>{let{getCLS:a,getFID:n,getFCP:i,getLCP:s,getTTFB:r}=t;a(e),n(e),i(e),s(e),r(e)}))};s.createRoot(document.getElementById("root")).render((0,r.jsx)(Ee,{children:(0,r.jsx)(cn,{})})),dn()})();
//# sourceMappingURL=main.7ecf5649.js.map